{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoHJGwOTeaJM"
      },
      "source": [
        "# Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU1Gi0sreaJR",
        "outputId": "ba59c73c-6f6a-49bb-afb4-9025b0e96d0e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
        "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InIADi38eaJU"
      },
      "outputs": [],
      "source": [
        "MILVUS_HOST = \"localhost\"\n",
        "MILVUS_PORT = \"19530\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcgLirxUeaJV",
        "outputId": "8a49ea44-47f5-4857-9d21-da7e9adc3fca"
      },
      "outputs": [],
      "source": [
        "from pymilvus import connections, utility, Collection\n",
        "\n",
        "connections.connect(host=\"localhost\", port=\"19530\")\n",
        "collections = utility.list_collections()\n",
        "print(\"Collections trước khi xoá:\", collections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Xoá collection\n",
        "collection_name = \"Vin\"\n",
        "if collection_name in collections:\n",
        "    collection = Collection(collection_name)\n",
        "    collection.drop()\n",
        "    print(f\"Collection '{collection_name}' đã bị xoá.\")\n",
        "else:\n",
        "    print(f\"Collection '{collection_name}' không tồn tại.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTITH3hueaJW"
      },
      "source": [
        "# Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qf48JS_IeaJX",
        "outputId": "7301fbf9-4a3b-425a-8c64-3107f1cfc02e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>link</th>\n",
              "      <th>pdf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Optimizing Remote Communication in X10</td>\n",
              "      <td>None</td>\n",
              "      <td>https://openalex.org/works/W2979877239</td>\n",
              "      <td>https://dl.acm.org/doi/pdf/10.1145/3345558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Solving Program Sketches with Large Integer Va...</td>\n",
              "      <td>None</td>\n",
              "      <td>https://openalex.org/works/W4286273216</td>\n",
              "      <td>https://dl.acm.org/doi/pdf/10.1145/3532849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Conjunctive Regular Path Queries with Capture ...</td>\n",
              "      <td>None</td>\n",
              "      <td>https://openalex.org/works/W4213413132</td>\n",
              "      <td>https://dl.acm.org/doi/pdf/10.1145/3514230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Remote Electronic Voting in Uncontrolled Envir...</td>\n",
              "      <td>None</td>\n",
              "      <td>https://openalex.org/works/W4288050909</td>\n",
              "      <td>https://dl.acm.org/doi/pdf/10.1145/3551386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A Case for Fine-grain Coherence Specialization...</td>\n",
              "      <td>None</td>\n",
              "      <td>https://openalex.org/works/W3157813827</td>\n",
              "      <td>https://dl.acm.org/doi/pdf/10.1145/3530819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  text  \\\n",
              "0             Optimizing Remote Communication in X10  None   \n",
              "1  Solving Program Sketches with Large Integer Va...  None   \n",
              "2  Conjunctive Regular Path Queries with Capture ...  None   \n",
              "3  Remote Electronic Voting in Uncontrolled Envir...  None   \n",
              "4  A Case for Fine-grain Coherence Specialization...  None   \n",
              "\n",
              "                                     link  \\\n",
              "0  https://openalex.org/works/W2979877239   \n",
              "1  https://openalex.org/works/W4286273216   \n",
              "2  https://openalex.org/works/W4213413132   \n",
              "3  https://openalex.org/works/W4288050909   \n",
              "4  https://openalex.org/works/W3157813827   \n",
              "\n",
              "                                          pdf  \n",
              "0  https://dl.acm.org/doi/pdf/10.1145/3345558  \n",
              "1  https://dl.acm.org/doi/pdf/10.1145/3532849  \n",
              "2  https://dl.acm.org/doi/pdf/10.1145/3514230  \n",
              "3  https://dl.acm.org/doi/pdf/10.1145/3551386  \n",
              "4  https://dl.acm.org/doi/pdf/10.1145/3530819  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "with open('/workspace/vinhnq/RAG_bot/Data/dataset.json', 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "data_list = [\n",
        "    {\n",
        "        \"title\": item.get(\"title\", \"\"),\n",
        "        \"text\": item.get(\"text\", \"\"),\n",
        "        \"link\": item.get(\"link\", \"\"),\n",
        "        \"pdf\": item.get(\"pdf\", \"\")\n",
        "    }\n",
        "    for item in data\n",
        "]\n",
        "\n",
        "# Chuyển list dữ liệu sang DataFrame của pandas với các cột cụ thể\n",
        "df = pd.DataFrame(data_list, columns=[\"title\", \"text\", \"link\", \"pdf\"])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w0V4k0aIeaJY",
        "outputId": "6676798c-5032-4f48-d8be-8f33545121cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>link</th>\n",
              "      <th>pdf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Preface: Selected Extended Papers from Interac...</td>\n",
              "      <td>[Journal of Automated Reasoning (2020) 64:793–...</td>\n",
              "      <td>https://openalex.org/works/W3027986581</td>\n",
              "      <td>https://link.springer.com/content/pdf/10.1007/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>A Safe Computational Framework for Integer Pro...</td>\n",
              "      <td>[arXiv:1809.01572v2  [math.CO]  21 Sep 2020A S...</td>\n",
              "      <td>https://openalex.org/works/W3211222374</td>\n",
              "      <td>http://arxiv.org/pdf/1809.01572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>A Posthumous Contribution by Larry Wos: Excerp...</td>\n",
              "      <td>[Journal of Automated Reasoning (2022) 66:575–...</td>\n",
              "      <td>https://openalex.org/works/W4210619513</td>\n",
              "      <td>https://link.springer.com/content/pdf/10.1007/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Importance Sampling for a Simple Markovian Int...</td>\n",
              "      <td>[arXiv:1610.06501v2  [math.PR]  1 Dec 2021Impo...</td>\n",
              "      <td>https://openalex.org/works/W3215346238</td>\n",
              "      <td>http://arxiv.org/pdf/1610.06501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>A Population's Feasible Posterior Beliefs</td>\n",
              "      <td>[arXiv:2202.01846v1  [cs.GT]  3 Feb 2022A Popu...</td>\n",
              "      <td>https://openalex.org/works/W4226521955</td>\n",
              "      <td>http://arxiv.org/pdf/2202.01846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                title  \\\n",
              "39  Preface: Selected Extended Papers from Interac...   \n",
              "40  A Safe Computational Framework for Integer Pro...   \n",
              "56  A Posthumous Contribution by Larry Wos: Excerp...   \n",
              "69  Importance Sampling for a Simple Markovian Int...   \n",
              "76          A Population's Feasible Posterior Beliefs   \n",
              "\n",
              "                                                 text  \\\n",
              "39  [Journal of Automated Reasoning (2020) 64:793–...   \n",
              "40  [arXiv:1809.01572v2  [math.CO]  21 Sep 2020A S...   \n",
              "56  [Journal of Automated Reasoning (2022) 66:575–...   \n",
              "69  [arXiv:1610.06501v2  [math.PR]  1 Dec 2021Impo...   \n",
              "76  [arXiv:2202.01846v1  [cs.GT]  3 Feb 2022A Popu...   \n",
              "\n",
              "                                      link  \\\n",
              "39  https://openalex.org/works/W3027986581   \n",
              "40  https://openalex.org/works/W3211222374   \n",
              "56  https://openalex.org/works/W4210619513   \n",
              "69  https://openalex.org/works/W3215346238   \n",
              "76  https://openalex.org/works/W4226521955   \n",
              "\n",
              "                                                  pdf  \n",
              "39  https://link.springer.com/content/pdf/10.1007/...  \n",
              "40                    http://arxiv.org/pdf/1809.01572  \n",
              "56  https://link.springer.com/content/pdf/10.1007/...  \n",
              "69                    http://arxiv.org/pdf/1610.06501  \n",
              "76                    http://arxiv.org/pdf/2202.01846  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1 = df.copy()\n",
        "# Lọc null với lặp\n",
        "df1 = df1.dropna(subset=['text'])\n",
        "df1 = df1.drop_duplicates(subset=[\"pdf\"])\n",
        "\n",
        "df1.head()      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2euv3175eaJZ",
        "outputId": "7ac91d21-31af-431f-b43f-e873adfac21f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of paper: 922\n",
            "Number of documents: 28662\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "# Chuyển sang dạng Document để dùng langchain\n",
        "documents = []\n",
        "for _, row in df1.iterrows():\n",
        "    for t in row['text']:\n",
        "        document = Document(\n",
        "            page_content=t,\n",
        "            metadata={\n",
        "                \"pdf\": row['pdf'],\n",
        "                \"link\": row['link'],\n",
        "                \"title\": row['title']\n",
        "            }\n",
        "        )\n",
        "        documents.append(document)\n",
        "\n",
        "print(f\"Number of paper: {len(df1)}\")\n",
        "print(f\"Number of documents: {len(documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_dU61b-6eaJZ",
        "outputId": "5de2f188-dda8-4c92-c09c-75e96cf6b1d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of chunk: 113383\n"
          ]
        }
      ],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50)\n",
        "\n",
        "splits = text_splitter.split_documents(documents)\n",
        "print(f\"Number of chunk: {len(splits)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzQSldcbeaJa"
      },
      "source": [
        "# MAINMAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfPhT4ofeaJa",
        "outputId": "060a7080-1fa2-4aad-95f3-b24c807c6a86"
      },
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "# Load model embedding\n",
        "model_name = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
        "model_kwargs = {'device': 'cuda', 'trust_remote_code': True}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "cache_folder = \"/workspace/vinhnq/cache_weights\"\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs,\n",
        "    cache_folder=cache_folder\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMnZoEdheaJb"
      },
      "outputs": [],
      "source": [
        "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection\n",
        "\n",
        "connections.connect(host='localhost', port='19530')\n",
        "# Tạo collection với pk, text, vector\n",
        "# là định dạng ban đầu khi dùng Milvus.from_documents\n",
        "# muốn đổi tên có thể đổi tham số đọc ở đây\n",
        "# https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.milvus.Milvus.html\n",
        "fields = [\n",
        "    FieldSchema(name='pk', dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
        "    FieldSchema(name='text', dtype=DataType.VARCHAR, max_length=2048),\n",
        "    FieldSchema(name='vector', dtype=DataType.FLOAT_VECTOR, dim=1024)\n",
        "]\n",
        "schema = CollectionSchema(fields, description=\"Document collection\")\n",
        "collection_name = \"Vin\"\n",
        "collection = Collection(name=collection_name, schema=schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSYlkmEEeaJc"
      },
      "outputs": [],
      "source": [
        "# Tạo loại tìm kiếm cho vector\n",
        "index_params = {\n",
        "    'metric_type':'COSINE',\n",
        "    'index_type':\"IVF_FLAT\",\n",
        "    'params':{'nlist': 1024}\n",
        "}\n",
        "collection.create_index(field_name=\"vector\", index_params=index_params)\n",
        "collection.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCGenV6IeaJc",
        "outputId": "b4868f9f-e2f8-448d-da00-28000040f04a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Journal of Automated Reasoning (2020) 64:793–794\\nhttps://doi.org/10.1007/s10817-020-09557-w\\nPreface: Selected Extended Papers from Interactive Theorem\\nProving 2018\\nJeremy Avigad1·Assia Mahboubi2,3\\nReceived: 15 April 2020 / Accepted: 24 April 2020 / Published online: 22 May 2020\\n© Springer Nature B.V. 2020\\nThe Ninth International Conference on Interactive Theorem Proving (ITP) w a sh e l do nJ u l y\\n9–12, 2018, in Oxford, UK, as part of the Federated Logic Conference . This special issue\\nof the Journal of Automated Reasoning contains expanded versions of six papers from that\\nconference, chosen by the program committee. All the papers chosen were rated highly inthe usual conference review process, but that was not the sole criteria for inclusion. We alsolooked for work that would beneﬁt from a more expanded, mature treatment, and we aimedfor a representative sample of topics.\\nThe expanded versions were reviewed according to the usual standards of this journal.\\nOf the six, two belong to the realm of formalized mathematics and veriﬁed mathematicalcomputation:\\nChristian Doczkal and Damien Pous, “Graph Theory in Coq: Minors, Treewidth, and', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09557-w.pdf', 'link': 'https://openalex.org/works/W3027986581', 'title': 'Preface: Selected Extended Papers from Interactive Theorem Proving 2018'}),\n",
              " Document(page_content='Christian Doczkal and Damien Pous, “Graph Theory in Coq: Minors, Treewidth, and\\nIsomorphisms”\\nRené Thiemann, Ralph Bottesch, Jose Divasón, Max W. Haslbeck, Sebastiaan J. C.\\nJoosten and Akihisa Yamada, “Formalization the LLL Basis Reduction Algorithm andthe LLL Factorization Algorithm in Isabelle/HOL”\\nThe ﬁrst describes a formal library for graph theory and some important results in that ﬁeld,\\nwhereas the second deals with the Lenstra–Lenstra–Lovász lattice basis reduction algorithm,an important algorithm in algebra and number theory. Three of the papers belong to the realmof hardware and software veriﬁcation:\\nMatthew L. Daggitt, Ran Zmigrod and Timothy G. Grifﬁn, “A Relaxation of Üresin &\\nDubois Asynchronous Fixed-Point Theory in Agda”\\nB Jeremy Avigad\\navigad@cmu.edu\\nAssia Mahboubi\\nassia.mahboubi@inria.fr\\n1Department of Philosophy, Carnegie Mellon University, Pittsburgh, PA 15213, USA', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09557-w.pdf', 'link': 'https://openalex.org/works/W3027986581', 'title': 'Preface: Selected Extended Papers from Interactive Theorem Proving 2018'}),\n",
              " Document(page_content='avigad@cmu.edu\\nAssia Mahboubi\\nassia.mahboubi@inria.fr\\n1Department of Philosophy, Carnegie Mellon University, Pittsburgh, PA 15213, USA\\n2Inria, LS2N, UFR Sciences et Techniques, 2, rue de la Houssinière, BP 92208, 44322 Nantes Cedex3, France\\n3Vrije Universiteit Amsterdam, Amsterdam, The Netherlands\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09557-w.pdf', 'link': 'https://openalex.org/works/W3027986581', 'title': 'Preface: Selected Extended Papers from Interactive Theorem Proving 2018'}),\n",
              " Document(page_content='794 J .A v i g a d ,A .M a h b o u b i\\nManuel Eberl, Max W. Haslbeck, and Tobias Nipkow, “Veriﬁed Analysis of Random\\nBinary Tree Structures”\\nHira Taqdees Syeda and Gerwin Klein, “Formal Reasoning under Cached Address\\nTranslation”\\nThe ﬁrst deals with the Üresin–Dubois algorithm, which plays an important role in the cor-\\nrectness of various distributed algorithms, the second deals with the analysis of randomizedalgorithms, and the third addresses the challenge of verifying low-level operating systemcode in the presence of caching. Finally, one paper deals with self-veriﬁcation of interactivetheorem provers:\\nMatthieu Sozeau, Abhishek Anand, Simon Boulier, Cyril Cohen, Yannick Forster,\\nFabian Kunze, Gregory Malecha, Nicolas Tabareau, and Théo Winterhalter, “The Meta-Coq Project”\\nThe paper reports on important progress towards developing a metaprogramming language\\nand support for writing veriﬁed tactics and metaprograms.\\nWe are grateful to the authors for enabling us to assemble such a ﬁne collection, and to', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09557-w.pdf', 'link': 'https://openalex.org/works/W3027986581', 'title': 'Preface: Selected Extended Papers from Interactive Theorem Proving 2018'}),\n",
              " Document(page_content='and support for writing veriﬁed tactics and metaprograms.\\nWe are grateful to the authors for enabling us to assemble such a ﬁne collection, and to\\nthe anonymous referees for their attention to detail and extremely thoughtful and helpfulreviews.\\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and\\ninstitutional afﬁliations.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09557-w.pdf', 'link': 'https://openalex.org/works/W3027986581', 'title': 'Preface: Selected Extended Papers from Interactive Theorem Proving 2018'}),\n",
              " Document(page_content='arXiv:1809.01572v2  [math.CO]  21 Sep 2020A Safe Computational Framework for Integer Programming app lied\\nto Chv´ atal’s Conjecture∗\\nLeon Eiﬂer1, Ambros Gleixner1, and Jonad Pulaj1,2\\n1Department of Mathematical Optimization, Zuse Institute Be rlin (ZIB), Berlin, Germany,\\n{eifler,gleixner,pulaj }@zib.de\\n2Department of Mathematics and Computer Science, Davidson C ollege, Davidson, NC\\njonad.pulaj@cavehill.uwi.edu\\nSeptember 22, 2020\\nAbstract\\nWe describe a general and safe computational framework that provides integer program-\\nming results with the degree of certainty that is required fo r machine-assisted proofs of\\nmathematical theorems. At its core, the framework relies on a rational branch-and-bound\\ncertiﬁcate produced by an exact integer programming solver , SCIP, in order to circumvent\\nﬂoating-point roundoﬀ errors present in most state-of-the -art solvers for mixed-integer pro-\\ngrams. The resulting certiﬁcates are self-contained and ch ecker software exists that can', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='grams. The resulting certiﬁcates are self-contained and ch ecker software exists that can\\nverify their correctness independently of the integer prog ramming solver used to produce\\nthe certiﬁcate. This acts as a safeguard against programmin g errors that may be present\\nin complex solver software. The viability of this approach i s tested by applying it to ﬁnite\\ncases of Chv´ atal’s conjecture, a long-standing open quest ion in extremal combinatorics. We\\ntake particular care to verify also the correctness of the in put for this speciﬁc problem, using\\nthe Coq formal proof assistant. As a result we are able to prov ide a ﬁrst machine-assisted\\nproof that Chv´ atal’s conjecture holds for all downsets who se union of sets contains seven\\nelements or less.\\n1 Introduction\\nThe work on algorithms and software for mathematical optimization is often motivated by the\\nsolution of real-world applications. This sometimes overshadows the value that these methods\\ncan have for answering questions in mathematics itself. Some of the m can quite naturally be\\ncast in the form of optimization problems. Prominent examples are th e extensive use of linear\\nprogrammingto settle Kepler’s conjecture [20] or the use of semide ﬁnite programming in discrete', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='cast in the form of optimization problems. Prominent examples are th e extensive use of linear\\nprogrammingto settle Kepler’s conjecture [20] or the use of semide ﬁnite programming in discrete\\ngeometry [6]. In addition, ﬁrst attempts at using integer programm ing have been made to settle\\nopen questions in extremal combinatorics [28], graph theory [25], an d graph pebbling [22].\\nThe use of integer programming(IP) for constructing rigorousma thematical proofs, however,\\nis faced with two main computational diﬃculties. First, virtually all sta te-of-the-art IP solvers\\nrely on fast ﬂoating-point arithmetic, hence their results are comp romised by roundoﬀ errors.\\n∗The work for this article has been conducted within the Resea rch Campus MODAL funded by the German\\nFederal Ministry of Education and Research (BMBF grant numb ers 05M14ZAM, 05M20ZBM).\\n1', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Second, most solvers do not provide suﬃcient output that would allo w to check and verify the\\ncorrectness of their result. These limitations are unfortunate giv en that the presence of integer\\nvariables allows for expressive models and that solvers for integer p rogramming problems have\\nstrongly increased in computational power over the last years [1].\\nIn marked contrast, satisﬁability solving (SAT) has been employed w ith considerable suc-\\ncess to answer open questions in discrete mathematics. A recent m ilestone is the solution of\\nthe boolean Pythagorean triples problem [21]. Satisﬁability solving and integer programming\\nshare the theoretical diﬃculty that compact certiﬁcates are in ge neral not available since both\\nSAT and IP are not known to be in co- NP. However, over the last years the SAT commu-\\nnity has established standards and tools for proof logging and solve r-independent veriﬁcation of\\nresults [33].\\nIn comparison, exact IP software with veriﬁable results is still in its in fancy. Besides domain-\\nspeciﬁc worksuch as for the traveling salesmansolverConcorde [3] or partial functionality within\\nsoftware libraries targeted towards polyhedral analysis [5, 7], the only exact, general IP solver', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='speciﬁc worksuch as for the traveling salesmansolverConcorde [3] or partial functionality within\\nsoftware libraries targeted towards polyhedral analysis [5, 7], the only exact, general IP solver\\nwe are aware of and whose results are not compromised by ﬂoating- point errors is an extension\\nof the solver SCIP [13]. Exact SCIP has recently been further exte nded by the possibility to\\nprint certiﬁcates that can be veriﬁed independently from the solut ion process [10]. The goal of\\nthis paper is to demonstrate how these tools can be employed to cre ate asafecomputational\\nframework for investigating a particular mathematical application b y integer programming. To\\nthis end, we couple\\n1. an exact rational IP solver, SCIP [13], with\\n2. IP certiﬁcatesfor its branch-and-boundtree outputthat can be veriﬁed independently from\\nthe solution process by the checker VIPR [10],\\n3. and veriﬁcation procedures for the correctness of the inputimplemented in a formal proof\\nassistant, Coq [14].\\nNotably, this framework features the combined use of an exact IP certiﬁcate and a formal proof', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='assistant, Coq [14].\\nNotably, this framework features the combined use of an exact IP certiﬁcate and a formal proof\\nassistant to ensure the correctness of the certiﬁcate’s input da ta. To the best of our knowledge,\\nthis has not been explored in the literature before.\\nWe apply this framework to Chv´ atal’s conjecture, which is a well-kno wn open problem in\\nextremal set theory dating back to 1974 and contained in Erd˝ os’s list of favorite combinatorial\\nproblems [17]. Using our framework, we obtain machine-assistedpro ofs for low-dimensionalcases\\nthat were previously unknown.\\nThe rest of this paper is organized as follows. Section 2 outlines the g eneral methodology for\\nusing exact rational integer programming together with input/out put veriﬁcation for machine-\\nassisted theorem proving. Section 3 describes the IP formulations that we use to model Chv´ atal’s\\nconjecture and presents valid inequalities for the underlying polyto pes and “cuts” from the\\nliterature that reduce the number of integral solutions to the IP f ormulations. Section 4 contains\\na detailed description of our experimental results and Section 5 con cludes with an outlook on', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='literature that reduce the number of integral solutions to the IP f ormulations. Section 4 contains\\na detailed description of our experimental results and Section 5 con cludes with an outlook on\\nfuture work. The implementation and results are freely available to t he public [16].\\n2 Veriﬁable Proofs for Integer Programming Results\\nIn the following, we outline our computational methodology used to s olve the integer programs\\npresented in Section 3 such that the results can be trusted and bo th input and output can be\\nveriﬁed independently of the IP solver used. Figure 1 illustrates the four components.\\n2', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Verification Solving Modeling\\nVIPR to verify\\nbranch-and-bound\\nData checker to\\nverify inputSolve IP with exact\\nSCIPModel problem\\nas integer program\\nFigure 1: General framework for modeling, solving, and verifying th e results of integer programs.\\nModeling. As the ﬁrst step, we use the modeling language ZIMPL [24] to formula te the integer\\nprogram. ZIMPL employs exact rational arithmetic when instantiat ing the model in order to\\nensure that no roundoﬀ errors are introduced before passing th e model to a solver.\\nSolving. Next, we solve the IP using the exact rational variant of the MIP so lver SCIP [13].\\nExact SCIP implements a hybrid branch-and-bound algorithm that c ombines ﬂoating-point and\\nexact rational arithmetic in a safe manner. Several methods are u sed in order to obtain safe\\ndual bounds by correcting relaxation solutions from fast ﬂoating- point linear programming (LP)\\nsolvers. An exact rational LP solver, QSopt ex [4], is used as sparingly as possible. Although ex-\\nact SCIP still lacks many more sophisticated techniques implemented in state-of-the-art ﬂoating-', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='act SCIP still lacks many more sophisticated techniques implemented in state-of-the-art ﬂoating-\\npointsolverssuchaspresolvingreductions, cuttingplanes, orsym metryhandling, itsdesignhelps\\nto yield superior performance compared to a na¨ ıve branch-and-b ound method solely relying on\\nrational LP solves.\\nOutput Veriﬁcation. Although exact SCIP is designed to provide safe results, the corre ctness\\nof the algorithm and implementation cannot easily be veriﬁed externa lly. To address this issue,\\nwe use VIPR [10], a recently developed certiﬁcate format that cons ists of the problem deﬁnition\\nfollowed by an encoding of the branch-and-bound proof as a list of v alid inequalities. It rests\\non three simple inference steps that allow for elementary, stepwise veriﬁcation: aggregation of\\ninequalities, rounding of right-hand sides, and resolution of a binary disjunction. In this sense, a\\nVIPR certiﬁcate can, in theory, be checked by hand, although in pr actice this may be prohibitive\\nfor larger certiﬁcates. Hence, the VIPR project comes with an au tomatic, standalone checker,', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='for larger certiﬁcates. Hence, the VIPR project comes with an au tomatic, standalone checker,\\nbut the simplicity of the format allows for the implementation of altern ative checkers.\\nExact SCIP can be conﬁgured to generate VIPR certiﬁcates durin g the solving process such\\nthat its result must not be trusted blindly. Its correctness can be veriﬁed completely indepen-\\ndently of the solving process.\\nInput Veriﬁcation. VIPR veriﬁcation only ensures the correctnessof the branch-an d-bound cer-\\ntiﬁcate with respect to the integer program encoded in the problem section of the certiﬁcate ﬁle.\\nHowever, due to implementation errors, the problem section of the certiﬁcate ﬁle may actually\\nnot match the integer program of interest. Therefore we implemen ted a safe input-checker that\\ninternally creates its own representation of the constraint matrix for Problem Pred(n). It then\\nreads the problem section of the certiﬁcate ﬁle and checks if the tw o constraint matrices coincide.\\nThis input checker is written using the Coq proof assistant [14], a mat hematical proof manage-', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='This input checker is written using the Coq proof assistant [14], a mat hematical proof manage-\\nment system. The matrix creation in this input checker is problem-sp eciﬁc, nevertheless it can\\neasily be adapted to formulations for similar problems.\\nAll in all, we are conﬁdent that this framework ensures a high level of trust in the compu-\\ntational proof of Theorem 1. All tools are made publicly available for r eview [16], including the\\ncertiﬁcate ﬁles for the computational results presented in Sectio n 4.\\n3', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='3 A Polyhedral Approach to Chv´ atal’s Conjecture\\nChv´ atal’sconjectureisawell-knownopenprobleminextremalsett heoryfrom1974,laterearning\\na spot among Erd˝ os’ favorite combinatorial problems [17]. Despite its popularity, researcheﬀorts\\nhaveyieldedlimitedprogress,mostlyrestrictedtospecialcasesan drelatedvariantsoftheoriginal\\nconjecture. Before continuing in more detail we need the following d eﬁnitions.\\nLet [n] :={1,2,...,n}. AfamilyFis a set of subsets of [ n]. LetU(F) denote the union of\\nall sets in F. A family Fis adownset if and only if A∈ FandB⊆AimpliesB∈ F. IfFis a\\ndownset then F∈ Fis abaseif and only if no strict supersets of Fare contained, i.e., F⊆D\\nandD∈ FimpliesF=D. A family Fis calledintersecting if and only if the intersection of any\\npairwise sets in Fis nonempty. A family Fis astarif and only there exists an element in U(F)', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='pairwise sets in Fis nonempty. A family Fis astarif and only there exists an element in U(F)\\ncontained in all sets of F. A family Fhas thestar property if and only if some maximum-sized\\nintersecting family in Fis a star. We are ready to state Chv´ atal’s conjecture as follows:\\nConjecture 1 (Chv´ atal [12]) .Every downset has the star property.\\nSch¨ onheim [29] showed that Chv´ atal’s conjecture holds for all do wnsetsDwhose bases have\\na nonempty intersection. Stein [31] proved the conjecture holds f or all downsets in which all\\nbut one of the bases is a simplestar, i.e., a star in which the intersection of all of its sets is\\nequal to the intersection of any of its two sets. Mikl´ os [26] showe d that Chv´ atal’s conjecture\\nholds for any downset Dthat contains an intersection family of size ⌊D/2⌋. Sterboul [32] proved\\nthat any downsets whose sets have three or less elements always s atisfy Conjecture 1. The last', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='that any downsets whose sets have three or less elements always s atisfy Conjecture 1. The last\\nresult was recently proven again in diﬀerent ways by Czabarka, Hur lbert, Kamat [15] and Olarte,\\nSantos, Spreer [27]. Furthermore, Chv´ atal maintains a website d edicated to the conjecture with\\na substantial list of publications on the topic [11].\\nOur main result on Chv´ atal’s conjecture is the following:\\nTheorem 1. Conjecture 1 holds for all downsets Dsuch that |U(D)| ≤7.\\nTo the best of our knowledge there is no known computational meth odology in the literature\\nthat investigates Conjecture 1 even for small ground sets. The p reviously known best bound on\\nthe cardinality of the ground set was |U(D)|= 5, which follows directly from [32] as we show in\\nProposition 3.\\nAlready Fishburn [18] highlighted the connection between combinato rial optimization and\\nChv´ atal’s conjecture and investigated related problems. Thus mo deling the conjecture as an IP\\nand using solvers that safeguard against numerical issues is a natu ral step to further investigate', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Chv´ atal’s conjecture and investigated related problems. Thus mo deling the conjecture as an IP\\nand using solvers that safeguard against numerical issues is a natu ral step to further investigate\\nConjecture 1. Furthermore, relying on an IP framework to invest igate Chv´ atal’s conjecture for\\nsmall ground sets has other advantages. First, the rich and well-d eveloped theory of polyhedral\\ncombinatorics, that is inherent in an IP approach, may lead to new ins ights on Conjecture 1.\\nSecond, as we see in Section 3.3, known partial results on Chv´ atal’s conjecture can be encoded\\nas “cuts” in our framework. This improves the performance of the exact rational solver and may\\nallow strengthening of Theorem 1 in the future.\\nIn the following sections we develop integer programming formulation s for Chv´ atal’s conjec-\\nture over ﬁxed-size ground sets. The formulations are based on d ecision variables that index\\nmembers of the power set. Due to the exponential nature of powe r sets, the size of the formula-\\ntions is bound to grow quickly with the size of the ground set. Howeve r, even for small ground\\nsets little is known and the results in Section 4 improve upon what is kno wn today.', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='tions is bound to grow quickly with the size of the ground set. Howeve r, even for small ground\\nsets little is known and the results in Section 4 improve upon what is kno wn today.\\n4', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='3.1 An Infeasibility-Based Formulation\\nThe ﬁrst IP model is formulated such that Chv´ atal’s conjecture h olds for the considered ground\\nset if and only if the IP has no solution. In other words, a feasible solu tion to the IP formulation\\nfor any ﬁxed nwould yield a counterexample to Chv´ atal’s conjecture. Let 2[n]denote the power\\nset of [n], then we consider the integer program Pinf(n),\\nmax∑\\nS∈2[n]xS (1a)\\nxT≤xS ∀T∈2[n],∀S∈2[n]:S⊂T, (1b)\\nyT+yS≤1 ∀T∈2[n]\\\\{∅},∀S∈2[n]\\\\{∅}:T∩S=∅,(1c)\\nyS≤xS ∀S∈2[n], (1d)\\n∑\\nS∈2[n]:i∈SxS+1≤∑\\nS∈2[n]\\\\{∅}yS∀i∈[n], (1e)', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='∑\\nS∈2[n]:i∈SxS+1≤∑\\nS∈2[n]\\\\{∅}yS∀i∈[n], (1e)\\nxS,yS∈ {0,1} ∀ S∈2[n].\\nHere,xencodes the set family S(x) :={S⊆[n] :xS= 1}andyencodes the sub family\\nS(y) :={S⊆[n] :yS= 1}. The ﬁrst class of downset inequalities (1b) ensures that S(x) is a\\ndownset. The second class of intersecting inequalities (1c) ensures that S(y)\\\\{∅}is an intersect-\\ning family. The third class of containment inequalities (1d) ensures that the intersecting family\\nis contained in the chosen downset, S(y)⊆ S(x). Finally, the fourth class of starinequalities\\n(1e) requires that the intersecting family has greater cardinality t han any star in the downset.\\nTheorem 2. Letnbe a positive integer. All downsets Fsuch that |U(F)| ≤nsatisfy Chv´ atal’s', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Theorem 2. Letnbe a positive integer. All downsets Fsuch that |U(F)| ≤nsatisfy Chv´ atal’s\\nconjecture if and only if Pinf(n)is infeasible.\\nProof.Fixn. Suppose that Chv´ atal’s conjecture does not hold, i.e., there exis ts a downset D\\nand an intersecting family Y ⊆ Dsuch that |Y|is larger than the size of every star in D. W.l.o.g.\\nassumeD ⊆2[n]. Letxandybe their incidence vectors, i.e., D=S(x) andY=S(y). By\\nconstruction, xandysatisfy constraints (1b–1d). Furthermore, for each element i∈[n],|Y|is\\nlarger than the size of all stars that have ias common element, hence (1e) is equally satisﬁed.\\nIn total, xandyconstitute a feasible solution to Pinf(n).\\nConversely, suppose all downsets Dsuch that |U(D)| ≤nsatisfy Chv´ atal’s conjecture. Sup-', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='In total, xandyconstitute a feasible solution to Pinf(n).\\nConversely, suppose all downsets Dsuch that |U(D)| ≤nsatisfy Chv´ atal’s conjecture. Sup-\\nposexandyare feasible solutions to Pinf(n). By (1b), S(x) forms a downset and |U(S(x))| ≤n.\\nBy (1c) and (1d), Y:=S(y)\\\\ {∅}forms an intersecting family contained in S(x). Hence, |Y|\\ncan be at most the size of the largest star contained in S(x),\\n|Y|=∑\\nS∈2[n]\\\\{∅}yS≤max\\ni∈[n]∑\\nS∈2[n]:i∈SxS. (2)\\nBut then constraint (1e) is violated for i0∈argmax i∈[n]∑\\nS∈2[n]:i∈SxS.\\nNote that the objective function (1a) of Pinf(n) is, in some sense, arbitrary since we only\\nneed to decide whether the integer program has a feasible solution o r not. The objective func-', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Note that the objective function (1a) of Pinf(n) is, in some sense, arbitrary since we only\\nneed to decide whether the integer program has a feasible solution o r not. The objective func-\\ntion encodes the cardinality of S(x), hence solving Pinf(n) amounts to searching for a largest\\ncounterexample to Conjecture 1. In the following we present a mor e advanced formulation that\\nuses the optimal value as an essential component.\\n5', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='3.2 An Optimality-Based Formulation\\nAs already noted in [27] it is suﬃcient to only consider downsets gener ated by an intersecting\\nfamily. We use this insight in the following, advanced formulation Popt(n),\\nmax∑\\nS∈2[n]\\\\{∅}yS−z (3a)\\nyT+yS≤1 ∀T∈2[n]\\\\{∅},∀S∈2[n]\\\\{∅}:T∩S=∅,(3b)\\n∑\\nS∈2[n]:i∈SxS≤z ∀i∈[n], (3c)\\nyT≤xS ∀T∈2[n],∀S∈2[n]:S⊆T, (3d)\\nxS,yS∈ {0,1} ∀ S∈2[n],\\nz∈Z≥0.\\nThe ﬁrst class of intersecting inequalities (3b) is the same as (1c), whereas the second class of\\nstarinequalities (3c) diﬀers from (1e). It ensures that the largest sta r is bounded above by the', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='starinequalities (3c) diﬀers from (1e). It ensures that the largest sta r is bounded above by the\\npositive integer variable z. Finally, the third class of generation inequalities (3d) ensures, as will\\nbe made clearer in the proof of Theorem 3, that an optimal solution o fPopt(n) considers only\\ndownsets generated by the intersecting family. We note that the g eneration inequalities (3d) can\\nalso be included in Pinf(n) instead of (1b) and (1d) by the same argument. Before we forma lly\\nstate and prove the correctness of Popt(n) with regards to Conjecture 1, we need the following\\nobservation.\\nObservation 1. Letnbe a positive integer. An optimal solution of Popt(n)satisﬁes at least one\\nstar inequality (3c)with equality.\\nObservation 1 follows from the objective function of Popt(n). Variable zis restricted only\\nfrom below by its lower bound zero and the left-hand sides of constr aints (3c). Since Popt(n) is\\na maximization problem and the objective coeﬃcient of zis negative, in an optimal solution the', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='a maximization problem and the objective coeﬃcient of zis negative, in an optimal solution the\\nvariablezwill be as small as possible. This implies that at least one star inequality ( 3c) is tight.\\nTheorem 3. Letnbe a positive integer. Downsets Dsuch that |U(D)| ≤nsatisfy Chv´ atal’s\\nconjecture if and only if the objective function value of an o ptimal solution of Popt(n)is zero.\\nProof.Fixn∈N. First note that Popt(n) is feasible since any star is also an intersecting family.\\nThus foranydownset D ⊆2[n], choosing xasthe indicatorvectorof Dandsetting the y-variables\\nsuch that they represent a maximum-cardinality star in Dyields a feasible solution. Choosing\\nzto be the maximum star cardinality, i.e., the smallest value such that co nstraints (3c) are\\nsatisﬁed, also proves a lower bound of zero on the objective value.\\nNow suppose all downsets Dsuch that |U(D)| ≤nsatisfy Chv´ atal’s conjecture and let\\nx,y,zbe an optimal solution for Popt(n). Then it suﬃces to show that∑', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='x,y,zbe an optimal solution for Popt(n). Then it suﬃces to show that∑\\nS∈2[n]\\\\{∅}yS≤z.\\nConstraints (3b) ensure that Y:=S(y)\\\\{∅}forms an intersecting family. Furthermore, the x-\\nvariablesdo not appearin the objectivefunction and arebounded b elow only by constraints(3d).\\nHence, w.l.o.g. we may assume that xS= max T⊇SyT. Then, by constraints (3d), D:=S(x) is\\na downset and Y ⊆ D. Assuming Chv´ atal’s conjecture ensures that |Y|=∑\\nS∈2[n]\\\\{∅}ySis at\\nmost the size of the largest star in D, which by constraints (3c) is less than or equal to z.\\nConversely, suppose there exists a counterexample to Chv´ atal’s conjecture, i.e., a downset\\nD,|U(D)| ≤n, and an intersecting family Y ⊆ Dsuch that |Y|is larger than the size of any', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='D,|U(D)| ≤n, and an intersecting family Y ⊆ Dsuch that |Y|is larger than the size of any\\nstar inD. W.l.o.g. assume D ⊆2[n]and letxandybe the incidence vectors of DandY,\\n6', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='respectively, i.e., D=S(x) andY=S(y). Letzbe the size of the largest star in D, i.e.,\\nz= max∑\\nS∈2[n]:i∈SxS. Then by construction, x,y,zis a feasible solution for Popt(n). Because\\nwe consider a counterexample, the objective function value is at lea st one.\\n3.3 Valid Inequalities and Model Reductions\\nAs mentioned in Section 1, one of the advantages of an IP approach is thatPinf(n) andPopt(n)\\ncan be studied in greater depth through polyhedral combinatorial techniques. Furthermore\\nknown results from the literature can be expressed as valid inequalit ies and problem reductions\\nforPinf(n) andPopt(n), in the sense that Theorems 2 and 3 still hold with these additional\\nconstraints, and the number of feasible solutions is less than or equ al to the number of current\\nsolutions. This is demonstrated in the following section and may help to increase the size of n\\nfor which the models can be solved.\\nFirst, consider the intersecting inequalities of form (1c) and (3b). WhenT= [n]\\\\S, these\\ncan be interpreted as a special case of the following partition inequa lities.', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='First, consider the intersecting inequalities of form (1c) and (3b). WhenT= [n]\\\\S, these\\ncan be interpreted as a special case of the following partition inequa lities.\\nProposition 1. Letnbe a positive integer and let Pbe a partition of [n]. Then the inequality\\n∑\\nS∈PyS≤1 (4)\\nis a valid for Pinf(n)andPopt(n).\\nProof.Suppose∑\\nS∈PyS≥2 for an integer feasible solution y, then there exist S,T∈ Pwith\\nyS=yT= 1, violating (1c) and (3b).\\nAs a consequence, intersection inequalities that do not cover the w hole ground set can be\\nstrengthened.\\nProposition 2. Letnbe a positive integer and S,T∈2[n]\\\\{∅}such that T∩S=∅. Suppose\\nS∪T̸= [n]. Then the intersecting inequality\\nyT+yS≤1 (5)\\nis dominated by a partition inequality.\\nProof.S,Tcan be completed to a partition by their complement [ n]\\\\(S∪T). Inequality (5) is', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='is dominated by a partition inequality.\\nProof.S,Tcan be completed to a partition by their complement [ n]\\\\(S∪T). Inequality (5) is\\ntrivially dominated by the corresponding partition inequality yT+yS+y[n]\\\\(S∪T)≤1.\\nThe large number of partitions prohibits the static addition of these inequalities to the for-\\nmulation. However, modern IP solvers automatically extract the co nﬂicting y-assignments from\\nconstraints(1c) and(3b) and add partitioninequalities dynamically. Next, considerthe following\\ncentral result.\\nTheorem 4 (Berge [8]) .IfDis a downset then Dis a disjoint union of pairs of disjoint sets,\\ntogether with ∅if|D|is odd.\\nThis yields the following result, that can easily be expressed as a valid in equality for Pinf(n)\\nandPopt(n), as in Corollary 2.\\nCorollary 1 (Anderson [2] p.105) .LetDbe a downset and Yan intersecting family such that\\nY ⊆ D. Then2|Y| ≤ |D| .\\n7', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Corollary 2. Letnbe any positive integer. Suppose the following inequality\\n∑\\nS∈2[n]\\\\{∅}2yS≤∑\\nS∈2[n]xS (6)\\nis added to Pinf(n)andPopt(n). Then Theorems 2 and 3 hold for the modiﬁed formulations of\\nPinf(n)andPopt(n), respectively.\\nThe following result is used in [27] to give a simple proof that Chv´ atal’s c onjecture holds for\\nall downsets whose sets have three elements or less.\\nTheorem 5 (Kleitman, Magnanti [23]) .Any intersecting family that is contained in the union\\nof two stars generates a downset that satisﬁes Conjecture 1.\\nAs a consequence, y-variables for sets with one or two elements can be ﬁxed to zero in Pinf(n)\\nandPopt(n).\\nCorollary 3. Letnbe any positive integer. For Pinf(n)andPopt(n)ﬁxyS= 0for allS∈2[n]', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='andPopt(n).\\nCorollary 3. Letnbe any positive integer. For Pinf(n)andPopt(n)ﬁxyS= 0for allS∈2[n]\\nsuch that 1≤ |S| ≤2. Then Theorems 2 and 3 hold for Pinf(n)andPopt(n), respectively, with\\nthe given ﬁxings.\\nProof.Suppose ystems from a solution of Pinf(n) orPopt(n), then it encodes an intersecting\\nfamilyY:=S(y)\\\\{∅}. If{i} ∈ Y, thenYis a star centered around i. If{i,j} ∈ Y, thenYis the\\nunion of two stars centered around iandj, respectively. By Theorem 5, these do not amount\\nto counterexamples to Chv´ atal’s conjecture and can safely be ex cluded from the formulations\\nwithout changing the feasibility status of Pinf(n) and the optimal objective value of Popt(n),\\nrespectively.\\nTheorem 5 can also be exploited for a short proof, that the conjec ture holds for all ground\\nsets of size less or equal than 5.\\nProposition 3. Conjecture 1 holds for all downsets Dsuch that |U(D)| ≤5.', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='sets of size less or equal than 5.\\nProposition 3. Conjecture 1 holds for all downsets Dsuch that |U(D)| ≤5.\\nProof.Consider an intersecting family Ysuch that |U(Y)| ≤5, w.l.o.g. Y ⊆2[5]. All 10 sets of\\nsize 3 have to be part of the intersecting family. If this is not the cas e, thenYis contained in the\\nunion of the stars of the remaining two elements and the conjectur e holds by Theorem 5. The\\nmaximal star, containing only elements of size 1 ,2,3 has size 11.\\nLet us now consider sets of size 4. There are ksets of size 4 in Ywith 0≤k≤(5\\n4)\\n. For any\\nstar, there exists at most one set of size 4 that does not contain t he common element. Therefore\\nthe size of the largest intersecting family is at most 10+ k, whereas the size of the largest star\\nis 11+k−1 = 10+ k.\\nSince the whole ground set can not be part of the intersecting family , this concludes the\\nproof.\\nVariable ﬁxings are certainly the most eﬀective improvements to the problem formulation,\\nsince they directly reduce the problem size as opposed to general v alid inequalities that increase', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='proof.\\nVariable ﬁxings are certainly the most eﬀective improvements to the problem formulation,\\nsince they directly reduce the problem size as opposed to general v alid inequalities that increase\\nthe number of constraints. If we know that Conjecture 1 holds fo r all downsets Dsuch that\\n|U(D)| ≤nfor some ﬁxed n, then we can use a simple variable ﬁxing scheme for the case when\\n|U(D)|=n+1, as follows.\\nProposition 4. Letnbe a ﬁxed positive integer. Suppose Pinf(n)is infeasible and the objective\\nfunction value of an optimal solution of Popt(n)is zero for all positive integers n0< n. Fix\\nxS= 1for allS∈2[n]such that |S|= 1. Then Theorems 2 and 3 hold for Pinf(n)andPopt(n),\\nrespectively, with the given ﬁxings.\\n8', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Proof.Consider the x-vector from a solution of Pinf(n) orPopt(n) and suppose that x{i}= 0\\nfor some element i∈[n]. As in the proofs of Theorems 2 and 3, we may assume that xencodes\\na downset D:=S(x) andY:=S(y)⊆ Dis an intersecting family. By the downset property,\\nxS= 0forall S∋i. Butthen |U(D)|< nandbyassumptionthesolutionisnotacounterexample\\nto Conjecture 1. Hence, we may ﬁx xS= 1 for all S∈2[n]such that |S|= 1.\\nWe can apply this proposition incrementally by starting from the case n= 6, with all x-\\nvariables for sets that contain exactly one element ﬁxed to 1. Afte r solving, we increase nby one\\nand repeat the procedure.\\nFinally, wediscusshowtoexploitthefundamentalresultof[32]asa nadditionalﬁxingscheme.\\nProposition 5. Letn≥6be a ﬁxed integer. In Pinf(n)andPopt(n)ﬁxxS= 1for allS∈2[4].', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Proposition 5. Letn≥6be a ﬁxed integer. In Pinf(n)andPopt(n)ﬁxxS= 1for allS∈2[4].\\nThen Theorems 2 and 3 hold, respectively, with the given ﬁxin gs.\\nProof.According to [32], counterexamples to Chv´ atal’s conjecture must feature a downset that\\ncontains at least one set of size four. By permuting the elements in [ n] suitably, we can always\\nensure that this set is {1,2,3,4}.\\nTo summarize, we arrive at the following improved formulation Pred(n),\\nmax∑\\nS∈2[n]\\\\{∅}yS−z (7a)\\nyT+yS≤1 ∀T∈2[n]\\\\{∅},∀S∈2[n]\\\\{∅}:T∩S=∅,(7b)\\n∑\\nS∈2[n]:i∈SxS≤z ∀i∈[n], (7c)\\nyT≤xS ∀T∈2[n],∀S∈2[n]:S⊆T, (7d)\\n∑', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='yT≤xS ∀T∈2[n],∀S∈2[n]:S⊆T, (7d)\\n∑\\nS∈2[n]\\\\{∅}2yS≤∑\\nS∈2[n]xS, (7e)\\nyS= 0 ∀S∈2[n]: 1≤ |S| ≤2, (7f)\\nxS= 1 ∀S∈2[n]:|S|= 1, (7g)\\nxS= 1 ∀S⊆[4], (7h)\\nxS,yS∈ {0,1} ∀ S∈2[n],\\nz∈Z≥0.\\nThis formulation serves as the basis for our proof of Theorem 1 tha t uses the following\\nequivalence incrementally for n= 6 and n= 7. We summarize our reductions in the following\\ntheorem.\\nTheorem 6. Letnbe a positive integer and suppose Chv´ atal’s conjecture hol ds for all downsets\\nDsuch that |U(D)| ≤n−1. Then all downsets Dsuch that |U(D)| ≤nsatisfy Chv´ atal’s', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Dsuch that |U(D)| ≤n−1. Then all downsets Dsuch that |U(D)| ≤nsatisfy Chv´ atal’s\\nconjecture if and only if the objective function value of an o ptimal solution of Pred(n)is zero.\\nProof.As follows from Corollary 2, constraint (7e) is a valid inequality for Popt(n). Corollary 3\\nshows that constraints (7f) do not exclude any counterexamples that may have objective func-\\ntion value greater than zero. According to Proposition 4, the same holds for constraints (7g)\\nunder the assumption that Chv´ atal’s conjecture is correct for s maller ground sets. According to\\nProposition 5, constraints (7h) may exclude counterexamples, bu t only as long as at least one\\nsymmetric counterexample remains feasible.\\n9', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='4 Computational Results\\nUsing the safe computationalframeworkoutlined in Section 2, we co uld solve Popt(n) andPred(n)\\nforn= 5,6, and 7, producing a machine-assisted proof of Theorem 1. Furth ermore, several\\nﬂoating-point MIP solvers could solve Pred(8) to optimality. Although this does not constitute\\na safe proof, it makes it highly likely that Chv´ atal’s conjecture holds forn= 8 and a search for\\ncounterexamples should focus on larger ground sets.\\nBeyond the plain question of solvability, in this section we provide deta ils regarding the\\nfollowing questions: What are the times spent for solving the integer programs and how are they\\naﬀected by the improvements in the formulations? How large a re the resulting certiﬁcates and\\nhow expensive is their veriﬁcation? How does the performanc e of the exact framework compare\\nto the performance of standard ﬂoating-point MIP solvers?\\nThe results for the optimality-based formulations are provided in Ta ble 1. All tests were run\\non a cluster of computing nodes with Intel Xeon Gold 5122 CPUs with 3 .6GHz and 96GB of', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='The results for the optimality-based formulations are provided in Ta ble 1. All tests were run\\non a cluster of computing nodes with Intel Xeon Gold 5122 CPUs with 3 .6GHz and 96GB of\\nmain memory. The exact version of SCIP was built with CPLEX 12.6.3 as ﬂ oating-point LP\\nsolver and QSopt ex 2.5.10 [4] for exact rational LP solves. As ﬂoating-point MIP solve r, we\\nused SCIP 6.0.0 [19], built with CPLEX 12.8.0 as the underlying LP solver. T he time limit was\\nset to 12 hours for all runs and on each computing node only one job was executed at a time.\\nTable 1: Computational details for solving the Chv´ atal IPs for the two formulations Popt(n)\\nandPred(n). The sizes reported for the VIPR certiﬁcates are for uncompre ssed text ﬁles. The\\nrunning time for input veriﬁcation is negligible and always below 5 second s.\\nSCIP 6.0.0 SCIP exact VIPR\\nIP n#vars #ineqs time [s] time [s] size [MB] time [s]', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='SCIP 6.0.0 SCIP exact VIPR\\nIP n#vars #ineqs time [s] time [s] size [MB] time [s]\\nPopt(n) 5 63 427 0.2 0.5 0.5 0.07\\n6 127 1336 2.3 22.6 73 4.6\\n7 255 4125 91.0 4024.2 21000 1258.3\\n8 511 12618 – – – –\\nPred(n) 5 31 433 0.1 0.1 0.018 0.005\\n6 88 1317 0.1 0.2 0.25 0.2\\n7 208 4050 13.5 124.5 163 28.9\\n8 455 12424 7278.9 – – –\\nFirst, we observe the eﬀectiveness of the additional inequalities an d ﬁxings applied in Pred(n).\\nThe running times of exact SCIP are signiﬁcantly reduced, as are th e sizes and veriﬁcation times\\nfor the VIPR certiﬁcates. Furthermore, only Pred(8) can be solved by ﬂoating-point SCIP, while\\nit times out for Popt(8). Second, note that the size of the IPs is not large compared to what', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='it times out for Popt(8). Second, note that the size of the IPs is not large compared to what\\nMIP solvers today can often handle easily in many industrial applicatio ns. This underlines the\\ndiﬃcultyoftheunderlyingcombinatorialquestion. Third, thesizesa ndrunningtimesofchecking\\nthe VIPR certiﬁcate are signiﬁcant but do not constitute a bottlen eck for the current framework.\\nNote that the times for input veriﬁcation in Coq are not reported, b ecause they are negligible\\nand always below 5 seconds.\\n10', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='5 Conclusion\\nThe goal of this paper was to bridge a gap that currently divides the ory and practice of inte-\\nger programming. In theory, the integer programming paradigm ho lds the promise of globally\\noptimal, proven results. In practice, however, there is no establis hed computational framework\\nthat rigorously safeguards results that are obtained with integer programming software against\\nnumerical and programming errors.\\nBridging this gap necessarily involved theoretical and practical asp ects. On the one hand, we\\ndeveloped non-trivial integer programming formulations for an exe mplary application: Chv´ atal’s\\nconjecture, along-standingopenquestionin extremalcombinato rics,whereevenlow-dimensional\\ncases are unanswered. One advantage of this approach was the ﬂ exibility of the IP formulations\\nto include partial results from the literature by valid inequalities and v ariable ﬁxings. Solving\\nthese formulations, we could show that counterexamples to the co njecture do not seem to exist\\nfor the cases |U(D)|= 6, 7, and 8, which were previously open.\\nOn the other hand, we had to develop and combine mathematical sof tware in order to equip\\nthese results with the level of numerical rigor and independent ver iﬁability that is required', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='On the other hand, we had to develop and combine mathematical sof tware in order to equip\\nthese results with the level of numerical rigor and independent ver iﬁability that is required\\nby computational proofs of mathematical theorems. Such veriﬁa ble computer proofs could be\\nproduced for the cases |U(D)|= 6 and 7. A proof for the case |U(D)|= 8 is tangible if\\nthe performance of the exact rational solver is enhanced in the fu ture. Hence, the results also\\nmotivate sustained work on closing the current performance gap b etween exact and inexact MIP\\nsolvers.\\nWe hope that the generality of the computational framework pres ented makes it useful for\\nthe investigation of other open questions in extremal combinatoric s and beyond. Most directly,\\nour IP models could be appropriately modiﬁed to investigate variation s on Chv´ atal’s conjecture\\nsuch as proposed by Snevily [30] or a generalizationof Chv´ atal’s con jecture proposed by Borg [9].\\nReferences\\n[1] Tobias Achterberg and Roland Wunderling. Mixed integer program ming: Analyzing 12\\nyears of progress. In Michael J¨ unger and Gerhard Reinelt, edito rs,Facets of Combinatorial', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='[1] Tobias Achterberg and Roland Wunderling. Mixed integer program ming: Analyzing 12\\nyears of progress. In Michael J¨ unger and Gerhard Reinelt, edito rs,Facets of Combinatorial\\nOptimization , pages 449–481, 2013.\\n[2] Ian Anderson. Combinatorics of ﬁnite sets . Courier Corporation, 2002.\\n[3] David Applegate, Ribert Bixby, Vasek Chvatal, and William Cook. Con corde tsp solver,\\n2006.\\n[4] David Applegate, William Cook, Sanjeeb Dash, and Daniel G. Espinoz a. Exact solutions to\\nlinear programming problems. Operations Research Letters , 35(6):693 – 699, 2007.\\n[5] Benjamin Assarf, Ewgenij Gawrilow, Katrin Herr, Michael Joswig, Benjamin Lorenz, An-\\ndreas Paﬀenholz, and Thomas Rehn. Computing convex hulls and cou nting integer points\\nwithpolymake .Mathematical Programming Computation , 9(1):1–38, 2017.\\n[6] Christine Bachoc and Frank Vallentin. New upper bounds for kissin g numbers from semidef-\\ninite programming. Journal of the American Mathematical Society , 21, 2006.', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='[6] Christine Bachoc and Frank Vallentin. New upper bounds for kissin g numbers from semidef-\\ninite programming. Journal of the American Mathematical Society , 21, 2006.\\n[7] Roberto Bagnara, Patricia M. Hill, and Enea Zaﬀanella. The Parma P olyhedra Library:\\nTowardacompleteset ofnumericalabstractionsforthe analysisa nd veriﬁcationofhardware\\nand software systems. Science of Computer Programming , 72(1–2):3–21, 2008.\\n11', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='[8] Claude Berge. A theorem related to the Chv´ atal conjecture. InProceedings of the Fifth\\nBritish Combinatorial Conference (Univ. Aberdeen, Aberde en, 1975) , pages 35–40, 1975.\\n[9] Peter Borg. On Chv´ atal’s conjecture and a conjecture on fam ilies of signed sets. European\\nJournal of Combinatorics , 32(1):140–145, 2011.\\n[10] Kevin KH Cheung, Ambros Gleixner, and Daniel E Steﬀy. Verifying Integer Programming\\nResults. In International Conference on Integer Programming and Combi natorial Optimiza-\\ntion, pages 148–160. Springer, 2017.\\n[11] Vaˇ sek Chv´ atal. A conjecture in extremal combinatorics.\\nhttp://users.encs.concordia.ca/ ~chvatal/conjecture.html (accessed September 18,\\n2020).\\n[12] Vaˇ sekChv´ atal. Intersecting families of edges in hypergraph s having the hereditary property.\\nInHypergraph Seminar , pages 61–66. Springer, 1974.\\n[13] William Cook, Thorsten Koch, Daniel E. Steﬀy, and Kati Wolter. A hybrid branch-and-', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='InHypergraph Seminar , pages 61–66. Springer, 1974.\\n[13] William Cook, Thorsten Koch, Daniel E. Steﬀy, and Kati Wolter. A hybrid branch-and-\\nbound approach for exact rational mixed-integer programming. Mathematical Programming\\nComputation , 5(3):305 – 344, 2013.\\n[14] Coq Development Team. The Coq Proof Assistant, version 8.8.0, April 2018.\\n[15] Eva Czabarka, Glenn Hurlbert, and Vikram Kamat. Chv´ aatal’s c onjecture for downsets of\\nsmall rank. ArXiv e-prints , 2017.\\n[16] Leon Eiﬂer. Integer programming proofs for Chv´ atal’s conje cture over ﬁnite ground sets.\\nhttps://github.com/leoneifler/chvatalip (accessed September 9, 2020).\\n[17] P´ al Erd˝ os. On the combinatorial problems which i would most lik e to see solved. Combina-\\ntorica, 1(1):25–42, 1981.\\n[18] Peter Fishburn. Combinatorial optimization problems for syste ms of subsets. SIAM Review ,\\n30(4):578–588, 1988.', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='torica, 1(1):25–42, 1981.\\n[18] Peter Fishburn. Combinatorial optimization problems for syste ms of subsets. SIAM Review ,\\n30(4):578–588, 1988.\\n[19] Ambros Gleixner, Michael Bastubbe, Leon Eiﬂer, Tristan Gally, G erald Gamrath,\\nRobert Lion Gottwald, Gregor Hendel, Christopher Hojny, Thorst en Koch, Marco E.\\nL¨ ubbecke, Stephen J. Maher, Matthias Miltenberger, Benjamin M ¨ uller, Marc E. Pfetsch,\\nChristian Puchert, Daniel Rehfeldt, Franziska Schl¨ osser, Christ oph Schubert, Felipe Ser-\\nrano, Yuji Shinano, Jan Merlin Viernickel, Matthias Walter, Fabian We gscheider, Jonas T.\\nWitt, and Jakob Witzig. The SCIP Optimization Suite 6.0. Technical Rep ort 18-26, ZIB,\\nTakustr. 7, 14195 Berlin, 2018.\\n[20] Thomas Hales, Mark Adams, Gertrud Bauer, Tat Dat Dang, Joh n Harrison, Le Truong', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Takustr. 7, 14195 Berlin, 2018.\\n[20] Thomas Hales, Mark Adams, Gertrud Bauer, Tat Dat Dang, Joh n Harrison, Le Truong\\nHoang, Cezary Kaliszyk, Victor Magron, Sean McLaughlin, Tat Than g Nguyen, and et al.\\nA formal proof of the kepler conjecture. Forum of Mathematics, Pi , 5:e2, 2017.\\n[21] Marijn JH Heule, Oliver Kullmann, and Victor W Marek. Solving and ve rifying the boolean\\npythagorean triples problem via cube-and-conquer. In International Conference on Theory\\nand Applications of Satisﬁability Testing , pages 228–245. Springer, 2016.\\n[22] Franklin Kenter and Daphne Skipper. Integer-programming bo unds on pebbling numbers\\nof cartesian-product graphs. In Donghyun Kim, R. N. Uma, and Ale xander Zelikovsky,\\neditors,Combinatorial Optimization and Applications , pages681–695,Cham, 2018.Springer\\nInternational Publishing.\\n12', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='[23] Daniel J Kleitman and Thomas L Magnanti. On the number of latent subsets of intersecting\\ncollections. Operations Research Center Working Papers , 1972.\\n[24] ThorstenKoch. Rapid Mathematical Prototyping . PhDthesis, TechnischeUniversit¨ atBerlin,\\n2004.\\n[25] GiuseppeLancia,EleonoraPippia,andFrancaRinaldi. Usingintege rprogrammingtosearch\\nfor counterexamples: A case study. In Alexander Kononov, Micha el Khachay, Valery A\\nKalyagin, and Panos Pardalos, editors, Mathematical Optimization Theory and Operations\\nResearch , pages 69–84, Cham, 2020. Springer International Publishing.\\n[26] Dezs¨ o Mikl´ os. Great intersecting families of edges in hereditar y hypergraphs. Discrete\\nmathematics , 48(1):95–99, 1984.\\n[27] Jorge Alberto Olarte, Francisco Santos, and Jonathan Spree r. Short proof of two cases of\\nChv´ atal’s conjecture. Discrete Mathematics , 342(8):2192 – 2194, 2019.\\n[28] Jonad Pulaj. Cutting Planes for Union-Closed Families . Dissertation, Technische Univer-\\nsit¨ at Berlin, 2017.', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='[28] Jonad Pulaj. Cutting Planes for Union-Closed Families . Dissertation, Technische Univer-\\nsit¨ at Berlin, 2017.\\n[29] Jochanan Sch¨ onheim. Hereditary systems and Chv´ atal’s con jecture. In Proceedings of the\\nFifth British Combinatorial Conference (Univ. Aberdeen, A berdeen, 1975) , pages 537–539,\\n1975.\\n[30] Hunter Snevily. Variations on Chv´ atal’s conjecture (2009).\\nhttps://faculty.math.illinois.edu/ ~west/regs/chvatal.html (accessed September\\n1, 2020).\\n[31] Peter Stein. On Chv´ atal’s conjecture related to a hereditary system.Discrete Mathematics ,\\n43(1):97–105, 1983.\\n[32] Fran¸ cois Sterboul. Sur une conjecture de V. Chv´ atal. In Cla ude Berge and Dijen Ray-\\nChaudhuri, editors, Hypergraph Seminar , pages 152–164. Springer, 1974.\\n[33] Nathan Wetzler, Marijn J. H. Heule, and Warren A. Hunt. DRAT- trim: Eﬃcient checking', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='[33] Nathan Wetzler, Marijn J. H. Heule, and Warren A. Hunt. DRAT- trim: Eﬃcient checking\\nand trimming using expressiveclausal proofs. In CarstenSinz and U we Egly, editors, Theory\\nand Applications of Satisﬁability Testing – SAT 2014 , pages 422–429, Cham, 2014. Springer\\nInternational Publishing.\\n13', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='This figure \"scheme.png\" is available in \"png\"\\n format from:\\nhttp://arxiv.org/ps/1809.01572v2', metadata={'pdf': 'http://arxiv.org/pdf/1809.01572', 'link': 'https://openalex.org/works/W3211222374', 'title': 'A Safe Computational Framework for Integer Programming Applied to Chvátal’s Conjecture'}),\n",
              " Document(page_content='Journal of Automated Reasoning (2022) 66:575–584\\nhttps://doi.org/10.1007/s10817-022-09617-3\\nA Posthumous Contribution by Larry Wos: Excerpts from an\\nUnpublished Column\\nSophie Tourret1·Christoph Weidenbach1\\nReceived: 5 July 2021 / Accepted: 10 January 2022 / Published online: 1 February 2022\\n© The Author(s) 2022\\nAbstract\\nShortly before Larry Wos passed away, he sent a manuscript for discussion to Sophie Tourret,\\nthe editor of the AAR newsletter. We present excerpts from this ﬁnal manuscript, put it in itshistoric context and explain its relevance for today’s research in automated reasoning.\\nKeywords History of automated reasoning ·Reasoning by instantiation ·Set of support ·\\nPuzzle ·First-order logic modulo arithmetic\\n1 Introduction\\nLarry Wos wrote the president’s column of the AAR Newsletter from its ﬁrst installment in', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='Puzzle ·First-order logic modulo arithmetic\\n1 Introduction\\nLarry Wos wrote the president’s column of the AAR Newsletter from its ﬁrst installment in\\nMarch 1983 till #131 in May 2020. The text below was not originally planned for the AARnewsletter, but was written for a colleague of his, to show a student how such a column canbe written. Larry sent this ﬁnal manuscript to Sophie Tourret in 2020 asking for feedback,but passed away before they could even start a discussion about it. We do not know if thetext ever made its way to the intended recipient, but, for sure, it would have made it to alater issue of the AAR newsletter, had Larry had time to ﬁnish it. Thus, we have decided topublish excerpts from this ﬁnal manuscript, put them into the historic context, and explaintheir relevance to automated reasoning research today.\\n2 The Column', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='2 The Column\\nThe typical column by Larry contained at least two elements: anecdotes on the (early) historyof automated reasoning followed by an open problem. Open problems came mainly fromthree areas: (ﬁnite) group theory, properties of metalogic formulations from the condenseddetachment or equivalential calculus, or logic puzzles. We present three excerpts from Larry’sﬁnal manuscript: two anecdotes from the early history of automated reasoning—namely onthe relevance of instances and the set of support strategy—and the Candy Puzzle.\\nB Christoph Weidenbach\\nweidenbach@mpi-inf.mpg.de\\n1Max Planck Institute for Informatics, Saarland Informatics Campus E1 4, 66123 Saarbrücken, Germany\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='576 S. Tourret, C. Weidenbach\\nFinding Relevant Instances: A key technique in (refutation-based) automated reasoning is\\nto identify relevant instances of universally quantiﬁed formulas. The unpublished columncontains several remarks by Larry emphasizing the role of ﬁnding such instances.\\nBy definition, automated reasoning refers to a field in\\nwhich a computer program is written that applies logicalreasoning. A person can reason in a manner that isunavailable to an automated reasoning program, a way thatis called instantiation. Instantiation is a type ofreasoning in which variables can be replaced with othervariables or with terms.\\nInstantiation of ﬁrst-order logic formulas was actually the basis of early attempts to auto-\\nmated reasoning [ 12,24] able to already automatically prove simple valid ﬁrst-order formulas.\\nWhile Gilmore [ 24] resolved quantiﬁer alternations by so called “multiplications” of ground\\ninstances of the formula, Davis and Putnam [ 12] already applied Skolemization to existen-', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='While Gilmore [ 24] resolved quantiﬁer alternations by so called “multiplications” of ground\\ninstances of the formula, Davis and Putnam [ 12] already applied Skolemization to existen-\\ntially quantiﬁed variables and instantiated with ground Herbrand terms. Noneveless, citingPrawitz “the main weakness of the ﬁrst programs for theorem proving was the manner of gen-erating substitution instances” [ 34]. Resolution was seen as—and actually still is—a major\\nbreakthrough, because it does not require guessing ground instances. However, if the set ofground instances of clauses needed for a proof is small, then explicitely generating theseground instances is to be preferred over resolving among the clauses. This fact is reﬂectedby state-of-the-art research where, e.g., InstGen [ 22] is currently the best single reasoning', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='approach to ﬁrst-order problems where a rather small set of ground instances from the inputclause set sufﬁces. InstGen is based on the instantiation of clauses guided by an abstraction ofthe ﬁrst-order clauses to propositional clauses. However, building resolvents on input clausescan lead to exponentially shorter proofs compared to solely reasoning on instances, even fordecidable fragments and small clause sets with only a few constants as the only functionsymbols [ 20,33]. For an overview of recent reasoning methods incorporating instantiation,\\nsee [ 6].\\nFor example, if you are studying groups in which the\\nsquare of every element is the identity e,and if you are\\nemploying the function fto mean product, then, with\\ninstantiation, you can obtain f(f(u,v ) , f(u,v ) )=efrom f(x,x)=\\ne.Since instantiation is unavailable for an automated\\nreasoning program, the obtaining of the precedingequation, f(f(u,v ) , f(u,v ) )=e,will not occur.\\nThe statement “instantiation is unavailable for an automated reasoning program” by Larry', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='The statement “instantiation is unavailable for an automated reasoning program” by Larry\\nmeans that ﬁnding the “relevant” instances towards a proof is often as hard as ﬁnding the proofitself. Since validity is not decidable in equational logic, ﬁnding the right instances cannotbe decidable as well, in general, hence instantiation by relevant instances is unavailablefor an automated reasoning program. Technically, almost all automated reasoning calculienable the addition of instances. The work of [ 22], see above, was actually an important step\\ntowards ﬁnding relevant instances through an abstraction into a decidable fragment, in thiscase propositional logic. For an overview on possibilities towards ﬁnding relevant instances,consider again [ 6]. Reasoning by SMT [ 32] (Satisﬁability Modulo Theories) is built on these\\nideas, see below.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='A Posthumous Contribution by Larry Wos: Excerpts from an… 577\\nNevertheless, group theory, and equational reasoning in general is a nice example for the\\npower of instantiation. Ground equations can always be oriented, e.g., by a Knuth–Bendixordering [ 26], and Knuth–Bendix completion terminates on a set of ground equalities and\\ndisequalities. Oriented equations are rewrite systems that are fundamental for many conceptsin computer science such as the semantics of programming languages and have thereforeobtained a lot of attention [ 11,13,27]. An alternative approach, typically implemented\\nin SMT [ 3,29,32] solvers, is to decide the satisﬁability of a set of ground equations by\\ncongruence closure [ 31]. Therefore, if a ﬁnite set of needed (ground) instances for a refutation\\nis known in advance, then the problem of whether a conjectured equation is a consequenceof other equations turns from being undecidable, in general, into a decidable problem.\\n1979 was the year that Veroff began to express an interest\\nin automated reasoning, and he has remained interested', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='1979 was the year that Veroff began to express an interest\\nin automated reasoning, and he has remained interested\\never since. In 1996, Veroff introduced his hints strategyfor directing a program’s reasoning in a manner thatproved to be more effective than is weighting.He introduced his “sketches” in 2001, an approach thatenabled him to answer various open questions.\\nV eroff introduced hints [42] to direct the proof search, integrated in Otter [ 28], the role\\nmodel of all modern theorem provers, designed by Bill McCune. Otter has a sophisticatedweight system for clauses. In its simplest form, the weight of the clause is the sum of the\\nweights of its symbols, and clauses with a small weight are preferred for performing infer-ences during proof search. A clause weighting mechanism is an inherent ingredient of all oftoday’s implementations of saturation-based theorem provers [ 5,18,36,38,41,45]. The hint', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='technique introduced by V eroff adds to the clause weighting mechanism: clauses subsumedby the hint clause or clauses subsuming the hint clause receive special treatment with respectto their weight. For example, if certain clauses sharing some abstract structure are thought tobe essential in ﬁnding a proof, then a clause representing this abstract structure can be usedas a hint clause. Then any clause that is subsumed, i.e., a superset of an instance of the hintclause, can be preferred for performing further inferences. In an extreme setting, hints cansimulate the restriction of inferences to certain ground instances. V eroff successfully used theclause hint technique to ﬁnd and analyze proofs [ 43] and combined it with another technique\\ncalled proof sketches . A proof sketch is an incomplete, possibly incorrect proof that is then\\nused to guide the search for a correct proof. A proof sketch may be obtained by an abstractionof the actual problem, for example by replacing non-variable terms with fresh variables.\\nThis idea of restricting inferences and instantiation to certain patterns plays also an impor-\\ntant role in SMT solving. Based on ideas from the Nelson-Oppen combination procedure [ 7,\\n9,10,16,30], modern SMT solvers are highly efﬁcient decision procedures for the ground', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='tant role in SMT solving. Based on ideas from the Nelson-Oppen combination procedure [ 7,\\n9,10,16,30], modern SMT solvers are highly efﬁcient decision procedures for the ground\\ncombination of several theories, e.g., ground ﬁrst-order logic with equality combined withground arithmetic—on this topic, see also The Candy puzzle, page 5. If this approach needs toconsider problems that also contain universally quantiﬁed formulas, it does so by consecutiveadditions of ground instances of these formulas. The research on this topic started with theSimplify system [ 14], where so-called triggers are used to generate ground instances out of', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='universally quantiﬁed formulas. A trigger is a term and only instances of this term are used forproof search, similar to the concept of hints. Simplify makes additional use of the decidabil-ity of equational reasoning on the ground level. It builds an explicit model of the generatedcongruence and then prefers instances of the trigger that are related to the congruence. Thisidea was generalized to consider ground models not only for an equational theory, but also\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='578 S. Tourret, C. Weidenbach\\nfor other theories for restricting the generation of ground instances [ 15,23]. More recently,\\nit has turned out that, as a last resort and if done with care, even an enumeration of possibleground instances can result in an efﬁcient system [ 35]. In summary, the ideas suggested by\\nLarry and his collaborators have inﬂuenced future research and are still further developednowadays, in particular in the areas of ﬁrst-order theorem proving and SMT solving.The Set Of Support Strategy: Another anecdote by Larry is on the origin of the set of support\\nstrategy [ 47].\\nIn a summer visit, Willam F. Miller, Director of the\\nApplied Mathematics Division at Argonne NationalLaboratory, invited John Alan Robinson. Miller introducedRobinson to Larry Wos and to Dan Carson, an introduction\\nthat had unbelievable consequences for the field that', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='Applied Mathematics Division at Argonne NationalLaboratory, invited John Alan Robinson. Miller introducedRobinson to Larry Wos and to Dan Carson, an introduction\\nthat had unbelievable consequences for the field that\\nwould eventually be called automated reasoning. WhileRobinson was visiting Argonne, he introduced his newinference rule that he called binary resolution.The introduction of the inference rule binary resolutionchanged the course of history for automatedreasoning forever.[...]When Carson, who was a brilliant programmer in IBMassembly, learned of the new inference rule, he wrote amechanical theorem-proving program encoding the rule.Carson and Wos used his program in an attempt to prove atrivial theorem in group theory. Carson’s program wasunable to find the sought-after proof. The theorem assertsthat, if the square of every element xin the group is the\\nidentity e, then the group is a commutative group,\\nf(x,y)=f(y,x)for every element in the group. Carson called', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='identity e, then the group is a commutative group,\\nf(x,y)=f(y,x)for every element in the group. Carson called\\nme by phone and said that, if I had nothing to suggest,we were finished, and he gave me forty-five minutes tocome up with something. After thirty-two minutes hadelapsed, he called again, and I told him about the set ofsupport strategy. Carson eagerly asked for permission toextend his program so that the program could apply the newstrategy. The rest is history: with the extended program,the sought-after proof was found and found in less than3 CPU-seconds. If Carson had not been so impatient,the use of some type of strategy would never have occurred.He is a hero for, without strategy, proofs would almostnever be found with a program that reasons logically.[...]Learning about the set of support strategy, Robinson setabout to prove that the strategy is refutation complete.\\nThe encoding of the group theory used at that time by Wos and his collaborators was\\nthe following [ 46,47]: the group operation is modeled by a ternary predicate P,w h e r e\\nP(x,y,z)stands for the group multiplication of xand yresulting in z. Using this predicate,\\nbasic properties of a group can be axiomatized. For example, associativity was represented by', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='P(x,y,z)stands for the group multiplication of xand yresulting in z. Using this predicate,\\nbasic properties of a group can be axiomatized. For example, associativity was represented by\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='A Posthumous Contribution by Larry Wos: Excerpts from an… 579\\nclauses like ¬P(x,y,u)∨¬ P(y,z,v )∨¬ P(u,z,w )∨P(x,v ,w ) by introducing explicit\\nresult variables for the sub-products. However, a group theory axiomatization solely built onthis predicate Pis not complete, in general, because Pis a relation and does not represent\\nthat the group operation is a function nor that it is total. For cases where this is needed, e.g.,proving that a group where the square of each element is the identity is commutative, anadditional binary predicate Rfor equality was added together with the equivalence relation\\naxioms for Rand the congruence axioms for Pand used functions. For example, for the\\nfunction fexpressing totality by the unit P(x,y,f(x,y))the congruence axiom ¬R(x,x\\n′)∨\\n¬R(y,y′)∨R(f(x,y),f(x′,y′))was added, for the group multiplication the congruence', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='′)∨\\n¬R(y,y′)∨R(f(x,y),f(x′,y′))was added, for the group multiplication the congruence\\naxiom ¬R(x,x′)∨¬ R(y,y′)∨¬ R(z,z′)∨¬ P(x,y,z)∨P(x′,y′,z′). The motivation for\\nthis encoding was to not expose the group multiplication to full equational reasoning whichturned out to be far more successfull, because Knuth–Bendix completion and equationalreasoning [ 26,37] were not yet developed at this time. The problem was attacked by resolution\\nthrough a partial axiomatization of equality, depending on what was needed for the actualproblem at hand. A number of different axiomatizations following this approach can be foundin [46]. Using such a formulation without speciﬁc equational reasoning, such problems are\\nstill a challenge to today’s automated reasoning systems. Examples of such encodings arecontained in the TPTP [ 40], e.g., the above-mentioned problem is called GRP001-1 in the\\nTPTP .\\nThe set of support strategy consists of dividing an unsatisﬁable clause set into two disjoint', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='TPTP .\\nThe set of support strategy consists of dividing an unsatisﬁable clause set into two disjoint\\nsets Nand S. Then, any resolution inference is restricted to use at least one clause from S,\\nthe set of support. Newly derived clauses are added to S. Wos together with his collaborators\\nshowed [ 47] that this restriction of the resolution calculus is complete if Nis satisﬁable. In\\na setting where a conjecture is to be shown from a set of satisﬁable axioms, such a setup caneasily be obtained by putting the axiom formulas into Nand the (negated) conjecture into S.\\nRecently, it has been shown that for completeness of the set of support strategy, it is necessaryand sufﬁcient that there exists a resolution refutation with at least one clause from S[25].\\nThe set of support strategy has become an integral part of many approaches to automatedreasoning. It is implemented in all ﬁrst-order logic resolution-based theorem provers [ 5,18,\\n36,38,41,45]. In case of additional ordering restrictions, it is still complete if the set Nis', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='36,38,41,45]. In case of additional ordering restrictions, it is still complete if the set Nis\\nclosed under non-redundant inferences. In the purely equational case, this boils down to thegeneration of all critical pairs modulo rewriting and elimination of trivial equations, and inthe case of ﬁrst-order logic with equality to the generation of all superposition inferencesmodulo redundancy [ 1].\\nThe Candy Puzzle: Puzzles have a long history in motivating automated reasoning research\\nby showing deﬁciencies of state-of-the-art reasoning calculi or systems. An early example isSchubert’s Steamroller problem [ 39], a puzzle that was not easy to solve without a concept\\nof typing and, therefore, motivated research in this direction. Larry’s manuscript containedthe following puzzle.\\nCandy Puzzle\\nJane’s Confections is an old-fashioned sweet shop next tothe old post office in Chicago, and sweet-toothed Illinoisresidents traveled many a mile to buy chocolate and caram-els, as they did when they were kids.This afternoon, four locals, all on their way to collecttheir children from a nearby junior high school, have pop-ped in to buy a bag of something scrumptious. From the clu-\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='580 S. Tourret, C. Weidenbach\\nes, can you say at what time each customer called, and what\\nweight of what sugary treat Jane sold them?\\n1. Tobias nipped in later than Sarah and bought one and\\na quarter pound more of his chosen sweet than the pur-chaser of toffee bought of toffee.\\n2. The customer who bought 3 pounds of creams was not the\\ncustomer who came in as the clock struck 3.\\n3. The second customer of these four bought one and a half\\npounds more humbugs than Ursula bought of her favoriteconfection.\\n4. Virgil bought one and a half pounds more of his selected\\nsweet than did the person who walked into the shop at3:10 but who did not buy lemondrops.\\n5. The customers called at 3, 3:05, 3:10, and 3:15.\\n6. They bought one and three quarter pounds, three pounds,\\nthree pounds and a quarter pound, and four and a halfpounds.\\nThe ﬁrst exercise is to solve the puzzle with the help of an automated reasoning system:\\nChallenge:\\n(1) Formulate the puzzle in logic and let an automated reasoning system ﬁnd the solution.\\nImplicitly, the assumption is that all mentioned constants occur exactly once in the solution.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='Challenge:\\n(1) Formulate the puzzle in logic and let an automated reasoning system ﬁnd the solution.\\nImplicitly, the assumption is that all mentioned constants occur exactly once in the solution.\\nFor example, every customer does exactly one purchase, each different sweet is bought exactlyonce, etc. Then the puzzle boils down to a ﬁnite domain problem with 4\\n4different possibilities\\nof a single purchase. It can then be formalized in pure ﬁrst-order logic—without theories—oreven translated into propositional logic and solved that way. Solving the puzzle amounts toﬁnding a model for the formalization, a task that is more difﬁcult than ﬁnding a refutation(proof). We did a formalization in ﬁrst-order logic and both SPASS [ 45]a n dV a m p i r e[ 36]ﬁ n d\\na solution in less than a second thanks to splitting [ 44]. Also the grounding of the ﬁrst-order\\nformulization can be immediately solved by any SA T solver starting at the performanceof MiniSat [ 19]. However, these formalizations require the explicit axiomatization of the', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='formulization can be immediately solved by any SA T solver starting at the performanceof MiniSat [ 19]. However, these formalizations require the explicit axiomatization of the\\nneeded arithmetic and linear-order concepts and properties involved in the puzzle. A morenatural formulization is possible in a ﬁrst-order logic over linear arithmetic. We could use afour-place predicate Pwhere P(u,x,y,z)means that ubought the amount xofyat time\\nz. For the timing we use the values 300, 305, 310, and 315 and for the amount the values in\\nquarter pounds, i.e., 7, 12, 13, and 18. Then a complete formalization is as follows. Firstly,we declare the existence of the four purchases\\nP(Tobias ,at,bt,ct)∧P(Sarah ,as,bs,cs)∧\\nP(Ursula ,au,bu,cu)∧P(Virgil ,av,bv,cv)\\nwhere all symbols starting with a,b,o r care constants (existentially quantiﬁed variables).\\nThen, we get from the ﬁrst clue\\n1.aP(Tobias ,x,y,z)∧P\\n(Sarah ,x′,y′,z′)→ z>z′', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='Then, we get from the ﬁrst clue\\n1.aP(Tobias ,x,y,z)∧P\\n(Sarah ,x′,y′,z′)→ z>z′\\n1.bP(Tobias ,x,y,z)∧P(u,x′,toffee ,z′)→ x=x′+5\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='A Posthumous Contribution by Larry Wos: Excerpts from an… 581\\nwhere all variables x,y,z,u(with primes) are universally quantiﬁed and ∧binds stronger\\nthan→. The second clue becomes\\n2P(c21,12,creams ,c22)∧c22̸=300\\nwhere the constants c21and c22are ﬁnally mapped by the ﬁnite domain axioms to the available\\ntimings, and persons. The clues three and four become\\n3P(c31,au+6,humbugs ,305 )∧c31̸=Ursula\\n4P(c41,av−6,c42,310 )∧c41̸=Virgil ∧c42̸=lemondrops\\nand the remaining clues are contained in the ﬁnite domain axioms.\\n5P(u,x,y,z)→ (z=300∨z=305∨z=310∨z=315 )\\n6P(u,x,y,z)→ (x=7∨x=12∨x=13∨x=18)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='6P(u,x,y,z)→ (x=7∨x=12∨x=13∨x=18)\\n7P(u,x,y,z)→ (y=toffee ∨y=creams ∨y=humbugs ∨y=lemondrops )\\n8P(u,x,y,z)→ (u=Tobias ∨u=Sarah ∨u=Ursula ∨u=Virgil )\\nSolving the puzzle formulated this way is a challenge. To the best of our knowledge, there\\nis no automated reasoning tool that can, without further massage, derive a solution fromthis formalization. We tried the SMT solvers CVC4 [ 4]a n dZ 3[ 17] without success. Also,\\napproaches based on resolution-style reasoning over constraint clauses will not succeed aslong as the ﬁnite domain axioms do not get special treatment [ 2,8]. One reason is the', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='approaches based on resolution-style reasoning over constraint clauses will not succeed aslong as the ﬁnite domain axioms do not get special treatment [ 2,8]. One reason is the\\ncombination of constants and universally quantiﬁed variables over numbers which, togetherwith ﬁrst-order predicates, leads to a logic that is no longer compact, in general. Recall thatcompactness here means that for every inﬁnite unsatisﬁable set of clauses there exists alwaysﬁnite unsatisﬁable subset. For example, the combination of ﬁrst-order predicates and linearrational arithmetic already enables the deﬁnition of the natural numbers and the introductionof a single constant can then cause non-compactness [ 21]. The formulas\\nNat (0)\\nNat (x)→Nat (x+1)\\nx<0→¬ Nat (x)\\n0<x<1→¬ Nat (x)\\nx>0∧Nat (x+1)→Nat (x)\\ndeﬁne the natural numbers with respect to a universally quantiﬁed variable xranging over the\\nrationals using the predicate Nat. Non-compactness arises when this deﬁnition is combinedwith the four formulas\\nNat (a)\\nP(0)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='rationals using the predicate Nat. Non-compactness arises when this deﬁnition is combinedwith the four formulas\\nNat (a)\\nP(0)\\nP(x)→ P(x\\n+1)\\n¬P(a)\\nfor some constant a. The combination of all the formulas is unsatisﬁable; however, every\\nﬁnite grounding of the formulas has a model. Still the above formulation of the puzzle issolvable, and even decidable because of the ﬁnite domain axioms. Further challenges are thefollowing:\\nChallenge:\\n(2) Is the solution from the clues unique?\\n(3) If clue six is removed, is it possible to derive automatically the amounts for the purchases?\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='582 S. Tourret, C. Weidenbach\\nConclusion: The scientiﬁc contributions by Larry Wos have shaped automated reasoning.\\nEven in his later years, his columns continued to offer relevant insight into the past ofautomated reasoning and presented challenges that are still relevant to automated reasonersnowadays. Larry Wos was a founder of automated reasoning. He died on 20 August 2020.\\nFunding Open Access funding enabled and organized by Projekt DEAL.\\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which\\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you giveappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence,and indicate if changes were made. The images or other third party material in this article are included in thearticle’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material isnot included in the article’s Creative Commons licence and your intended use is not permitted by statutoryregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/ .\\nReferences', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='References\\n1. Bachmair, L., Ganzinger, H.: Rewrite-based equational theorem proving with selection and simpliﬁcation.\\nJ. Log. Comput. 4(3), 217–247 (1994)\\n2. Bachmair, L., Ganzinger, H., Waldmann, U.: Refutational theorem proving for hierarchic ﬁrst-order\\ntheories. Appl. Algebra Eng. Commun. Comput. 5, 193–212 (1994)\\n3. Barrett, C.W., Sebastiani, R., Seshia, S.A., Tinelli, C.: Satisﬁability modulo theories. In: Biere, A., Heule,\\nM., van Maaren, H., Walsh, T. (eds.) Handbook of Satisﬁability. Frontiers in Artiﬁcial Intelligence andApplications, vol. 185, pp. 825–885. IOS Press (2009)\\n4. Barrett, C.W., Conway, C.L., Deters, M., Hadarean, L., Jovanovic, D., King, T., Reynolds, A., Tinelli,', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='4. Barrett, C.W., Conway, C.L., Deters, M., Hadarean, L., Jovanovic, D., King, T., Reynolds, A., Tinelli,\\nC.: CVC4. In: Gopalakrishnan, G., Qadeer, S. (eds.) Computer Aided V eriﬁcation - 23rd InternationalConference, CA V 2011, Snowbird, UT, USA, July 14–20, 2011. Proceedings, Springer, Lecture Notes inComputer Science, vol. 6806, pp. 171–177 (2011)\\n5. Bentkamp, A., Blanchette, J., Cruanes, S., Waldmann, U.: Superposition for lambda-free higher-order\\nlogic. Log. Methods Comput. Sci. 17(2), 1–38 (2021)\\n6. Bonacina, M.P ., Furbach, U., Sofronie-Stokkermans, V .: On ﬁrst-order model-based reasoning. In: Martí-', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='6. Bonacina, M.P ., Furbach, U., Sofronie-Stokkermans, V .: On ﬁrst-order model-based reasoning. In: Martí-\\nOliet, N., Ölveczky, P .C., Talcott, C.L. (eds.) Logic, Rewriting, and Concurrency—Essays dedicated toJosé Meseguer on the Occasion of His 65th Birthday, Springer, Lecture Notes in Computer Science, vol.9200, pp. 181–204 (2015)\\n7. Bonacina, M.P ., Fontaine, P ., Ringeissen, C., Tinelli, C.: Theory combination: beyond equality sharing.\\nIn: Lutz, C., Sattler, U., Tinelli, C., Turhan, A., Wolter, F. (eds.) Description Logic, Theory Combination,and All That—Essays Dedicated to Franz Baader on the Occasion of His 60th Birthday, Springer, LectureNotes in Computer Science, vol. 11560, pp. 57–89 (2019)\\n8. Bromberger, M., Fiori, A., Weidenbach, C.: Deciding the Bernays–Schoenﬁnkel fragment over bounded', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='8. Bromberger, M., Fiori, A., Weidenbach, C.: Deciding the Bernays–Schoenﬁnkel fragment over bounded\\ndifference constraints by simple clause learning over theories. In: Henglein, F., Shoham, S., Vizel, Y . (eds.)V eriﬁcation, Model Checking, and Abstract Interpretation - 22nd International Conference, VMCAI 2021,Copenhagen, Denmark, January 17–19, 2021, Proceedings, Springer, Lecture Notes in Computer Science,vol. 12597, pp. 511–533 (2021)\\n9. Bruttomesso, R., Cimatti, A., Franzén, A., Griggio, A., Sebastiani, R.: Delayed theory combination vs.\\nNelson–Oppen for satisﬁability modulo theories: a comparative analysis. Ann. Math. Artif. Intell. 55(1–2),\\n63–99 (2009)\\n10. Chocron, P .D., Fontaine, P ., Ringeissen, C.: Politeness and combination methods for theories with bridging\\nfunctions. J. Autom. Reason. 64(1), 97–134 (2020)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='63–99 (2009)\\n10. Chocron, P .D., Fontaine, P ., Ringeissen, C.: Politeness and combination methods for theories with bridging\\nfunctions. J. Autom. Reason. 64(1), 97–134 (2020)\\n11. Comon, H., Godoy, G., Nieuwenhuis, R.: The conﬂuence of ground term rewrite systems is decidable in\\npolynomial time. In: 42nd Annual Symposium on Foundations of Computer Science, FOCS 2001, 14–17October 2001, pp. 298–307. Nevada, USA, IEEE Computer Society, Las V egas (2001)\\n12. Davis, M., Putnam, H.: A computing procedure for quantiﬁcation theory. J. ACM 7(3), 201–215 (1960)\\n13. Dershowitz, N., Plaisted, D.A.: Rewriting. In: Robinson, J.A., V oronkov, A. (eds.) Handbook of Auto-\\nmated Reasoning, vol. 2, pp. 535–610. Elsevier and MIT Press (2001)\\n14. Detlefs, D., Nelson, G., Saxe, J.B.: Simplify: a theorem prover for program checking. J. ACM 52(3),', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='14. Detlefs, D., Nelson, G., Saxe, J.B.: Simplify: a theorem prover for program checking. J. ACM 52(3),\\n365–473 (2005)\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='A Posthumous Contribution by Larry Wos: Excerpts from an… 583\\n15. de Moura, L.M., Bjørner, N.: Efﬁcient e-matching for SMT solvers. In: Pfenning, F. (ed.) Automated\\nDeduction—CADE-21, 21st International Conference on Automated Deduction, Bremen, Germany, July17–20, 2007, Proceedings, Springer, Lecture Notes in Computer Science, vol. 4603, pp. 183–198 (2007)\\n16. de Moura, L.M., Bjørner, N.: Model-based theory combination. Electron. Notes Theor. Comput. Sci.\\n198(2), 37–49 (2008)\\n17. de Moura, L.M., Bjørner, N.: Z3: an efﬁcient SMT solver. In: Ramakrishnan, C.R., Rehof, J. (eds.) Tools\\nand Algorithms for the Construction and Analysis of Systems, 14th International Conference, TACAS2008, Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2008,\\nBudapest, Hungary, March 29–April 6, 2008. Proceedings, Springer, Lecture Notes in Computer Science,', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='Budapest, Hungary, March 29–April 6, 2008. Proceedings, Springer, Lecture Notes in Computer Science,\\nvol. 4963, pp. 337–340 (2008)\\n18. Duarte, A., Korovin, K.: Implementing superposition in iProver (system description). In: Peltier, N.,\\nSofronie-Stokkermans, V . (eds.) Automated Reasoning—10th International Joint Conference, IJCAR2020, Paris, France, July 1–4, 2020, Proceedings, Part II, Springer, Lecture Notes in Computer Science,vol. 12167, pp. 388–397 (2020)\\n19. Eén, N., Sörensson, N.: An extensible SA T-solver. In: Giunchiglia, E., Tacchella, A. (eds.) Theory and\\nApplications of Satisﬁability Testing, 6th International Conference, SA T 2003. Santa Margherita Ligure,Italy, May 5–8, 2003 Selected Revised Papers, Springer, Lecture Notes in Computer Science, vol. 2919,pp. 502–518 (2003)\\n20. Fiori, A., Weidenbach, C.: SCL clause learning from simple models. In: Fontaine, P . (ed.) Automated', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='20. Fiori, A., Weidenbach, C.: SCL clause learning from simple models. In: Fontaine, P . (ed.) Automated\\nDeduction—CADE 27—27th International Conference on Automated Deduction, Natal, Brazil, August27–30, 2019, Proceedings, Springer, Lecture Notes in Computer Science, vol. 11716, pp. 233–249 (2019)\\n21. Fiori, A., Weidenbach, C.: SCL with Theory Constraints. CoRR arXiv:2003.04627 (2020)\\n22. Ganzinger, H., Korovin, K.: New directions in instantiation-based theorem proving. In: 18th IEEE Sym-\\nposium on Logic in Computer Science (LICS 2003), 22–25 June 2003, Ottawa, Canada, Proceedings,\\nIEEE Computer Society, pp. 55–64 (2003)\\n23. Ge, Y ., de Moura, L.M.: Complete instantiation for quantiﬁed formulas in satisﬁabiliby modulo theories.\\nIn: Computer Aided V eriﬁcation, 21st International Conference, CA V 2009, Grenoble, France, June 26–July 2, 2009. Proceedings, Springer, Lecture Notes in Computer Science, vol. 5643, pp. 306–320 (2009)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='24. Gilmore, P .C.: A proof method for quantiﬁcation theory: its justiﬁcation and realization. IBM J. Res. Dev.\\n4(1), 28–35 (1960)\\n25. Haifani, F., Tourret, S., Weidenbach, C.: Generalized completeness for SOS resolution and its application\\nto a new notion of relevance. In: Platzer, A., Sutcliffe, G. (eds.) Automated Deduction—CADE 28—28th International Conference on Automated Deduction, Virtual Event, July 12–15, 2021, Proceedings,Springer, Lecture Notes in Computer Science, vol. 12699, pp. 327–343 (2021)\\n26. Knuth, D.E., Bendix, P .B.: Simple word problems in universal algebras. In: Leech, I. (ed.) Computational\\nProblems in Abstract Algebra, pp. 263–297. Pergamon Press (1970)\\n27. Lankford Dallas, S.: Canonical inference. Technical Report A TP-32, Southwestern University, George-\\ntown, Texas (1975)\\n28. McCune, W.: OTTER 2.0. In: Stickel, M.E. (ed.) 10th International Conference on Automated Deduction,', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='town, Texas (1975)\\n28. McCune, W.: OTTER 2.0. In: Stickel, M.E. (ed.) 10th International Conference on Automated Deduction,\\nKaiserslautern, FRG, July 24–27, 1990, Proceedings, Springer, Lecture Notes in Computer Science, vol.\\n449, pp. 663–664 (1990)\\n29. Monniaux, D.: A survey of satisﬁability modulo theory. In: Gerdt, V .P ., Koepf, W., Seiler, W.M.,\\nV orozhtsov, E.V . (eds.) Computer Algebra in Scientiﬁc Computing—18th International Workshop, CASC2016, Bucharest, Romania, September 19–23, 2016, Proceedings, Springer, Lecture Notes in ComputerScience, vol. 9890, pp. 401–425 (2016)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='30. Nelson, G., Oppen, D.C.: Simpliﬁcation by cooperating decision procedures. ACM Trans. Program. Lang.\\nSyst. 1(2), 245–257 (1979)\\n31. Nelson, G., Oppen, D.C.: Fast decision procedures based on congruence closure. J. ACM 27(2), 356–364\\n(1980)\\n32. Nieuwenhuis, R., Oliveras, A., Tinelli, C.: Solving SA T and SA T modulo theories: from an abstract\\nDavis–Putnam–Logemann–Loveland procedure to dpll(T). J. ACM 53(6), 937–977 (2006)\\n33. Pérez, J.A.N., V oronkov, A.: Proof systems for effectively propositional logic. In: Armando, A., Baum-\\ngartner, P ., Dowek, G. (eds.) Automated Reasoning, 4th International Joint Conference, IJCAR 2008,Sydney, Australia, August 12–15, 2008, Proceedings, Springer, Lecture Notes in Computer Science, vol.5195, pp. 426–440 (2008)\\n34. Prawitz, D.: Commentary by the author: an improved proof procedure. In: Siekmann, J., Wrightson, G.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='34. Prawitz, D.: Commentary by the author: an improved proof procedure. In: Siekmann, J., Wrightson, G.\\n(eds.) Automation of Reasoning: Classical Papers on Computational Logic, vol. 1, pp. 159–161. Springer\\n(1983)\\n35. Reynolds, A., Barbosa, H., Fontaine, P .: Revisiting enumerative instantiation. In: Beyer, D., Huisman, M.\\n(eds.) Tools and Algorithms for the Construction and Analysis of Systems—24th International Confer-\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='584 S. Tourret, C. Weidenbach\\nence, TACAS 2018, Held as Part of the European Joint Conferences on Theory and Practice of Software,\\nETAPS 2018, Thessaloniki, Greece, April 14–20, 2018, Proceedings, Part II, Springer, Lecture Notes inComputer Science, vol. 10806, pp. 112–131 (2018)\\n36. Riazanov, A., V oronkov, A.: The design and implementation of V AMPIRE. AI Commun. 15(2–3), 91–110\\n(2002)\\n37. Robinson, J.A., V oronkov, A. (eds.): Handbook of Automated Reasoning, vol. 2. Elsevier and MIT Press\\n(2001)\\n38. Schulz, S., Cruanes, S., Vukmirovic, P .: Faster, higher, stronger: E 2.3. In: Fontaine, P . (ed.) Automated\\nDeduction—CADE 27—27th International Conference on Automated Deduction, Natal, Brazil, August\\n27–30, 2019, Proceedings, Springer, Lecture Notes in Computer Science, vol. 11716, pp. 495–507 (2019)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='27–30, 2019, Proceedings, Springer, Lecture Notes in Computer Science, vol. 11716, pp. 495–507 (2019)\\n39. Stickel, M.E.: Schubert’s steamroller problem: formulation and solutions. J. Autom. Reason. 2(1), 89–101\\n(1986)\\n40. Sutcliffe, G.: The TPTP problem library and associated infrastructure—from CNF to TH0, TPTP v.6.4.0.\\nJ. Autom. Reason. 59(4), 483–502 (2017)\\n41. Tammet, T.: GKC: a reasoning system for large knowledge bases. In: Fontaine, P . (ed.) Automated\\nDeduction—CADE 27—27th International Conference on Automated Deduction, Natal, Brazil, August27–30, 2019, Proceedings, Springer, Lecture Notes in Computer Science, vol. 11716, pp. 538–549 (2019)\\n42. V eroff, R.: Using hints to increase the effectiveness of an automated reasoning program: case studies. J.\\nAutom. Reason. 16(3), 223–239 (1996)\\n43. V eroff, R.: Solving open questions and other challenge problems using proof sketches. J. Autom. Reason.\\n27(2), 157–174 (2001)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='43. V eroff, R.: Solving open questions and other challenge problems using proof sketches. J. Autom. Reason.\\n27(2), 157–174 (2001)\\n44. Weidenbach, C.: Combining superposition, sorts and splitting. In: Robinson, J.A., V oronkov, A. (eds.)\\nHandbook of Automated Reasoning, vol. 2, pp. 1965–2013. Elsevier and MIT Press (2001)\\n45. Weidenbach, C., Dimova, D., Fietzke, A., Kumar, R., Suda, M., Wischnewski, P .: SPASS version 3.5.\\nIn: Schmidt, R.A. (ed.) Automated Deduction—CADE-22, 22nd International Conference on Automated\\nDeduction, Montreal, Canada, August 2–7, 2009. Proceedings, Springer, Lecture Notes in ComputerScience, vol. 5663, pp. 140–145 (2009)\\n46. Wos, L., Carson, D.F., Robinson, G.A.: The unit preference strategy in theorem proving. In: Proceedings\\nof the 1964 fall Joint Computer Conference, part I, AFIPS 1964 (Fall, part I), San Francisco, California,USA, October 27–29, 1964, ACM, pp. 615–621 (1964)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='of the 1964 fall Joint Computer Conference, part I, AFIPS 1964 (Fall, part I), San Francisco, California,USA, October 27–29, 1964, ACM, pp. 615–621 (1964)\\n47. Wos, L., Robinson, G.A., Carson, D.F.: Efﬁciency and completeness of the set of support strategy in\\ntheorem proving. J. ACM 12(4), 536–541 (1965)\\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and\\ninstitutional afﬁliations.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-022-09617-3.pdf', 'link': 'https://openalex.org/works/W4210619513', 'title': 'A Posthumous Contribution by Larry Wos: Excerpts from an Unpublished Column'}),\n",
              " Document(page_content='arXiv:1610.06501v2  [math.PR]  1 Dec 2021Importance samplingforasimple Markovianintensity\\nmodelusingsubsolutions\\nBOUALEM DJEHICHE, HENRIK HULT, and PIERRE NYQUIST, Department of Mathematics,\\nKTHRoyal Instituteof Technology,Sweden\\nThispaperconsidersimportancesamplingforestimationof rare-event probabilitiesinaspeciﬁccollectionof\\nMarkovian jump processes usedfor e.g. modelling of credit r isk. Previous attempts at designing importance\\nsamplingalgorithmshaveresultedinpoorperformanceandt hemaincontributionofthepaperisthedesign\\nof eﬃcient importancesampling algorithms usingsubsoluti ons.Thedynamics of thejumpprocesses causes\\nthecorrespondingHamilton-Jacobiequationstohaveanint ricatestate-dependence,whichmakesthedesign\\nof eﬃcient algorithms diﬃcult. We provide theoretical resu lts that quantify the performance of importance\\nsampling algorithms in general and construct asymptotical ly optimal algorithms for some examples. The\\ncomputationalgain comparedtostandard MonteCarlois illu stratedbynumerical examples.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='sampling algorithms in general and construct asymptotical ly optimal algorithms for some examples. The\\ncomputationalgain comparedtostandard MonteCarlois illu stratedbynumerical examples.\\nCCS Concepts: • Mathematicsof computing →Probabilityandstatistics ;Stochasticprocesses ;\\nAdditionalKeyWordsandPhrases:Largedeviations,MonteC arlo,importancesampling,Markovianintensity\\nmodels,credit risk\\nACM Reference Format:\\nBoualemDjehiche,HenrikHult,andPierreNyquist.2020.Im portancesamplingforasimpleMarkovianinten-\\nsitymodelusingsubsolutions. ACMTrans.Model.Comput.Simul. 0,0,Article0(2020), 25pages.https://doi.org/0\\n1 INTRODUCTION\\nIn this paper we analyse and develop Monte Carlo methods for rare -event estimation in certain\\nMarkovianintensitymodels,aclassofstochasticjumpmodels wherethejump-intensitiesareMar-\\nkovianwithrespecttodeterministic functionsofthecurrentst ateoftheentiresystem.Suchmod-\\nelsareprevalentine.g.operationsresearch—particularlyi ntheﬁnancialcontext,seee.g.[ 40]and', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='elsareprevalentine.g.operationsresearch—particularlyi ntheﬁnancialcontext,seee.g.[ 40]and\\nthereferencestherein,andforqueueingmodels[ 2]—stochasticchemicalkinetics[ 1,39],andpop-\\nulationmodels[ 32,34].Fornon-trivialjump-intensities,explicitcomputationsbec omeintractable\\nand there isa needforeﬃcient computational methods.\\nWefocusourstudyonaparticularclassofmodels,previousl yusedfore.g.creditriskmodelling,\\nfor which the construction of eﬃcient computational schemes tu rns out to be very challenging.\\nSpeciﬁcally, we consider the diﬃcult task of designing eﬃcient i mportance sampling algorithms\\nfor Markovian intensity models of the form used in [ 10]. In [10,11] the authors study diﬀerent\\ntypesofMonteCarlomethodsforestimatingrare-eventprobabi lities,correspondingtolargeport-\\nfoliolosses,intwomodelsforcreditrisk.In[ 10]bothimportancesamplingandinteractingparticle', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='foliolosses,intwomodelsforcreditrisk.In[ 10]bothimportancesamplingandinteractingparticle\\nsystemsareusedtoestimatetheprobabilityoflargeportfo liolossesbeforeaﬁxedtimehorizonand\\nAuthors’address:BoualemDjehiche,boualem@kth.se;HenrikH ult,hult@kth.se;PierreNyquist, pierren@kth.se,Depart-\\nment ofMathematics, KTHRoyal Instituteof Technology, Stockhol m, Sweden,10044.\\nPermission to make digital or hard copies of all or part of this work f or personal or classroom use is granted without fee\\nprovided that copies are not made or distributed for proﬁt or comme rcial advantage and that copies bear this notice and\\nthe full citation on the ﬁrst page. Copyrights for components of th is work owned by others than ACM must be honored.\\nAbstractingwithcreditispermitted.Tocopy otherwise,orrepublis h,topost onserversortoredistributetolists,requires\\nprior speciﬁc permission and/or afee.Request permissions fromperm issions@acm.org.\\n© 2020Association for Computing Machinery.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='prior speciﬁc permission and/or afee.Request permissions fromperm issions@acm.org.\\n© 2020Association for Computing Machinery.\\nXXXX-XXXX/2020/0-ART0$15.00\\nhttps://doi.org/0\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:2 Djehiche, Hultand Nyquist\\nitisshownthatbothschemesresultinpoorperformancefordi ﬀerent instancesoftheunderlying\\nmodel.\\nImportance sampling is one of the most successful approaches to rare-event sampling and has\\nbeen used in a wide array of areas in applied probability [ 3,35]. In recent years, two main sys-\\ntematicapproacheshaveemergedforthe designofprovably e ﬃcient methods:onebased oncon-\\nstructing appropriate Lyapunov functions, developed mainly by B lanchet, Glynn and co-authors\\n—see e.g. [ 4–8]—and one based on linking importance sampling to appropriate (sub )solutions of\\nHamilton-Jacobiequations,developed by Dupuis, Wangand co-au thors—seee.g.[ 9,14,16–22].\\nIn this work, we use the subsolution approach to address the p roblem studied in [ 10]. For the\\nmodel in [ 10] we obtain asymptotically optimal importance sampling algor ithms and, for a natu-\\nralgeneralisation ofthatmodel,we showhowthe subsolution approachcanbe usedtoconstruct\\neﬃcient algorithms, validated by their performance in numeric al experiments. To the best of our', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='ralgeneralisation ofthatmodel,we showhowthe subsolution approachcanbe usedtoconstruct\\neﬃcient algorithms, validated by their performance in numeric al experiments. To the best of our\\nknowledge,this is the ﬁrst work to apply the subsolution appr oach to obtain eﬃcient algorithms\\nin the setting of pure-jump processes with jump rates that hav e a non-zero gradient on a set of\\npositive measure. This is diﬀerent from, for example, queuei ng models, where importance sam-\\npling has been used extensively, the qualitative diﬀerence bei ng that in the setting considered\\nhere,aﬃnefunctionsofthestateoftheprocesswillnotproducee ﬃcientalgorithms.Rather,here\\nthe gradient ofthe subsolution must also bestate-dependent.\\nThemodellingofcreditriskanddefaultsinlargeportfoliosh asseenmuchworkinrecentyears,\\nin addition to [ 10,11], see for example [ 26,27,38,40] and references therein. In those works, the\\nauthorsconsiderrathercomplexmodelsforthestochasticde faultintensity,meanttocaptureprop-\\nerties observed in the market, study the behavior of default s as the size of the portfolio goes to', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='authorsconsiderrathercomplexmodelsforthestochasticde faultintensity,meanttocaptureprop-\\nerties observed in the market, study the behavior of default s as the size of the portfolio goes to\\ninﬁnity andconsideraﬃnepoint processmodelsin thissetting.In[ 27]it isemphasisedthat stan-\\ndardMonteCarloistypicallyslowforlargeportfoliosandlong timehorizons(hencetheirdesireto\\ndevelop new methods).Understanding how to design eﬃcient Monte Ca rlo methods,in this case\\nimportance sampling, even for rather simple models is a valuab le step towards constructing fast\\nandaccuratemethodsformoreinvolvedsystems.Forageneralov erview ofMonteCarlomethods\\nused in ﬁnancial engineering see [ 28]; examples of the use of importance sampling can be found\\nin [29–31]. In the more general setting of Markov jump processes, other c ommon Monte Carlo\\nmethodsincludesplitting,thecross-entropymethodandgenealo gicalmethods,seee.g.[ 3,12,36].\\nWenotethatalthoughthemotivationforthisparticularmode lcomesfromcreditrisk,theprob-', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Wenotethatalthoughthemotivationforthisparticularmode lcomesfromcreditrisk,theprob-\\nlem under consideration ﬁts into the more general context of Monte C arlo methods for Markov\\njumpprocesseswithmean-ﬁeld characteristics,asalargepa rtofthe analysisdoesnotdependon\\nthe speciﬁcformofthe jumpintensities.\\nTheremainderofthepaperisorganizedasfollows.InSection 2weintroducetherelevant Mar-\\nkovianintensity modelforcreditrisk,associatedstochasti cprocessesandprobabilitiesofinterest.\\nSection3reviews large deviation results for the type of Markov proce sses under consideration.\\nIn Section 4we review the basics of importance sampling for processes of th e type described in\\nSection2, including the relevant measure of eﬃciency, and describe how eﬃc ient algorithms are\\nlinkedtosubsolutions ofHamilton-Jacobiequations.Themainr esult oftheSection,Theorem 4.1,\\nquantiﬁestheperformanceofalgorithmsconstructedfromsubs olutions.InSection 5weconstruct\\neﬃcientalgorithmsinthemulti-dimensionalsetting.Lastly,i nSection 6wepresentnumericalex-', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='eﬃcientalgorithmsinthemulti-dimensionalsetting.Lastly,i nSection 6wepresentnumericalex-\\nperiments that illustrate the performance of the proposed imp ortance sampling algorithms. For\\ncompleteness, Appendix Acontains a formal derivation of the Hamilton-Jacobi equation o f Sec-\\ntion4.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:3\\n1.1 Notation\\nThefollowingnotationisused.Elementsin R/u1D451aredenotedbyboldfont,e.g. x,y,z,whereas/u1D465,/u1D466.alt,/u1D467\\ndenoteelementsof R.Withsomeabuseofnotation, 0denotesthezeroelementin R/u1D451forany/u1D451≥1.\\nFor/u1D457=1,...,/u1D45B,e/u1D457denotes the /u1D451-dimensional vector with a 1in the/u1D457th entry and all remaning\\nentries set to 0: e1=(1,0,...,0),e2=(0,1,0,...,0)and so on. For a set /u1D434∈R/u1D451and/u1D45B∈N,/u1D45B/u1D434\\ndenotes the set {/u1D45Bx : x∈/u1D434}. For an open set /u1D434inR/u1D451,/u1D4361(/u1D434)is the space of continuous real', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='functionson /u1D434withcontinuouspartialderivatives. Foracompactset /u1D43E,/u1D4361(/u1D43E)referstofunctions\\nthat are/u1D4361(/u1D434)on some open neighbourhood /u1D434of/u1D43E. For/u1D447∈ [0,∞),AC([0,/u1D447];R/u1D451)denotes\\nthe set of absolutely continuous functions /u1D713:[0,/u1D447] →R/u1D451andD([0,∞);R/u1D451)denotes the set of\\ncàdlàgfunctionsfrom [0,∞)toR/u1D451.Forafunction /u1D453:R/u1D451→R,∇/u1D453denotesthegradientof /u1D453.The\\npartial derivative with respect to one variable is denote by su bscript:/u1D453/u1D465/u1D456=/u1D715\\n/u1D715/u1D465/u1D456/u1D453. Similarly, for a', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D715/u1D465/u1D456/u1D453. Similarly, for a\\nfunction/u1D453:R×R/u1D451→R, the gradient of /u1D453with respect to the R/u1D451-valued argument xis denoted\\nby∇x/u1D453=(/u1D453/u1D4651,...,/u1D453/u1D465/u1D451).For functions /u1D453:R→Rthe derivative is simply denoted /u1D453′.\\n2 MODEL AND PROBLEMFORMULATION\\nTheclassofmodelsofinterest isasubset ofcontinuous-time pu re jumpMarkovprocesseson R/u1D451,\\nfor some/u1D451≥1. More speciﬁcally, in this paper we restrict to pure-birth p rocesses with an upper\\nlimitof/u1D45B/u1D464/u1D457∈Nbirthsinthe /u1D457thcomponent, /u1D457=1,...,/u1D451,for/u1D464/u1D457>0suchthat/u1D45B/u1D464/u1D457isintegerand', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D4641+ ··· +/u1D464/u1D451=1. Such a process can be viewed as modelling a population of /u1D45B∈Nindividuals\\ndivided into /u1D451groups,with /u1D45B/u1D464/u1D457∈Nindividuals inthe /u1D457thgroup,countingthenumberoftimesa\\nspeciﬁcevent(correspondingtoajump/birth)occursineachgr oup;inthecreditriskmodelin[ 10],\\nmentioned in the previous section,the “event” is the default ofa n obligor and groupscorrespond\\nto obligors with the same credit rating. For notational convenienc e, we deﬁne /u1D437⊂R/u1D451to be the\\nCartesian product\\n/u1D437=[0,/u1D4641] ×···× [ 0,/u1D464/u1D451].', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Cartesian product\\n/u1D437=[0,/u1D4641] ×···× [ 0,/u1D464/u1D451].\\nThesets/u1D437and/u1D45B/u1D437=[0,/u1D45B/u1D4641] ×···× [ 0,/u1D45B/u1D464/u1D451]willactasstate spacesforthestochasticprocesses\\nwe consider.In thispaper we focuson jumpintensities of thefor m\\n/u1D706/u1D457(x)=/u1D44E/u1D457(/u1D464/u1D457−/u1D465/u1D457)/u1D452/u1D44F⟨1,x⟩, /u1D457=1,.../u1D451,x∈/u1D437, (1)\\nfor/u1D44E1,...,/u1D44E/u1D451and/u1D44FinR+, where⟨·,·⟩denotes the standard scalar product in R/u1D451. For each/u1D45B,', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='{/u1D444/u1D45B(/u1D461);/u1D461≥0},/u1D444/u1D45B(0)=0∈R/u1D451, denotes a/u1D451-dimensional continuous-time pure jump Markov\\nprocess on/u1D45B/u1D437with inﬁnitesimal generator /u1D43F/u1D45Bdeﬁned as follows: for q∈/u1D45B/u1D437, so thatq=/u1D45Bxfor\\nsomex∈/u1D437,\\n/u1D43F/u1D45B/u1D453(q)=/u1D45B/u1D451/summationdisplay.1\\n/u1D457=1/u1D706/u1D457(x)[/u1D453(q+e/u1D457) −/u1D453(q)],\\nfor/u1D453in some suitable class of functions. The process /u1D444/u1D45B\\n/u1D457(/u1D461)represents the number of jumps in', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='for/u1D453in some suitable class of functions. The process /u1D444/u1D45B\\n/u1D457(/u1D461)represents the number of jumps in\\nthe/u1D457thgroupuptotime /u1D461.Theform( 1)ismotivatedby[ 10],whereit isusedformodellingcredit\\nrisk. Therein the process /u1D444/u1D45Bcounts the number of defaults in /u1D451subgroups of obligors, out of a\\nportfolio of /u1D45Bobligors. The vector a=(/u1D44E1,...,/u1D44E/u1D451)characterises the default intensities in the /u1D451\\ndiﬀerent groups,whereas /u1D44Fdeterminesthecontagioneﬀectofthetotalnumberofdefaultso nthe\\nentire portfolio. The model ( 1) is a generalisation of the one used in the examples in [ 10]: here\\ndiﬀerent groupsare allowedtohavediﬀerent intensities /u1D44E/u1D456.In[10],theauthorshint atamodelof', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='diﬀerent groupsare allowedtohavediﬀerent intensities /u1D44E/u1D456.In[10],theauthorshint atamodelof\\nthe form ( 1), with intensities diﬀering between groups, but never explicit ly state or consider any\\nsuch examples. A similar collection of models is also conside red in [40]. Therein the dependence\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:4 Djehiche, Hultand Nyquist\\nstructure does not allow for the type of contagion eﬀect caused by the exponential term in ( 1),\\nhowever they consider more generaljump-diﬀusion models.\\nWe are interested in studying the probability of the sum of the c omponents of /u1D444/u1D45Bexceeding\\nsome(high)thresholdbeforeaﬁxedtimehorizon /u1D447,whichisalsothefocusof[ 10].Moreprecisely,\\nforsome/u1D467∈ (0,1),we study the probability /u1D45D/u1D45Bgiven by\\n/u1D45D/u1D45B=P(/u1D451/summationdisplay.1\\n/u1D457=1/u1D444/u1D45B\\n/u1D457(/u1D447) ≥/u1D45B/u1D467)\\n=P(/u1D451/summationdisplay.1\\n/u1D457=1/u1D444/u1D45B', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='=P(/u1D451/summationdisplay.1\\n/u1D457=1/u1D444/u1D45B\\n/u1D457(/u1D461) ≥/u1D45B/u1D467,forsome/u1D461≤/u1D447)\\n.\\nThesecondequalityfollowsfromthefactthat /u1D444/u1D45Bisnon-decreasing.Forlarge /u1D45Btheeventthat /u1D444/u1D45B\\nexceeds/u1D45B/u1D467before time /u1D447is a rare event, i.e., the probability /u1D45D/u1D45Bwill be small. For such choices of\\n/u1D467standard Monte Carlo will be ineﬃcient for estimating /u1D45D/u1D45Band the goal of the paper is to con-\\nstructeﬃcientimportancesamplingalgorithmsforthistask.T heconstructionofsuchalgorithms\\nbecomes challenging when the intensities /u1D706/u1D457are state-dependent, particularly when there is de-', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='becomes challenging when the intensities /u1D706/u1D457are state-dependent, particularly when there is de-\\npendencebetweenthediﬀerentcomponentsasin( 1)(sometimesreferredtoascross-excitation of\\nthe components), and a detailed analysis is needed to ﬁnd an appropr iate sampling distribution.\\nIn the context of credit risk the described problem amounts to s tudying the probability that the\\nproportion ofdefaultsin theportfolio exceeds /u1D467before time /u1D447.\\nImportance sampling amounts to choosing a new set of jump intensitie s¯/u1D706/u1D457,/u1D457=1,...,/u1D451, as\\ndescribed in Section 4.2, and consider the corresponding jumpprocess ¯/u1D44B/u1D45B. In order to choosethe\\n¯/u1D706/u1D457ssothattheresultingalgorithmbecomeseﬃcient,asymptotic resultsas/u1D45Bgoestoinﬁnity serve\\nasa guide.For this,denote by {/u1D44B/u1D45B(/u1D461);/u1D461≥0}the scaledprocess', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='asa guide.For this,denote by {/u1D44B/u1D45B(/u1D461);/u1D461≥0}the scaledprocess\\n/u1D44B/u1D45B(/u1D461)=1\\n/u1D45B/u1D444/u1D45B(/u1D461), (2)\\nalsoknownasthedensitydependentpopulationprocess;seee.g. Chapter11in[ 23]Theprobability\\n/u1D45D/u1D45Bcanthen be expressed in termsofthe scaledprocess /u1D44B/u1D45B,\\n/u1D45D/u1D45B=P(/u1D451/summationdisplay.1\\n/u1D457=1/u1D44B/u1D45B\\n/u1D457(/u1D447) ≥/u1D467)\\n=P(/u1D451/summationdisplay.1\\n/u1D457=1/u1D44B/u1D45B\\n/u1D457(/u1D461) ≥/u1D467for some/u1D461≤/u1D447)\\n, (3)', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D457(/u1D461) ≥/u1D467for some/u1D461≤/u1D447)\\n, (3)\\nand large deviation asymptotics can be employed for this prob ability (i.e., for the process /u1D44B/u1D45B) to\\naid in the choiceof ¯/u1D706/u1D457sand thussamplingdistribution.\\n3 LARGEDEVIATIONS FOR THESEQUENCEOF SCALEDJUMP-PROCESSES\\nForeach/u1D45B,the process {/u1D44B/u1D45B(/u1D461);/u1D461≥0}in (2)isacontinuous-time purejumpMarkovprocesswith\\ninﬁnitesimal generator /u1D434/u1D45Bdeﬁned by\\n/u1D434/u1D45B/u1D453(x)=/u1D45B/u1D451/summationdisplay.1\\n/u1D457=1/u1D706/u1D457(x)[/u1D453(x+e/u1D457//u1D45B) −/u1D453(x)],', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='for/u1D453in somesuitable classoffunctions,andtakesvalues(withprob abilityone)in D([0,∞);R/u1D451).\\nThegenerator /u1D434/u1D45Bhasan associated (scaled)Hamiltonian, /u1D43B/u1D45B,deﬁned by\\n/u1D43B/u1D45B/u1D453(/u1D465)=1\\n/u1D45B/u1D452−/u1D45B/u1D453(/u1D465)/u1D434/u1D45B/u1D452/u1D45B/u1D453(x)=/u1D451/summationdisplay.1\\n/u1D457=1/u1D706/u1D457(x)(/u1D452/u1D45B(/u1D453(x+e/u1D457//u1D45B)−/u1D453(x))−1).\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:5\\nFor example,if thefunction /u1D453is/u1D4361and,for/u1D6FC∈R/u1D451,the sum/summationtext.1\\n/u1D457/u1D706/u1D457(x)/u1D452⟨/u1D6FC,e/u1D457⟩isﬁnite, it holdsthat\\nlim\\n/u1D45B→∞/u1D43B/u1D45B/u1D453(x)=/u1D451/summationdisplay.1\\n/u1D457=1/u1D706/u1D457(x)(/u1D452⟨∇/u1D453(x),e/u1D457⟩−1).\\nDeﬁne thefunction /u1D43B:/u1D437×R/u1D451→Rby\\n/u1D43B(x,/u1D6FC)=/u1D451/summationdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D43B(x,/u1D6FC)=/u1D451/summationdisplay.1\\n/u1D457=1/u1D706/u1D457(x)(/u1D452⟨/u1D6FC,e/u1D457⟩−1), (4)\\nand let/u1D43Fbe the convexconjugateof /u1D43B,\\n/u1D43F(x,/u1D6FD)=sup\\n/u1D6FC∈R/u1D451[\\n⟨/u1D6FC,/u1D6FD⟩ −/u1D43B(x,/u1D6FC)]\\n.\\nAstraightforward calculation gives theexplicit formof /u1D43F,\\n/u1D43F(x,/u1D6FD)=⟨/u1D6FD,log/u1D6FD\\n/u1D706(x)⟩ − ⟨/u1D6FD−/u1D706(x),1⟩, (5)', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D706(x)⟩ − ⟨/u1D6FD−/u1D706(x),1⟩, (5)\\nwhere/u1D6FD//u1D706(x)denotescomponent-wisedivision;thefunctions /u1D43Band/u1D43FarereferredtoastheHamil-\\ntonian and the Lagrangian,respectively.\\nDuetotheassumptions onthejumpintensities /u1D706/u1D457—whichdeﬁnethejumprates /u1D45F/u1D45Bofthe{/u1D44B/u1D45B}\\nprocesses, see Section 4.2—for each/u1D447<∞, the sequence {/u1D44B/u1D45B}satisﬁes Laplace principle on the\\nsample pathlevel; see [ 25,37].', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='sample pathlevel; see [ 25,37].\\nT/h.sc/e.sc/o.sc/r.sc/e.sc/m.sc 3.1. The sequence {/u1D44B/u1D45B(/u1D461);/u1D461∈ [0,/u1D447]}satisﬁes the Laplace principle with rate function\\n/u1D43Cxgiven by\\n/u1D43Cx(/u1D713)={∫/u1D447\\n0/u1D43F(/u1D713(/u1D461),/u1D713′(/u1D461))/u1D451/u1D461, /u1D713∈ AC([0,/u1D447];R/u1D451),non-decreasingand /u1D713(0)=x,\\n∞, otherwise.\\nThat is, forany x∈R/u1D451and bounded,continuous function ℎ:D([0,/u1D447];R/u1D451) →R,\\nlim\\n/u1D45B→∞1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='lim\\n/u1D45B→∞1\\n/u1D45Blog/u1D438x[exp{−/u1D45Bℎ(/u1D44B/u1D45B)}]=−inf\\n/u1D713{/u1D43Cx(/u1D713) +ℎ(/u1D713)},\\nwherethe inﬁmum isover /u1D713∈ AC([0,/u1D447];R/u1D451), non-decreasing and /u1D713(0)=x.\\nWe end this section by hinting at how the large deviation principl e connects to the design of\\neﬃcient simulation algorithms.Let /u1D437/u1D467bethe set\\n/u1D437/u1D467={\\ny=(/u1D466.alt1,...,/u1D466.alt/u1D451) ∈/u1D437:/u1D451/summationdisplay.1\\n/u1D457=1/u1D466.alt/u1D457≥/u1D467}\\n,', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D457=1/u1D466.alt/u1D457≥/u1D467}\\n,\\nand deﬁne the function /u1D448:[0,/u1D447] ×/u1D437→ [0,∞]asa conditional version ofthe rate function:\\n/u1D448(/u1D461,x)=inf\\n/u1D713{/uni222B.dsp/u1D447\\n/u1D461/u1D43F(/u1D713(/u1D460),/u1D713′(/u1D460))/u1D451/u1D460:/u1D713(/u1D461)=x, /u1D713(/u1D447) ∈/u1D437/u1D467}\\n, (6)\\nwhere the inﬁmum is over /u1D713∈ AC([0,/u1D447];R/u1D451)that are non-negative and non-decreasing (in\\neach component). For each pair (/u1D461,x),/u1D448(/u1D461,x)is interpreted as the large deviation rate function', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='each component). For each pair (/u1D461,x),/u1D448(/u1D461,x)is interpreted as the large deviation rate function\\nassociated with the probability of reaching the set /u1D437/u1D467before time /u1D447, when starting in state xat\\ntime/u1D461. According to Theorem 3.1, the convex conjugate /u1D43Fof/u1D43Bacts as the local rate function\\nfor the sequence {/u1D44B/u1D45B}. This conjugacybetween /u1D43Fand/u1D43Bprovides the connection to a Hamilton-\\nJacobiequation,whichcanbeusedfordesigningeﬃcientsimulat ionalgorithms;seeSection 5and\\nAppendix A.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:6 Djehiche, Hultand Nyquist\\n4 IMPORTANCESAMPLING\\nInthissectionweﬁrstreviewthebasicsofimportancesampli nganddescribetheimportancesam-\\nplingestimatorof ( 3)whenusinganalternativestochastickernel(correspondingtoa nalternative\\nsampling distribution). We then introduce a Hamilton-Jacobi eq uation related to the dynamics\\nof the model of Section 2and recall the notion of subsolutions to this type of partial diﬀ erential\\nequation (PDE). In Section 4.3we prove the main result of this section, Theorem 4.1, which char-\\nacterises the performance of importance sampling algorithms b ased on subsolutions, by linking\\nthe relative error to theinitial value ofthe subsolution.\\n4.1 Basicsofimportancesampling\\nImportancesamplingisthemethodtosimulateasystemunderdiﬀ erentdynamics,i.e.probability\\ndistribution,thanintheoriginalmodel.Inthepresentsetting thetaskistoestimatetheprobability', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='distribution,thanintheoriginalmodel.Inthepresentsetting thetaskistoestimatetheprobability\\n/u1D45D/u1D45B=P(/u1D44B/u1D45B(/u1D447) ∈/u1D437/u1D467), wherePdescribes the original dynamics for the process /u1D44B/u1D45B. To perform\\nimportancesampling,considerdiﬀerentdynamicsandtheassociat edprobabilitymeasure ¯Q/u1D45Bsuch\\nthatP≪¯Q/u1D45B; it is enough for the absolute continuity to hold on a sub- /u1D70E-algebra that contains\\nan appropriate part of the state space, e.g. in this case the s et/u1D437/u1D467. One sample of the importance\\nsamplingestimator,denotedby ˆ/u1D45D/u1D45B,istheindicatorfunctionoftheeventtimestheRadon-Nikodym\\nderivative associated with the changeofmeasure from Pto¯Q/u1D45B:', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='derivative associated with the changeofmeasure from Pto¯Q/u1D45B:\\nˆ/u1D45D/u1D45B=/u1D43C{/u1D44B/u1D45B(/u1D447) ∈/u1D437/u1D467}/u1D451P\\n/u1D451¯Q/u1D45B,\\nwhere/u1D44B/u1D45Bnow has dynamics according to ¯Q/u1D45B. Including the Radon-Nikodym derivative ensures\\nthatˆ/u1D45D/u1D45Bisan unbiased estimator of /u1D45D/u1D45B:\\n/u1D438¯Q/u1D45B[ˆ/u1D45D/u1D45B]=/u1D438¯Q/u1D45B[\\n/u1D43C{/u1D44B/u1D45B(/u1D447) ∈/u1D437/u1D467}/u1D451P\\n/u1D451¯Q/u1D45B]', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D451¯Q/u1D45B]\\n=/u1D438P[/u1D43C{/u1D44B/u1D45B(/u1D447) ∈/u1D437/u1D467}]=/u1D45D/u1D45B.\\nChoosingasuitablealternativemeasure ¯Q/u1D45Brequiresameasureofeﬃciency.Thestandardmeasure\\nofeﬃciencyfor unbiased estimators isthe relative error,\\nRE(ˆ/u1D45D/u1D45B)=√\\nVar(ˆ/u1D45D/u1D45B)\\n/u1D45D/u1D45B, (7)\\nwhereasmallerrelativeerrorcorrespondstoamoreeﬃciental gorithm.Byconsideringthesquare\\nofRE(ˆ/u1D45D/u1D45B)andwriting outthedeﬁnition ofthevariance,weseethatminimisi ng therelative error\\namounts to minimising the second moment /u1D438¯Q/u1D45B[ˆ/u1D45D2', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='amounts to minimising the second moment /u1D438¯Q/u1D45B[ˆ/u1D45D2\\n/u1D45B]. The aim is therefore to choose a sampling\\ndistribution that minimises the second moment whilst still bei ng feasible to implement (cf. the\\noptimal zero-variance changeofmeasure [ 3]).\\nHow small can we hope for the second moment to be? By Jensen’s inequa lity,/u1D438¯Q/u1D45B[ˆ/u1D45D2\\n/u1D45B] ≥/u1D45D2\\n/u1D45B\\nand using the largedeviation principle ofTheorem 3.1we have\\nliminf\\n/u1D45B→∞1\\n/u1D45Blog/u1D438¯Q/u1D45B[ˆ/u1D45D2\\n/u1D45B] ≥2liminf\\n/u1D45B→∞1\\n/u1D45Blog/u1D45D/u1D45B≥ −2/u1D448(0,0),', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D45B→∞1\\n/u1D45Blog/u1D45D/u1D45B≥ −2/u1D448(0,0),\\nwhere/u1D448is deﬁned in ( 6). This lower bound for the logarithmic asymptotics of ˆ/u1D45D2\\n/u1D45Bholds true for\\nany¯Q/u1D45B. A given ¯Q/u1D45Bis said to be asymptotically optimal if the corresponding upper bound holds\\naswell,that is if\\nlimsup\\n/u1D45B→∞1\\n/u1D45Blog/u1D438¯Q/u1D45B[ˆ/u1D45D2\\n/u1D45B] ≤ −2/u1D448(0,0).\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:7\\nThisisthenotion ofoptimality weare concernedwith inthispap er.Fortheupcominganalysisit\\nis useful to note that the secondmoment of ˆ/u1D45D/u1D45Bunder¯Q/u1D45Bis equal to the ﬁrst momentof ˆ/u1D45D/u1D45Bunder\\nP,\\n/u1D438¯Q/u1D45B[ˆ/u1D45D2\\n/u1D45B]\\n=/u1D438¯Q/u1D45B[\\n/u1D43C{/u1D44B/u1D45B(/u1D447) ∈/u1D437/u1D467}(/u1D451P\\n/u1D451¯Q/u1D45B)2]\\n=/u1D438P[\\n/u1D43C{/u1D44B/u1D45B(/u1D447) ∈/u1D437/u1D467}/u1D451P\\n/u1D451¯Q/u1D45B]\\n.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D451¯Q/u1D45B]\\n.\\n4.2 Importancesamplingfor the process /u1D44B/u1D45B\\nTofacilitate importance sampling, the dynamics of the process /u1D44B/u1D45Bcan be described by character-\\nising the/u1D444/u1D45Bprocess as follows (recall that /u1D44B/u1D45Bis a scaled version of /u1D444/u1D45B): The jump intensity for\\n/u1D444/u1D45Bforgoingfrom astate /u1D45Bx=/u1D45B(/u1D4651,...,/u1D465/u1D451)to/u1D45Bx+e/u1D457=(/u1D45B/u1D4651,/u1D45B/u1D4652,...,/u1D45B/u1D465 /u1D457+1,...,/u1D45B/u1D465 /u1D451)is\\n/u1D45F/u1D45B(x;e/u1D457)=/u1D45B/u1D706/u1D457(x).', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D45F/u1D45B(x;e/u1D457)=/u1D45B/u1D706/u1D457(x).\\nThenthetotal jumpintensity, when in state /u1D45Bx,is given by\\n/u1D445(x)=/u1D451/summationdisplay.1\\n/u1D457=1/u1D45F/u1D45B(x;e/u1D457)=/u1D451/summationdisplay.1\\n/u1D457=1/u1D45B/u1D706/u1D457(x).\\nLet/u1D4471,/u1D4472,...be the jump times of /u1D444/u1D45B,/u1D4470=0, and/u1D70F/u1D458=/u1D447/u1D458−/u1D447/u1D458−1the time between jumps,\\n/u1D458=1,2,....Thestochastic kernelof /u1D444/u1D45Bis then given by', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D458=1,2,....Thestochastic kernelof /u1D444/u1D45Bis then given by\\nΘ/u1D45B(/u1D451/u1D461,e/u1D457|x)=P(/u1D70F/u1D458+1=/u1D451/u1D461,/u1D444/u1D45B(/u1D447/u1D458+1) −/u1D444/u1D45B(/u1D447/u1D458)=e/u1D457|/u1D444/u1D45B(/u1D447/u1D458)=/u1D45Bx)\\n=/u1D45F/u1D45B(x;e/u1D457)/u1D452−/u1D445(x)/u1D461/u1D451/u1D461,(8)\\nwhere/u1D458issome integer.\\nThe dynamics of the process /u1D44B/u1D45Bare determined by the stochastic kernel Θ/u1D45Bin (8). Importance', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='The dynamics of the process /u1D44B/u1D45Bare determined by the stochastic kernel Θ/u1D45Bin (8). Importance\\nsampling amountsto using a diﬀerent stochastic kernel ¯Θ/u1D45B,\\n¯Θ/u1D45B(/u1D451/u1D461,e/u1D457|/u1D465)=¯/u1D45F/u1D45B(x;e/u1D457)/u1D452−¯/u1D445(x)/u1D461/u1D451/u1D461, (9)\\nwith¯/u1D445(x)=/summationtext.1/u1D451\\n/u1D457=1¯/u1D45F/u1D45B(x;e/u1D457)and jumpintensities ¯/u1D45F/u1D45B(x,·)ofthe form\\n¯/u1D45F/u1D45B(x,e/u1D457)=/u1D45B¯/u1D706/u1D457(x),', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='¯/u1D45F/u1D45B(x,e/u1D457)=/u1D45B¯/u1D706/u1D457(x),\\nfor some vector ¯/u1D706(x)=(¯/u1D7061(x),...,¯/u1D706/u1D451(x)). That is, similar to /u1D706and/u1D45F/u1D45B,¯/u1D706is a function from /u1D437to\\n[0,∞)/u1D451and the jump intensities ¯/u1D45F/u1D45B(x,·)are obtained by scaling this function by /u1D45B. Hence, the\\nchoiceofstochastic kernel ¯Θ/u1D45Bisdetermined by thechoiceof ¯/u1D706.\\nFor/u1D467∈ (0,1),deﬁne/u1D441/u1D467asthenumberofjumpsrequiredfortheprocesstoreachthetar getset\\n/u1D437/u1D467,\\n/u1D441/u1D467=inf{\\n/u1D458≥1 :/u1D451/summationdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D437/u1D467,\\n/u1D441/u1D467=inf{\\n/u1D458≥1 :/u1D451/summationdisplay.1\\n/u1D457=1/u1D444/u1D45B\\n/u1D457(/u1D447/u1D458) ≥/u1D45B/u1D467}\\n=inf{\\n/u1D458≥1 :/u1D44B/u1D45B(/u1D447/u1D458) ∈/u1D437/u1D467}\\n,\\nand/u1D4410asthe numberofjumpsneededtoexceedtime /u1D447,\\n/u1D4410=inf{/u1D458≥1 :/u1D447/u1D458>/u1D447}.\\nAsingle sampleof the importancesamplingestimator basedon ¯Θ/u1D45Bin (9) isgiven by\\nˆ/u1D45D/u1D45B=/u1D43C{/u1D441/u1D467</u1D4410}/u1D441/u1D467/productdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D458=1Θ/u1D45B(/u1D70F/u1D458,/u1D463/u1D458|/u1D44B/u1D45B(/u1D447/u1D458−1))\\n¯Θ/u1D45B(/u1D70F/u1D458,/u1D463/u1D458|/u1D44B/u1D45B(/u1D447/u1D458−1)), (10)\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:8 Djehiche, Hultand Nyquist\\nwhere/u1D463/u1D458∈ {e1,...,e/u1D451}is the direction of the /u1D458th jump and the /u1D70F/u1D458s denote times between jumps\\n(see Section 2). The goal is now to choose the stochastic kernel ¯Θ/u1D45Bso that the second moment\\n/u1D438¯Q/u1D45B[ˆ/u1D45D2\\n/u1D45B]is assmall aspossible.\\n4.3 Hamilton-Jacobiequation and choice ofsamplingdistri bution\\nStarting from a largedeviation scaling ofthe second moment /u1D438¯Q/u1D45B[ˆ/u1D45D2\\n/u1D45B],and deﬁning arelated sto-\\nchasticcontrolproblem,Dupuis,Wangandco-authors,haveest ablishedthateﬃcientimportance\\nsamplingalgorithmsareconnectedtocertainPDEsofHamilton-J acobitype,seeforexample[ 9,21].\\nMore precisely, the form of the PDE follows from minimising a pa rticular value function associ-', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='More precisely, the form of the PDE follows from minimising a pa rticular value function associ-\\natedwiththesecondmoment /u1D438¯Q/u1D45B[ˆ/u1D45D2\\n/u1D45B]andanasymptoticanalysisreminiscentoftheweakconver-\\ngenceapproachtolargedeviations[ 15].Inthesettingconsideredinthispaper,thePDE,henceforth\\nreferredtoastheIsaacsequation,ofinterestisdeﬁnedasfoll ows:Afunction /u1D44A:[0,/u1D447]×R/u1D451,with\\n/u1D44A/u1D461denoting the time-derivative of /u1D44A, solves the Isaacs equation if it satisﬁes, in an appropriat e\\nsense,{\\n/u1D44A/u1D461(/u1D461,x) −2/u1D43B(/u1D465,−1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='sense,{\\n/u1D44A/u1D461(/u1D461,x) −2/u1D43B(/u1D465,−1\\n2∇x/u1D44A(/u1D461,x))=0(/u1D461,x) ∈ [0,/u1D447) ×/u1D437\\\\/u1D437/u1D467,\\n/u1D44A(/u1D447,x)=0, x∈/u1D437/u1D467,(11)\\nand/u1D44A(/u1D447,x)=∞forx∉/u1D437/u1D467. For importance sampling, the sampling distribution should be\\nconstructedfromasubsolutionto( 11);aformalderivationofthisequationisprovidedinAppendi x\\nA.\\nAclassical subsolution to ( 11)is a continuously diﬀerentiable function ¯/u1D44Athat satisﬁes\\n¯/u1D44A/u1D461(/u1D461,x) −2/u1D43B(\\nx,−1\\n2∇x/u1D44A(/u1D461,x))', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='x,−1\\n2∇x/u1D44A(/u1D461,x))\\n≥0,(/u1D461,x) ∈ [0,/u1D447) × (/u1D437\\\\/u1D437/u1D467), (12)\\nand\\n¯/u1D44A(/u1D447,x) ≤0,x∈/u1D437/u1D467. (13)\\nSuppose that ¯/u1D44Aissucha subsolution to ( 11).Theformalderivation ofthisHamilton-Jacobiequa-\\ntion,speciﬁcallyProposition A.1,suggeststhatthesamplingdistribution ¯Q/u1D45Bshouldbeconstructed\\nfrom¯/u1D44Abyusing jumpintensities\\n¯/u1D706/u1D457(x)=/u1D706/u1D457(x)exp{\\n−1\\n2⟨∇x¯/u1D44A(/u1D461,x),e/u1D457⟩}\\n, /u1D457=1,...,/u1D451. (14)\\nThis is the form to be used for sampling distributions througho ut the remainder of this paper.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content=', /u1D457=1,...,/u1D451. (14)\\nThis is the form to be used for sampling distributions througho ut the remainder of this paper.\\nStartingwith[ 21],ithasbeenshownforarangeofmodels—in[ 21]theauthorsconsiderprimarily\\nsums of iid random variables and empirical measures of ﬁnite-st ate Markov chains—the perfor-\\nmanceofanimportancesamplingalgorithmbasedonasubsolutio n¯/u1D44Aisdeterminedbytheinitial\\nvalue¯/u1D44A(0,0). In Theorem 4.1we prove this result for the model under consideration here. Fi rst,\\na detour on the connection between the variational problem /u1D448deﬁned in ( 6) and subsolutions to\\n(11).\\nRecallthat/u1D448(/u1D461,x)isthevariationalrepresentation ofthelargedeviation rate oftheprobability\\nof reaching the set /u1D437/u1D467before time /u1D447, starting in xat time/u1D461. It turns out that the function /u1D448(/u1D461,x)\\nis aviscosity solution to the Hamilton-Jacobiequation', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='is aviscosity solution to the Hamilton-Jacobiequation\\n{\\n/u1D448/u1D461(/u1D461,x) −/u1D43B(/u1D465,−∇x/u1D448(/u1D461,x))=0,(/u1D461,x) ∈ [0,/u1D447) × (/u1D437\\\\/u1D437/u1D467),\\n/u1D448(/u1D447,x)=0, x∈/u1D437/u1D467.(15)\\nFor a range of diﬀerent assumptions on the Hamiltonian /u1D43B, this result has been established at\\nvarying levels of rigour, see for example [ 24]. For assumptions suitable for this paper, a rigorous\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:9\\nproof is provided in [ 13]. Moreover, subsolutions to the equation ( 15) give rise to subsolutions to\\nthe equation( 11).Indeed,a subsolution ¯/u1D448to(15) satisﬁes\\n2¯/u1D448/u1D461(/u1D461,x) −2/u1D43B(\\n/u1D465,−2∇x¯/u1D448(/u1D461,x)\\n2)\\n=2(¯/u1D448/u1D461(/u1D461,x) −/u1D43B(x,−∇x¯/u1D448(/u1D461,x)))≥0,\\nwhere the inequality followsfrom the subsolution property. It follows that 2¯/u1D448is a subsolution to\\ntheHamilton-Jacobiequation( 11).Therefore,toconstructeﬃcientsamplingalgorithmsitsuﬃc es\\nto consider subsolutions to the Hamilton-Jacobi equation ( 15). This also implies that if the func-\\ntion/u1D448canbecomputedexplicitly,asymptoticallyoptimalimport ancesamplingalgorithmscanbe', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='tion/u1D448canbecomputedexplicitly,asymptoticallyoptimalimport ancesamplingalgorithmscanbe\\nobtained byusing ¯/u1D44A=2/u1D448in (14).\\nWe are now ready to state and prove the main result regarding perf ormance of importance\\nsampling algorithmsbased onsubsolutions to ( 11),forthe modelunder consideration.\\nT/h.sc/e.sc/o.sc/r.sc/e.sc/m.sc 4.1. Let¯/u1D44Abe a subsolution of (11)which is/u1D4361(/u1D437). Ifˆ/u1D45D/u1D45Bis the importance sampling\\nestimator based on thevector of jumpintensities ¯/u1D706deﬁnedin (14), then\\nlimsup\\n/u1D45B→∞1\\n/u1D45Blog/u1D438¯Θ/u1D45B[ˆ/u1D45D2\\n/u1D45B]\\n≤ −¯/u1D44A(0,0)\\n2−/u1D448(0,0).', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D45B]\\n≤ −¯/u1D44A(0,0)\\n2−/u1D448(0,0).\\nBeforeembarkingontheproofofTheorem 4.1,wenotethattheformalderivation oftheIsaacs\\nequation ( 11) in Appendix Asuggests that the performance, as measured by the relative er ror, is\\ndetermined by the initial value of ¯/u1D44A. This is precisely the conclusion of Theorem 4.1and thus\\nthereisnoneedtomaketheformalargumentsofthederivationri gorous;thederivationservesto\\nprovide intuition forthe formofthe Hamilton-Jacobiequatio n.\\nP/r.sc/o.sc/o.sc/f.sc.The likelihood ratio between the sampling distribution ¯Q/u1D45B(stochastic kernel ¯Θ/u1D45B) and\\nthe original distribution P(stochastic kernel Θ/u1D45B)can beexpressed as\\n/u1D451P\\n/u1D451¯Q/u1D45B=exp{/uni222B.dsp/u1D447/u1D441/u1D467', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D451P\\n/u1D451¯Q/u1D45B=exp{/uni222B.dsp/u1D447/u1D441/u1D467\\n0(¯/u1D445(/u1D44B/u1D45B(/u1D460)) −/u1D445(/u1D44B/u1D45B(/u1D460)))/u1D451/u1D460+/u1D441/u1D467/summationdisplay.1\\n/u1D458=1log/u1D45F/u1D45B(/u1D44B/u1D45B(/u1D447/u1D458−1),/u1D463/u1D458)\\n¯/u1D45F/u1D45B(/u1D44B/u1D45B(/u1D447/u1D458−1),/u1D463/u1D458)}\\n.\\nToanalyzethe expectationofthe likelihoodratio,deﬁne the m easure/u1D45A/u1D45B(·,·)onR/u1D451,givenR/u1D451,by', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D45A/u1D45B(x,/u1D451y)=/u1D451/summationdisplay.1\\n/u1D457=1/u1D45B/u1D706/u1D457(x)/u1D6FFe/u1D457(/u1D451y),x∈R/u1D451.\\nFurthermore,let {/u1D440/u1D45B(/u1D461,·)}/u1D461denotethepointprocessdeﬁnedbythejumpsof /u1D44B/u1D45B.Thatis,/u1D440/u1D45B(/u1D461,/u1D435)\\nis thenumberof jumpsof /u1D44B/u1D45Bin(0,/u1D461]in directions that are in /u1D435⊂R/u1D451,\\n/u1D440/u1D45B(/u1D461,/u1D435)=/u1D45B/u1D451/summationdisplay.1\\n/u1D457=1/u1D44B/u1D45B', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D457=1/u1D44B/u1D45B\\n/u1D457(/u1D461)/u1D43C{e/u1D457∈/u1D435}.\\nAt anytime /u1D461, the instantaneous jumpintensity of /u1D440/u1D45Bis/u1D45A/u1D45B(/u1D44B/u1D45B(/u1D461),·).\\nWith the jumpintensities ¯/u1D706taken asin ( 14),thelikelihoodratio canbe expressed as\\n/u1D451P\\n/u1D451¯Q/u1D45B=exp{/uni222B.dsp/u1D447/u1D441/u1D467\\n0/u1D45B/u1D43B(\\n/u1D44B/u1D45B(/u1D460),−1\\n2∇x¯/u1D44A(/u1D460,/u1D44B/u1D45B(/u1D460)))\\n/u1D451/u1D460\\n+1\\n2/u1D441/u1D467/summationdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D451/u1D460\\n+1\\n2/u1D441/u1D467/summationdisplay.1\\n/u1D458=1⟨∇x¯/u1D44A(/u1D447/u1D458−1,/u1D44B/u1D45B(/u1D447/u1D458−1)),/u1D463/u1D458⟩}\\n.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:10 Djehiche, Hultand Nyquist\\nUsing the deﬁnitions of /u1D45A/u1D45Band/u1D440/u1D45B,the likelihoodratio takesthe form\\n/u1D451P\\n/u1D451¯Q/u1D45B=exp{/uni222B.dsp/u1D447/u1D441/u1D467\\n0/u1D45B/u1D43B(\\n/u1D44B/u1D45B(/u1D460),−1\\n2∇x¯/u1D44A(/u1D460,/u1D44B/u1D45B(/u1D460)))\\n/u1D451/u1D460\\n+/u1D45B\\n2/uni222B.dsp/u1D447/u1D441/u1D467\\n0/uni222B.dsp\\nR/u1D451(\\n¯/u1D44A(/u1D460,/u1D44B/u1D45B(/u1D460) +y', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='R/u1D451(\\n¯/u1D44A(/u1D460,/u1D44B/u1D45B(/u1D460) +y\\n/u1D45B) −¯/u1D44A(/u1D460,/u1D44B/u1D45B(/u1D460)))\\n/u1D451/u1D440/u1D45B(/u1D460,y)\\n−/u1D45B\\n2/u1D441/u1D467/summationdisplay.1\\n/u1D458=1(¯/u1D44A(/u1D447/u1D458−1,/u1D44B/u1D45B(/u1D447/u1D458−1) +/u1D463/u1D458//u1D45B) −¯/u1D44A(/u1D447/u1D458−1,/u1D44B/u1D45B(/u1D447/u1D458−1)))\\n+/u1D45B\\n2/u1D441/u1D467/summationdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='+/u1D45B\\n2/u1D441/u1D467/summationdisplay.1\\n/u1D458=1⟨∇x¯/u1D44A(/u1D447/u1D458−1,/u1D44B/u1D45B(/u1D447/u1D458−1)),/u1D463/u1D458//u1D45B⟩}\\n.\\nBypartial integration\\n/uni222B.dsp/u1D447/u1D441/u1D467\\n0/uni222B.dsp\\nR/u1D451(¯/u1D44A(/u1D460,/u1D44B/u1D45B(/u1D460) +y//u1D45B) −¯/u1D44A(/u1D460,/u1D44B/u1D45B(/u1D460)))/u1D451/u1D440/u1D45B(/u1D460,y)', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='=¯/u1D44A(/u1D447/u1D441/u1D467,/u1D44B/u1D45B(/u1D447/u1D441/u1D467)) −¯/u1D44A(0,0) −/uni222B.dsp/u1D447/u1D441/u1D467\\n0¯/u1D44A/u1D461(/u1D460,/u1D44B/u1D45B(/u1D460))/u1D451/u1D460.\\nSince¯/u1D44Aisassumedtobe /u1D4361(/u1D437)andthestatespace /u1D437isacompactsubset of R/u1D451,theconvergence\\n/u1D45B(\\n¯/u1D44A(\\n/u1D461,x+e/u1D457\\n/u1D45B)\\n−¯/u1D44A(/u1D461,x))\\n→ ⟨∇x¯/u1D44A(/u1D461,x),e/u1D457⟩,', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='→ ⟨∇x¯/u1D44A(/u1D461,x),e/u1D457⟩,\\nas/u1D45B→ ∞,isuniform in x.Hence,there is a sequence /u1D436/u1D45Bsuchthat/u1D436/u1D45B→0as/u1D45B→ ∞,and\\nsup\\nx∈/u1D437,/u1D457∈{1,...,/u1D451}/barex/barex/barex⟨∇x¯/u1D44A(/u1D461,x),e/u1D457⟩ −/u1D45B(\\n¯/u1D44A(\\n/u1D461,x+e/u1D457\\n/u1D45B)\\n−¯/u1D44A(/u1D461,x))/barex/barex/barex≤/u1D436/u1D45B.\\nThe uniformconvergencethusimplies the upperbound', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='The uniformconvergencethusimplies the upperbound\\n/u1D441/u1D467/u1D436/u1D45B≥/u1D45B/u1D441/u1D467/summationdisplay.1\\n/u1D458=1(⟨∇x¯/u1D44A(/u1D447/u1D458−1,/u1D44B/u1D45B(/u1D447/u1D458−1)),/u1D463/u1D458//u1D45B⟩\\n−¯/u1D44A(/u1D447/u1D458−1,/u1D44B/u1D45B(/u1D447/u1D458−1) +/u1D463/u1D458//u1D45B) +¯/u1D44A(/u1D447/u1D458−1,/u1D44B/u1D45B(/u1D447/u1D458−1))),\\nwhichgives an upperbound forthe likelihoodratio,\\n/u1D451P\\n/u1D451¯Q/u1D45B≤exp{', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='whichgives an upperbound forthe likelihoodratio,\\n/u1D451P\\n/u1D451¯Q/u1D45B≤exp{\\n−/u1D45B\\n2/uni222B.dsp/u1D447/u1D441/u1D467\\n0(\\n¯/u1D44A/u1D461(/u1D460,/u1D44B/u1D45B(/u1D460)) −2/u1D43B(\\n/u1D44B/u1D45B(/u1D460),−1\\n2∇x¯/u1D44A(/u1D460,/u1D44B/u1D45B(/u1D460))))\\n/u1D451/u1D460\\n+/u1D45B\\n2¯/u1D44A(/u1D447/u1D441/u1D467,/u1D44B/u1D45B(/u1D447/u1D441/u1D467)) −/u1D45B\\n2¯/u1D44A(0,0) +1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='2¯/u1D44A(0,0) +1\\n2/u1D441/u1D467/u1D436/u1D45B}\\n.\\nTheassumptionthat ¯/u1D44Aisasubsolutionto( 11)impliesthattheﬁrstintegralisboundedfrombelow\\nby0.Moreover, bythedeﬁnition of /u1D441/u1D467,¯/u1D44A(/u1D447/u1D441/u1D467,/u1D44B/u1D45B(/u1D447/u1D441/u1D467)) ≤0.Hence,the followingupperbound\\nholdsfor ˆ/u1D45D/u1D45B=/u1D43C{/u1D441/u1D467</u1D4410}(/u1D451P//u1D451¯Q/u1D45B),\\n/u1D438Θ/u1D45B[\\n/u1D43C{/u1D441/u1D467</u1D4410}/u1D451P\\n/u1D451¯Q/u1D45B]', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D43C{/u1D441/u1D467</u1D4410}/u1D451P\\n/u1D451¯Q/u1D45B]\\n≤/u1D438Θ/u1D45B[\\n/u1D43C{/u1D441/u1D467</u1D4410}exp{\\n−/u1D45B\\n2¯/u1D44A(0,0) +1\\n2/u1D441/u1D467/u1D436/u1D45B}]\\n=/u1D452−/u1D45B\\n2¯/u1D44A(0,0)/u1D438Θ/u1D45B[\\n/u1D43C{/u1D441/u1D467</u1D4410}/u1D4521\\n2/u1D441/u1D467/u1D436/u1D45B]\\n.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:11\\nDue to the form of the jump intensity /u1D45F/u1D45B, the process /u1D444/u1D45B, hence also the process /u1D44B/u1D45B, can have\\nat most/u1D45Bjumps. It follows that /u1D441/u1D467≤/u1D45B. Combined with the upper bound just derived for the\\nexpectation of ˆ/u1D45D/u1D45B,this yieldsthe upperbound\\n1\\n/u1D45Blog/u1D438Θ/u1D45B[\\n/u1D43C{/u1D441/u1D467</u1D4410}/u1D451P\\n/u1D451¯Q/u1D45B]\\n≤ −1\\n2¯/u1D44A(0,0) +/u1D436/u1D45B\\n2+1\\n/u1D45Blog/u1D45D/u1D45B.\\nTheresultnowfollowsfromthelargedeviationprinciplefor /u1D45D/u1D45Bandthepropertiesofthesequence', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Theresultnowfollowsfromthelargedeviationprinciplefor /u1D45D/u1D45Bandthepropertiesofthesequence\\n/u1D436/u1D45B,\\nlimsup\\n/u1D45B→∞1\\n/u1D45Blog/u1D438Θ/u1D45B[\\n/u1D43C{/u1D441/u1D467</u1D4410}/u1D451P\\n/u1D451¯Q/u1D45B]\\n≤ −1\\n2/u1D44A(0,0) −/u1D448(0,0).\\n□\\n5 SUBSOLUTIONS AND ASSOCIATED SAMPLING ALGORITHMS\\nIn this section we construct a type of subsolution to ( 11) that gives rise to eﬃcient importance\\nsampling algorithms for the model described in Section 2. Recall from Section 4that the Isaacs\\nequation ( 11)ofinterest is\\n{\\n/u1D44A/u1D461(/u1D461,x) −2/u1D43B(/u1D465,−1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='equation ( 11)ofinterest is\\n{\\n/u1D44A/u1D461(/u1D461,x) −2/u1D43B(/u1D465,−1\\n2∇x/u1D44A(/u1D461,x))=0(/u1D461,x) ∈ [0,/u1D447) ×/u1D437\\\\/u1D437/u1D467,\\n/u1D44A(/u1D447,x)=0, x∈/u1D437/u1D467,\\nand for a subsolution ¯/u1D44Aof this equation the corresponding importance sampling algorit hm is\\ndeﬁned byusing jumpintensities ( 14):\\n¯/u1D706/u1D457(x)=/u1D706/u1D457(x)exp{\\n−1\\n2⟨∇x¯/u1D44A(/u1D461,x),e/u1D457⟩}\\n, /u1D457=1,...,/u1D451.\\nBefore considering arbitrary dimension /u1D451, we begin with ﬁnding the optimal time-homogeneous', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content=', /u1D457=1,...,/u1D451.\\nBefore considering arbitrary dimension /u1D451, we begin with ﬁnding the optimal time-homogeneous\\nsampling distribution for /u1D451=1. The one-dimensional case sets the stage for the more general\\nconstruction andprovides insight into the underlyingidea.\\n5.1 The optimal time-homogeneoussamplingdistribution\\nAsanillustrationoftheideaforhowtoconstructsubsolutio nsforarbitrarydimension /u1D451,aspecial\\ncase of a method described in [ 13], we start by considering the case /u1D451=1.Recallthat to evaluate\\nthe performance of any importance sampler based on a subsolutio n¯/u1D44A, the initial value ¯/u1D44A(0,0)\\nshould be compared to 2/u1D448(0,0), with/u1D448as in (6). To facilitate such a comparison, we have the\\nfollowingresult.\\nP/r.sc/o.sc/p.sc/o.sc/s.sc/i.sc/t.sc/i.sc/o.sc/n.sc5.1. For/u1D451=1,the largedeviation rateisgiven by', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D448(0,0)=/uni222B.dsp/u1D467\\n0log(\\n1+/u1D450\\n/u1D706(/u1D466.alt))\\n/u1D451/u1D466.alt−/u1D450/u1D447,\\nwhere/u1D450solves the equation\\n/uni222B.dsp/u1D467\\n0/u1D451/u1D466.alt\\n/u1D706(/u1D466.alt) +/u1D450=/u1D447.\\nThis result can be proved using e.g. convex optimisation argum ents. However, it is a special\\ncase of a more general result by the authors (Theorem 5.3), presented later in this section and a\\nseparate proofis omitted.\\nAs mentioned in the introduction we now only consider algorithms fo r which the change of\\nmeasureisindependentof /u1D461.Thatis,if ¯/u1D44Aisthesubsolutionfromwhichthesamplingdistribution', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='measureisindependentof /u1D461.Thatis,if ¯/u1D44Aisthesubsolutionfromwhichthesamplingdistribution\\nis constructed, then ∇/u1D465¯/u1D44A(/u1D461,/u1D465)is a function of only /u1D465∈R; even though /u1D465∈Rhere, we use the\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:12 Djehiche, Hultand Nyquist\\nnotation∇/u1D465¯/u1D44Aforthederivativewithrespectto /u1D465tofacilitatecomparisonwiththerestofthepaper.\\nToemphasizetheassumptionthat ∇/u1D465¯/u1D44A(/u1D461,/u1D465)isafunctionofonly /u1D465,not/u1D461,andtoeasenotation,let\\n/u1D6FC(/u1D465)=−∇/u1D465¯/u1D44A(/u1D461,/u1D465)/2.Thenthejumpintensity usedforimportancesamplingcanbeexpr essedas\\n¯/u1D706(/u1D465)=/u1D706(/u1D465)exp{\\n−1\\n2∇/u1D465¯/u1D44A(/u1D461,/u1D465)}\\n=/u1D706(/u1D465)exp{/u1D6FC(/u1D465)}.\\nFrom theassumptions on ¯/u1D44A,we canrepresent sucha functionas', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='From theassumptions on ¯/u1D44A,we canrepresent sucha functionas\\n¯/u1D44A(/u1D461,/u1D465)=−2/uni222B.dsp/u1D465\\n0/u1D6FC(/u1D466.alt)/u1D451/u1D466.alt+/u1D454(/u1D461) +/u1D43E,\\nfor some function /u1D454and constant /u1D43E. Let/u1D434(/u1D465)=∫/u1D465\\n0/u1D6FC(/u1D466.alt)/u1D451/u1D466.altand consider only functions /u1D454of the\\nform/u1D454(/u1D461)=2/u1D450/u1D461, forsome constant /u1D450.Then,\\n¯/u1D44A/u1D461(/u1D461,/u1D465)=2/u1D450,∇/u1D465¯/u1D44A(/u1D461,/u1D465)=−2/u1D6FC(/u1D465).', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='For¯/u1D44Atobeasubsolution, /u1D434,/u1D454and/u1D43Emustbechosensothatconditions( 12)-(13)aresatisﬁed.For\\n(12) to hold,/u1D6FCmust be suchthat\\n0≤¯/u1D44A/u1D461(/u1D461,/u1D465) −2/u1D43B(\\n/u1D465,−1\\n2∇/u1D465¯/u1D44A(/u1D461,/u1D465))\\n=2/u1D450−2/u1D706(/u1D465)(\\n/u1D452/u1D6FC(/u1D465)−1)\\n,\\nwhichimplies that /u1D6FC(/u1D465)must satisfy\\n/u1D6FC(/u1D465) ≤log(\\n1+/u1D450\\n/u1D706(/u1D465))\\n.\\nBy setting/u1D6FC(/u1D465)equal to the right-hand side of the previous display, equalit y is achieved in ( 12).', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='.\\nBy setting/u1D6FC(/u1D465)equal to the right-hand side of the previous display, equalit y is achieved in ( 12).\\nHowever/u1D6FCiswell-deﬁnedonlyfor /u1D450≥ −inf/u1D465≤/u1D467/u1D706(/u1D467).Forthisparticularchoiceof ¯/u1D44Atheterminal\\ncondition ( 13) becomes\\n0≥¯/u1D44A(/u1D447,/u1D467)=2/u1D450/u1D447−2/u1D434(/u1D467) +/u1D43E,\\nand theconstant /u1D43Emust satisfy\\n/u1D43E≤2/u1D434(/u1D467) −2/u1D450/u1D447.\\nFrom thediscussion in Section 4and at thebeginning ofthis section,it isclearthat it isdesirabl e\\nto have the initial value ¯/u1D44A(0,0)as large as possible. Here, ¯/u1D44A(0,0)=/u1D43Eand the inequality gives', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='to have the initial value ¯/u1D44A(0,0)as large as possible. Here, ¯/u1D44A(0,0)=/u1D43Eand the inequality gives\\nthe upper bound 2/u1D434(/u1D467) −2/u1D450/u1D447; take/u1D43Eto be equal to this upper bound. The resulting subsolution\\n¯/u1D44Ais given by\\n¯/u1D44A(/u1D461,/u1D465)=2/uni222B.dsp/u1D467\\n/u1D465log(\\n1+/u1D450\\n/u1D706(/u1D466.alt))\\n/u1D451/u1D466.alt−2/u1D450(/u1D447−/u1D461).\\nLastly,the constant /u1D450cannow be chosenso asto maximize ¯/u1D44A(0,0):Take/u1D450=/u1D450∗,\\n/u1D450∗=argmax¯/u1D44A(0,0)=argmax{\\n2/uni222B.dsp/u1D467\\n0log(', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D450∗=argmax¯/u1D44A(0,0)=argmax{\\n2/uni222B.dsp/u1D467\\n0log(\\n1+/u1D450\\n/u1D706(/u1D466.alt))\\n/u1D451/u1D466.alt−2/u1D450/u1D447}\\n,\\nwhere only /u1D450>−inf/u1D465≤/u1D467/u1D706(/u1D465)are considered. Diﬀerentiability with respect to /u1D450implies that the\\noptimal/u1D450∗must bea solution tothe equation\\n/uni222B.dsp/u1D467\\n0/u1D451/u1D466.alt\\n/u1D706(/u1D466.alt) +/u1D450=/u1D447. (16)\\nFor thischoiceof /u1D450∗the subsolution ¯/u1D44Ahasinitial value\\n¯/u1D44A(0,0)=2/uni222B.dsp/u1D467\\n0log(\\n1+/u1D450∗', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='¯/u1D44A(0,0)=2/uni222B.dsp/u1D467\\n0log(\\n1+/u1D450∗\\n/u1D706(/u1D466.alt))\\n/u1D451/u1D466.alt−2/u1D450∗/u1D447.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:13\\nComparing this expression to that of Proposition 5.1, we see that the importance sampling algo-\\nrithm associatedwith ¯/u1D44Ais asymptoticallyoptimal.\\nTopresentthemoregeneralresult,webeginwithintroducingthe Mañépotential[ 33].For/u1D450∈R\\nandx,y∈R/u1D451,theMañépotential at level c , denotedby /u1D446/u1D450(x,y),isdeﬁned as\\n/u1D446/u1D450(x,y)=inf{/uni222B.dsp/u1D70F\\n0(/u1D450+/u1D43F(/u1D713(/u1D460),/u1D713′(/u1D460)))/u1D451/u1D460, /u1D713(0)=x, /u1D713(/u1D70F)=y}\\n,', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content=',\\nwhere/u1D43FisthelocalratefunctiondeﬁnedinSection 3andtheinﬁmumistakenover /u1D713∈ AC([0,∞):R/u1D451)\\nand/u1D70F>0.Inthecurrentsetting,because /u1D44B/u1D45B(0)=0(inthecontextofcreditrisk,thiscorresponds\\nto no defaults at time 0), the initial value of interest is x0=0. The following results, Lemma\\n5.2and Theorem 5.3, show how one can construct subsolutions, and thus importance sam pling\\nalgorithms, using the relation between the Mañé potential /u1D446/u1D450(0,y)and the Hamiltonian /u1D43B. The\\nﬁrst result establishes that /u1D446/u1D450(0,y)is a subsolution, a type of generalised solution often used for\\nHamilton-Jacobiequations[ 24],to a stationary equationinvolving the Hamiltonian /u1D43B.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Hamilton-Jacobiequations[ 24],to a stationary equationinvolving the Hamiltonian /u1D43B.\\nL/e.sc/m.sc/m.sc/a.sc5.2(/c.sc/f.sc.P/r.sc/o.sc/p.sc/o.sc/s.sc/i.sc/t.sc/i.sc/o.sc/n.sc2.2/i.sc/n.sc[ 13]).Thefunction y/u\\\\i∈∞A6.e\\\\dl→/u1D446/u1D450(0,y)isaviscosity solution ofthe\\nstationary Hamilton-Jacobi equation\\n/u1D43B(y,∇/u1D446(y))=/u1D450, (17)\\nforally≠0and/u1D450>/u1D450/u1D43B, where/u1D450/u1D43Bsatisﬁes\\n/u1D450/u1D43B≥sup\\nxinf\\np/u1D43B(x,p).', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D450/u1D43B≥sup\\nxinf\\np/u1D43B(x,p).\\nThe constant /u1D450/u1D43Bis known as Mañé’s critical value , see [33]. For the speciﬁc model considered\\nhere (seeExample 2.1in [ 13]),\\n/u1D450/u1D43B=−inf\\nx∈/u1D437\\\\/u1D437/u1D467/u1D451/summationdisplay.1\\n/u1D457=1/u1D706/u1D457(x).\\nNote that this is consistent with the discussion leading up to Pr oposition 5.1,where it was neces-\\nsary to take /u1D450>−inf/u1D465≤/u1D467/u1D706(/u1D465)(recall that Proposition 5.1 concerns the one-dimensional setti ng,\\n/u1D465,/u1D467∈R).\\nThe following theorem is a combination of results in [ 13] adapted to the current setting. It is a\\ngeneralisation to higher dimensions of the method used for the o ne-dimensional case; for /u1D451=1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='The following theorem is a combination of results in [ 13] adapted to the current setting. It is a\\ngeneralisation to higher dimensions of the method used for the o ne-dimensional case; for /u1D451=1\\nthe theoremestablishes the optimality of theimportancesam pling algorithmpreviously derived.\\nT/h.sc/e.sc/o.sc/r.sc/e.sc/m.sc 5.3 (/c.sc/f.sc. S/e.sc/c.sc/t.sc/i.sc/o.sc/n.sc/s.sc 3 /a.sc/n.sc/d.sc 5 /i.sc/n.sc [ 13]).Suppose/u1D446:R/u1D451→Ris a classical subsolution to\\n(17). Consider thecollection of functions ¯/u1D448/u1D450,y:R×R/u1D451→Rdeﬁnedby\\n¯/u1D448/u1D450,y(/u1D461,x)=/u1D446(y) −/u1D446(x) −/u1D450(/u1D447−/u1D461)', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='where/u1D450>/u1D450/u1D43Bandy∈/u1D715/u1D437/u1D467. Then¯/u1D448/u1D450,y(·,·)is a classical subsolution to (15). Speciﬁcally, if y/u\\\\i∈∞A6.e\\\\dl→\\n/u1D446/u1D450(0,y)is/u1D4361(/u1D437),then the corresponding ¯/u1D448/u1D450,yisaclassical subsolution to (15).\\nMoreover, for /u1D451=1, ifwe take/u1D466.alt=/u1D467and/u1D450such that\\n¯/u1D448/u1D450,/u1D467(0,0)=sup\\n/u1D450>/u1D450/u1D43B{/u1D446/u1D450(0,/u1D467) −/u1D450/u1D447},\\nthe corresponding ¯/u1D448/u1D450,/u1D467(0,0)isequal to value of the largedeviation ratefunction at (0,0);', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='the corresponding ¯/u1D448/u1D450,/u1D467(0,0)isequal to value of the largedeviation ratefunction at (0,0);\\n¯/u1D448/u1D450,/u1D467(0,0)=/u1D448(0,0).\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:14 Djehiche, Hultand Nyquist\\nTheresulttogetherwiththeprecedingdiscussionstatestha t,for/u1D450>/u1D450/u1D43Band/u1D466.alt∈/u1D715/u1D437/u1D467,¯/u1D44A=2¯/u1D448/u1D450,y\\nis a subsolution to the equation ( 11). Moreover, in the case /u1D451=1, it states that ¯/u1D44Aattains the\\nmaximalinitialvalue 2/u1D448(0,0)ifwechoose /u1D450appropriately.Itfollowsthatthecorrespondingchoice\\nofthe sampling distribution achieves asymptoticoptimalit y; see Section 4for arigorousproof.\\nItisimportanttopointoutthatTheorem 5.3andtheresultsonperformance(primarilyTheorem\\n4.1) do not depend on the explicit form of the original jump intensity, described by /u1D706. Rather,\\nboth hold for any Markovian birth process with the structure d escribed in Section 2. However,\\nthe particular choice of /u1D706becomes crucial when computing the explicit change of measure for a', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='both hold for any Markovian birth process with the structure d escribed in Section 2. However,\\nthe particular choice of /u1D706becomes crucial when computing the explicit change of measure for a\\nspeciﬁcmodel,whichin the contextof Theorem 5.3amountsto computingthe Mañé potential.\\nFor/u1D451=1,/u1D715/u1D437/u1D467={/u1D467}andthe Mañé potential isprecisely the function\\n/u1D446/u1D450(0,/u1D465)=/uni222B.dsp/u1D465\\n0log(\\n1+/u1D450\\n/u1D706(/u1D466.alt))\\n/u1D451/u1D466.alt.\\nThus,the construction of ¯/u1D44Aaccordingto Theorem 5.3isprecisely the subsolution constructed in\\nSection5.1,andProposition 5.1becomesacorollaryofTheorem 5.3;asymptoticoptimalityfollows\\nfroma combinationof Proposition 5.1andTheorem 4.1.\\n5.2 Samplingdistribution for multi-dimensional model', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='froma combinationof Proposition 5.1andTheorem 4.1.\\n5.2 Samplingdistribution for multi-dimensional model\\nWe now approach the task of ﬁnding an explicit change of measure fo r the model ( 1), where the\\njumpintensities are ofthe form\\n/u1D706/u1D457(x)=/u1D44E/u1D457(/u1D464/u1D457−/u1D465/u1D457)/u1D452/u1D44F/summationtext.1/u1D451\\n/u1D456=1/u1D465/u1D456, /u1D457=1,...,/u1D451,\\nfor some non-negative /u1D44E/u1D457s and/u1D44F. Recall (see Section 2) that the original model in [ 10] did not\\nallow for diﬀerent jump intensities for the diﬀerent components of the process /u1D444/u1D45B, i.e. they only', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='allow for diﬀerent jump intensities for the diﬀerent components of the process /u1D444/u1D45B, i.e. they only\\nconsidered the case /u1D44E/u1D456≡/u1D44E,/u1D456=1,...,/u1D451,forsome intensity /u1D44E, rendering the model essentially one-\\ndimensional.Themodel( 1),andbyextensionthesimulationalgorithmsconstructedinth ispaper,\\nis thusageneralisation ofthat considered in [ 10].\\nAs outlined in the previous sections, the idea is to construct a s uitable subsolution: grounded\\nin Theorem 5.3, the idea is to ﬁnd ∇x¯/u1D44A(/u1D461,x)=−2∇x/u1D446/u1D450(0,x).For/u1D451=1,the derivation of /u1D446/u1D450(0,/u1D466.alt)\\nis provided in Section 5.1and the correspondingsampling distribution hasjump intensity ¯/u1D706(/u1D465)=', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='is provided in Section 5.1and the correspondingsampling distribution hasjump intensity ¯/u1D706(/u1D465)=\\n/u1D706(/u1D465)/u1D452/u1D6FC(/u1D465;/u1D450),where\\n/u1D6FC(/u1D465,/u1D450)=log(\\n1+/u1D450\\n/u1D706(/u1D465))\\n,\\nand/u1D450solves (16). Hence, for the one-dimensional model the change of measure used for impor-\\ntance sampling is completely known up to the constant /u1D450, which one might need to determine\\nnumerically.\\nFor/u1D451≥2, a natural approach is to try and solve the variational problem i n the deﬁnition of\\n/u1D446/u1D450(0,x).Anotherapproachistheone(implicitly)usedfor /u1D451=1:Findafunction /u1D6FC(x;/u1D450)thatsolves\\nthe equation', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='the equation\\n/u1D450=/u1D43B(x,/u1D6FC(x,/u1D450))=/u1D451/summationdisplay.1\\n/u1D457=1/u1D706/u1D457(x)(\\n/u1D452⟨/u1D6FC(x,/u1D450),e/u1D457⟩−1)\\n, (18)\\nand then attempt to ﬁnd a potential /u1D434(x;/u1D450)such that ∇x/u1D434(x;/u1D450)=/u1D6FC(x;/u1D450). However, for /u1D451>1,\\nthis requires that /u1D6FC(x;/u1D450)forms a conservative vector ﬁeld. Finding such solutions to ( 18) clearly\\ndependson thechoiceof /u1D706and isa non-trivial task alreadyfor rathersimple choices.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:15\\nBefore discussing further the problem of ﬁnding eﬃcient sampling distributions for /u1D451>1, we\\nreturn to the special case considered in [ 10]:/u1D44E/u1D457≡/u1D44E,/u1D457=1,...,/u1D451, so that all groups are homoge-\\nneous. In this case the change of measure can once again be found ex plicitly by choosing /u1D6FC(x;/u1D450)\\naccordingto\\n⟨/u1D6FC(x;/u1D450),e/u1D457⟩=log(\\n1+/u1D450\\n/summationtext.1/u1D451\\n/u1D456=1/u1D706/u1D456(x))\\n, /u1D457=1,...,/u1D451. (19)\\nThis deﬁnes a conservative vector ﬁeld and the corresponding pote ntial/u1D434(x;/u1D450), as well as the\\noptimal/u1D450,is analogousto before,with', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='optimal/u1D450,is analogousto before,with\\n/u1D434(x;/u1D450)=/uni222B.dsp/summationtext.1/u1D465/u1D456\\n0log(\\n1+/u1D450\\n˜/u1D706(/u1D466.alt))\\n/u1D451/u1D466.alt,\\nwhere˜/u1D706(/u1D466.alt)=/u1D44E(1−/u1D466.alt)/u1D452/u1D44Fy. Note that this relies on the form of the /u1D706/u1D457s, speciﬁcally the fact that/summationtext.1\\n/u1D456/u1D706/u1D456(x)is a function of x=(/u1D4651,...,/u1D465/u1D451)only through the sum/summationtext.1\\n/u1D456/u1D465/u1D456. An interesting observation\\nisthatthischoiceofsamplingdistributionamountsto ∇x¯/u1D44Abeingperpendiculartothebarrierthe', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='isthatthischoiceofsamplingdistributionamountsto ∇x¯/u1D44Abeingperpendiculartothebarrierthe\\nprocessistrying to cross, whichseemsintuitively appealing.\\nThefunction /u1D6FC(x,/u1D450)deﬁned by( 19) isa solution to thestationary equation ( 18)forthe general\\nmodel (1), with diﬀerent intensities /u1D44E/u1D456, not just the eﬀectively one-dimensional case of [ 10]. It is\\ntherefore tempting to base the sampling distribution on this c hoice also for the general model.\\nHowever, this /u1D6FC(x,/u1D450)is not necessarily a conservative vector ﬁeld: for /u1D451=2the (scalar) curl\\nof/u1D6FC(x,/u1D450)is such that the necessary condition for existence of a potential /u1D434(x,/u1D450)with/u1D6FC(x,/u1D450)=\\n∇x/u1D434(x,/u1D450)becomes', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='∇x/u1D434(x,/u1D450)becomes\\n/u1D452/u1D44F(/u1D4651+/u1D4652)\\n(/u1D7061(x) +/u1D7062(x))2+/u1D7061(x) +/u1D7062(x)(/u1D44E1−/u1D44E2)=0,\\nwhich does not hold when the two groups have diﬀerent intensities . At the moment, for general\\nchoicesof a∈R/u1D451and/u1D44F>0,itisnotknowntotheauthorshowtoﬁndtheMañépotential /u1D446/u1D450(0,x)\\ncorrespondingto( 1);forexample,forthecase /u1D44F=0theabovechoicedoesproduceaconservative\\nvector ﬁeld and we can use the corresponding subsolution. Still, the obtained results can be used\\nto guide thedesign ofsampling algorithmsand next we discuss one suggestion.\\nConsiderthegeneralformofthejumpintensitymodel,wherethe /u1D44E/u1D457’sarenon-negativeandnot', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Considerthegeneralformofthejumpintensitymodel,wherethe /u1D44E/u1D457’sarenon-negativeandnot\\nnecessarily equal.Let /u1D44E∗=∨/u1D451\\n/u1D457=1/u1D44E/u1D457and deﬁne the vector /u1D6FC(x;/u1D450)by\\n⟨/u1D6FC(x;/u1D450),e/u1D457⟩=log(\\n1+/u1D450\\n/summationtext.1/u1D451\\n/u1D457=1/u1D44E∗(/u1D464/u1D457−/u1D465/u1D457)/u1D452/u1D44F/summationtext.1/u1D465/u1D456)\\n, /u1D457=1,...,/u1D451.\\nThischoiceof /u1D6FC(x;/u1D450)satisﬁes', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content=', /u1D457=1,...,/u1D451.\\nThischoiceof /u1D6FC(x;/u1D450)satisﬁes\\n/u1D43B(/u1D465,/u1D6FC(x;/u1D450))=/u1D450(/summationtext.1/u1D451\\n/u1D457=1/u1D44E/u1D457(/u1D464/u1D457−/u1D465/u1D457)\\n/summationtext.1/u1D451\\n/u1D457=1/u1D44E∗(/u1D464/u1D457−/u1D465/u1D457))\\n≤/u1D450,\\nand thus\\n/u1D450−/u1D43B(x,/u1D6FC(x;/u1D450)) ≥0.\\nThis is the correct inequality for a subsolution to the statio nary Hamilton-Jacobi equation. Let', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='This is the correct inequality for a subsolution to the statio nary Hamilton-Jacobi equation. Let\\n/u1D434(x;/u1D450)bethe potential for thevector ﬁeld /u1D6FC(x;/u1D450)and deﬁne thecorresponding ¯/u1D44A(/u1D461,x)by\\n¯/u1D44A(/u1D461,x)=2/u1D434(y;/u1D450) −2/u1D434(x;/u1D450) −2/u1D450(/u1D447−/u1D461).\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:16 Djehiche, Hultand Nyquist\\nThisisasubsolutionto( 11)andwebaseourimportancesamplingalgorithmonthischoiceof ¯/u1D44A.for\\nthe special case of [ 10], with all groups homogeneous, ¯/u1D44Acoincides with the optimal subsolution.\\nHowever, optimal performanceis no longerguaranteedby Theorem 5.3.;\\nIn order to use this choice of ¯/u1D44Ait remains to determine the constant /u1D450. For this, the physical\\ninterpretationof /u1D450astheenergyleveladdedtothesystemcanbeused.Thechoiceo f/u1D450shouldthen\\nbesuchthattrajectoriesof /u1D44B/u1D45Bunderthesamplingmeasuretakeanappropriateamountoftimeto\\nreach/u1D437/u1D467;ﬁndingthisenergyleveldoesnotaddanysigniﬁcantcomputationalc ost.However,good\\nperformanceisnolongersuggestedbyTheorem 5.3.Inlieu oftheoreticalresults onperformance,\\nthis algorithmis studied numericallyin Section 6, forsome choicesofparameter values for /u1D451=2', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='this algorithmis studied numericallyin Section 6, forsome choicesofparameter values for /u1D451=2\\nand/u1D451=3,exhibiting goodperformancein the rare-event setting.\\nWe end the section with a brief remark on the importance sampling algorithms used in [ 10].\\nThereinthe jumpintensities ofthe sampling distributions are o fthe form\\n¯/u1D706/u1D457(x)=/u1D6FE/u1D706/u1D457(x),\\nfordiﬀerent valuesof /u1D6FE.Thischoicecorrespondstoa state-independent changeofmeasur e. Such\\njumpintensitiesareobtainedasaspecialcaseof ( 14)byconsideringsubsolutions ¯/u1D44Athatareaﬃne\\nin the state-variable x. However, such aﬃne subsolutions will typically not achieve a m aximal\\ninitial value, which explains the poor performance observed in [10]: whereas therein the value\\nof/u1D6FEis selected via a trial-and-error strategy, an analysis using s ubsolutions shows that even the\\noptimal choiceof /u1D6FEwill not lead to asymptotic optimality.\\n6 NUMERICAL EXPERIMENTS', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='optimal choiceof /u1D6FEwill not lead to asymptotic optimality.\\n6 NUMERICAL EXPERIMENTS\\nWe now present some numerical experiments for the importance samp ling algorithms proposed\\nin Section 5, for diﬀerent choices of number of groups /u1D451and parameter values in ( 1): recall that\\nthe jumpintensities are of the form\\n/u1D706/u1D457(x)=/u1D44E/u1D457(/u1D464/u1D457−/u1D465/u1D457)/u1D452/u1D44F/summationtext.1/u1D451\\n/u1D456=1/u1D465/u1D456, /u1D457=1,...,/u1D451,\\nforsomenon-negative /u1D44E/u1D457sand/u1D44F. Inparticular,weimplementtheoptimaltime-homogeneousim -\\nportancesampler(deﬁnedinTheorem 5.3)fortheone-dimensionalexamplesstudied in[ 10],veri-\\nfyingnumericallytheasymptotic optimality that followsfro macombination ofTheorem 4.1and', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='fyingnumericallytheasymptotic optimality that followsfro macombination ofTheorem 4.1and\\nProposition 5.1.Notethattheresultspresentedinthissectionarebasedont heembeddeddiscrete-\\ntimeMarkovchain {/u1D44B/u1D45B(/u1D447/u1D457);/u1D457≥0},asopposedtothecontinuous-timeprocess {/u1D44B/u1D45B(/u1D461);/u1D461∈ [0,/u1D447]};\\nthisdoesnotaﬀecttheperformanceanalysisintheprevioussec tions,whichremainsintactforthe\\nembeddedchain,see e.g.Sections7 and9 in [ 16].\\nBefore reporting our results, some comments on the numerical re sults in [ 10] are in place.\\nTherein, the authors do not compute the probability of the event {/u1D44B/u1D45B(/u1D447) ≥/u1D467}, for/u1D467∈ (0,1),', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='but rather of {/u1D44B/u1D45B(/u1D461)=/u1D456//u1D45B}for each/u1D456=1,2,...,/u1D45B. Moreover, they use a range of parameters to\\ndecide the importance sampling intensity, changing the parameter for diﬀerent /u1D456∈ {1,2,...,/u1D45B}.\\nBecause of this, that only no or extreme contagion are considered , and the fact that no type of\\nuncertainty forthe estimates (suchasrelative errors) are re ported,the results are not suitable for\\ndirect comparisons to those presented in this paper. The main t akeaway from the numerical ex-\\nperimentsin[ 10]istheineﬃciencyofthestate-independentimportancesamplingal gorithm,and\\ntheinteractingparticlesystemmethod,usedthereinwhenthe reismoderatetoextremecontagion\\npresentinthemodel,showingtheneedforstate-dependentalterna tivesinthecaseofimportance\\nsampling.\\nInwhatfollowsourexperimentsaregroupedintoexampleswith homogeneousgroups(i.e.,one\\nor more groups with the same intensities), which in principle ca n be compared to the results in', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='sampling.\\nInwhatfollowsourexperimentsaregroupedintoexampleswith homogeneousgroups(i.e.,one\\nor more groups with the same intensities), which in principle ca n be compared to the results in\\n[10],andexampleswith /u1D451≥2groupswithdiﬀerent intensities. Forallexperiments,theesti mates\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:17\\narebasedon 100batcheswith /u1D441=5000samplesineachbatch;probability estimatesandrelative\\nerrorsare computedover batches.\\nHomogeneousgroupswith noto moderate contagion. For the homogeneoussetting, to stay consis-\\ntentwith[ 10],thenumberofobligorsis /u1D45B=125,thetimeofmaturityis /u1D447=5andwehaveusedas\\nintensity/u1D44E=0.01;in the credit risk context,this correspondsto a homogeneousp oolof obligors,\\nall with default rate 0.01 (when we do not account for contagion e ﬀects). In Tables 1and2we\\npresentsimulationresultsfortheone-dimensionalversionoft hemodel( 1)for/u1D44F=0(Table1)and\\n/u1D44F=5(Table2). The subsolution used to construct the sampling distributio n is that of Theorem\\n5.3.\\nAsdescribedin Section 5,thehomogeneousversion ofthe modelcan essentially bereduc edto\\ntheone-dimensionalsetting,regardlessofthedimension /u1D451,andtheaccuracyoftheasymptotically', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='theone-dimensionalsetting,regardlessofthedimension /u1D451,andtheaccuracyoftheasymptotically\\noptimalsimulationalgorithmisnotaﬀected.Toillustratet hispoint,weconsideranexamplewith\\n/u1D451=5,/u1D44E=0.01,/u1D44F=5and equal partitioning amongst the /u1D451groups:/u1D464/u1D457=1//u1D451,/u1D457=1,...,/u1D451; the\\nnumericalresults are presented in Table 3(compareto Table 2).\\nTable 1. Importance sampling and Monte Carlo estimates for t he case of independent obligors; /u1D451=1,/u1D45B=\\n125,/u1D447=5,/u1D44E=0.01,/u1D44F=0.\\nImportancesampling Monte Carlo\\n/u1D467 ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B) ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B)', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0.108.238e-3 0.0219 8.282e-3 0.1389\\n0.151.089e-5 0.027 1.200e-5 3.978\\n0.201.737e-9 0.028 - -\\n0.257.250e-15 0.031 - -\\n0.303.499e-20 0.039 - -\\n0.354.470e-26 0.038 - -\\n0.401.624e-32 0.037 - -\\nTable 2. Importance sampling and Monte Carlo estimates for a model with moderate contagion; /u1D451=1,\\n/u1D45B=125,/u1D447=5,/u1D44E=0.01,/u1D44F=5.\\nImportancesampling Monte Carlo\\n/u1D467 ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B) ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B)\\n0.104.389e-2 0.0183 4.383e-2 0.0613', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0.104.389e-2 0.0183 4.383e-2 0.0613\\n0.159.337e-4 0.0210 9.660e-4 0.480\\n0.209.183e-6 0.0266 1.800e-5 3.196\\n0.252.552e-8 0.0273 - -\\n0.301.380e-10 0.0295 - -\\n0.357.280e-13 0.0343 - -\\n0.404.089e-15 0.0322 - -\\nThe results in Tables 1–3illustrate the asymptotically optimal performace of the pr oposed\\nmethodin thecaseofahomogeneousmodel(i.e.,allintensities /u1D44E/u1D457areequal).Table 1corresponds\\nto the example of independent obligors ( /u1D44F=0) studied in Section 4 in [ 10]. The results in Table\\n2are for a model with moderate contagion,in-between the cases of independent obligors( /u1D44F=0)\\nand extreme contagion ( /u1D44F=13). For/u1D44F=0, the algorithm in [ 10] works well, however for mod-', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='and extreme contagion ( /u1D44F=13). For/u1D44F=0, the algorithm in [ 10] works well, however for mod-\\nels with moderate contagion it performs poorly even in the one- dimensional case, whereas the\\nmethodpresented here is asymptoticallyoptimal.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:18 Djehiche, Hultand Nyquist\\nTable 3. Importance sampling and Monte Carloestimates for a homogeneous model with moderate conta-\\ngion;/u1D451=5,/u1D45B=125,/u1D447=5,/u1D44E/u1D457=0.01,/u1D457=1,...,5,/u1D44F=5,/u1D464/u1D457=1/5,/u1D457=1,...,5.\\nImportancesampling Monte Carlo\\n/u1D467 ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B) ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B)\\n0.104.391e-2 0.0202 7.800e-2 0.0632\\n0.159.334e-4 0.0292 9.200e-4 0.516\\n0.208.447e-6 0.0362 2.000e-6 10.000\\n0.252.565e-8 0.0454 - -\\n0.301.385e-10 0.0543 - -', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0.252.565e-8 0.0454 - -\\n0.301.385e-10 0.0543 - -\\n0.357.247e-13 0.0577 - -\\n0.404.102e-15 0.0734 - -\\nInhomogeneous groups with moderate contagion. We now move to experiments with /u1D451=2and\\n/u1D451=3in(1),i.e.,inthecreditriskcontext,weallowtheretobemoreth anonegroupofobligorswith\\ndiﬀerentdefaultintensities.Theimportancesamplingresultsa reobtainedusingthesubsolution ¯/u1D44A\\ndescribedinSection 5.2.Notethatwehavenotattemptedtooptimisetheselectionoft heconstant /u1D450\\ninthediﬀerentcomputationsandthiscouldpotentiallydriveth erelativeerrordownevenfurther.\\nAsaﬁrstexample,weconsidertwogroups, /u1D451=2,withintensities /u1D44E1=0.01,/u1D44E2=0.05andmod-', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='erate contagion /u1D44F=5, with the ﬁrst group constituting 80%of the population; numerical results\\nare presented in Table 4. Although the algorithm is not provably optimal in this inhomo geneous\\nTable 4. Importance sampling, using ¯/u1D44A, and Monte Carlo estimates for inhomogeneous groups; /u1D451=2,\\n/u1D45B=125,/u1D447=2,/u1D44E=(0.01,0.05),/u1D44F=5,/u1D464=(0.8,0.2).\\nImportancesampling Monte Carlo\\n/u1D467 ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B) ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B)\\n0.080.0331 0.0218 0.0328 0.0738\\n0.102.923e-3 0.0271 3.002e-3 0.258\\n0.124.592e-4 0.0354 4.700e-4 0.678', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0.102.923e-3 0.0271 3.002e-3 0.258\\n0.124.592e-4 0.0354 4.700e-4 0.678\\n0.142.167e-5 0.0457 2.200e-5 2.859\\n0.162.457e-6 0.0460 - -\\n0.207.094e-9 0.0570 - -\\n0.241.382e-11 0.0800 - -\\n0.282.077e-14 0.102 - -\\ncase,it exhibits excellent performance,with arelative erro r of onlyabout 10%forprobabilities of\\norder10−14.\\nNext, we consider three groups, /u1D451=3, with intensities /u1D44E1=0.005,/u1D44E2=0.01, and/u1D44E3=0.05,\\nand moderate contagion ( /u1D44F=5). The two ﬁrst groups constitute 40% of the population each and\\nthethirdgroup,withintensity /u1D44E3=0.05,constitutestheremaining20%;thenumericalresultsare\\npresented in Table 5.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='thethirdgroup,withintensity /u1D44E3=0.05,constitutestheremaining20%;thenumericalresultsare\\npresented in Table 5.\\nSimilar to the results in Table 4, the importance sampling results in Table 5, based on the sub-\\nsolution ¯/u1D44A, are excellent for the range of /u1D467considered here. Compared to the homogeneous set-\\nting—seeTables 1-3—therelativeerrorstartstoslowlyincreaseastheprobabil itybecomessmaller.\\nThis is to be expected,as ¯/u1D44Adoes not correspond to an asymptotically optimal method.Howe ver\\ntheimprovementoverbothstandardMonteCarloandthemethodspr esentedin[ 10]issubstantial:\\neven for probabilities of order 10−16the observed relative error is below 1/4. Together with the\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:19\\nTable 5. Importance sampling, using ¯/u1D44A, and Monte Carlo estimates for inhomogeneous groups; /u1D451=3,\\n/u1D45B=125,/u1D447=2,/u1D44E=(0.005,0.01,0.05),/u1D44F=5,/u1D464=(0.4,0.4,0.2).\\nImportancesampling Monte Carlo\\n/u1D467 ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B) ˆ/u1D45D/u1D45BRE(ˆ/u1D45D/u1D45B)\\n0.040.406 0.0131 0.406 0.0156\\n0.081.534e-2 0.0267 1.511e-2 0.119\\n0.121.078e-4 0.0432 9.600e-5 1.340\\n0.143.272e-6 0.0445 2.000e-6 10.000\\n0.162.708e-7 0.0547 – –', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0.143.272e-6 0.0445 2.000e-6 10.000\\n0.162.708e-7 0.0547 – –\\n0.203.363e-10 0.0686 – –\\n0.242.631e-13 0.107 – –\\n0.281.581e-16 0.211 – –\\notherresultsinthissections,thisshowshowthesubsolutio napproachtoimportancesamplingin\\ngeneral,andtheproposedmethodinparticular,canleadtosig niﬁcantimprovement inthedesign\\nofeﬃcient algorithmscomparedto a “naive” state-independent ch ange-of-measure.\\nACKNOWLEDGMENTS\\nWe thank the Associate Editor and anonymous referees for helpful feedback and suggestions,\\nwhichhelpedimprove the manuscript.\\nB. Djehiche’s research was supported by the Swedish Researc h Council, H. Hult’s research\\nwas supported by the Göran Gustafsson Foundation, and P. Nyquis t’s research was supported\\nby the Verg foundation, the Swedish Research Council (VR-2018- 07050) and the Wallenberg AI,\\nAutonomous Systems and Software Program (WASP) funded by the Knu t and Alice Wallenberg', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='by the Verg foundation, the Swedish Research Council (VR-2018- 07050) and the Wallenberg AI,\\nAutonomous Systems and Software Program (WASP) funded by the Knu t and Alice Wallenberg\\nFoundation. We are very gratefulfor their ﬁnancial support.\\nREFERENCES\\n[1] DavidFAndersonandThomasGKurtz.2011. ContinuoustimeMarkov chainmodelsforchemicalreactionnetworks.\\nInDesign and analysis ofbiomolecularcircuits . Springer,3–42.\\n[2] Søren Asmussen. 2003. Applied probability and queues (seconded.). Springer,NewYork, NY.\\n[3] Søren Asmussen and Peter W. Glynn. 2007. Stochastic simulation: Algorithms and analysis (ﬁrst ed.). Springer, New\\nYork, NY. vi+476pages.\\n[4] Jose Blanchet, HenrikHult, and KevinLeder.2013. Rare-Event S imulation forStochastic Recurrence Equations with\\nHeavy-Tailed Innovations. ACMTrans.Model. Comput.Simul. 23,4,Article22 (2013),25pages.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Heavy-Tailed Innovations. ACMTrans.Model. Comput.Simul. 23,4,Article22 (2013),25pages.\\n[5] Jose Blanchet andChenxinLi.2011. Eﬃcient Rare Event Simulation fo rHeavy-Tailed Compound Sums. ACMTrans.\\nModel. Comput.Simul. 21,2,Article9(2011),23pages.\\n[6] JoseH.BlanchetandPeterW.Glynn.2008. Eﬃcientrare-eventsimu lationforthemaximumofaheavy-tailedrandom\\nwalk.Ann. ofAppl. Prob. 18,4 (2008),1351–1378.\\n[7] Jose H. Blanchet, Peter W. Glynn, and Kevin Leder. 2012. On Lyap unov inequalities and subsolutions for eﬃcient\\nimportance sampling. TOMACS 22,3 (2012),1104–1128.\\n[8] Jose H. Blanchet and Jingchen Liu. 2008. State-dependent importa nce sampling forregularly varying randomwalks.\\nAdv. Appl.Prob. 40(2008),1104–1128.\\n[9] Amarjit Budhiraja andPaul Dupuis.2019. Representations andweak convergencemethods forthe analy sis andapprox-', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='[9] Amarjit Budhiraja andPaul Dupuis.2019. Representations andweak convergencemethods forthe analy sis andapprox-\\nimation ofrare events (ﬁrsted.). Springer,NewYork, NY.\\n[10] René Carmona and Stéphane Crépey. 2010. Particle methods for the estimation of credit portfolio loss distributions.\\nInt. J.Theor. Appl.Finance 13,4(2010),577–602. https://doi.org/10.1142/S0219024910005905\\n[11] René Carmona, Jean-Pierre Fouque, and Douglas Vestal. 2009. Interacting particle systems for the computation of\\nrare credit portfoliolosses. Finance Stoch. 13,4 (2009),613–633. https://doi.org/10.1007/s00780-009-0098-8\\n[12] Pierre Del Moral and Josselin Garnier. 2005. Genealogical part icle analysis of rare events. Ann. Appl. Probab. 15, 4\\n(2005),2496–2534. https://doi.org/10.1214/105051605000000566\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:20 Djehiche, Hultand Nyquist\\n[13] BoualemDjehiche,HenrikHult,andPierreNyquist.2019.Min-ma xrepresentationsofviscositysolutionsofHamilton-\\nJacobi equations. Preprint(2019).\\n[14] Leder Kevin Dupuis, Paul and Hui Wang. 2007. Importance sampl ing for sums of random variables with regularly\\nvarying tails. ACMTransactions of Modeling and ComputerSimulation 17 (2007).\\n[15] Paul Dupuis and Richard S. Ellis.1997. A weak convergenceapproach to the theory of largedeviation s(ﬁrst ed.). John\\nWiley&Sons, Inc.,NewYork, NY.vii+479pages.\\n[16] Paul Dupuis, Kevin Leder, and Hui Wang. 2009. Importance samp ling for weighted-serve-the-longest-queue. Math.\\nOper. Res. 34,3 (2009),642–660. https://doi.org/10.1287/moor.1090.0389\\n[17] PaulDupuis,AliDevinSezer,andHuiWang.2007. Dynamicimport ancesamplingforqueueingnetworks. Ann.Appl.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='[17] PaulDupuis,AliDevinSezer,andHuiWang.2007. Dynamicimport ancesamplingforqueueingnetworks. Ann.Appl.\\nProbab.17,4(2007),1306–1346. https://doi.org/10.1214/105051607000000122\\n[18] Paul Dupuis, Konstantinos Spiliopoulos, and Hui Wang. 2012. Impo rtance sampling for multiscale diﬀusions. Multi-\\nscale Model.Simul. 10,1(2012),1–27. https://doi.org/10.1137/110842545\\n[19] Paul Dupuis and Hui Wang. 2004. Importance sampling, large dev iations and diﬀerential games. Stoch. and Stoch.\\nReports76,6(2004),481–508.\\n[20] PaulDupuis andHuiWang. 2005. Dynamicimportance sampling forunif ormlyrecurrentMarkovchains. Ann.Appl.\\nProbab.15,1A(2005),1–38. https://doi.org/10.1214/105051604000001016', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Probab.15,1A(2005),1–38. https://doi.org/10.1214/105051604000001016\\n[21] PaulDupuis andHui Wang.2007. Subsolutionsof anIsaacs equa tion andeﬃcientschemesforimportance sampling.\\nMathematics ofOperations Research 32,3(2007),723–757.\\n[22] PaulDupuisandHuiWang.2009. Importance samplingforJackso n networks. QueueingSyst. 62,1-2(2009),113–157.\\nhttps://doi.org/10.1007/s11134-009-9124-y\\n[23] StewartN.EthierandThomasG.Kurtz.1986. Markovprocesses:Characterizationandconvergence . JohnWiley&Sons,\\nInc.,NewYork. x+534pages. https://doi.org/10.1002/9780470316658\\n[24] Lawrence C.Evans.2010. Partial diﬀerential equations (second ed.).Graduate StudiesinMathematics, Vol.19. Amer-\\nican Mathematical Society, Providence,RI.xxii+749pages. https://doi.org/10.1090/gsm/019', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='ican Mathematical Society, Providence,RI.xxii+749pages. https://doi.org/10.1090/gsm/019\\n[25] JinFengandThomasG.Kurtz.2006. Largedeviationsforstochastic processes .MathematicalSurveysandMonographs,\\nVol.131. American Mathematical Society, Providence,RI.xii+410p ages.\\n[26] Kay Giesecke, Konstantinos Spiliopoulos, and Richard B. Sowers. 2013. Defaultclustering inlarge portfolios: typical\\nevents.Ann. Appl. Probab. 23,1 (2013),348–385. https://doi.org/10.1214/12-AAP845\\n[27] Kay Giesecke, Konstantinos Spiliopoulos, Richard B. Sowers, and Justin A. Sirignano. 2015. Large portfolio asymp-\\ntotics forlossfrom default. Math. Finance 25,1 (2015),77–114. https://doi.org/10.1111/maﬁ.12011\\n[28] PaulGlasserman.2004. MonteCarlomethodsinﬁnancialengineering .ApplicationsofMathematics(NewYork),Vol.53.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='[28] PaulGlasserman.2004. MonteCarlomethodsinﬁnancialengineering .ApplicationsofMathematics(NewYork),Vol.53.\\nSpringer-Verlag,NewYork. xiv+596pages. Stochastic Modellinga nd Applied Probability.\\n[29] Paul Glasserman, PhilipHeidelberger,and Perwez Shahabudd in.2002. Portfolio value-at-risk with heavy-tailed risk\\nfactors.Math. Finance 12,3 (2002),239–269. https://doi.org/10.1111/1467-9965.00141\\n[30] Paul Glasserman and Jingyi Li. 2005. Importance sampling for po rtfolio credit risk. Management Science 51 (2005),\\n1643–1656.\\n[31] Paolo Guasoni and Scott Robertson. 2008. Optimal importance s ampling with explicit formulas in continuous time.\\nFinance Stoch. 12,1 (2008),1–19. https://doi.org/10.1007/s00780-007-0053-5\\n[32] Willi Jäger, Hermann Rost, and Petre Tautu. 2013. Biological Growthand Spread: Mathematical Theories and Ap plica-', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='[32] Willi Jäger, Hermann Rost, and Petre Tautu. 2013. Biological Growthand Spread: Mathematical Theories and Ap plica-\\ntions, Proceedings ofa ConferenceHeldat Heidelberg,July 16–21, 1979 . Vol.38. Springer Science &Business Media.\\n[33] R.Mañé.1997. Lagrangianﬂows:thedynamicsofgloballyminimizing orbits.Bull.BrazilianMathematical Society 28,\\n2 (1997),141–153.\\n[34] Sylvie Méléard and Denis Villemonais. 2012. Quasi-stationary dist ributions and population processes. Probability\\nSurveys9(2012),340–410.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='2 (1997),141–153.\\n[34] Sylvie Méléard and Denis Villemonais. 2012. Quasi-stationary dist ributions and population processes. Probability\\nSurveys9(2012),340–410.\\n[35] GerardoRubinoand BrunoTuﬃn (Eds.).2009. Rareevent simulation using Monte Carlomethods . John Wiley&Sons,\\nLtd.,Chichester.x+268pages. https://doi.org/10.1002/9780470745403\\n[36] Reuven Y. Rubinsteinand DirkP. Kroese. 2004. The cross-entropy method . Springer-Verlag, NewYork. xx+300pages.\\nhttps://doi.org/10.1007/978-1-4757-4321-0 A uniﬁed approach to combinatorial optimization, Monte-Carlo simula-\\ntion, andmachine learning.\\n[37] Adam Shwartz and Alan Weiss. 1995. Large deviations for performance analysis . Chapman & Hall, London. x+556\\npages. Queues,communications, and computing, With an appendix byRobe rtJ. Vanderbei.\\n[38] Konstantinos Spiliopoulos and Richard B. Sowers. 2015. Default clustering in large pools: large deviations. SIAM J.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='[38] Konstantinos Spiliopoulos and Richard B. Sowers. 2015. Default clustering in large pools: large deviations. SIAM J.\\nFinancial Math. 6,1 (2015),86–116. https://doi.org/10.1137/130944060\\n[39] N.G.vanKampen. 1981. Stochastic processesinphysics andchemistry .LectureNotesinMathematics,Vol.888. North-\\nHolland PublishingCo.,Amsterdam-New York. xiv+419pages.\\n[40] XZhang,JBlanchet,KGisecke,andP.WGlynn.2015. Aﬃnepointproc esses:approximationandeﬃcientsimulation.\\nMath. Oper. Res. 40,4(2015),797–819.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:21\\nA DERIVATION OF ISAACS EQUATION\\nFor completeness, and for the reader who wishes to develop some intuition, we end the paper\\nwithaformalderivationoftheIsaacsequationassociatedw iththeimportancesamplingestimator\\n(10).Naturally,theargumentfollowscloselythegeneralstepsu sedinotherworksonthesubsolu-\\ntionapproachfordynamicimportancesampling;see[ 21]foranoverview. Weemphasizethatthe\\nderivation is ofa formalnature andnot all steps are motivated r igorously.\\nRecalling the discussion in Section 4, the main quantity of interest for performanceanalysis is\\nthe secondmoment\\nE¯Q/u1D45B[ˆ/u1D45D2\\n/u1D45B]\\n=EQ/u1D45B[\\n/u1D43C{/u1D441/u1D467</u1D4410}/u1D441/u1D467/productdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D43C{/u1D441/u1D467</u1D4410}/u1D441/u1D467/productdisplay.1\\n/u1D458=1Θ/u1D45B(/u1D451/u1D70F/u1D458,/u1D463/u1D458|/u1D44B/u1D45B(/u1D447/u1D458−1))\\n¯Θ/u1D45B(/u1D451/u1D70F/u1D458,/u1D463/u1D458|/u1D44B/u1D45B(/u1D447/u1D458−1))]\\n.\\nToﬁnd themost eﬃcient choiceof ¯Θ/u1D45B,one canminimise this secondmomentwith respect to ¯Θ/u1D45B:\\nDeﬁne/u1D449/u1D45Bto bethis optimal secondmoment,\\n/u1D449/u1D45B=inf\\n¯Θ/u1D45B/u1D438Θ/u1D45B[', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D449/u1D45B=inf\\n¯Θ/u1D45B/u1D438Θ/u1D45B[\\n/u1D43C{/u1D441/u1D467</u1D4410}/u1D441/u1D467/productdisplay.1\\n/u1D458=1Θ/u1D45B(/u1D451/u1D70F/u1D458,/u1D463/u1D458|/u1D44B/u1D45B(/u1D447/u1D458−1))\\n¯Θ/u1D45B(/u1D451/u1D70F/u1D458,/u1D463/u1D458|/u1D44B/u1D45B(/u1D447/u1D458−1))]\\n,\\nand deﬁne/u1D44A/u1D45Bthrougha large-deviation-type scaling,\\n/u1D44A/u1D45B=−1\\n/u1D45Blog/u1D449/u1D45B,', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D44A/u1D45B=−1\\n/u1D45Blog/u1D449/u1D45B,\\nToemploytoolsfromstochasticcontrol,forboth /u1D449/u1D45Band/u1D44A/u1D45Bonecandeﬁnetime-and-state-dependent\\nanaloguesby conditioning:\\n/u1D449/u1D45B(/u1D461,x)=inf\\n¯Θ/u1D45B/u1D438Θ/u1D45B[\\n/u1D43C{/u1D441/u1D467</u1D4410}/u1D441/u1D467/productdisplay.1\\n/u1D458=/u1D459Θ/u1D45B(/u1D451/u1D70F/u1D458,/u1D463/u1D458|/u1D44B/u1D45B(/u1D447/u1D458−1))', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='¯Θ/u1D45B(/u1D451/u1D70F/u1D458,/u1D463/u1D458|/u1D44B/u1D45B(/u1D447/u1D458−1))|/u1D44B/u1D45B(/u1D461)=x]\\n,(20)\\nwhere/u1D459is such that /u1D447/u1D459−1≤/u1D461</u1D447/u1D459, and/u1D44A/u1D45B(/u1D461,x)is deﬁned from /u1D449/u1D45B(/u1D461,x)as/u1D44A/u1D45Bis from/u1D449/u1D45B.By the\\nmemoryless property of the exponential distribution no correc tion for the ﬁrst step is needed in\\n(20);/u1D70F/u1D459and/u1D70F/u1D459|/u1D70F/u1D459≥/u1D461−/u1D447/u1D459−1have thesame distribution.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='As described in Section 4the jump intensities under consideration are of the form ¯/u1D45F/u1D45B(x,e/u1D457)=\\n/u1D45B¯/u1D706/u1D457(x), where¯/u1D706(x)=(¯/u1D7061(x),...,¯/u1D706/u1D451(x))is not identical to the zero element in R/u1D451. Since each\\nstochastickernel ¯Θ/u1D45Bisdeterminedbythe corresponding ¯/u1D706,theinﬁmumin ( 20)isover those ¯/u1D706(x)\\nthat are zero only for directions /u1D457for which/u1D706is zero. Note that there will be a slight abuse of\\nnotationinthatsupremumandinﬁmumistakenover ¯/u1D45F/u1D45B,andinincludingtheargument xalthough\\nthe optimization will alwaystakeplace fora ﬁxedstate x.\\nBecausetheprocess /u1D44B/u1D45Bisconstantbetweenjumps,thelikelihoodratioin( 20)canbeexpressed\\nas', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Becausetheprocess /u1D44B/u1D45Bisconstantbetweenjumps,thelikelihoodratioin( 20)canbeexpressed\\nas\\nexp{/uni222B.dsp/u1D447/u1D441/u1D467\\n/u1D447/u1D459(¯/u1D445(/u1D44B/u1D45B(/u1D460)) −/u1D445(/u1D44B/u1D45B(/u1D460)))/u1D451/u1D460+/u1D441/u1D467/summationdisplay.1\\n/u1D458=/u1D459log/u1D45F/u1D45B(/u1D44B/u1D45B(/u1D447/u1D458−1),/u1D463/u1D458)\\n¯/u1D45F/u1D45B(/u1D44B/u1D45B(/u1D447/u1D458−1),/u1D463/u1D458)}\\n=exp{/u1D441/u1D467/summationdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='=exp{/u1D441/u1D467/summationdisplay.1\\n/u1D458=/u1D459(\\n(¯/u1D445(/u1D44B/u1D45B(/u1D447/u1D458−1)) −/u1D445(/u1D44B/u1D45B(/u1D447/u1D458−1)))/u1D70F/u1D458\\n+log/u1D45F/u1D45B(/u1D44B/u1D45B(/u1D447/u1D458−1),/u1D463/u1D458)\\n¯/u1D45F/u1D45B(/u1D44B/u1D45B(/u1D447/u1D458−1),/u1D463/u1D458))}\\n.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:22 Djehiche, Hultand Nyquist\\nIntegration over the joint distribution of (/u1D70F/u1D459,/u1D463/u1D459),using the independence ofthe /u1D70F/u1D458’s, yields\\n/u1D449/u1D45B(/u1D461,x)=inf\\n¯/u1D45F/u1D45B(x,·)/uni222B.dsp∞\\n0/u1D451/summationdisplay.1\\n/u1D457=1exp{\\n(¯/u1D445(x) −/u1D445(x))/u1D462+log/u1D45F/u1D45B(x,e/u1D457)\\n¯/u1D45F/u1D45B(x,e/u1D457)}\\n×/u1D438Θ/u1D45B[\\n/u1D43C{/u1D441/u1D467</u1D4410}exp{/uni222B.dsp/u1D447/u1D441/u1D467', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D43C{/u1D441/u1D467</u1D4410}exp{/uni222B.dsp/u1D447/u1D441/u1D467\\n/u1D447/u1D459+1(¯/u1D445(/u1D44B/u1D45B(/u1D460)) −/u1D445(/u1D44B/u1D45B(/u1D460)))/u1D451/u1D460\\n+/u1D441/u1D467/summationdisplay.1\\n/u1D458=/u1D459+1log/u1D45F/u1D45B(/u1D44B/u1D45B(/u1D447/u1D458−1),/u1D463/u1D458)\\n¯/u1D45F/u1D45B(/u1D44B/u1D45B(/u1D447/u1D458−1),/u1D463/u1D458)}\\n|/u1D44B/u1D45B(/u1D461+/u1D462)=x+e/u1D457', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='|/u1D44B/u1D45B(/u1D461+/u1D462)=x+e/u1D457\\n/u1D45B]\\n×/u1D45F/u1D45B(x,e/u1D457)/u1D452−/u1D445(x)/u1D462/u1D451/u1D462,\\nandbythedynamicprogrammingprinciple /u1D449/u1D45B(/u1D461,x)satisﬁesthefollowingdynamicprogramming\\nequation,\\n/u1D449/u1D45B(/u1D461,x)=inf\\n¯/u1D45F/u1D45B(x,·){/uni222B.dsp∞\\n0/u1D451/summationdisplay.1\\n/u1D457=1/u1D452(¯/u1D445(x)−/u1D445(x))/u1D462/u1D45F/u1D45B(x,e/u1D457)\\n¯/u1D45F/u1D45B(x,e/u1D457)', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='¯/u1D45F/u1D45B(x,e/u1D457)\\n×/u1D449/u1D45B(/u1D461+/u1D462,x+e/u1D457\\n/u1D45B)/u1D45F/u1D45B(x,e/u1D457)/u1D452−/u1D445(x)/u1D462/u1D451/u1D462}\\n.(21)\\nFrom equation( 21) for/u1D449/u1D45B(/u1D461,x)we obtain thecorresponding equationfor /u1D44A/u1D45B(/u1D461,x),\\n/u1D45B/u1D44A/u1D45B(/u1D461,x)=sup\\n¯/u1D45F/u1D45B(x,·){\\n−log/uni222B.dsp∞\\n0/u1D451/summationdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='¯/u1D45F/u1D45B(x,·){\\n−log/uni222B.dsp∞\\n0/u1D451/summationdisplay.1\\n/u1D457=1/u1D452(¯/u1D445(x)−/u1D445(x))/u1D462/u1D45F/u1D45B(x,e/u1D457)\\n¯/u1D45F/u1D45B(x,e/u1D457)\\n×/u1D452−/u1D45B/u1D44A/u1D45B(/u1D461+/u1D462,/u1D465+/u1D452/u1D457\\n/u1D45B)/u1D45F/u1D45B(/u1D465,/u1D452/u1D457)/u1D452−/u1D445(/u1D465)/u1D462/u1D451/u1D462}\\n.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='.\\nLetˆΘ/u1D45Bdenote the stochastic kernel based on a set of jump intensities ˆ/u1D45F/u1D45B(x,·), whereˆ/u1D45F/u1D45B(x,e/u1D457)=\\n/u1D45Bˆ/u1D706/u1D457(x)for some function ˆ/u1D706:/u1D437→R/u1D451. From the relative entropy representation for exponential\\nintegrals(see,e.g., [ 15,21]),\\n/u1D45B/u1D44A/u1D45B(/u1D461,x)=sup\\n¯/u1D45F/u1D45B(x,·)inf\\nˆΘ/u1D45B{\\nH(ˆΘ/u1D45B|Θ/u1D45B) +/uni222B.dsp∞\\n0/u1D451/summationdisplay.1\\n/u1D457=1((/u1D445(x) −¯/u1D445(x))/u1D462', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0/u1D451/summationdisplay.1\\n/u1D457=1((/u1D445(x) −¯/u1D445(x))/u1D462\\n+log¯/u1D45F/u1D45B(x,e/u1D457)\\n/u1D45F/u1D45B(x,e/u1D457)+/u1D45B/u1D44A/u1D45B(/u1D461+/u1D462,x+e/u1D457\\n/u1D45B))ˆ/u1D45F/u1D45B(x,e/u1D457)/u1D452−ˆ/u1D445(x)/u1D462/u1D451/u1D462}\\n,\\nwhereHdenotes the relative entropy. The inﬁmum over ˆΘ/u1D45Bis equivalent to inﬁmum over jump\\nintensities ˆ/u1D45F/u1D45B(x,·)andthelikelihoodratiobetween ˆΘ/u1D45BandΘ/u1D45Bisofthesameformasthelikelihood', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='ratio between ¯Θ/u1D45BandΘ/u1D45B. Writing out the relative entropy term explicitly and moving /u1D45B/u1D44A/u1D45B(/u1D461,x)\\nto the right-handside,\\n0=sup\\n¯/u1D45F/u1D45B(x,·)inf\\nˆ/u1D45F/u1D45B(x,·){/uni222B.dsp∞\\n0/u1D451/summationdisplay.1\\n/u1D457=1(\\n(2/u1D445(x) −¯/u1D445(x) −ˆ/u1D445(x))/u1D462 (22)\\n+log¯/u1D45F/u1D45B(x,e/u1D457) +logˆ/u1D45F/u1D45B(x,e/u1D457) −2log/u1D45F/u1D45B(x,e/u1D457) (23)', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='+/u1D45B(/u1D44A/u1D45B(/u1D461+/u1D462,x+e/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x)))\\nˆ/u1D45F/u1D45B(x,e/u1D457)/u1D452−ˆ/u1D445(x)/u1D462/u1D451/u1D462}\\n. (24)\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:23\\nThe three terms on the right-hand side are treated separately . Theﬁrst two integrals are straight-\\nforward tocompute:\\n/uni222B.dsp∞\\n0/u1D451/summationdisplay.1\\n/u1D457=1(\\n2/u1D445(x) −¯/u1D445(x) −ˆ/u1D445(x))\\n/u1D462ˆ/u1D45F/u1D45B(x,e/u1D457)/u1D452−ˆ/u1D445(x)/u1D462/u1D451/u1D462\\n=1\\nˆ/u1D445(x)(\\n2/u1D445(x) −¯/u1D445(x) −ˆ/u1D445(x))\\n,\\nand\\n/uni222B.dsp∞\\n0/u1D451/summationdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content=',\\nand\\n/uni222B.dsp∞\\n0/u1D451/summationdisplay.1\\n/u1D457=1(log¯/u1D45F/u1D45B(x,e/u1D457) +logˆ/u1D45F/u1D45B(x,e/u1D457) −2log/u1D45F/u1D45B(x,e/u1D457))ˆ/u1D45F/u1D45B(x,e/u1D457)/u1D452−ˆ/u1D445(x)/u1D462/u1D451/u1D462\\n=1\\nˆ/u1D445(x)/u1D451/summationdisplay.1\\n/u1D457=1ˆ/u1D45F/u1D45B(x,e/u1D457)(log¯/u1D45F/u1D45B(x,e/u1D457) +logˆ/u1D45F/u1D45B(x,e/u1D457) −2log/u1D45F/u1D45B(x,e/u1D457)).', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='The third integral, with integrand given in ( 24), can be expressed as an expectation involving an\\nexponentiallydistributedrandomvariable.Indeed,let {/u1D709/u1D45B}beasequenceofrandomvariableseach\\nhaving anexponential distribution with mean ˆ/u1D445(x)−1.Then,\\n/uni222B.dsp∞\\n0/u1D451/summationdisplay.1\\n/u1D457=1/u1D45B(\\n/u1D44A/u1D45B(/u1D461+/u1D462,x+e/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x))\\nˆ/u1D45F/u1D45B(x,e/u1D457)/u1D452−ˆ/u1D445(x)/u1D462/u1D451/u1D462\\n=/u1D451/summationdisplay.1\\n/u1D457=1ˆ/u1D45F/u1D45B(x,e/u1D457)\\nˆ/u1D445(x)/u1D438[', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D457=1ˆ/u1D45F/u1D45B(x,e/u1D457)\\nˆ/u1D445(x)/u1D438[\\n/u1D45B(/u1D44A/u1D45B(/u1D461+/u1D709/u1D45B,x+e/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x))]\\n.\\nThe expression involving (theintegrals of)( 22)-(24)canthen be rewritten as\\n0=sup\\n¯/u1D45F/u1D45B(x,·)inf\\nˆ/u1D45F/u1D45B(x,·){\\n1\\nˆ/u1D445(x)(2/u1D445(x) −¯/u1D445(x) −ˆ/u1D445(x))\\n+1\\nˆ/u1D445(x)/u1D451/summationdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='+1\\nˆ/u1D445(x)/u1D451/summationdisplay.1\\n/u1D457=1ˆ/u1D45F/u1D45B(x,e/u1D457)(log¯/u1D45F/u1D45B(x,e/u1D457) +logˆ/u1D45F/u1D45B(x,e/u1D457) −2log/u1D45F/u1D45B(x,e/u1D457))\\n+/u1D451/summationdisplay.1\\n/u1D457=1ˆ/u1D45F/u1D45B(x,e/u1D457)\\nˆ/u1D445(x)/u1D438[\\n/u1D45B(/u1D44A/u1D45B(/u1D461+/u1D709/u1D45B,x+e/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x))]}\\n.\\nDeﬁne thefunction /u1D459:R→ [0,∞]by', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='.\\nDeﬁne thefunction /u1D459:R→ [0,∞]by\\n/u1D459(/u1D465)={\\n/u1D465log/u1D465−/u1D465+1, /u1D465≥0\\n∞, otherwise.\\nWith/u1D709/u1D45B∼Exp(/u1D45BˆΛ(x))and using the same notation for the jump intensities ˆ/u1D45F/u1D45Band¯/u1D45F/u1D45B(i.e.,ˆ/u1D706,ˆΛ\\nand¯/u1D706,¯Λ),the equation ofinterest canbeexpressed as\\n0=sup\\n¯/u1D706(x)inf\\nˆ/u1D706(x){\\n1\\nˆΛ(x)(\\n2/u1D451/summationdisplay.1\\n/u1D457=1/u1D706/u1D457(x)/u1D459(ˆ/u1D706/u1D457(x)\\n/u1D706/u1D457(x))−/u1D451/summationdisplay.1', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D706/u1D457(x))−/u1D451/summationdisplay.1\\n/u1D457=1¯/u1D706/u1D457(x)/u1D459(ˆ/u1D706/u1D457(x)\\n¯/u1D706/u1D457(x)))\\n+1\\nˆΛ(x)/u1D451/summationdisplay.1\\n/u1D457=1ˆ/u1D706/u1D457(x)/u1D438[\\n/u1D45B(/u1D44A/u1D45B(/u1D461+/u1D709/u1D45B,x+e/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x))]}\\n.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='0:24 Djehiche, Hultand Nyquist\\nRecallthat/u1D44A/u1D461and∇x/u1D44Adenotesthetimederivative of /u1D44Aandthegradientinthespacevariable x,\\nrespectively.ToformallyobtainalimitPDErelatedtothes tochasticcontrolproblem,assumethat\\nthere isasuitable limit /u1D44Afor/u1D44A/u1D45B.More precisely,thatthere isasmoothfunction /u1D44Asuchthat,as\\n/u1D45B→ ∞,/u1D44A/u1D45B(/u1D461,x) →/u1D44A(/u1D461,x)and\\n/u1D45B(/u1D44A/u1D45B(/u1D461+/u1D462\\n/u1D45B,x+e/u1D457', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D45B(/u1D44A/u1D45B(/u1D461+/u1D462\\n/u1D45B,x+e/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x)) →/u1D462/u1D44A/u1D461(/u1D461,x) + ⟨∇x/u1D44A(/u1D461,x),e/u1D457⟩.\\nConsider the expectationinvolving the /u1D709/u1D45B’s.By achangeofvariable,\\n/u1D438[\\n/u1D45B(/u1D44A/u1D45B(/u1D461+/u1D709/u1D45B,x+/u1D452/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x))]\\n=/uni222B.dsp∞\\n0/u1D45B(', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D45B) −/u1D44A/u1D45B(/u1D461,x))]\\n=/uni222B.dsp∞\\n0/u1D45B(\\n/u1D44A/u1D45B(/u1D461+/u1D709,x+/u1D452/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x))\\n/u1D45BˆΛ(x)/u1D452−/u1D45BˆΛ(x)/u1D709/u1D451/u1D709\\n=/uni222B.dsp∞\\n0/u1D45B(\\n/u1D44A/u1D45B(/u1D461+/u1D70F\\n/u1D45B,x+e/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x))\\nˆΛ(x)/u1D452−ˆΛ(x)/u1D70F/u1D451/u1D70F.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='ˆΛ(x)/u1D452−ˆΛ(x)/u1D70F/u1D451/u1D70F.\\nAs/u1D45Bgoes to inﬁnity, the assumed convergence of /u1D44A/u1D45Bimplies that, for each /u1D70F, the integrand con-\\nvergesto/u1D70F/u1D44A/u1D461(/u1D461,x) + ⟨∇x/u1D44A(/u1D461,x),e/u1D457⟩. Takingthelimit inside the expectation,\\nlim\\n/u1D45B→∞/u1D438[\\n/u1D45B(/u1D44A/u1D45B(/u1D461+/u1D709/u1D45B,x+e/u1D457\\n/u1D45B) −/u1D44A/u1D45B(/u1D461,x))]\\n=/u1D44A/u1D461(/u1D461,x)', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='=/u1D44A/u1D461(/u1D461,x)\\nˆΛ(x)+ ⟨∇x/u1D44A(/u1D461,x),e/u1D457⟩.\\nThus, in the limit as /u1D45Bgoes to inﬁnity, the dynamic programming equation for /u1D44A/u1D45Bgives rise to\\nthe followingIsaacsequation,\\n0=sup\\n¯/u1D706(x)inf\\nˆ/u1D706(x)1\\nˆΛ(x){/u1D451/summationdisplay.1\\n/u1D457=1(\\n2/u1D706/u1D457(x)/u1D459(ˆ/u1D706/u1D457(x)\\n/u1D706/u1D457(x))−¯/u1D706/u1D457(x)/u1D459(ˆ/u1D706/u1D457(x)\\n¯/u1D706/u1D457(x)))\\n+/u1D44A/u1D461(/u1D461,x)', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='¯/u1D706/u1D457(x)))\\n+/u1D44A/u1D461(/u1D461,x)\\n+/u1D451/summationdisplay.1\\n/u1D457=1ˆ/u1D706/u1D457(x)⟨/u1D437/u1D44A(/u1D461,x),e/u1D457⟩}\\n.(25)\\nNote that, aside from the time derivative /u1D44A/u1D461(/u1D461,x), this is equation (6.4) in [ 16] (with∇/u1D44A(/u1D465)re-\\nplacedby ∇x/u1D44A(/u1D461,x)).Deﬁne the Hamiltonian Hon/u1D437×R/u1D451by\\nH(x,/u1D6FC)=sup\\n¯/u1D706(x)inf\\nˆ/u1D706(x){/u1D451/summationdisplay.1\\n/u1D457=1(', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='¯/u1D706(x)inf\\nˆ/u1D706(x){/u1D451/summationdisplay.1\\n/u1D457=1(\\n2/u1D706/u1D457(x)/u1D459(ˆ/u1D706/u1D457(x)\\n/u1D706/u1D457(x))−¯/u1D706/u1D457(x)/u1D459(ˆ/u1D706/u1D457(x)\\n¯/u1D706/u1D457(x))+ˆ/u1D706/u1D457(\\n¯/u1D465)⟨/u1D6FC,e/u1D457⟩)}\\n.\\nRecallthe deﬁnition ( 4)of the Hamiltonian /u1D43B,\\n/u1D43B(x,/u1D6FC)=/u1D451/summationdisplay.1\\n/u1D457=1/u1D706/u1D457(x)(\\n/u1D452⟨/u1D6FC,e/u1D457⟩−1)\\n.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='/u1D452⟨/u1D6FC,e/u1D457⟩−1)\\n.\\nThe followingresult from[ 16]characterizessaddle pointsof H.\\nP/r.sc/o.sc/p.sc/o.sc/s.sc/i.sc/t.sc/i.sc/o.sc/n.scA.1 (P/r.sc/o.sc/p.sc/o.sc/s.sc/i.sc/t.sc/i.sc/o.sc/n.sc6.2/i.sc/n.sc[ 16]).For anyx∈/u1D437and/u1D6FC∈R/u1D451,\\nH(x,/u1D6FC)=−2/u1D43B(x,−/u1D6FC\\n2),\\nand thesaddlepointfor Hisgiven by (¯/u1D706,ˆ/u1D706)such that', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='2),\\nand thesaddlepointfor Hisgiven by (¯/u1D706,ˆ/u1D706)such that\\n¯/u1D706/u1D457(x)=ˆ/u1D706/u1D457(x)=/u1D706/u1D457(x)/u1D452−⟨/u1D6FC,e/u1D457⟩\\n2.\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='Importancesamplingforasimple Markovianintensitymodel 0:25\\nAs mentioned in [ 16], from the existence of saddle points for Hone can argue that the factor\\nˆΛ(x)−1in (25) can be removed. Indeed, the time derivative does not change thi s and the Isaacs\\nequation ( 25)becomes\\n/u1D44A/u1D461(/u1D461,x) +H(x,∇x/u1D44A(/u1D461,x))=0. (26)\\nFromthedeﬁnitionofthevaluefunction /u1D449/u1D45B(/u1D461,x)itisclearthat /u1D44A/u1D45B(/u1D461,x)mustsatisfytheterminal\\ncondition\\n/u1D44A/u1D45B(/u1D447,x)={\\n0,x∈/u1D437/u1D467,\\n∞,otherwise,\\nwhich in turn carries over to the function /u1D44A.Proposition A.1combinedwith this terminal condi-\\ntion implies that the Isaacsequation ( 26) isindeed the Hamilton-Jacobiequation\\n{', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='tion implies that the Isaacsequation ( 26) isindeed the Hamilton-Jacobiequation\\n{\\n/u1D44A/u1D461(/u1D461,x) −2/u1D43B(x,−1\\n2∇x/u1D44A(/u1D461,x))=0(/u1D461,x) ∈ [0,/u1D447) ×/u1D437\\\\/u1D437/u1D467,\\n/u1D44A(/u1D447,x)=0, x∈/u1D437/u1D467.(27)\\nACMTrans. Model. Comput. Simul.,Vol. 0,No. 0,Article0. Public ation date:2020.', metadata={'pdf': 'http://arxiv.org/pdf/1610.06501', 'link': 'https://openalex.org/works/W3215346238', 'title': 'Importance Sampling for a Simple Markovian Intensity Model Using Subsolutions'}),\n",
              " Document(page_content='arXiv:2202.01846v1  [cs.GT]  3 Feb 2022A Population’s Feasible Posterior Beliefs∗\\nItai Arieli†, Yakov Babichenko‡\\nFebruary 7, 2022\\nAbstract\\nWe consider a population of Bayesian agents who share a commo n prior over\\nsome ﬁnite state space and each agent is exposed to some infor mation about the\\nstate. We ask which distributions over empirical distribut ions of posteriors beliefs\\nin the population are feasible. We provide a necessary and su ﬃcient condition for\\nfeasibility. We apply this result in several domains. First , we study the problem\\nof maximizing the polarization of beliefs in a population. S econd, we provide a\\ncharacterization ofthefeasibleagent-symmetricproduct distributionsofposteriors.\\nFinally, we studyan instance of aprivate Bayesian persuasi onproblem andprovide\\na clean formula for the sender’s optimal value.\\n1 Introduction\\nEconomics is deeply concerned with the question of whether agents ’ behaviors can be\\nrationalized in the sense that they can be explained as an equilibrium be havior in a\\nBayesian model with rational agents. Onesuch related question is u nder what conditions', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='rationalized in the sense that they can be explained as an equilibrium be havior in a\\nBayesian model with rational agents. Onesuch related question is u nder what conditions\\nagents’ beliefs, i.e., posterior distribution, are compatible with Baye s’s rule? This ques-\\ntioniswellunderstoodforthesingleagentwherebythesplittinglemm a([Aumann et al. ,\\n1995,Blackwell ,1951]) feasibility simply means that the expectation of the posterior\\n∗Itai acknowledges support from the Ministry of Science and Techn ology (grant 19400214). Yakov\\nacknowledges support from the Israel Science Foundation (gran t 2021296).\\n†Faculty of Industrial Engineering and Management, Technion: The Israel Institute of Technology,\\niarieli@technion.ac.il\\n‡Faculty of Industrial Engineering and Management, Technion: The Israel Institute of Technology,\\nyakovbab@technion.ac.il\\n1', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='equals the prior. But the characterization of feasible posterior dis tribution for two or\\nmore agents is trickier.\\nThe ﬁrst paper to address the feasibility of posterior distributions for more than\\none agent is [ Dawid et al. ,1995] who characterize feasible distributions for two agents.\\nRecently a growing number of papers have examined the feasibility of posterior distribu-\\ntions and their connection to information design problems. [ Arieli et al. ,2021] connect\\nthe notion of feasibility to the agreement theorem of [ Aumann,1976] and to the re-\\nlated no-trade theorem of [ Milgrom and Stokey ,1982]. A follow-up paper by [ Morris,\\n2020] generalizes the result in [ Arieli et al. ,2021] to an arbitrary ﬁnite state space. De-\\nspite these elegant connections, in general, determining whether a given distribution of\\nposterior beliefs is feasible is a tough question.\\nIn this work we study an anonymous variant of the feasibility question. The object\\nwhose feasibility we are willing to determine is a distribution over the empirical distri-\\nbutions of posterior beliefs in the population rather then a distribution over proﬁles of\\nposteriors . The diﬀerence between these two variants is that a proﬁle of post eriors in-', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='butions of posterior beliefs in the population rather then a distribution over proﬁles of\\nposteriors . The diﬀerence between these two variants is that a proﬁle of post eriors in-\\ndicates which agent holds which posterior, while the anonymous vers ion of the problem\\nonly reveals how many agents hold each posterior without revealing t heir identity.\\nSurprisingly, we show that determining feasibility for the anonymous variant of the\\nproblem is relatively easy, especially in the case where the number of d iﬀerent posteriors\\nfor an individual in the population is low. Our characterization (Theor em1) provides\\na necessary and suﬃcient condition for a distribution over empirical samples of a popu-\\nlation to be feasible. The characterization relies on the observation that conditional on\\na state the frequencies of posterior beliefs in the population can be identiﬁed. We show\\nthat every combination of spreads of these expected frequencie s (one for each state) is\\nfeasible. Unlike the feasibility characterization by [ Arieli et al. ,2021] and [Morris,2020],\\nour characterization does not become more complex as the number of agents in the pop-\\nulation increases. Furthermore, the complexity of our character ization does not increase\\nwith the number of states either. However, the parameter of the number of possible', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='our characterization does not become more complex as the number of agents in the pop-\\nulation increases. Furthermore, the complexity of our character ization does not increase\\nwith the number of states either. However, the parameter of the number of possible\\nposteriors in the population has an eﬀect on the complexity of our ch aracterization.\\nAs was mentioned above, the feasibility problem is an intriguing instanc e of ratio-\\nnalization in the case where an econometrician observes the distribu tion over empirical\\ndistributions of posteriors in the population. In the context of rat ionalization, it is nat-\\n2', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='ural to consider another variant where the econometrician obser ves a single sample; i.e.,\\nshe observes a single empirical distribution of posteriors and wants to determine whether\\nit is possible that the agents are Bayesian.1[Molavi,2021] shows that every empirical\\ndistribution of posteriors can be rationalized. This question is equiva lent to understand-\\ning which empirical distributions of posteriors might belong to the sup port of a feasible\\ndistribution. Our results can be viewed as an extension of [ Molavi,2021]; however, we\\ngo a step further and determine the entire set of feasible distribut ions rather than focus\\non points that might belong to the support.\\nWe apply our main theorem in three diﬀerent domains.\\nPolarization The question of how polarized the posteriors of two Bayesian agent s\\nmight be has been previously studied. Diﬀerent measures of polariza tion have been\\nsuggested, including the distance between the posteriors [ Dubins and Pitman ,1980], the\\ndistance to the power α[Arieli et al. ,2021], and the indicator function of the posterior’s\\ndistance being above some threshold [ Burdzy and Pal ,2019,Burdzy and Pitman ,2020].\\nThe case of a quadratic distance can be naturally generalized to mult iple agents by', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='distance being above some threshold [ Burdzy and Pal ,2019,Burdzy and Pitman ,2020].\\nThe case of a quadratic distance can be naturally generalized to mult iple agents by\\nconsidering the variance of the belief’s in the population. The maximal polarization for\\ntwo agents is obtained by revealing the state to one agent and prov iding no information\\nto the other agent ([ Arieli et al. ,2021]). We extend this result to every population of\\nagents of even size: the maximal polarization is obtained by revealing the state to half of\\nthe population and providing no information to the other half. Furth ermore, we extend\\nthis result to an arbitrary state space (not necessarily binary).\\nPrivate private information A fascinating instantiation of the feasibility problem is\\nthatofproductdistributions. Ifthedistributionofbeliefproﬁlesis aproductdistribution\\nthen the information that agent ireceives does not aﬀect her belief about the posteriors\\nof her peers. [ He et al.,2021] refer to this property as private private information of the\\nagents. The feasibility of product distributions has been considere d in [He et al.,2021,\\nArieli et al. ,2021,Gutmann et al. ,1991a]andwecurrentlyhaveagoodunderstanding of', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='Arieli et al. ,2021,Gutmann et al. ,1991a]andwecurrentlyhaveagoodunderstanding of\\nthis problem for the two-agent case. However, the feasibility of pr oduct distributions for\\nmore then two agents currently does not have a characterization . We contribute to this\\n1[Shmaya and Yariv ,2016,De Oliveira and Lamba ,2019] have studied Bayesian rationalization of\\nthe behavior of a single agent in a repeated environment.\\n3', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='line of literature by providing a characterization of feasible agent-symmetric product\\ndistributions for an arbitrary number of agents. This characteriz ation takes a simple\\nform in the case where the marginals of the product distributions ar e binary-supported.\\nPrivate Bayesian Persuasion The Bayesian persuasion setting is quite well un-\\nderstood in the case where the sender communicates with the rece ivers publicly. In\\nparticular the value of the sender is characterized by the notion of concaviﬁcation\\n[Kamenica and Gentzkow ,2011,Aumann et al. ,1995]. However, if the sender is allowed\\nto communicate privately with each receiver, the characterization of the value is known\\nonly in special cases. A particular case that has been studied in [ Arieli and Babichenko ,\\n2019,Babichenko and Barman ,2016,Dughmi and Xu ,2019] is the following. A mar-\\nketer (sender) tries to persuade agents (receivers) to adopt a product whose quality\\nis either high or low. [ Arieli and Babichenko ,2019,Babichenko and Barman ,2016,\\nDughmi and Xu ,2019] characterize optimal policies for the sender in special cases of\\nsender’s utility function such as supermodular or anonymous submo dular utilities. We', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='Dughmi and Xu ,2019] characterize optimal policies for the sender in special cases of\\nsender’s utility function such as supermodular or anonymous submo dular utilities. We\\nprovide an additional natural instance of the problem where the op timal sender’s value\\n(and the optimal policy) can be characterized. We consider the cas e with a homoge-\\nneous population of agents (i.e., all agents have an identical utility fu nction) and the\\nsender’s utility function is a monotonic anonymous function (i.e., a fun ction of a frac-\\ntion of the adopters). Interestingly, similarly to the standard Bay esian persuasion model\\n([Kamenica and Gentzkow ,2011]), our characterization also relies on the notion of con-\\ncaviﬁcation. However, the concaviﬁcation in our case is applied in a diﬀ erent domain.\\nWe illustrate the key ideas of our main result via an example in Section 2. Section 3\\nproceeds with the model and the main result. Section 4studies the implications of our\\nresults to maximal polarization of beliefs in a population. In Section 5we discuss the\\nconnections of our anonymous version of feasibility with the previou sly studied (non-\\nanonymous) version and present an application to private private in formation. Finally,', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='connections of our anonymous version of feasibility with the previou sly studied (non-\\nanonymous) version and present an application to private private in formation. Finally,\\nSection6demonstrates an application in a Bayesian persuasion framework.\\n4', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='2 Warm-up Example\\nLet Ω = {0,1}be a binary state space with a common prior µ=1\\n2. We identify ∆(Ω)\\nwith [0,1], which indicates the probability that is assigned to ω= 1. An information\\nstructure for nagents comprises nmeasurable sets {Si}n\\ni=1as well as a probability dis-\\ntribution G∈∆(Ω×S1× ··· ×Sn). We note that almost surely any realization of n\\nsignals (s1,...,s n) deﬁnes nposterior beliefs G(ω|si) fori∈[n]. In the example of the\\npresent section we assume that G(ω|si)∈ {1\\n4,3\\n4}almost surely for every i∈[n]; namely,\\nany information that an agent is exposed to results in a posterior of either1\\n4or3\\n4. The\\ninformation structure Gand the signal realization s= (s1,...,s n) induce a distribution\\nof posteriors in the population . Since we have assumed that there are only two possible\\nposteriors we can identify the distribution of posteriors in the popu lation with a fraction\\nHs∈ {0,1\\nn,2\\nn,...,1}, whereHs=k', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='posteriors we can identify the distribution of posteriors in the popu lation with a fraction\\nHs∈ {0,1\\nn,2\\nn,...,1}, whereHs=k\\nnindicates that kagents in the population have the\\nhigh posterior3\\n4, andn−kagents have the low posterior1\\n4.\\nThe information structure Ginduces a distribution over distributions of posteriors in\\nthepopulation PG∈∆({0,1\\nn,2\\nn,...,1}). Wewill call such a PGthepopulation’s empirical\\nposteriors for short. The population’s empirical posteriors anonymize the iden tity of the\\nindividuals and considers only the empirical distributions of the belief d istribution.\\nApopulation’sempiricalposteriors PiscalledfeasibleifP=PGforsomeinformation\\nstructure of nagents. A characterization of the feasible population’s empirical po steriors\\nis given in the following proposition. We denote by δcthe Dirac measure on an element\\nc.\\nProposition 1. A population’s empirical posteriors P∈∆({0,1\\nn,2\\nn,...,1}) is feasible if\\nand only if Pis a mean-preserving spread of the distribution1\\n2δ1\\n4+1', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='n,2\\nn,...,1}) is feasible if\\nand only if Pis a mean-preserving spread of the distribution1\\n2δ1\\n4+1\\n2δ3\\n4.\\nTo demonstrate the applicability of Proposition 1consider, for instance, a popula-\\ntion ofn= 9 agents. The uniform distribution U({0,1\\n9,2\\n9,...,1}) is feasible because\\nU({0,1\\n9,2\\n9,...,1}) is a mean-preserving spread of1\\n2δ1\\n4+1\\n2δ3\\n4=U({1\\n4,3\\n4}); that is, there\\nexists an information structure such that with probability1\\n10the distribution of posteri-\\nors in the population will be iagents with posterior3\\n4and 9−iagents with posterior1\\n4\\nfor every i= 0,1,...,9.\\nThe uniform distribution U({1\\n9,2\\n9,...,8\\n9}) is infeasible because U({1\\n9,2\\n9,...,8\\n9}) is not\\na mean-preserving spread of1\\n2δ1\\n4+1\\n2δ3\\n4=U({1\\n4,3\\n4}); that is, there is no information\\n5', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='structure such that with probability1\\n8the distribution of posteriors in the population\\nwill beiagents with posterior3\\n4and 9−iagents with posterior1\\n4for every i= 1,2,...,8.\\nProposition 1is a special case of our main result, which characterizes the feasibilit y of\\nan arbitrary distribution. We ﬁnd it useful to present the proof of Proposition 1because\\nit contains the main proof ideas of the general case (Theorem 1).\\nProof of Proposition 1.First, we show that every feasible distribution must be a mean-\\npreserving spread of1\\n2δ1\\n4+1\\n2δ3\\n4. Conditional on state ω= 1, every agent i∈[n] has a\\nposterior of3\\n4with probability3\\n4. Therefore, conditional on state ω= 1, the expected\\nnumber of agents with the high posterior3\\n4is3\\n4. Similarly, conditional on state ω= 0,\\nthe expected number of agents with the high posterior3\\n4is1\\n4. Denoting by Pωthe\\npopulation’s posteriors conditional on ωwe obtain a decomposition of PasP=1\\n2P0+\\n1\\n2P1whereE[P0] =1\\n4andE[P1] =3', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='population’s posteriors conditional on ωwe obtain a decomposition of PasP=1\\n2P0+\\n1\\n2P1whereE[P0] =1\\n4andE[P1] =3\\n4. We refer to P0as the spread of δ1\\n4, we refer to P1\\nas the spread of δ3\\n4, and we get that Pis a mean-preserving spread of1\\n2δ1\\n4+1\\n2δ3\\n4.\\nConversely, let P=1\\n2Q0+1\\n2Q1whereE[Q0] =1\\n4andE[Q1] =3\\n4be a mean-preserving\\nspreadof1\\n2δ1\\n4+1\\n2δ3\\n4. SinceP∈∆({0,1\\nn,...,1})wealsohave Qω∈∆({0,1\\nn,...,1}). Denote\\nαω\\nk=Qω({k\\nn}). We deﬁne an information structure Gas follows. In state ωwe draw an\\nintegerkwith probability αω\\nk, then we choose a subset A⊂[n] of size|A|=kuniformly', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='integerkwith probability αω\\nk, then we choose a subset A⊂[n] of size|A|=kuniformly\\nat random (among all possible subsets of size k), and ﬁnally we send a high signal h\\nto all agents in the subset Aand a low signal lto the remaining agents. We need to\\nshow that the posterior of an agent who has observed a signal his3\\n4and the posterior\\nof an agent who has observed a signal lis1\\n4. In state ωthe signal his obtained with\\nprobability∑n\\ni=0αω\\nkk\\nn=E[Qω] because αω\\nkis the probability that the subset is of size k\\nand since the subset is random the probability that agent iis included isk\\nn. Therefore,\\nthe posterior of an agent who has observed signal hequals\\nE[Q1]\\nE[Q0]+E[Q1]=3\\n4.\\nSimilar considerations show that the posterior of an agent who has o bserved a signal l\\nis1\\n4.\\n6', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='3 Model and the Main Result\\nIt turns out that the characterization of feasibility from Section 2can be naturally ex-\\ntended to a much more general case. Neither the restriction to bin ary possible posteriors\\nnor the restriction to a binary state space are needed. We start b y introducing the\\ngeneral model.\\nFor a set Awe denote by ∆ n(A)⊂∆(A) the set of empirical samples of size n, i.e.,\\n∆n(A) ={∑\\nk∈[n]1\\nnδak:ak∈Afork∈[n]}(note that any a∈Amay appear in the\\nsum more than once).\\nLet Ω = {1,...,m}be a ﬁnite state space. An information structure for nagents\\ncomprises nmeasurable sets {Sj}n\\nj=1as well as a probability distribution G∈∆(Ω×S1×\\n···×Sn). Wedenoteby Gntheset ofall informationstructures of nagents. The marginal\\ndistribution on Ω forms the prior; i.e., the prior µ∈∆(Ω) satisﬁes µi=G(ω=i)', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='distribution on Ω forms the prior; i.e., the prior µ∈∆(Ω) satisﬁes µi=G(ω=i)\\nfor any state ω∈Ω. Any realization of nsignals (s1,...,s n) deﬁnes almost surely n\\nposterior beliefs G(ω|sj) forj∈[n]. Hence Gand the signal realization s= (s1,...,s n)\\ninduce a distribution of posteriors in the population Hs∈∆n(∆(Ω)) that is given by\\n∑\\nj∈[n]1\\nnδG(ω|sj).\\nThe information structure Ginduces a distribution over distributions of posteriors in\\nthe population PG∈∆(∆n(∆(Ω))), which we call the population’s empirical posteriors\\nfor short.\\nIn the case where Sjis ﬁnite for every j, we letG(s) be the unconditional probability\\nof a signal vector s∈S1×···×Sn. In this case we can write\\nPG=∑\\ns∈S1×···×SnG(s)δHs, (1)', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='of a signal vector s∈S1×···×Sn. In this case we can write\\nPG=∑\\ns∈S1×···×SnG(s)δHs, (1)\\nwhereδHs∈∆n(∆(Ω)) is a Dirac measure on Hs.\\nDeﬁnition 1. A distribution P∈∆(∆n(∆(Ω))) is called feasiblefor a prior µ∈∆(Ω)\\nifP=PGfor some information structure G∈ Gn. We denote by Pn(µ)⊆∆(∆n(∆(Ω)))\\nthe set of all feasible distributions for a prior µ∈∆(Ω) and nagents.\\nNote that if the signal sets {Sj}n\\nj=1are ﬁnite, PGassigns probability one to measures\\nHs∈∆n(∆(Ω)) that are supported on some ﬁnite set {y1,...,y m} ⊆∆(Ω) (where\\nm≤∑', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='m≤∑\\nj|Sj|). In general, we say that P∈ Pisﬁnitely supported if there exists a ﬁnite\\n7', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='setY⊆∆(Ω) of posteriors such that Passigns probability one to the set of measures\\n∆(∆n(Y)).\\n3.1 Main Result\\nFor anyP∈∆(∆n(∆(Ω))) we let ˜P∈∆(∆(Ω)) be the expected measure that Pinduces\\non ∆(Ω). That is, for every Borel subset B⊆∆(Ω),\\n˜P(B) =∫\\n∆(Ω)H(B)dP(H).\\nIn particular, if Pis ﬁnitely supported we can write P=∑k\\nj=1ajHj(whereHj∈\\n∆n(∆(Ω)),aj≥0 and∑\\njaj= 1); then\\n˜P(B) =k∑\\nj=1ajHj(B).\\nWe deﬁne mother distributions ˜Pω∈∆(∆(Ω)) for ω∈Ω as follows:\\nd˜Pω(x) =1\\nµωxωd˜P(x).', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='d˜Pω(x) =1\\nµωxωd˜P(x).\\nIfPis ﬁnitely supported we simply have ˜Pω(x) =xω˜P(x)\\nµω.\\nFinally, let P′∈∆((∆(∆(Ω))) be the the measure that is deﬁned as follows:\\nP′=∑\\nω∈[m]µωδ˜Pω,\\nwhereδ˜Pω∈∆((∆(∆(Ω))) are Dirac measures. Our main result states the follow ing:\\nTheorem 1. A distribution P∈∆(∆n(∆(Ω))) is feasible for nagents and a prior\\nµ∈∆(Ω) if and only if Pis a mean-preserving spread of P′.\\nThe proof follows a similar logic to the proof of Proposition 1; however, the general\\ncase diﬀers from the binary-posterior case in the following respect . A key observation\\nin the proof of Theorem 1, as well as the proof of Proposition 1, is that the expected\\ndistribution of posteriors conditional on a state ωcan be identiﬁed. In the binary-', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='in the proof of Theorem 1, as well as the proof of Proposition 1, is that the expected\\ndistribution of posteriors conditional on a state ωcan be identiﬁed. In the binary-\\nposterior case, conditional on any state ω,every individual in the population has on\\n8', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='averagethehighposterior(3\\n4inProposition 1)withaﬁxedprobabilitythatisdetermined\\nby the two possible posteriors. In the case of more than two poste riors we cannot deduce\\nsuch a strong statement about each individual in the population.2Nevertheless, it turns\\nout that the averagedistribution of posteriors over the population conditional on a stat e\\ncan be identiﬁed. To do so, we simply do the exercise of deducing the a verageconditional\\n(˜Pω) distribution of posteriors from the average ex-antedistribution of posteriors ( ˜P).\\nThe validity of the above deduction follows from the linearity of expec tation and the\\nlinearity of the operator that maps an ex-ante distribution of post eriors to a conditional\\ndistribution of posteriors. Once we show that conditional on a stat eω∈Ω the average\\ndistribution of posteriors must be ˜Pω, the necessity for the mean-preserving spread (of\\nP′) condition immediately follows. To prove suﬃciency we construct an in formation\\nstructure with the population’s empirical posteriors Pusing similar arguments to those\\nof Proposition 1.\\n3.2 The binary-state binary-posterior case', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='structure with the population’s empirical posteriors Pusing similar arguments to those\\nof Proposition 1.\\n3.2 The binary-state binary-posterior case\\nIn the case where the state space is binary and the posteriors get only two values a,b\\nwhere 0≤a < µ < b ≤1, the distribution Pis an element of ∆(∆ n({a,b})) or simply\\nan element of ∆( {0,1\\nn,...,1}) that indicates the weight of bin the distribution. In the\\nlatter representation of the population’s empirical posteriors the terms˜Pωforω= 0,1\\nrepresent the expected fraction of agents that have the high po sterior conditional on a\\nstate. This expectation equals the probability of an agent having th e high posterior in\\nthesingle-agent case. Simple calculations show that ˜P1=(µ−a)b\\n(b−a)µand˜P0=(µ−a)(1−b)\\n(b−a)(1−µ).\\nThus, we deduce the following corollary:\\nCorollary 1. A population’s empirical posteriors P∈∆({0,1\\nn,2\\nn,...,1}) is feasible for', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='Thus, we deduce the following corollary:\\nCorollary 1. A population’s empirical posteriors P∈∆({0,1\\nn,2\\nn,...,1}) is feasible for\\nthe prior µand the posteriors a < µ < b if and only if Pis a mean-preserving spread of\\nµδ(µ−a)b\\n(b−a)µ+(1−µ)δ(µ−a)(1−b)\\n(b−a)(1−µ).\\nThe fact that µPand˜Pωcan be deduced directly from the values of the posteriors a\\n2Consider, for instance, a binary-state space with three possible p osteriors 0 < a < b < µ < c < 0.\\nAgent 1 has only two possible posteriors aandc. Agent 2 has only two possible posteriors bandc.\\nObviously, agents 1 and 2 will have diﬀerent distributions of posterio rs conditional on any state.\\n9', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='andbis a special feature of the binary-posterior case.3In the general case, the terms µP\\nand˜Pωare not determined by the support of the posteriors but rather a re determined\\nby the distribution Pas described above in the deﬁnitions of these terms.\\nWealsonoticethatforsingle-dimensionaldistributionsitiseasytode terminewhether\\nthe distribution is a mean-preserving spread of a given binary-supp ort distribution as\\nfollows. Let P∈∆({0,1\\nn,2\\nn,...,1}) be a distribution that assigns a probability of pito\\ni\\nnand letαδa+(1−α)δbbe a binary-support distribution with a < b. We consider the\\nα-quantile distribution of Pthat is deﬁned as follows. We let kbe the index such that\\n∑\\ni<kpi≤α <∑\\ni≤kpi. We let qk=α−∑\\ni<kpi. Theα-quantile distribution of Pis\\ndenoted by P|αand is deﬁned to be the distribution that assigns a probability ofpi\\nαtoi\\nn\\nfor every i < kand assigns a probability ofqk\\nαtok', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='denoted by P|αand is deﬁned to be the distribution that assigns a probability ofpi\\nαtoi\\nn\\nfor every i < kand assigns a probability ofqk\\nαtok\\nn. Simply speaking, P|αis the distri-\\nbution of Pconditional on the event that the realization belongs to the lower α-quantile\\nofP. The following lemma characterizes the mean-preserving spread pr operty.\\nLemma 1. A distribution P∈∆({0,1\\nn,2\\nn,...,1}) is a mean-preserving spread of B=\\nαδa+(1−α)δbif and only if E[P] =E[B] andE[P|α]≤a.\\nProof.Wedenoteby FP,FBtheCDFsfor PandB. Wehavethat Pisameanpreserving\\nspread of Bif and only if E[P] =E[B] and for every t∈[0,1] we have∫t\\n0FP(x)dx≥\\n∫t\\n0FB(x)dx. Moreover, it is well known that it suﬃces to check this inequality only\\nfor points tsuch that FP(t) crosses FB(t). In our case FBis piecewise constant with', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='0FB(x)dx. Moreover, it is well known that it suﬃces to check this inequality only\\nfor points tsuch that FP(t) crosses FB(t). In our case FBis piecewise constant with\\nvalues 0,α,1 in the corresponding segments [0 ,a),[a,b),[b,1]. Therefore, in our case it\\nis suﬃcient to check the inequality at the single point t=k\\nn.\\nNote that the CDF of P|αisFP|α(x) =α−1FP(x). Hence we have\\n∫k\\nn\\n0FP(x)dx=α∫k\\nn\\n0FP|α(x)dx=α(\\nk\\nn−∫k\\nn\\n0(1−FP|α(x))dx)\\n=α(k\\nn−E[P|α])\\n.\\nWe also have∫k\\nn\\n0FB(x)dx=α(k\\nn−a) and therefore∫k\\nn\\n0FP(x)dx≥∫k\\nn\\n0FB(x)dxif and\\nonly ifE[P|α]≤a.\\n3Those properties hold for the case of binary posteriors and an arb itrary state space.\\n10', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='3.3 Proof of Theorem 1\\nLetP∈∆(∆n(∆(Ω)) be a mean-preserving spread of P′. Namely, there exist mdistri-\\nbutionsQω∈∆(∆(Ω)) with expectation ˜Pωsuch that\\nP=∑\\nω∈ΩµωQω.\\nWe now deﬁne a signaling structure Gthat implements Pas follows. Let Sj= ∆(Ω)\\nfor every agent jand letG(ω) =µifor every state i∈Ω. We deﬁne G(s|ω) by coupling\\nthis measure with Qωas follows. We draw H∈∆n(∆(Ω)) according to Qω. Every such\\nHhas the form H=∑\\nk∈[n]1\\nnδxkwherexk∈∆(Ω). For every realized Hwe draw a\\npermutation π: [n]→[n] uniformly at random across all permutations and send signal\\nxπ(j)to every agent j. Thus, overall the probability that agent jobserves the signal xk\\nis1\\nnfor every j,k∈[n].', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='xπ(j)to every agent j. Thus, overall the probability that agent jobserves the signal xk\\nis1\\nnfor every j,k∈[n].\\nWe claim that PG=P. To see this, by the construction, it is enough to show\\nthatG(ω|sj=x) =xωfor every agent j∈[n] and state ω∈Ω. We note ﬁrst that\\nsinceHis drawn according to Qωand since the expectation of Qωis˜Pωwe have that\\nG(sj∈B|ω) =˜Pω(B) for every Borel measurable set B⊂∆(Ω). Therefore, by Bayes’s\\nrule, for every ω∈Ω,we have that\\nG(ω|sj=x) =µωd˜Pω\\nd˜P(x)\\n∑\\nω′∈Ωµω′d˜Pω′\\nd˜P(x)(2)\\nwith probability 1.\\nWe recall that d ˜Pω(x) =xω\\nµωd˜P(x).Therefore,µω′d˜Pω′(x)', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='with probability 1.\\nWe recall that d ˜Pω(x) =xω\\nµωd˜P(x).Therefore,µω′d˜Pω′(x)\\nd˜P(x)=xω′for every state ω′∈Ω.\\nHence, Equation ( 2) implies that G(ω|sj=x) =xω∑\\nω′∈Ωxω′=xωas desired.\\nWe now turn to the converse direction; namely, we show that every feasibleP∈ Pn\\nis a mean-preserving spread of P′. For clarity of exposition we prove this statement\\nonly for the case where Pis ﬁnitely supported. The extension of the proof to arbitrary\\ndistributions Pis relegated to the Appendix Aand essentially follows from the fact that\\nany distribution Pcan be approximated (in the weak* topology) by ﬁnitely supported\\nones.\\nWe assume that P=PGis induced by an information structure G∈∆(Ω×S1×···×\\nSn) with ﬁnite signal sets Sifor every i∈[n] (the ﬁnite support assumption). In addition\\n11', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='to the distribution P, we next deﬁne a few other auxiliary measures. First, for every\\nstateω∈Ω letPω\\nG∈∆(∆n(∆(Ω))) be the conditional distribution of Hsconditional on\\nstateω. That is, similar to Equation ( 1),\\nPω\\nG=∑\\ns∈S1×···×SnG(s|ω)δHs.\\nIt follows that\\nP=∑\\nω∈ΩµωPω\\nG. (3)\\nFor every ω∈Ω, let˜Pω\\nGbe the expectation of Pω\\nG. By deﬁnition, the measure Pω\\nGis a\\nmean-preserving spread of δ˜Pω\\nG. Therefore, in particular, by Equation ( 3)Pis a mean-\\npreserving spread of the measure∑\\nω∈Ωµωδ˜Pω\\nG.In order to complete the proof we need\\nto show that ˜Pωas deﬁned above equals ˜Pω\\nGfor every state ω∈Ω.', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='G.In order to complete the proof we need\\nto show that ˜Pωas deﬁned above equals ˜Pω\\nGfor every state ω∈Ω.\\nFor each signal sj∈SjletG(|sj)∈∆(Ω) be the conditional probability on Ω given\\nthe signal sj. LetHsj=δG(|sj).Using this notation, for any vector of realized signals\\ns= (s1,...,s n), one can write the measure Hsas follows:\\nHs=1\\nnn∑\\nj=1Hsj.\\nTherefore, we have\\nP=∑\\ns∈S1×···×SnG(s)1\\nnn∑\\nj=1Hsj.\\nHence, by deﬁnition of ˜P, for every x∈∆(Ω) we have\\n˜P({x}) =∑\\ns∈S1×···×SnG(s)1\\nnn∑\\nj=1Hsj(x) =1\\nnn∑\\nj=1∑\\nsj∈Sj,G(|sj)=xG(sj).\\nSimilarly, for any state ω∈Ω,', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='nn∑\\nj=1∑\\nsj∈Sj,G(|sj)=xG(sj).\\nSimilarly, for any state ω∈Ω,\\n˜Pω\\nG({x}) =∑\\ns∈S1×···×SnG(s|ω)1\\nnn∑\\nj=1Hsj(x) =1\\nnn∑\\nj=1∑\\nsj∈Sj,G(|sj)=xG(sj|ω).\\nIt follows from Bayes’s rule that if G(ω|sj) =xω, thenG(sj|ω) =xωG(sj)\\nµω.Hence\\n˜Pω\\nG({x}) =xω\\nµω˜P({x}) for every x∈∆(Ω). Thus d˜PG,ω({x}) =xω\\nµωd˜P({x}).Therefore,\\nfor every ω∈Ω it holds that ˜Pω\\nG=˜Pω, as desired.\\n12', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='4 Polarization\\nThe question of how polarized the posteriors of Bayesian agents mig ht be has been stud-\\nied in [Dubins and Pitman ,1980], [Burdzy and Pitman ,2020], and [Arieli et al. ,2021].\\nThese papers focuse on the case of two receivers. In [ Dubins and Pitman ,1980] polar-\\nization is measured by the absolute distance |x1−x2|and more generally in [ Arieli et al. ,\\n2021] polarization is measured by the function |x1−x2|αfor some α >0, where xi∈[0,1]\\ndenotes the posteriors of agent i= 1,2. The case of α= 2 is a particularly convenient\\ncase to study from a technical perspective. It is also a natural ca se to study for the\\nfollowing descriptive reason: it has a natural extension to an arbitr ary number of agents\\nas we show below.\\nGiven a distribution of posteriors in the population H∈∆n([0,1]), we can measure\\npolarization via Var( H). Note that in the special case of n= 2 with posteriors x1,x2\\nthe variance is(x1−x2)2\\n4, which (up to a factor of 4) is exactly the case of α= 2.', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='the variance is(x1−x2)2\\n4, which (up to a factor of 4) is exactly the case of α= 2.\\nThe results of [ Dubins and Pitman ,1980] forα= 1 and of [ Arieli et al. ,2020] for\\nα≤2 show that for the case of two agents the information structure that maximizes\\npolarization is the one that reveals the state to one agent and prov ides no information\\nto the other agent.4This information structure achieves an expected variance ofµ(1−µ)\\n4\\nfor information structures with prior µ∈[0,1]. We show that the same result is true for\\nevery even number of players: the information structure that ma ximizes polarization is\\nthe one that reveals the state to half of the agents and provides n o information to the\\nother half of the agents.\\nThe polarization of Gis the expected variance of the distribution of posteriors in the\\npopulation. That is, for any G∈ GletVG=∫\\n∆([0,1])Var(H)dG(H).\\nProposition 2. Letµ∈[0,1] be the prior. For every even n, the information structure\\nthat maximizes the polarization of nagents is the one that reveals the state to half of the', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='Proposition 2. Letµ∈[0,1] be the prior. For every even n, the information structure\\nthat maximizes the polarization of nagents is the one that reveals the state to half of the\\nagents and reveals no information to the other half. The expected polarization equals\\nµ(1−µ)\\n4.\\nFor every odd n, the maximal polarization is bounded between\\n(\\n1−1\\nn2)µ(1−µ)\\n4≤max\\nG∈GnVG≤µ(1−µ)\\n4.\\n4It remains an open problem to specify the information structure th at maximizes polarization for\\nα >2, even for the case of two agents.\\n13', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='For an odd number of agents, Proposition 2provides asymptotically tight bounds\\nwhenn→ ∞. It remains an open problem to provide the precise characterizatio n\\nof polarization for an odd number of agents. Interestingly, the ide a of sending full\\ninformation or no information to each one of the agents is no longer o ptimal for an odd\\nnumber of agents as demonstrated in the following example.\\nExample 1. Forn= 3 and prior µ=1\\n2, consider the information structure where the\\nstate is revealed to agent 3, and agents i= 1,2 receive the signals si\\n1,si\\n2according to the\\nfollowing distribution conditional on a state:\\nω= 0 ω= 1\\ns2\\n1s2\\n2 s2\\n1s1\\n2\\ns1\\n11/31/3 s1\\n101/3\\ns1\\n21/30s1\\n21/31/3\\nAgenti’s posterior after observing si\\n1is 1/3; her posterior after observing si\\n2is 2/3.\\nThe resulting distribution over posterior proﬁles is uniform over the proﬁles:\\n{(1\\n3,1\\n3,0),(1\\n3,2\\n3,0),(2\\n3,1\\n3,0),(1\\n3,2\\n3,1),(2', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='{(1\\n3,1\\n3,0),(1\\n3,2\\n3,0),(2\\n3,1\\n3,0),(1\\n3,2\\n3,1),(2\\n3,1\\n3,1),(2\\n3,2\\n3,1)}.\\nThe expected variance is2\\n62\\n81+4\\n62\\n27=14\\n243, which is above1\\n18, where1\\n18is the maximal\\nexpected variance that can be obtained by sending to every player either full information\\nor no information about the state.\\nProof of Proposition 2.First we show that VG≤µ(1−µ)\\n4for every number of agents n\\n(odd or even). This statement can be equivalently stated with resp ect to a feasible pop-\\nulation’s empirical posteriors. We denote VP=∫\\n∆([0,1])Var(H)dP(H) and we trivially\\nhave max G∈GnVG= max P∈Pn(µ)VP.\\nLetP∈ Pn(µ).By Theorem 1we can decompose P=µPP1+ (1−µP)P0where', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='LetP∈ Pn(µ).By Theorem 1we can decompose P=µPP1+ (1−µP)P0where\\nE[Pω] =˜Pω. Therefore, VP=µPVP1+(1−µP)VP0.LetP′=µPδ˜P1+(1−µP)δ˜P0. Note\\nthat since P∈ P(µ) it also holds that P′∈ P(µ).We claim that VP≤VP′. To see this,\\n14', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='note that for any ω= 0,1,\\nVPω=∫\\n∆([0,1])Var(H)dPω(H) =∫\\n∆([0,1])EH[x2]−(EH[x])2dPω(H) = (4)\\n∫\\n∆([0,1])EH[x2]dPω(H)−∫\\n∆([0,1])(EH[x])2dPω(H) =\\nE˜Pω[x2]−∫\\n∆([0,1])(EH[x])2dP(H)≤ (5)\\nE˜Pω[x2]−(E˜Pω[x]))2= Var(δ˜Pω) (6)\\nNote that equation ( 4) follows from Var( H) =EH[x2]−(EH[x])2. Equation ( 5) follows\\nfrom the fact that the operation EH(x2) : ∆(∆([0 ,1]))→Ris a linear operator and so\\nfor every Q∈∆(∆([0,1])) we have that∫\\n∆([0,1])EH[x2]dQ(H) =E˜Q[x2]. The inequality', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='for every Q∈∆(∆([0,1])) we have that∫\\n∆([0,1])EH[x2]dQ(H) =E˜Q[x2]. The inequality\\nin (6) follows from Jensen’s inequality. Since VP′=µPVδ˜P1+(1−µP)VδP0it follows that\\nVP′≥VP.\\nNote that ˜P1,˜P0satisfy\\nd˜P1=x\\nµd˜Pand d˜P0=1−x\\n1−µd˜P,\\nfor some ˜P∈∆([0,1]) with expectation µ, and hence the variances can be written as\\nVar(˜P1) =∫\\n[0,1]x3\\nµd˜P(x)−(∫\\n[0,1]x2\\nµd˜P(x))2\\nVar(˜P0) =∫\\n[0,1]x2(1−x)\\n1−µd˜P(x)−(∫\\n[0,1]x(1−x)\\n1−µd˜P(x))2\\nTherefore,', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='1−µd˜P(x)−(∫\\n[0,1]x(1−x)\\n1−µd˜P(x))2\\nTherefore,\\nVP≤µVar(˜P1)+(1−µ)Var(˜P0) =\\n∫\\n[0,1]x3+x2(1−x)d˜P(x)−1\\nµ(∫\\n[0,1]x2d˜P(x))2\\n−1\\n1−µ(∫\\n[0,1]x(1−x)d˜P(x))2\\n=\\n∫\\n[0,1]x2d˜P(x)−1\\nµ(∫\\n[0,1]x2d˜P(x))2\\n−1\\n1−µ(\\nµ−∫\\n[0,1]x2d˜P(x))2\\n=\\n(1+µ\\n1−µ)∫\\n[0,1]x2d˜P(x)−1\\nµ(1−µ)(∫\\n[0,1]x2d˜P(x))2\\n−µ2\\n1−µ.\\n15', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='DenoteA=∫\\n[0,1]x2d˜P(x) and we obtain VP≤(1+µ\\n1−µ)A−1\\nµ(1−µ)A2−µ2\\n1−µ. This is a degree\\n2 polynomial whose global maximum isµ(1−µ)\\n4that is obtained at A=µ(1+µ)\\n2.\\nTo show thatµ(1−µ)\\n4is achievable for an even number of players, we calculate the\\nexpected variance for the information structure that reveals th e state ton\\n2of the players\\nand reveals nothing to the remainingn\\n2players and get preciselyµ(1−µ)\\n4.\\nTo show that (1 −1\\nn2)µ(1−µ)\\n4is achievable for an odd number of players, we calculate\\nthe expected variance for the information structure that revea ls the state ton+1\\n2of the\\nplayers and reveals no information to the remainingn−1\\n2players and get the desired\\nexpression.\\n4.1 Multiple States\\nFor an arbitrary ﬁnite state space Ω, one might measure polarizatio n of a distribution', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='2players and get the desired\\nexpression.\\n4.1 Multiple States\\nFor an arbitrary ﬁnite state space Ω, one might measure polarizatio n of a distribution\\nof posteriors in the population via Pol( H) =Ex∼H[∥x−E[H]∥2\\n2], wherexandE[H] are\\n|Ω|-dimensional vectors of beliefs in the simplex. Note that Pol( H) =∑\\nω∈ΩVar(Xω),\\nwhereXωdenotes the random variable of the posterior probability that is ass igned to\\nstateω∈Ω. Therefore, for an arbitrary state space we obtain the following corollary.\\nCorollary 2. For every prior µ∈∆(Ω) and every even nthe information structure\\nthat maximizes the expected polarization (i.e., EH∼PPol(H)) ofnagents is the one that\\nreveals the state to half of the agents and reveals no information t o the other half.\\nThe corollary simply follows from the fact that Pol( H) =∑\\nω∈ΩVar(Xω) and the\\ndescribed information structure simultaneously maximizes Var( Xω) for allω∈Ω.\\n5 Vectorial Feasibility', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='ω∈ΩVar(Xω) and the\\ndescribed information structure simultaneously maximizes Var( Xω) for allω∈Ω.\\n5 Vectorial Feasibility\\nIn this section we connect our results on the feasibility of distributio ns overempirical\\ndistributions of beliefs with the notion of the feasibility of distributions over vectors of\\nbeliefs. As mentioned in the Introduction, the latter notion of feasibility ha s been previ-\\nously studied in [ Dawid et al. ,1995,Arieli et al. ,2021,He et al.,2021]. To distinguish\\nbetween the two notions we refer to the latter notion as vectorial feasibility .\\nThemodelissimilartotheonepresentedinSection 3. Givenaninformationstructure\\nI∈∆(Ω×S1×...×Sn), every realization of signals ( si)i∈[n]induces a vector of beliefs\\n16', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='(xi(si))i∈[n]. Hence, every information structure induces a distribution over v ectors of\\nbeliefsVI∈∆((∆(Ω)n).\\nDeﬁnition 2. A distribution V∈∆((∆(Ω)n) isvector feasible if there exists Isuch\\nthatV=VI.\\nEvery distribution V∈∆((∆(Ω)n) induces a distribution P(V)∈∆(∆n(∆(Ω)))\\nsimply because every vector of beliefs induces an empirical distribut ion of beliefs in\\nthe population. We observe that the feasibility of P(V) is a necessary but insuﬃcient\\ncondition for the feasibility of V. Indeed this condition is necessary, because if there\\nexists no Ithat will induce the distribution of empirical distributions P(V) thenV\\ncannot be implemented by any I. It is also not hard to see that the feasibility of P(V)\\nis an insuﬃcient condition for the feasibility of5V.\\nTherefore, the tools developed in this paper might be useful for de termining the\\nvectorial infeasibility of Vby checking our condition for the feasibility of P(V). The\\nfollowing subsection demonstrates that in suﬃciently symmetric cas es the feasibility of', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='vectorial infeasibility of Vby checking our condition for the feasibility of P(V). The\\nfollowing subsection demonstrates that in suﬃciently symmetric cas es the feasibility of\\nP(V) serves as a necessary and suﬃcient condition for the vectorial feasibility of V.\\nIn particular, using our results we are able to deduce new insights ab out feasible and\\ninfeasible vector distributions V.\\n5.1 Private private information\\nAspecial caseofdistributions Vwhose vectorial feasibility hasbeen studied in[ He et al.,\\n2021,Arieli et al. ,2021,Gutmann et al. ,1991b] is that of |Ω|= 2 and a productdistri-\\nbutionV= Πi∈[n]QiwhereQi∈∆([0,1]) is the distribution of the beliefs of agent i.\\n[He et al.,2021] refer to this class of distributions as private private information because\\nthe private information of agents other than idoes not aﬀect their beliefs about agent\\ni’s belief. In any case, the belief of every agent j̸=iabout agent i’s belief will be Qi.\\n5To construct a counterexample consider |Ω|= 2,n= 2 and consider any feasiblevector distribution', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='5To construct a counterexample consider |Ω|= 2,n= 2 and consider any feasiblevector distribution\\nV′withV′(a,b)>0 for some a̸=b. LetVbe a distribution that is obtained from V′by moving some\\npositive mass from ( a,b) to (b,a). The distribution Vbecomes vector infeasible because it violates the\\nmartingale condition for both agents. However P(V) =P(V′) remains feasible.\\nAnother counterexamplethat does not violate the martingale cond ition for any playeris the following.\\nLet|Ω|= 2 and n= 3. The distribution V=1\\n2δ(1\\n3,1\\n3,2\\n3)+1\\n2δ(2\\n3,2\\n3,1\\n3)is vector infeasible because agents 1\\nand 2 are agreeing to disagree with agent 3 in both points of the supp ort of this distribution. However,\\nP(V), which is the distribution where with probability1\\n2two of the three agents have a posterior ofj\\n3\\n(without specifying their identity) and the remaining agent has a pos terior of3−j\\n3forj= 1,2, is feasible\\nby Corollary 1.\\n17', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='For a discussion on the attractiveness of this property see [ He et al.,2021,Arieli et al. ,\\n2021]. A special case of private private information that has received at tention in the\\nexisting literature (see [ He et al.,2021,Arieli et al. ,2021,Gutmann et al. ,1991b]) is\\nthesymmetric case where V=Qn. The characterization of the feasible and infeasible\\nV=Qnis known for the case of n= 2 ([He et al.,2021]) but remains unclear for n≥3.\\nConsider now the case of a ﬁnitely supported Q. For the case of V=Qnthe induced\\ndistribution over empirical distributions P(V) is the multinomial distribution. More\\nformally, assume that Qis supported on x1,...,xk∈[0,1] and assigns a probability of\\nαitoxi. Let MN( n,Q) be the multinomial distribution that draws nsamples from\\n{xi}i∈[k]according to Q. In the standard deﬁnition of the multinomial distribution it\\nis assumed that the outcome is a vector of integers ( n1,...,nk) that sum up to nand', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='is assumed that the outcome is a vector of integers ( n1,...,nk) that sum up to nand\\nindicates the number of times x1,...,xkhave been chosen. In our case, we refer to the\\noutcome of MN( n,Q) as (n1\\nn,...,nk\\nn) and hence the outcome is an element of ∆ n(∆(Ω)).\\nThe following proposition shows that in this case the feasibility of P(V) is a necessary\\nand suﬃcient condition for the vectorial feasibility of V=Qn. In particular, it provides\\na novel characterization of vectorial feasibility for this class of dis tributions.\\nProposition 3. For a binary state space Ω and Q∈∆([0,1]) the product distribu-\\ntionV=Qnfornagents is vector feasible if and only if the multinomial distribution\\nMN(n,Q) is a mean-preserving spread of6(1−µ)Qω=0+µQω=1.\\nProof.DenoteP=P(V) = MN(n,Q). Note that ˜P=Q. By Theorem 1,Pis feasible', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='Proof.DenoteP=P(V) = MN(n,Q). Note that ˜P=Q. By Theorem 1,Pis feasible\\nif and only if Pis a mean-preserving spread of (1 −µ)Qω=0+µQω=1.\\nIfP=P(V) is infeasible then Vis not vector feasible, as discussed above.\\nIfPis feasible, we observe that Vcan be viewed as the uniquedistribution Wwith\\nthe following two properties:\\n1.P(W) =P.\\n2.Wassignsanequalprobabilitytoeverytwovectors( y1,...,yn),(y′\\n1,...,y′\\nn)∈ {x1,...,xk}n\\nwith the same empirical distributions of beliefs.\\nIt is easy to check that our construction of the information struc ture in the proof of\\n6We recall that Qω∈∆([0,1]) denotes the distribution of beliefs conditional on state ωin the case\\nwhere the ex-ante distribution of beliefs is Q.\\n18', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='Theorem 1induces a distribution over vectors ofbeliefs thatsatisﬁes these t wo properties\\nand hence this information structure implements V. Thus,Vis feasible.\\nDetermining whether MN( n,Q) isa mean-preserving spread of(1 −µ)Q0+µQ1might\\nnot be an easy task in the case where k(i.e., the support size of Q) is large. This is\\nbecause MN( n,Q) is a distribution over elements in ∆([ k]), and in high dimensions the\\nmean-preserving condition might not be easy to check. However, f ork= 2 the multi-\\nnomial distribution becomes simply a binomial distribution and the mean -preserving\\ncondition is easily veriﬁable by Lemma 1. Thus, for Qwith a binary support we get the\\nfollowing condition for the vectorial feasibility of V=Qn.\\nCorollary 3. LetQ∈∆({a,b}) where 0 < a < µ < b < 1. The distribution V=Qnis\\nvector feasible (for nagents) if and only if7E[Bin(n,µ−a\\nb−a)|µ]≤(µ−a)b\\n(b−a)µ.', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='vector feasible (for nagents) if and only if7E[Bin(n,µ−a\\nb−a)|µ]≤(µ−a)b\\n(b−a)µ.\\nThat is, the corollary states that in order to determine the feasibilit y ofV=Qnone\\nshould calculate the expectation of the µ-quantile of the Binomial distribution. If it\\nexceeds some constant, then the distribution is infeasible. Otherw ise it is feasible. Below\\nis a case where we can provide an explicit formula for the feasibility for every number of\\nagents.\\nna\\n2345678910110.5\\n0.250.4\\nFigure 1: The values of afor which the product distribution Qnis feasible as a function\\nof the number of agents n.\\n7We adopt here our previous convention for the multinomial distribut ion, and assume that the\\nBinomial distribution receives values in {0,1\\nn,...,1}and not in {0,1,...,n}.\\n19', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='Example 2. Letµ=1\\n2and letQ=1\\n2δa+1\\n2δ1−afor 0< a <1\\n2. Forn= 2mand for\\nn= 2m+1, the distribution V=Qnis feasible if and only if a≥1\\n2−(2m\\nm)\\n2−2m−1(see\\nFigure1). This observation is a consequence of Corollary 3, where the expectation of\\nthe1\\n2-quantile of the Bin( n,1\\n2) distribution can be explicitly computed and is provided\\nin the following lemma.\\nLemma 2. For every m∈Nwe have\\nE[Bin(2m,p)|1\\n2] =E[Bin(2m+1,p)|1\\n2] =1\\n2−(2m\\nm)\\n2−2m−1.\\nThe proof of this lemma is relegated to Appendix B.\\nAsymptotically, for large population of nagents, the threshold value of afor which\\nV=Qnis feasible is a≥1\\n2−(2m\\nm)\\n2−2m−1≈1\\n2−1√\\n2πn. Another interesting phenomenon\\nis that the threshold value of ais identical for an even nand forn+1.', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='m)\\n2−2m−1≈1\\n2−1√\\n2πn. Another interesting phenomenon\\nis that the threshold value of ais identical for an even nand forn+1.\\n6 Private Bayesian Persuasion of a Homogeneous\\nPopulation\\nWe next consider an application of our result to private Bayesian per suasion. As in\\n[Arieli and Babichenko ,2019], consider a sender who is a marketer that tries to sell a\\nproduct to a group of agents. Consider a binary state space Ω = {0,1}with a common\\npriorµ. The agents’ action set is A={0,1}, where action a= 1 represents a decision to\\nbuy the product and action a= 0 represents a decision not to buy the product. Playing\\na= 0 yields a utility of 0. The state represents the quality of the produ ct. Inω= 1\\nthe product is of good quality and worth 1 to the agents while in state ω= 0 it is worth\\n−τ\\n1−τto the agent, where τ∈(0,1). Thus, at a posterior of τthe agents are indiﬀerent\\nbetween buying and not buying the product. We assume that the ag ents share no payoﬀ', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='between buying and not buying the product. We assume that the ag ents share no payoﬀ\\nexternalities. Let u: [0,1]→Rbe the utility of the sender, where u(x) represents her\\nutility from persuading a fraction xof agents to take action 1. We assume that uis\\nnon-decreasing and that µ < τ(otherwise the policy that reveals no information would\\nbe optimal). We denote by Vnthe optimal utility the sender canachieve inan interaction\\nwithnagents.\\n20', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='[Arieli and Babichenko ,2019,Babichenko and Barman ,2016] study a heterogeneous\\nvariant of this setting, where each agent possesses an individual t hreshold τi∈(0,1). In\\nthe heterogeneous case a clean formula for Vnhas been deduced only in the case where\\nuis concave; see [ Arieli and Babichenko ,2019].8Here we observe that the homogeneous\\npopulation variant of the problem can be solved using our main result ( Theorem 1) and\\na clean formula for Vncan be provided.\\n01\\nn2\\nn1\\nFigure 2: Concaviﬁcation over a grid. The function uis displayed in black. The concav-\\niﬁcation over the grid cav n(u) is displayed in blue.\\nWe denote by cav n(u) : [0,1]→Rthe concaviﬁcation of uwhenuis restricted to the\\n1\\nn-gridpoints {0,1\\nn,2\\nn,...,1}only (see Figure 2). Namely, cav n(u) is the minimial concave\\nfunction that satisﬁes cav n(u)(x)≥u(x) for every x∈ {0,1\\nn,2\\nn,...,1}. Equivalently, for', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='function that satisﬁes cav n(u)(x)≥u(x) for every x∈ {0,1\\nn,2\\nn,...,1}. Equivalently, for\\neveryy∈[0,1] we deﬁne\\ncavn(u)(y) = max\\nQ∈∆n({0,1}),E[Q]=yEx∼Q[u(x)]. (7)\\nThe characterization of the sender’s optimal value is as follows.\\nProposition 4. The optimal utility for the sender is\\nVn=µu(1)+(1−µ)cavn(u)(µ(1−τ)\\nτ(1−µ)).\\nThe formula for the value can be interpreted as follows. In state ω= 1 all agents\\ntake action 1 and the utility is u(1). In state ω= 0 an expected fraction ofµ(1−τ)\\nτ(1−µ)agents\\nadopt the product and the sender is allowed to optimize over all the d istributions with\\n8A polynomial algorithm for computing Vnhas been deduced in [ Babichenko and Barman ,2016].\\n21', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='expectationµ(1−τ)\\nτ(1−µ)in order to achieve cav n(u)(µ(1−τ)\\nτ(1−µ)).\\nNote that the concaviﬁcation in Proposition 4diﬀers fromthe classic characterization\\nof the value via concaviﬁcation ([ Kamenica and Gentzkow ,2011]). The standard char-\\nacterization applies concaviﬁcation to a function whose domain is tha t of the posterior\\nbeliefs. Our characterization (for this special case) applies conca viﬁcation to a function\\nwhose domain is that of a fraction of the buyers.\\nProposition 4also provides an asymptotic characterization of the value for large\\npopulations. Denote V∗= lim n→∞Vnand denote by cav( u) the standard notion of\\nconcaviﬁcation (without restricting it to a grid). By Proposition 4we have\\nV∗=µu(1)+(1−µ)cav(u)(µ(1−τ)\\nτ(1−µ))\\nbecause cav n(u) point-wise converges to cav( u) asn→ ∞for non-decreasing functions\\nu.', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='τ(1−µ))\\nbecause cav n(u) point-wise converges to cav( u) asn→ ∞for non-decreasing functions\\nu.\\nProof of Proposition 4.The idea is to utilize Corollary 1. To do so, we should be able\\nto identify the possible posteriors that agents could have in an optim al policy, and to\\nprove that there are only two possible values for these posteriors . To this end, we utilize\\nthe following observation from [ Arieli and Babichenko ,2019].\\nLemma 3 ([Arieli and Babichenko ,2019]).There exists an optimal policy with the\\nfollowing properties:\\n•The policy uses binary signals Si={si\\n0,si\\n1}for each agent i, and each agent takes\\naction 1 if and only if she receives the signal si\\n1.\\n•In stateω= 1 signal si\\n1is sent to all agents with probability 1.\\n•In stateω= 0 each agent igets the signal si\\n1with probability9µ(1−τ)\\nτ(1−µ).\\nBy Lemma 3we deduce that the only two possible posteriors for an agent are 0 a nd\\nτ. Now we can use Corollary 1, which states that P∈∆({0,1\\nn,2', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='τ. Now we can use Corollary 1, which states that P∈∆({0,1\\nn,2\\nn,...,1}) is feasible\\nif and only if Pis a mean-preserving spread of µδ1+ (1−µ)δµ(1−τ)\\nτ(1−µ), wherePis the\\nnumber of agents with posterior τ. This set of mean-preserving spreads consists of all\\n9The Lemma does not indicate on the correlation of the si\\n1signals among the agents conditional on\\nstateω= 0.\\n22', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='µδ1+ (1−µ)QwhereQ∈∆({0,1\\nn,2\\nn,...,1}) satisfy E[Q] =µ(1−τ)\\nτ(1−µ)and the utility of\\nthe sender for each such mean-preserving spread is µu(1)+(1−µ)Ex∼Q[u(x)], which is\\nprecisely the concaviﬁcation formula of Equation ( 7).\\nReferences\\nItai Arieli and Yakov Babichenko. Private Bayesian persuasion. Journal of Economic\\nTheory, 182:185–217, 2019.\\nItai Arieli, Yakov Babichenko, and Rann Smorodinsky. Identiﬁable in formation struc-\\ntures.Games and Economic Behavior , 120:16–27, 2020.\\nItai Arieli, Yakov Babichenko, Fedor Sandomirskiy, and Omer Tamuz . Feasible joint\\nposterior beliefs. Journal of Political Economy , 129(9):2546–2594, 2021.\\nRobert J Aumann. Agreeing to disagree. Annals of Statistics , 4(6):1236–1239, 1976.\\nRobert J Aumann, Michael Maschler, and Richard E Stearns. Repeated Games with', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='Robert J Aumann, Michael Maschler, and Richard E Stearns. Repeated Games with\\nIncomplete Information . MIT Press, 1995.\\nYakov Babichenko and Siddharth Barman. Computational aspects of private Bayesian\\npersuasion. arXiv preprint arXiv:1603.01444 , 2016.\\nDavid Blackwell. Comparison of experiments. In Proceedings of the Second Berkeley\\nSymposium on Mathematical Statistics and Probability , pages 93–102. University of\\nCalifornia Press, 1951.\\nKrzysztof Burdzy and Soumik Pal. Contradictory predictions. arXiv preprint\\narXiv:1912.00126 , 2019.\\nKrzysztof Burdzy and Jim Pitman. Bounds on the probability of radic ally diﬀerent\\nopinions. Electronic Communications in Probability , 25:1–12, 2020.\\nAP Dawid, MH DeGroot, J Mortera, R Cooke, S French, C Genest, MJ Schervish,\\nDV Lindley, KJ McConway, and RL Winkler. Coherent combination of ex perts’ opin-\\nions.Test, 4(2):263–313, 1995.\\n23', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='Henrique De Oliveira and Rohit Lamba. Rationalizing dynamic choices. Available at\\nSSRN 3332092 , 2019.\\nLester E Dubins and Jim Pitman. A maximal inequality for skew ﬁelds. Zeitschrift f¨ ur\\nWahrscheinlichkeitstheorie und verwandte Gebiete , 52(3):219–227, 1980.\\nShaddin Dughmi and Haifeng Xu. Algorithmic Bayesian persuasion. SIAM Journal on\\nComputing , (3):STOC16–68, 2019.\\nSam Gutmann, JHB Kemperman, JA Reeds, and Larry A Shepp. Exist ence of prob-\\nability measures with given marginals. The Annals of Probability , 19(4):1781–1797,\\n1991a.\\nSam Gutmann, JHB Kemperman, JA Reeds, and Larry A Shepp. Exist ence of prob-\\nability measures with given marginals. The Annals of Probability , 19(4):1781–1797,\\n1991b.\\nKevin He, Fedor Sandomirskiy, and Omer Tamuz. Private private info rmation. arXiv\\npreprint arXiv:2112.14356 , 2021.', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='1991b.\\nKevin He, Fedor Sandomirskiy, and Omer Tamuz. Private private info rmation. arXiv\\npreprint arXiv:2112.14356 , 2021.\\nEmir Kamenica and Matthew Gentzkow. Bayesian persuasion. American Economic\\nReview, 101(6):2590–2615, 2011.\\nPaul Milgrom and Nancy Stokey. Information, trade and common kn owledge. Journal\\nof Economic Theory , 26(1):17–27, 1982.\\nPooya Molavi. Tests of Bayesian rationality. arXiv preprint arXiv:2109.07007 , 2021.\\nStephen E Morris. No trade and feasible joint posterior beliefs. Working paper , 2020.\\nEran Shmaya and Leeat Yariv. Experiments on decisions under unce rtainty: A theoret-\\nical framework. American Economic Review , 106(7):1775–1801, 2016.\\nA Extending the Proof of Theorem 1to inﬁnitely\\nsupported distributions\\nWe have proved in Section 3.3that a ﬁnitely supported feasible Pmust be a mean-\\npreserving spread of P′. Here we extend this result to arbitrary feasible distributions\\n24', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='P.\\nLetGbe an information structure Gfornagents where {Si}n\\ni=1are (possibly inﬁ-\\nnite) measurable sets. Note that the measure PGthat is induced by Gcan be weakly\\napproximated using PG′whenG′is a ﬁnite information structure. To do this, we use the\\nfollowing standard trick. First we partition ∆(Ω) using a ﬁnite partitio nDδsuch that\\neach element D∈ Dδis a convex set and has a diameter at most δ. We deﬁne the new\\nsignal space S′\\ni=Dδfor every agent i. We then couple together GandG′as follows. We\\ndraw a signal proﬁle according to Gand tell each agent ionly of the partition element\\ninDδin which the posterior P(ω= 1|si) lies. It is easy to see that PG′weakly converges\\ntoPasδgoes to 0.\\nIt now remains to show that if {Pk}k⊂∆(∆n(∆(Ω))) is a sequence of measures with\\nﬁnite support that weakly converges to Psuch that Pkis a mean-preserving spread of', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='ﬁnite support that weakly converges to Psuch that Pkis a mean-preserving spread of\\nP′for every k, thenPalso satisﬁes the this condition.\\nNote that Pk=∑\\nω∈ΩµωPω\\nk. Since ∆(∆ n(∆(Ω))) is a weakly compact space we can\\nassume (by taking subsequences if necessary) that all sequence s{Pω\\nk}kweakly converge\\nto a measure Pωfor every state ω∈Ω. Therefore, P=∑\\nω∈ΩµωPω. We further note\\nthat taking the expected measure is a weakly continuous operator from ∆(∆ n(∆(Ω))) to\\n∆(∆(Ω)). Therefore, the sequences {˜Pk}kand{˜Pω\\nk}kconverge to ˜Pand˜Pωrespectively\\nfor every ω. Therefore Pis a mean-preserving spread of P′=∑\\nω∈Ωµωδ˜Pωas desired.\\nFurthermore, since for every kandω∈Ω,\\nd˜Pω\\nk(x) =1', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='ω∈Ωµωδ˜Pωas desired.\\nFurthermore, since for every kandω∈Ω,\\nd˜Pω\\nk(x) =1\\nµωxωd˜Pk(x),\\nit follows that in the limit for every ω∈Ω,\\nd˜Pω(x) =1\\nµωxωd˜P(x),\\nas desired.\\n25', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='B Proof of Lemma 2\\nThe distribution Bin(2 m+1,1\\n2)|1\\n2assigns a probability of(2m+1\\nk)\\n2−2mtok\\n2m+1for every\\nk≤m, hence its expectation is given by\\nE[Bin(2m+1,1\\n2)|1\\n2] =m∑\\nk=1(2m+1\\nk)\\n2−2mk\\n2m+1=2−2m\\n2m+1m∑\\nk=1(2m+1\\nk)\\nk\\n=2−2m\\n2m+1(2m+1)m−1∑\\nk=0(2m\\nk)\\n= 2−2m1\\n2(\\n22m−(2m\\nm))\\n=1\\n2−(2m\\nm)\\n2−2m−1(8)\\nwhere the third equality follows from the fact that both expression s∑m\\nk=1(2m+1\\nk)\\nkand\\n(2m+1)∑m−1\\nk=0(2m\\nk)\\ncount the number of possible choices of a subset of at most kpeople', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='k)\\nkand\\n(2m+1)∑m−1\\nk=0(2m\\nk)\\ncount the number of possible choices of a subset of at most kpeople\\nand their leader out of a group of 2 m+ 1 people. The ﬁrst expression ﬁrst chooses\\nthe group and thereafter the leader. The second expression ﬁrs t chooses the leader and\\nthereafter complements it with a subset.\\nThe distribution Bin(2 m,1\\n2)|1\\n2assigns a probability of(2m\\nk)\\n2−2m+1tok\\n2mfor every\\nk < mand assigns a probability of(2m\\nm)\\n2−2mto1\\n2, and hence its expectation is given by\\nE[Bin(2m,1\\n2)|1\\n2] =m−1∑\\nk=1(2m\\nk)\\n2−2m+1k\\n2m+(2m\\nm)\\n2−2m−1\\n=2−2m+1\\n2mm−1∑\\nk=1(2m\\nk)\\nk+(2m\\nm)\\n2−2m−1\\n=2−2m+1\\n2m2mm−2∑\\nk=0(2m−1\\nk)', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='k)\\nk+(2m\\nm)\\n2−2m−1\\n=2−2m+1\\n2m2mm−2∑\\nk=0(2m−1\\nk)\\n+(2m\\nm)\\n2−2m−1\\n= 2−2m+11\\n2(\\n22m−1−2(2m−1\\nm−1))\\n+(2m\\nm)\\n2−2m−1\\n=1\\n2−2−2m+1(2m−1\\nm−1)\\n+(2m\\nm)\\n2−2m−1\\n=1\\n2−(2m\\nm)\\n2−2m−1\\nwhere the argument for the third equality is similar to the third equalit y in Equation\\n(8).\\n26', metadata={'pdf': 'http://arxiv.org/pdf/2202.01846', 'link': 'https://openalex.org/works/W4226521955', 'title': \"A Population's Feasible Posterior Beliefs\"}),\n",
              " Document(page_content='arXiv:1912.10769v2  [cs.DS]  30 Nov 2021Online Throughput Maximization on Unrelated Machines:\\nCommitment is No Burden\\nFranziska Eberle∗Nicole Megow†Kevin Schewior‡\\nDecember 2, 2021\\nAbstract\\nWe consider a fundamental online scheduling problem in which jobs with processing\\ntimes and deadlines arrive online over time at their release dates. The task is to deter-\\nmine a feasible preemptive schedule on a single or multiple possibly unrela ted machines\\nthat maximizes the number of jobs that complete before their dead line. Due to strong\\nimpossibility results for competitive analysis on a single machine, we req uire that jobs\\ncontain some slackε >0, which means that the feasible time window for scheduling a job\\nis at least 1+ εtimes its processing time on each eligible machine. Our contribution is\\ntwo-fold: (i) We give the ﬁrst non-trivial online algorithms for throu ghput maximization\\non unrelated machines, and (ii), this is the main focus of our paper, w e answer the ques-\\ntion on how to handle commitment requirements which enforce that a scheduler has to\\nguaranteeat acertainpoint in time the completionofadmitted jobs. Thisis veryrelevant,', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='tion on how to handle commitment requirements which enforce that a scheduler has to\\nguaranteeat acertainpoint in time the completionofadmitted jobs. Thisis veryrelevant,\\ne.g., in providing cloud-computing services, and disallows last-minute r ejections of critical\\ntasks. We present an algorithm for unrelated machines that is Θ(1\\nε)\\n-competitive when\\nthe scheduler must commit upon starting a job. Somewhat surprisin gly, this is the same\\noptimal performance bound (up to constants) as for scheduling w ithout commitment on\\na single machine. If commitment decisions must be made before a job’s slack becomes\\nless than a δ-fraction of its size, we prove a competitive ratio of O(1\\nε−δ)\\nfor 0< δ < ε.\\nThis result nicely interpolates between commitment upon starting a j ob and commitment\\nupon arrival. For the latter commitment model, it is known that no (ra ndomized) online\\nalgorithm admits any bounded competitive ratio. While we mainly focus o n scheduling\\nwithout migration, our results also hold when comparing against a migr atory optimal\\nsolution in case of identical machines.\\n1 Introduction\\nWe consider the following online scheduling problem: there are given munrelated parallel', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='without migration, our results also hold when comparing against a migr atory optimal\\nsolution in case of identical machines.\\n1 Introduction\\nWe consider the following online scheduling problem: there are given munrelated parallel\\nmachines. Jobs from an unknown job set arrive online over tim e at their release dates rj.\\nEach job jhas adeadline djand aprocessing time pij∈R+∪{∞}, which is the execution\\n∗Department of Mathematics, London School of Economics and P olitical Sciences, UK. Email:\\nfranziska.eberle@posteo.de .\\n†Faculty for Mathematics and Computer Science, University o f Bremen, Germany. Email:\\nnicole.megow@uni-bremen.de . Partially supported by the German Science Foundation (DFG ) under con-\\ntract ME 3825/1.\\n‡Departement of Mathematics and Computer Science, Universi ty of Cologne, Germany. Email:\\nkschewior@gmail.com . Partially supported by the DAAD within the PRIME program us ing funds of BMBF\\nand the EU Marie Curie Actions.\\n1', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='time ofjwhen processing on machine i; both job parameters become known to an algorithm\\nat job arrival. We denote a machine iwithpij<∞aseligiblefor jobj. If all machines are\\nidentical, pij=pjholds for every job j, and we omit the index i. aremidentical parallel\\nmachines to process these jobs or a subset of them. When sched uling these jobs or a subset\\nof them, we allow preemption , i.e., the processing of a job can be interrupted at any time a nd\\nmay resume later without any additional cost. We mainly stud y scheduling without migration\\nwhich means that a job must runcompletely on one machine. In c ase that we allow migration,\\na preempted job can resume processing on any machine, but no j ob can run simultaneously\\non two or more machines.\\nInafeasible schedule, two jobsare neverprocessingat thes ametime onthesamemachine.\\nA job is said to complete if it receives pijunits of processing time on machine iwithin\\nthe interval [ rj,dj) ifjis processed by machine i. The number of completed jobs in a\\nfeasible schedule is called throughput . The task is to ﬁnd a feasible schedule with maximum\\nthroughput. We refer to this problem as throughput maximization .', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='feasible schedule is called throughput . The task is to ﬁnd a feasible schedule with maximum\\nthroughput. We refer to this problem as throughput maximization .\\nAs jobs arrive online and scheduling decisions are irrevoca ble, we cannot hope to ﬁnd an\\noptimal schedule even when scheduling on a single machine [1 2]. To assess the performance\\nof online algorithms, we resort to standard competitive analysis . This means, we compare\\nthe throughput of an online algorithm with the throughput ac hievable by an optimal oﬄine\\nalgorithm that knows the job set in advance.\\nOn a single machine, it is well-known that “tight” jobs with dj−rj≈pjprohibit com-\\npetitive online decision making as jobs must start immediat ely and do not leave a chance for\\nobservingonlinearrivals [7]. Thus, it iscommonly require dthat jobscontain some slackε >0,\\ni.e., every job jsatisﬁesdj−rj≥(1+ε)pj. In the more general setting with unrelated ma-\\nchines, we assume that each job jsatisﬁes dj−rj≥(1 +ε)pijfor each machine ithat is', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='chines, we assume that each job jsatisﬁes dj−rj≥(1 +ε)pijfor each machine ithat is\\neligible for j, i.e., each machine iwithpij<∞. The competitive ratio of our online algo-\\nrithm will be a function of ε; the greater the slack, the better should the performance of our\\nalgorithm be. This slackness parameter has been considered in a multitude of previous work,\\ne.g., in [2,5,10,16,17,30,34]. Other results for scheduli ng with deadlines use speed scaling,\\nwhich can be viewed as another way to add slack to the schedule , see, e.g., [1,3,21,23,32].\\nIn this paper, we focus on the question how to handle commitment requirements in online\\nthroughput maximization. Modeling commitment addresses t he issue that a high-throughput\\nschedule may abort jobs close to their deadlines in favor of m any shorter and more urgent\\ntasks [15], which may not be acceptable for the job owner. Con sider a company that starts\\noutsourcing mission-critical processes to external cloud s and that needs a guarantee that jobs\\ncomplete beforeacertain timepointwhentheycannot bemove d to anothercomputingcluster', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='outsourcing mission-critical processes to external cloud s and that needs a guarantee that jobs\\ncomplete beforeacertain timepointwhentheycannot bemove d to anothercomputingcluster\\nanymore. In other situations, a commitment to complete jobs might be required even earlier\\njust before starting the job, e.g., for a faultless copy of a d atabase [10].\\nDiﬀerent commitment models have been formalized [2,10,30]. The requirement to commit\\nat a job’s release date has been ruled out for online throughp ut maximization by strong\\nimpossibility results (even for randomized algorithms) [1 0]. We distinguish two commitment\\nmodels.\\n(i)Commitment upon job admission : an algorithm may discard a job any time before its\\nstart, we say its admission. This reﬂects a situation such as the faultless copy of a\\ndatabase.\\n(ii)δ-commitment : given 0 < δ < ε, an algorithm must commit to complete a job while\\nthe job’s remaining slack is at least a δ-fraction of its original processing time. This\\n2', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='models an early enough commitment (parameterized by δ) for mission-critical jobs. For\\nidentical parallel machines, the latest time for committin g to jobjis thendj−(1+δ)pj.\\nWhen given unrelated machines, such a commitment model migh t be arguably less\\nrelevant. We consider it only for non-migratory schedules a nd include also the choice of\\na processor in the commitment; we deﬁne the latest time point for committing to job j\\nasdj−(1+δ)pijwhen processing jon machine i.\\nRecently, a ﬁrst uniﬁed approach has been presented for thes e models for a single ma-\\nchine [10]. In this and other works [2,30], there remained ga ps in the performance bounds\\nand it was left open whether scheduling with commitment is ev en “harder” than without\\ncommitment. Moreover, it remained unsettled whether the pr oblem is tractable on multiple\\nidentical or even heterogeneous machines.\\nInthiswork, wegivetight resultsforonlinethroughputmax imization onunrelatedparallel\\nmachines and answer the “hardness” question to the negative . We give an algorithm that\\nachieves the provably best competitive ratio (up to constan t factors) for the aforementioned', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='machines and answer the “hardness” question to the negative . We give an algorithm that\\nachieves the provably best competitive ratio (up to constan t factors) for the aforementioned\\ncommitment models. Somewhat surprisingly, we show that the same competitive ratio of\\nO(1\\nε)\\ncan be achieved for both, scheduling withoutcommitment and withcommitment upon\\nadmission. For unrelated machines, this is the ﬁrst nontriv ial result for online throughput\\nmaximization with and without commitment. For identical pa rallel machines, this is the ﬁrst\\nonlinealgorithmwithboundedcompetitiveratioforarbitr aryslackparameter ε. Interestingly,\\nfor this machine environment, our algorithm does not requir e job migration in order to be\\ncompetitive against a migratory algorithm.\\n1.1 Related work\\nPreemptive online scheduling and admission control have be en studied rigorously. There are\\nseveral results regarding the impact of deadlines on online scheduling; see, e.g., [6,16,17] and\\nreferences therein. In the following we give an overview of t he literature focused on (online)\\nthroughput maximization.\\nOﬄine scheduling. In case that the jobs and their characteristics are known to t he sched-', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='references therein. In the following we give an overview of t he literature focused on (online)\\nthroughput maximization.\\nOﬄine scheduling. In case that the jobs and their characteristics are known to t he sched-\\nuler in advance, the notion of commitment is irrelevant as an oﬄine algorithm only starts jobs\\nthat will be completed on time; there is no beneﬁt in starting jobs without completing them.\\nThe oﬄine problem is well understood: For throughput maximi zation on a single machine,\\nthere is a polynomial-time algorithm by Lawler [28]. The mor e general model, in which each\\njobjhas aweightwjand the task is to maximize the total weight of jobs completed on time\\n(weighted throughput ), is NP-hard, and we do not expect polynomial time algorithm s. The al-\\ngorithm by Lawler solves this problem optimally in time O(n5wmax), where wmax= max jwj,\\nand can be used to design a fully polynomial-time approximat ion scheme (FPTAS) [33].\\nWhen given multiple identical machines, (unweighted) thro ughput maximization becomes\\nNP-hard even for identical release dates [29]. Kalyanasund aram and Pruhs [24] show a 6-', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='When given multiple identical machines, (unweighted) thro ughput maximization becomes\\nNP-hard even for identical release dates [29]. Kalyanasund aram and Pruhs [24] show a 6-\\napproximate reduction to the single-machine problem which implies a (6+ δ)-approximation\\nalgorithm for weighted throughputmaximization onidentic al parallel machines, forany δ >0,\\nusing the FPTAS for the single-machine problem [33]. Preemp tive throughput maximization\\non unrelated machines is much less understood from an approx imation point of view. The\\nproblem is known to be strongly NP-hard [14], even without re lease dates [35]. We are not\\naware of any approximation results for preemptive throughp ut maximization on unrelated\\n3', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='machines. The situation is diﬀerent for non-preemptive sche duling. In this case, throughput\\nmaximization is MAX-SNP hard [4] and several approximation algorithms for this general\\nproblem as well as for identical parallel machines and other special cases are known; see,\\ne.g., [4,9,20].\\nOnline scheduling without commitment. For single-machine throughput maximiza-\\ntion, Baruah, Haritsa, and Sharma [6] show that, in general, no deterministic online al-\\ngorithm achieves a bounded competitive ratio. Thus, their r esult justiﬁes our assumption\\nonε-slackness of each job. Moreover, they consider special cas es such as unit-size jobs or\\nagreeable deadlines where they provide constant-competit ive algorithms even without further\\nassumptions on the slack of the jobs. Here, deadlines are agr eeable if rj≤rj′for two jobs j\\nandj′impliesdj≤dj′. In our prior work [10], we improve upon previous bounds [23, 30] for\\ngeneral instances by giving an O(1\\nε)\\n-competitive algorithm, and we show an asymptotically\\nmatching lower bound for deterministic algorithms.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='general instances by giving an O(1\\nε)\\n-competitive algorithm, and we show an asymptotically\\nmatching lower bound for deterministic algorithms.\\nFor maximizing weighted throughput, Lucier et al. [30] give anO(1\\nε2)\\n-competitive on-\\nline algorithm for scheduling on identical parallel machin es. In a special case of this problem,\\ncalledmachine utilization the goal is to maximize the total processing time of complete d jobs,\\ni.e., forpj=wjfor any job j. This problem is much more tractable. On a single machine,\\nBaruah et al. [7,8] provide a best-possible online algorith m achieving a competitive ratio of 4,\\neven without any slackness assumptions. Baruah and Haritsa [5] are the ﬁrst to investigate\\nthe problem under the assumption of ε-slack and give a1+ε\\nε-competitive algorithm which\\nis asymptotically best possible. For parallel identical ma chines (though without migration),\\nDasGupta and Palis [11] give a simple greedy algorithm that a chieves the same performance\\nguarantee of1+ε\\nεand give an asymptotically matching lower bound. Schwiegel shohn and', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='DasGupta and Palis [11] give a simple greedy algorithm that a chieves the same performance\\nguarantee of1+ε\\nεand give an asymptotically matching lower bound. Schwiegel shohn and\\nSchwiegelshohn [34] show that migration helps an online alg orithm and improves the com-\\npetitive ratio toO(m√\\n1/ε)\\nformmachines.\\nIn a line of research without slackness assumption, Baruah e t al. [8] show a lower bound\\nof (1+√\\nk)2for deterministic single-machine algorithms, where k=maxjwj/pj\\nminjwj/pjis theimpor-\\ntance ratio of a given instance. Koren and Shasha give a matching upper bo und [27] and\\ngeneralize it to Θ(ln k) for parallel machines if k >1 [26]. Interestingly, Kalyanasundaram\\nand Pruhs [25] give a randomizedO(1)-competitive algorithm for throughput maximization\\non a single machine without slackness assumption, which is i n stark contrast to the impossi-\\nbility resultfor deterministic single-machine algorithm s. Very recently, Moseley et al. [31] give', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='on a single machine without slackness assumption, which is i n stark contrast to the impossi-\\nbility resultfor deterministic single-machine algorithm s. Very recently, Moseley et al. [31] give\\na remarkableO(1)-competitive deterministic algorithm for m≥2 parallel identical machines.\\nOnline scheduling with commitment upon job arrival. In our prior work [10], we rule\\nout bounded competitive ratios for any (even randomized) on line algorithm for throughput\\nmaximization with commitment upon job arrival, even on a sin gle machine. Previously, such\\nimpossibility results where only shown exploiting weights [30].\\nAgain, the special case wj=pj, or machine utilization, is much more tractable than\\nweighted or unweighted throughput maximization. A simple g reedy algorithm already\\nachieves the best possible competitive ratio1+ε\\nεon a single machine, even for commit-\\nment upon arrival, as shown by DasGupta and Palis [11] and the matching lower bound\\nby Garay et al. [16]. For scheduling with commitment upon arr ival onmparallel identical\\nmachines, there is an O(m√\\n1/ε)-competitive algorithm and an almost matching lower bound\\nby Schwiegelshohn and Schwiegelshohn [34] Suprisingly, th is model also allows for bounded\\n4', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='competitive ratios when preemption is not allowed. In this s etting, Goldwasser and Ker-\\nbikov [18] give a best possible(\\n2 +1\\nε)\\n-competitive algorithm on a single machine. Very\\nrecently, Jamalabadi, Schwiegelshohn, and Schwiegelshoh n [22] extend this model to parallel\\nmachines; their algorithm is near optimal with a performanc e guarantee approaching ln1\\nε\\nasmtends to inﬁnity.\\nOnline scheduling with commitment upon admission and δ-commitment. In our\\nprevious work [10], we design an online single-machine algo rithm, called the region algorithm ,\\nthat simultaneously (with the respective choice of paramet ers) achieves the ﬁrst non-trivial\\nupper bounds for both commitment models. For commitment upo n job admission, our bound\\nisO(1\\nε2)\\n, and in the δ-commitment model it is O(ε\\n(ε−δ)δ2)\\n, for 0< δ < ε. For scheduling\\non identical parallel machines and commitment upon admissi on, Lucier et al. [30] give a\\nheuristic that empirically performs very well but for which they cannot show a rigorous worst-', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='on identical parallel machines and commitment upon admissi on, Lucier et al. [30] give a\\nheuristic that empirically performs very well but for which they cannot show a rigorous worst-\\ncase bound. In fact, Azar et al. [2] show that no bounded compe titive ratio is possible for\\nweighted throughput maximization for small ε. Forδ=ε\\n2in theδ-commitment model, they\\ndesign (in the context of truthful mechanisms) an online alg orithm for weighted throughput\\nmaximization that is Θ(1\\n3√1+ε−1+1\\n(3√1+ε−1)2)\\n-competitive if the slack εis suﬃciently large,\\ni.e., ifε >3. For weighted throughput, thiscondition on theslack isne cessary asis shownby a\\nstrong general lower bound, even on a single machine [10]. Fo r the unweighted setting, wegive\\ntheﬁrstrigorous upperboundfor arbitrary εin this paperforboth models, commitment upon\\nadmissionand δ-commitment, intheidentical andevenintheunrelatedmach ineenvironment.\\nMachine utilization is again better understood. As commitm ent upon arrival is more', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='admissionand δ-commitment, intheidentical andevenintheunrelatedmach ineenvironment.\\nMachine utilization is again better understood. As commitm ent upon arrival is more\\nrestrictive than commitment upon admission and δ-commitment, the previously mentioned\\nresults immediately carry over and provide bounded competi tive ratios.\\n1.2 Our results and techniques\\nOur main result is an algorithm that computes a non-migrator y schedule that is best possible\\n(uptoconstant factors) foronlinethroughputmaximizatio n withandwithoutcommitment on\\nidentical parallel machines and, more generally, on unrela ted machines. This is the ﬁrst non-\\ntrivial online result for unrelated machines and it closes g aps for identical parallel machines.\\nOur algorithm is universally applicable (by setting parame ters properly) to both commitment\\nmodels as well es scheduling without commitment.\\nTheorem 1. Consider throughput maximization on unrelated machines wit hout migration.\\nThere is anO(1\\nε−δ′)\\n-competitive non-migratory online algorithm for scheduli ng with commit-\\nment, where δ′=ε\\n2in the model with commitment upon admission and δ′= max{δ,ε\\n2}in the\\nδ-commitment model.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='ment, where δ′=ε\\n2in the model with commitment upon admission and δ′= max{δ,ε\\n2}in the\\nδ-commitment model.\\nFor scheduling with commitment upon admission, this is (up t o constant factors) an\\noptimal online algorithm with competitive ratio Θ(1\\nε)\\n, matching the lower bound of Ω(1\\nε)\\nfor\\nm= 1 [10]. For scheduling with δ-commitment, our result interpolates between the models\\nwithcommitment uponstartingajobandcommitment uponarri val. Ifδ≤ε\\n2, thecompetitive\\nratio is Θ(1\\nε)\\n, which is again best possible [10]. For δ→ε, the commitment requirements\\nessentially implies commitment upon job arrival which has u nbounded competitive ratio [10].\\nIn our analysis, we compare a non-migratory schedule, obtai ned by our algorithm, with an\\noptimal non-migratory schedule. However, in the case of ide ntical machines the throughput\\n5', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='of an optimal migratory schedule can only be larger by a const ant factor than the throughput\\nof an optimal non-migratory schedule. In fact, Kalyanasund aram and Pruhs [24] showed that\\nthis factor is at most6m−5\\nm. Thus, the competitive ratio for our non-migratory algorit hm,\\nwhen applied to identical machines, holds (up to this consta nt factor) also in a migratory\\nsetting.\\nCorollary 1. Consider throughput maximization with or without migration on parallel iden-\\ntical machines. There is an O(1\\nε−δ′)\\n-competitive non-migratory online algorithm for schedul-\\ning with commitment, where δ′=ε\\n2in the model with commitment upon admission and\\nδ′= max{δ,ε\\n2}in theδ-commitment model.\\nThe challenge in online scheduling with commitment is that, once we committed to com-\\nplete a job, the remaining slack of this job has to be spent ver y carefully. The key component\\nis a job admission scheme which is implemented by diﬀerent par ameters. The high-level ob-\\njectives are:\\n1. never start a job for the ﬁrst time if its remaining slack is too small (parameter δ),', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='jectives are:\\n1. never start a job for the ﬁrst time if its remaining slack is too small (parameter δ),\\n2. during the processing of a job, admit only signiﬁcantly sh orter jobs (parameter γ), and\\n3. for each admitted shorter job, block some time period (par ameterβ) during which no\\nother jobs of similar size are accepted.\\nWhile the ﬁrst two goals are quite natural and have been used b efore in the single and\\nidentical machine setting [10,30], the third goal is crucia l for our new tight result. The\\nintuition is the following: Think of a single eligible machi ne in a non-migratory schedule.\\nSuppose we committed to complete a job with processing time 1 and have only a slack of\\nO(ε) left before the deadline of this job. Suppose that csubstantially smaller jobs of size1\\nc\\narrive where cis the competitive ratio we aim for. On the one hand, if we do no t accept\\nany of them, we cannot hope to achieve c-competitiveness. On the other hand, accepting too\\nmany of them ﬁlls up the slack and, thus, leaves no room for eve n smaller jobs. The idea is', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='many of them ﬁlls up the slack and, thus, leaves no room for eve n smaller jobs. The idea is\\nto keep the ﬂexibility for future small jobs by only acceptin g anε-fraction of jobs of similar\\nsize (within a factor two).\\nWe distinguish two time periods that guide the acceptance de cisions. During the schedul-\\ning interval of a jobj, we have a more restrictive acceptance scheme that ensures t he comple-\\ntion ofjwhereas in the blocking period we guarantee the completion of previously accepted\\njobs. We call our algorithm blockingalgorithm. This acceptance scheme is much more reﬁned\\nthan the one of the known region algorithm in [10] that uses on e long region with a uniform\\nacceptance threshold and is then too conservative in accept ing jobs.\\nGiven that we consider the non-migratory version of the prob lem, a generalization from a\\nsingletomultiplemachinesseemsnatural. Itisinterestin g, however, thatsuchageneralization\\nworks, essentially on a per-machine basis, even for unrelat ed machines and comes at no loss\\nin the competitive ratio.\\nClearly, scheduling with commitment is more restrictive th an without commitment.\\nTherefore, our algorithm is also O(1\\nε)\\n-competitive for maximizing the throughput on un-', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='in the competitive ratio.\\nClearly, scheduling with commitment is more restrictive th an without commitment.\\nTherefore, our algorithm is also O(1\\nε)\\n-competitive for maximizing the throughput on un-\\nrelated machines without any commitment requirements. Aga in, this is optimal (up to con-\\nstant factors) as it matches the lower bound on the competiti ve ratio for deterministic online\\nalgorithms on a single machine [10].\\n6', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Corollary 2. There is a Θ(1\\nε)\\n-competitive algorithm for online throughput maximizatio n on\\nunrelated machines without commitment requirements and wi thout migration.\\nHowever, for scheduling without commitment, we are able to g eneralize the simpler re-\\ngion algorithm presented for the single-machine problem in [10] to scheduling on unrelated\\nmachines.\\nTheorem 2. A generalization of the region algorithm is Θ(1\\nε)\\n-competitive for online through-\\nput maximization on unrelated machines without commitment requirements and without mi-\\ngration.\\nBesidespresentingasimpleralgorithmforthroughputmaxi mization withoutcommitment,\\nwe show this result to present an additional application of o ur technical ﬁndings for the\\nanalysis of the blocking algorithm. We give details later. O n a high level, we show a key\\nlemma on the size of non-admitted jobs for a big class of onlin e algorithms which results in\\nan upper bound on the throughput of an optimal (oﬄine) non-mi gratory algorithm. This\\nkey lemma can be used in the analysis of both algorithms, bloc king and region. In fact, also\\nthe analysis of the original region algorithm for a single ma chine [10] becomes substantially\\neasier.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='key lemma can be used in the analysis of both algorithms, bloc king and region. In fact, also\\nthe analysis of the original region algorithm for a single ma chine [10] becomes substantially\\neasier.\\nIn case of identical machines, again, we can apply the result by Kalyanasundaram and\\nPruhs [24] that states that the throughput of an optimal migr atory schedule is larger by at\\nmost a constant factor than the throughput of an optimal non- migratory schedule. Thus, the\\nresult in Theorem 2 holds also in a migratory setting when sch eduling on identical machines.\\nCorollary 3. A generalization of the region algorithm is Θ(1\\nε)\\n-competitive for online through-\\nput maximization on multiple identical machines without co mmitment requirements, with and\\nwithout migration.\\nOutline of the paper\\nIn Section 2, we describe and outline the analysis of our new n on-migratory algorithm. It\\nconsists of two parts, which are detailed in Sections 3 and 4: ﬁrstly, we argue that all jobs\\nadmitted by our algorithm can complete by their deadline and , secondly, we prove that we\\nadmit “suﬃciently many” jobs. In Section 5, we generalize th e known region algorithm,', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='admitted by our algorithm can complete by their deadline and , secondly, we prove that we\\nadmit “suﬃciently many” jobs. In Section 5, we generalize th e known region algorithm,\\ndeveloped for a single machine in our prior work [10], to a non -migratory algorithm without\\ncommitment on unrelated machines. We show how to apply a new k ey technique developed\\nfor the analysis in Section 4 to analyze it and prove the samec ompetitive ratio (up to constant\\nfactors) as for a single machine.\\n2 The blocking algorithm\\nIn this section, we describe the blocking algorithm for scheduling with commitment. We\\nassume that the slackness constant ε >0 and, in the δ-commitment model, δ∈(0,ε) are\\ngiven. If δis not part of the input or if δ≤ε\\n2, then we set δ=ε\\n2.\\nThe algorithm never migrates jobs between machines, i.e., a job is only processed by the\\nmachine that initially started to process it. In this case, w e say the job has been admitted to\\nthis machine. Moreover, our algorithm commits to completin g a job upon admission (even\\nin theδ-commitment model). Hence, its remaining slack has to be spe nt very carefully on\\n7', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='admitting other jobs to still be competitive. As our algorit hm does not migrate jobs, it\\ntransfers the admission decision to the shortest admitted a nd not yet completed job on each\\nmachine. A job only admits signiﬁcantly shorter jobs and pre vents the admission of too many\\njobs of similar size. To this end, the algorithm maintains tw o types of intervals for each\\nadmitted job, a scheduling interval and ablocking period . A job can only be processed in\\nits scheduling interval. Thus, it has to complete in this int erval while admitting other jobs.\\nJobjonly admits jobs that are smaller by a factor of at least γ=δ\\n16<1. For an admitted\\njobk, jobjcreates a blocking period of length at most βpik, whereβ=16\\nδ, which blocks\\nthe admission of similar-length jobs (cf. Figure 1). The sch eduling intervals and blocking\\nperiods of jobs admitted by jwill always be pairwise disjoint and completely contained i n\\nthe scheduling interval of j.\\nscheduling interval blocking period\\nτFigure 1: Scheduling interval, blocking period, and processing inte rvals\\nScheduling jobs. Independent of the admission scheme, the blocking algorith m follows\\ntheShortest Processing Time (SPT) order for the set of uncompleted jobs assigned to a', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Scheduling jobs. Independent of the admission scheme, the blocking algorith m follows\\ntheShortest Processing Time (SPT) order for the set of uncompleted jobs assigned to a\\nmachine. SPT ensures that a job jhas highest priority in the blocking periods of any job k\\nadmitted by j.\\nAdmitting jobs. The algorithm keeps track of available jobs at any time point τ. A jobj\\nwithrj≤τis called available for machine iif it has not yet been admitted to a machine by\\nthe algorithm and its deadline is not too close, i.e., dj−τ≥(1+δ)pij.\\nWhenever a job jis available for machine iat a time τsuch that time τis not contained in\\nthe scheduling interval of any other job admitted to i, the shortest such job jis immediately\\nadmitted to machine iat time aj:=τ, creating the scheduling interval S(j) = [aj,ej),\\nwhereej=aj+(1+δ)pijand an empty blocking period B(j) =∅. In general, however, the\\nblocking period of a job jis a ﬁnite union of time intervals associated with j, and its size is\\nthe sum of lengths of the intervals, denoted by |B(j)|. Both, blocking period and scheduling', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='blocking period of a job jis a ﬁnite union of time intervals associated with j, and its size is\\nthe sum of lengths of the intervals, denoted by |B(j)|. Both, blocking period and scheduling\\ninterval, depend on machine ibut we omit ifrom the notation as it is clear from the context;\\nboth periods are created after job jhas been assigned to machine i.\\nFour types of events trigger a decision of the algorithm at ti meτ: the release of a job, the\\nend of a blocking period, the end of a scheduling interval, an d the admission of a job. In any\\nof these four cases, the algorithm calls the admission routine . This subroutine iterates over\\nall machines iand checks if j, the shortest job on iwhose scheduling interval contains τ, can\\nadmit the currently shortest job j⋆available for machine i.\\nTo this end, any admitted job jchecks whether pij⋆< γpij. Only such jobs qualify for\\nadmission by j. Upon admission by j, jobj⋆obtains two disjoint consecutive intervals, the\\nscheduling interval S(j⋆) = [aj⋆,ej⋆) and the blocking period B(j⋆) of size at most βpij⋆. At', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='scheduling interval S(j⋆) = [aj⋆,ej⋆) and the blocking period B(j⋆) of size at most βpij⋆. At\\nthe admission of job j⋆, the blocking period B(j⋆) is planned to start at ej⋆, the end of j⋆’s\\nscheduling interval. During B(j⋆), jobjonly admits jobs kwithpik<1\\n2pij⋆.\\n8', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Hence, when job jdecides if it admits the currently shortest available job j⋆at timeτ, it\\nmakes surethat j⋆is suﬃciently small andthat nojob kof similar(or even smaller)processing\\ntime is blocking τ, i.e., it veriﬁes that τ /∈B(k) for all jobs kwithpik≤2pij⋆admitted to\\nthe same machine. In this case, we say that j⋆is achildofjand that jis theparentofj⋆,\\ndenoted by π(j⋆) =j. If jobj⋆is admitted at time τby jobj, the algorithm sets aj⋆=τ\\nandej⋆=aj⋆+(1+δ)pij⋆and assigns the scheduling interval S(j⋆) = [aj⋆,ej⋆) toj⋆.\\nIfej⋆≤ej, the routine sets fj⋆= min{ej,ej⋆+βpij⋆}which determines B(j⋆) = [ej⋆,fj⋆).', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='As the scheduling and blocking periods of children kofjare supposed to be disjoint, we\\nhave toupdate the blocking periods . First consider the job kwithpik>2pij⋆admitted to the\\nsame machine whose blocking period contains τ(if it exists), and let [ e′\\nk,f′\\nk) be the maximal\\ninterval of B(k) containing τ. We set f′′\\nk= min{ej,f′\\nk+ (1 +δ+β)pij⋆}and replace the\\ninterval [ e′\\nk,f′\\nk) by [e′\\nk,τ)∪[τ+(1+δ+β)pij⋆,f′′\\nk). For all other jobs kwithB(k)∩[τ,∞)̸=∅\\nadmitted to the same machine, we replace the remaining part o f their blocking period [ e′\\nk,f′\\nk)\\nby [e′\\nk+ (1 +δ+β)pij⋆,f′′\\nk) wheref′′\\nk:= min{ej,f′\\nk+ (1 +δ+β)pij⋆}. In this update, we', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='k) wheref′′\\nk:= min{ej,f′\\nk+ (1 +δ+β)pij⋆}. In this update, we\\nfollow the convention that [ e,f) =∅iff≤e. Observe that the length of the blocking period\\nmight decrease due to such updates.\\nNote that ej⋆> ejis also possible as jdoes not take the end of its own scheduling inter-\\nvalejinto account when admitting jobs. Thus, theschedulinginte rval ofj⋆would end outside\\nthe scheduling interval of jand inside the blocking period of j. During B(j), the parent π(j)\\nofj, did not allocate the interval [ ej,ej⋆) for completing jobs admitted by jbut for ensuring\\nits own completion. Hence, the completion of both j⋆andπ(j) is not necessarily guaran-\\nteed anymore. To prevent this, we modify all scheduling intervals S(k) (including S(j)) that\\ncontain time τof jobs admitted to the same machine as j⋆and their blocking periods B(k).\\nFor each job kadmitted to the same machine with τ∈S(k) (including j) andej⋆> ek, we', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='For each job kadmitted to the same machine with τ∈S(k) (including j) andej⋆> ek, we\\nsetek=ej⋆. We also update their blocking periods (in fact, single inte rvals) to reﬂect their\\nnew starting points. If the parent π(k) ofkdoes not exist, B(k) remains empty; otherwise\\nwe setB(k):= [ek,fk) wherefk= min{eπ(k),ek+βpik}. Note that, after this update, the\\nblocking periods of any but the largest such job will be empty . Moreover, the just admitted\\njobj⋆does not get a blocking period in this special case.\\nDuring the analysis of the algorithm, we show that any admitt ed jobjstill completes\\nbeforeaj+(1+δ)pijand that ej≤aj+(1+2δ)pijholds in retrospect for all admitted jobs j.\\nThus, any job jthat admits another job j⋆tentatively assigns this job a scheduling interval\\nof length (1+ δ)pij⋆but, for ensuring its own completion, it is prepared to lose ( 1+2δ)pij⋆', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='of length (1+ δ)pij⋆but, for ensuring its own completion, it is prepared to lose ( 1+2δ)pij⋆\\ntime units of its scheduling interval S(j). We summarize the blocking algorithm in Figure 2.\\nRoadmap for the analysis\\nDuring the analysis, it is suﬃcient to concentrate on instan ces with small slack, as also\\nnoted in [10]. For ε >1 we run the blocking algorithm with ε= 1, which only tightens\\nthe commitment requirement, and obtain constant competiti ve ratios. Thus, we assume\\n0< ε≤1. For 0< δ < ε, in theδ-commitment model an online scheduler needs to commit to\\nthe completion of a job jno later than dj−(1+δ)pij. Hence, committing to the completion\\nof a jobjat an earlier point in time clearly satisﬁes committing at a r emaining slack of δpij.\\nTherefore, we may assume δ∈[ε\\n2,ε).\\nTheblockingalgorithmdoesnotmigrateanyjob. Intheanaly sis, wecomparethethrough-\\nput of our algorithm to the solution of an optimal non-migrat ory schedule. To do so, we rely', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='put of our algorithm to the solution of an optimal non-migrat ory schedule. To do so, we rely\\non a key design principle of the blocking algorithm, which is that, whenever the job set ad-\\n9', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Figure 2: Blocking algorithm\\nScheduling Routine: At all times τand on all machines i, run the job with shortest\\nprocessing time that has been admitted to iand has not yet completed.\\nEvent:Release of a new job at time τ\\nCall Admission Routine.\\nEvent:End of a blocking period or scheduling interval at time τ\\nCall Admission Routine.\\nAdmission Routine:\\ni←1\\nj⋆←a shortest job available at τfor machine i, i.e.,j⋆∈argmin{pij|j∈ J,rj≤\\nτanddj−τ≥(1+δ)pij}\\nwhilei≤mdo\\nK←the set of jobs on machine iwhose scheduling intervals contain τ\\nifK=∅then\\nadmit job j⋆to machine i,aj⋆←τ, andej⋆←aj⋆+(1+δ)pij⋆\\nS(j⋆)←[aj⋆,ej⋆) andB(j⋆)←∅\\ncall Admission Routine\\nelse\\nj←argmin{pik|k∈K}', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='call Admission Routine\\nelse\\nj←argmin{pik|k∈K}\\nifj⋆< γpijandτ /∈B(j′) for allj′admitted to iwithpij′≤2pij⋆then\\nadmit job j⋆to machine i,aj⋆←τ, andej⋆←aj⋆+(1+δ)pij⋆\\nifej⋆≤ejthen\\nfj⋆←min{ej,ej⋆+βpij⋆}\\nS(j⋆)←[aj⋆,ej⋆) andB(j⋆)←[ej⋆,fj⋆)\\nelse\\nS(j⋆)←[aj⋆,ej⋆) andB(j⋆)←∅\\nmodifyS(k) andB(k) fork∈K\\nupdateB(j′) forj′admitted to machine iwithB(j′)∩[τ,∞)̸=∅\\ncall Admission Routine\\nend if\\nelse\\ni←i+1', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='call Admission Routine\\nend if\\nelse\\ni←i+1\\nj⋆←a shortest job available at τfor machine i, i.e.,j⋆∈argmin{pij|j∈J,rj≤\\nτanddj−τ≥(1+δ)pij}\\nend if\\nend if\\nend while\\n10', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='mitted to a machine is ﬁxed, the scheduling of the jobs follow s the simple SPT order. This\\nenables us to split the analysis into two parts.\\nIn the ﬁrst part, we argue that the scheduling routine can han dle the admitted jobs\\nsuﬃciently well. That is, every admitted jobs is completed o n time; see Section 3. Here, we\\nuse that the blocking algorithm is non-migratory and consid er each machine individually.\\nFor the second part, we observe that the potential admission of a new job j⋆to machine i\\nis solely based on its availability and on its size relative t oji, the job currently processed\\nby machine i. More precisely, given the availability of j⋆, ifpij⋆< γpiji, the time does not\\nbelong to the blocking period of a job kiadmitted to machine iwithpij⋆≥1\\n2pikiandiis\\nthe ﬁrst machine (according to machine indices) with this pr operty, then j⋆is admitted to\\nmachine i. This implies that min{\\nγpiji,1\\n2piki}\\nacts as a threshold , and only available jobs\\nwith processing time less than this threshold qualify for ad mission by the blocking algorithm', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='machine i. This implies that min{\\nγpiji,1\\n2piki}\\nacts as a threshold , and only available jobs\\nwith processing time less than this threshold qualify for ad mission by the blocking algorithm\\non machine i. Hence, any available job that the blocking algorithm does n ot admit has to\\nexceed the threshold.\\nBased on this observation, we develop a general charging sch eme foranynon-migratory\\nonline algorithm satisfying the property that, at any time τ, the algorithm maintains a time-\\ndependent threshold and the shortest available job smaller than this threshold is admitted\\nby the algorithm. We formalize this description and analyze the competitive ratio of such\\nalgorithms in Section 4 before applying this general result to our particular algorithm.\\n3 Completing all admitted jobs on time\\nWe show that the blocking algorithm ﬁnishes every admitted j ob on time in Theorem 3.\\nTheorem 3. Let0< δ < εbe ﬁxed. If 0< γ <1andβ≥1satisfy\\nβ/2\\nβ/2+(1+2 δ)(\\n1+δ−2(1+2δ)γ)\\n≥1, (1)\\nthen the blocking algorithm completes any job jadmitted at aj≤dj−(1+δ)pijon time.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='≥1, (1)\\nthen the blocking algorithm completes any job jadmitted at aj≤dj−(1+δ)pijon time.\\nRecall that we chose γ=δ\\n16andβ=16\\nδ, which guarantees that Equation (1) is satisﬁed.\\nAs the blocking algorithm does not migrate jobs, it suﬃces to consider each machine\\nindividuallyinthissection. Theproofrelies on thefollow ing observations: (i) Thesizes ofjobs\\nadmitted by job jthat interrupt each others’ blocking periods are geometric ally decreasing,\\n(ii) the scheduling intervals of jobs are completely contai ned in the scheduling intervals of\\ntheir parents, and (iii) scheduling in SPT order guarantees that job jhas highest priority in\\nthe blocking periods of its children. We start by proving the following technical lemma about\\nthe length of the ﬁnal scheduling interval of an admitted job j, denoted by|S(j)|. In the\\nproof, we use that π(k) =jfor two jobs jandkimplies that pik< γpij.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='proof, we use that π(k) =jfor two jobs jandkimplies that pik< γpij.\\nLemma 1. Let0< δ < εbe ﬁxed. If γ >0satisﬁes(1+2δ)γ≤δ,then|S(j)|≤(1+2δ)pij.\\nMoreover, S(j)contains the scheduling intervals and blocking periods of a ll descendants of j.\\nProof.Consider a machine iand letjbe a job admitted to machine i. By deﬁnition of\\nthe blocking algorithm, the end point ejof the scheduling interval of job jis only modiﬁed\\nwhenjor one of j’s descendants admits another job. Let us consider such a cas e: If job j\\nadmits a job kwhose scheduling interval does not ﬁt into the scheduling in terval of j, we\\nsetej=ek=ak+(1+δ)pikto accommodate the scheduling interval S(k) within S(j). The\\n11', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='same modiﬁcation is applied to any ancestor j′ofjwithej′< ek. This implies that, after\\nsuch a modiﬁcation of the scheduling interval, neither jnor any aﬀected ancestor j′ofjare\\nthe smallest jobs in their scheduling intervals anymore. In particular, no job whose scheduling\\ninterval was modiﬁed in such a case at time τis able to admit jobs after τ. Hence, any job j\\ncan only admit other jobs within the interval [ aj,aj+(1+δ)pij). That is, ak≤aj+(1+δ)pij\\nfor every job kwithπ(k) =j.\\nThus, by induction, it is suﬃcient to show that ak+ (1 + 2δ)pik≤aj+ (1 + 2δ)pijfor\\nadmitted jobs kandjwithπ(k) =j. Note that π(k) =jimpliespik< γpij. Hence,\\nak+(1+2δ)pik≤(aj+(1+δ)pij)+(1+2 δ)γpij≤aj+(1+2δ)pij,', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='ak+(1+2δ)pik≤(aj+(1+δ)pij)+(1+2 δ)γpij≤aj+(1+2δ)pij,\\nwhere the last inequality follows from the assumption (1+2 δ)γ≤δ. Due to the construction\\nofB(k) upon admission of some job kby jobj, we also have B(k)⊆S(j).\\nProof of Theorem 3. Letjbe a job admitted by the blocking algorithm to machine iwith\\naj≤dj−(1+δ)pij. Showing that job jcompletes before time d′\\nj:=aj+(1+δ)pijproves the\\ntheorem. Dueto schedulingin SPTorder, each job jhas highest priority in its own scheduling\\ninterval if the time point does not belongto the schedulingi nterval of a descendant of j. Thus,\\nit suﬃces to show that at most δpijunits of time in [ aj,d′\\nj) belong to scheduling intervals S(k)\\nof descendants of j. By Lemma 1, the scheduling interval of any descendant k′of a child k', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='j) belong to scheduling intervals S(k)\\nof descendants of j. By Lemma 1, the scheduling interval of any descendant k′of a child k\\nofjis contained in S(k). Hence, it is suﬃcient to only consider K, the set of children of j.\\nIn order to bound the contribution of each child k∈K, we impose a class structure on\\nthe jobs in Kdepending on their size relative to job j. More precisely, we deﬁne ( Cc(j))c∈N0,\\nwhereCc(j) contains all jobs k∈Kthat satisfyγ\\n2c+1pij≤pik<γ\\n2cpij. Ask∈Kimpliespik<\\nγpij, each child of jbelongs to exactly one class and ( Cc(j))c∈N0in fact partitions K.\\nConsider two jobs k,k′∈Kwhere, upon admission, kinterrupts the blocking period of k′.\\nBy deﬁnition, we have pik<1\\n2pik′. Hence, the chosen class structure ensures that kbelongs\\nto a strictly higherclass than k′, i.e., there are c,c′∈Nwithc > c′such that k∈Cc(j)', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='to a strictly higherclass than k′, i.e., there are c,c′∈Nwithc > c′such that k∈Cc(j)\\nandk′∈Cc′(j). In particular, the admission of a job k∈Cc(j) implies either that kis the ﬁrst\\njob of classCc(j) thatjadmits or that the blocking period of the previous job in clas sCc(j)\\nhas completed. Based on this distinction, we are able to boun d the loss of scheduling time\\nforjinS(j) due to S(k) of a child k. Speciﬁcally, we partition Kinto two sets. The ﬁrst\\nsetK1contains all children of jthat where admitted as the ﬁrst jobs in their class Cc(j). The\\nsetK2contains the remaining jobs.\\nWe start with K2. Consider a job k∈Cc(j) admitted by j. By Lemma 1, we know\\nthat|S(k)|= (1 +µδ)pik, where 1≤µ≤2. Letk′∈Cc(j) be the previous job admitted', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='that|S(k)|= (1 +µδ)pik, where 1≤µ≤2. Letk′∈Cc(j) be the previous job admitted\\nbyjin classCc(j). Then, B(k′)⊆[ek′,ak). Since scheduling and blocking periods of children\\nofjare disjoint, jhas highest scheduling priority in B(k′). Hence, during B(k′)∪S(k) jobj\\nis processed for at least |B(k′)|units of time. In other words, jis processed for at least\\na|B(k′)|\\n|B(k′)∪S(k)|-fraction of B(k′)∪S(k). We rewrite this ratio as\\n|B(k′)|\\n|B(k′)∪S(k)|=βpik′\\nβpik′+(1+µδ)pik=νβ\\nνβ+(1+µδ),\\nwhereν:=pik′\\npik∈(1\\n2,2]. By diﬀerentiating with respect to νandµ, we observe that the last\\nterm is increasing in νand decreasing in µ. Thus, we lower bound this expression by\\n|B(k′)|', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='term is increasing in νand decreasing in µ. Thus, we lower bound this expression by\\n|B(k′)|\\n|B(k′)∪S(k)|≥β/2\\nβ/2+(1+2 δ).\\n12', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Therefore, jis processed for at least aβ/2\\nβ/2+(1+2δ)-fraction in⋃\\nk∈KB(k)∪⋃\\nk∈K2S(k).\\nWe now consider the set K1. The total processing volume of these jobs is bounded from\\nabove by∑∞\\nc=0γ\\n2cpij= 2γpij.By Lemma 1,|S(k)| ≤(1 + 2δ)pik. Combining these two\\nobservations, we obtain⏐⏐⋃\\nk∈K1S(k)⏐⏐≤2(1+2δ)γpij.Combining the latter with the bound\\nforK2, we conclude that jis scheduled for at least\\n⏐⏐⏐[aj,d′\\nj)\\\\⋃\\nk∈KS(k)⏐⏐⏐≥β/2\\nβ/2+(1+2 δ)(\\n(1+δ)−2(1+2δ)γ)\\npij≥pij\\nunits of time, where the last inequality follows from Equati on (1). Therefore, jcompletes\\nbefored′', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='pij≥pij\\nunits of time, where the last inequality follows from Equati on (1). Therefore, jcompletes\\nbefored′\\nj=aj+(1+δ)pij≤dj, which concludes the proof.\\n4 Competitiveness: admitting suﬃciently many jobs\\nThis section shows that the blocking algorithm admits suﬃci ently many jobs to be O(1\\nε−δ)\\n-\\ncompetitive. As mentioned before, this proof is based on the observation that, at time τ,\\nthe blocking algorithm admits any job available for machine iif its processing time is less\\nthanγpiji, wherejiis the job processed by machine iat timeτ, and this time point is not\\nblocked by another job kipreviously admitted by jito machine i. We start by formalizing this\\nobservation for a class of non-migratory online algorithms before proving that this enables us\\nto bound the number of jobs any feasible schedule successful ly schedules during a particular\\nperiod. Then, we use it to show that the blocking algorithm is indeedO(1\\nε−δ)\\n-competitive.\\n4.1 A class of online algorithms\\nIn this section, we investigate a class of non-migratory onl ine algorithms. Recall that a job j', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='ε−δ)\\n-competitive.\\n4.1 A class of online algorithms\\nIn this section, we investigate a class of non-migratory onl ine algorithms. Recall that a job j\\nis called available for machine iat timeτif it is released beforeor at time τ,dj−τ≥(1+δ)pij,\\nand is not yet admitted.\\nWe consider a non-migratory online algorithm Awith the following properties.\\n(P1)Aonly admits available jobs.\\n(P2) Retrospectively, for each time τand each machine i, there is a threshold uiτ∈[0,∞]\\nsuch that any job jthat was available for machine iand not admitted to machine iby\\nAat timeτsatisﬁes pij≥uiτ. The function u(i):R→[0,∞],τ↦→uiτis piece-wise\\nconstant and right-continuous for every machine i∈{1,...,m}. Further, there are\\nonly countably many points of discontinuity. (This last pro perty is used to simplify the\\nexposition.)\\nKey lemma on the size of non-admitted jobs\\nFor the proof of the main result in this section, we rely on the following strong, structural', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='exposition.)\\nKey lemma on the size of non-admitted jobs\\nFor the proof of the main result in this section, we rely on the following strong, structural\\nlemma about the volume processed by a feasible non-migrator y schedule in some time interval\\nand the size of jobs admitted by a non-migratory online algor ithm satisfying (P1) and (P2)\\nin the same time interval.\\nLetσbe a feasible non-migratory schedule. Without loss of gener ality, we assume that σ\\ncompletes all jobs that it started on time. Let Xσbe the set of jobs completed by σand not\\nadmitted byA. For 1≤i≤m, letXσ\\nibe the set of jobs in Xσprocessed by machine i.\\nLetCxbe the completion time of job x∈Xσinσ.\\n13', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Lemma 2. Let0≤ϑ1≤ϑ2and ﬁxx∈Xσ\\nias well as Y⊂Xσ\\ni\\\\{x}. If\\n(R)rx≥ϑ1as well as ry≥ϑ1for ally∈Y,\\n(C)Cx≥Cyfor ally∈Y, and\\n(P)∑\\ny∈Ypiy≥ε\\nε−δ(ϑ2−ϑ1)\\nhold, then pix≥uiϑ2, whereuiϑ2is the threshold imposed by Aat timeϑ2. In particular,\\nifui,ϑ2=∞, then no such job xexists.\\nProof.We show the lemma by contradiction. More precisely, we show t hat, ifpix< uiϑ2, the\\nschedule σcannot complete xon time and, hence, is not feasible.\\nRemember that x∈Xσ\\niimplies thatAdid not admit job xat any point ϑ. At time ϑ2,\\nthere are two possible reasons why xwas not admitted: pix≥uiϑ2ordx−ϑ2<(1+δ)pix. In', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='there are two possible reasons why xwas not admitted: pix≥uiϑ2ordx−ϑ2<(1+δ)pix. In\\ncase of the former, the statement of the lemma holds. Toward a contradiction, suppose pix<\\nuiϑ2and, thus, dx−ϑ2<(1+δ)pixhas to hold. As job xarrives with a slack of at least εpix\\nat its release date rxandrx≥ϑ1by assumption, we have\\nϑ2−ϑ1≥ϑ2−dx+dx−rx>−(1+δ)pix+(1+ε)pix= (ε−δ)pix. (2)\\nSincealljobsin Ycompleteearlierthan xbyAssumption(C)andareonlyreleasedafter ϑ1\\nby (R), the volume processed by σin [ϑ1,Cx) on machine iis at leastε\\nε−δ(ϑ2−ϑ1) +pix\\nby (P). Moreover, σcan process at most a volume of ( ϑ2−ϑ1) on machine iin [ϑ1,ϑ2). These\\ntwo bounds imply that σhas to process job parts with a processing volume of at least\\nε', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='two bounds imply that σhas to process job parts with a processing volume of at least\\nε\\nε−δ(ϑ2−ϑ1)+pix−(ϑ2−ϑ1)>δ\\nε−δ(ε−δ)pix+pix= (1+δ)pix\\nin [ϑ2,Cx), where the inequality follows using Inequality (2). Thus, Cx≥ϑ2+(1+δ)pix> dx,\\nwhich contradicts the feasibility of σ.\\nObservethat, by(P1)and(P2), theonlinealgorithm Aadmitsajobavailableformachine i\\nif it satisﬁes pij< uiτ. In particular, if uiτ=∞for some time point τ, thenAadmits any\\njob available for machine i. Hence, for 0≤ϑ1≤ϑ2withuiϑ2=∞, there does not exist a\\njobx∈Xσ\\niand a set Y⊂Xσ\\ni\\\\{x}satisfying (R), (C), and (P) for machine i.\\nBounding the number of non-admitted jobs', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='iand a set Y⊂Xσ\\ni\\\\{x}satisfying (R), (C), and (P) for machine i.\\nBounding the number of non-admitted jobs\\nIn this section, we use the Properties (P1) and (P2) to bound t he throughput of a non-\\nmigratory optimal (oﬄine) algorithm. To this end, we ﬁx an in stance as well as an opti-\\nmal schedule with job set Opt. LetAbe a non-migratory online algorithm satisfying (P1)\\nand (P2).\\nLetXbe the set of jobs in Optthat the algorithm Adid not admit. We assume without\\nloss of generality that all jobs in Optcomplete on time. Since Optas well asAare non-\\nmigratory, we compare the throughput machine-wise. To this end, we ﬁx one machine i.\\nLetXi⊂Xbe the set of jobs scheduled on machine ibyOpt.\\nAssumption (P2) guarantees that the threshold ui,τis piece-wise constant and right-\\ncontinuous, i.e., u(i)is constant on intervals of the form [ τt,τt+1). LetIrepresent the set of', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='continuous, i.e., u(i)is constant on intervals of the form [ τt,τt+1). LetIrepresent the set of\\nmaximal intervals It= [τt,τt+1) whereu(i)is constant. That is, ui,τ=utholds for all τ∈It\\nandui,τt+1̸=ut, whereut:=ui,τt, The main result of this section is the following theorem.\\n14', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Theorem 4. LetXibe the set of jobs that are scheduled on machine iin the optimal schedule.\\nLetI={I1,...,IT}be the set of maximal intervals on machine iofAsuch that the machine-\\ndependent threshold is constant for each interval and has th e valueutin interval It= [τt,τt+1).\\nThen,\\n|Xi|≤T∑\\nt=1ε\\nε−δτt+1−τt\\nut+T,\\nwhere we setτt+1−τt\\nut= 0ifut=∞andτt+1−τt\\nut=∞if{τt,τt+1}∩{−∞,∞}̸=∅andut<∞.\\nWe observe that T=∞trivially proves the statement as Xicontains at most ﬁnitely\\nmany jobs. The same is true ifτt+1−τt\\nut=∞for some t∈[T]. Hence, for the remainder of\\nthis section we assume without loss of generality that Ionly contains ﬁnitely many intervals\\nand thatτt+1−τt\\nut<∞holds for every t∈[T].', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='this section we assume without loss of generality that Ionly contains ﬁnitely many intervals\\nand thatτt+1−τt\\nut<∞holds for every t∈[T].\\nTo prove this theorem, we develop a charging scheme that assi gns jobs x∈Xito intervals\\ninI. Theidea behindour charging scheme is that Optdoes not contain arbitrarily many jobs\\nthat are available in Itsinceutprovides a natural lower bound on their processing times. In\\nparticular, the processing time of any job that is releasedduring interval Itand not admitted\\nby the algorithm exceeds the lower bound ut. Thus, the charging scheme relies on the release\\ndaterxand the size pixof a job x∈Xias well as on the precise structure of the intervals\\ncreated byA.\\nThe charging scheme we develop is based on a careful modiﬁcat ion of the following par-\\ntition (Ft)T\\nt=1of the set Xi. Fix an interval It∈Iand deﬁne the set Ft⊆Xias the set\\nthat contains all jobs x∈Xireleased during It, i.e.,Ft={x∈Xi:rx∈It}. Since, upon\\nrelease, each job x∈Xiis available and not admitted by A, the next fact directly follows', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='release, each job x∈Xiis available and not admitted by A, the next fact directly follows\\nfrom Properties (P1) and (P2).\\nFact 1. For all jobs x∈Ftit holdspix≥ut. In particular, if ut=∞, thenFt=∅.\\nIn fact, the charging scheme maintains this property and onl y assigns jobs in Xito inter-\\nvalsItifpix≥ut. In particular, no job will be assigned to an interval with ut=∞.\\nWe now formalize how many jobs in Xiare assigned to a speciﬁc interval It. Let\\nϕt:=⌊ε\\nε−δτt+1−τt\\nut⌋\\n+1\\nifut<∞, andϕt= 0 ifut=∞. We refer to ϕtas thetarget number ofIt. As discussed\\nbefore, we assumeτt+1−τt\\nut<∞, and, thus, the target number is well-deﬁned. If each of the\\nsetsFtsatisﬁes|Ft|≤ϕt, then theorem 4 immediately follows. In general, |Ft|≤ϕtdoes not', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='setsFtsatisﬁes|Ft|≤ϕt, then theorem 4 immediately follows. In general, |Ft|≤ϕtdoes not\\nhave to be true since jobs in Optmay be preempted and processed during several intervals It.\\nTherefore, for proving theorem 4, we show that there always e xists another partition ( Gt)T\\nt=1\\nofXisuch that|Gt|≤ϕtholds.\\nThe high-level idea of this proof is the following: Consider an interval It= [τt,τt+1). IfFt\\ndoes not contain too many jobs, i.e., |Ft|≤ϕt, we would like to set Gt=Ft. Otherwise, we\\nﬁnd a later interval It′with|Ft′|< ϕt′such that we can assign the excess jobs in FttoIt′.\\nProof of theorem 4. As observed before, it suﬃces to show the existence of a parti tionG=\\n(Gt)T\\nt=1ofXisuch that|Gt|≤ϕtin order to prove the theorem.\\nIn order to repeatedly apply lemma 2, we only assign excess jo bsx∈FttoGt′fort < t′if', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='In order to repeatedly apply lemma 2, we only assign excess jo bsx∈FttoGt′fort < t′if\\ntheirprocessingtimeisat leastthethresholdof It′, i.e.,pix≥ut′. Byourchoice ofparameters,\\n15', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='a setGt′withϕt′many jobs of size at least ut′“covers” the interval It′= [τt′,τt′+1) as often\\nas required by (P) in lemma 2, i.e.,\\n∑\\nx∈Gt′pix≥ϕt′·ut′=(⌊ε\\nε−δτt′+1−τt′\\nut′⌋\\n+1)\\n·ut′≥ε\\nε−δ(τt′+1−τt′).(3)\\nThe proof consists of two parts: the ﬁrst one is to inductivel y (ont) construct the parti-\\ntionG= (Gt)T\\nt=1ofXi, where|Gt|≤ϕtholds for t∈[T−1]. The second one is the proof\\nthat a job x∈Gtsatisﬁespix≥utwhich will imply|GT|≤ϕT. During the construction of G\\nwe deﬁne temporary sets At⊂Xifor intervals It. The set Gtis chosen as a subset of Ft∪At\\nof appropriate size. In order to apply lemma 2 to each job in Atindividually, alongside At,', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='of appropriate size. In order to apply lemma 2 to each job in Atindividually, alongside At,\\nwe construct a set Yx,tand a time τx,t≤rxfor each job x∈Xithat is added to At. LetC∗\\ny\\nbe the completion time of some job y∈Xiin the optimal schedule Opt. The second part of\\nthe proof is to show that x,τx,t, andYx,tsatisfy\\n(R)ry≥τx,tfor ally∈Yx,t,\\n(C)C∗\\nx≥C∗\\nyfor ally∈Yx,t, and\\n(P)∑\\ny∈Yx,tpiy≥ε\\nε−δ(τt−τx,t).\\nThis implies that x,Y=Yx,t,ϑ1=τx,t, andϑ2=τtsatisfy the conditions of Lemma 2,\\nand thus the processing time of xis at least the threshold at time τt, i.e.,pix≥uiτt=ut.\\nConstructing G= (Gt)T\\nt=1.We inductively construct the sets Gtin the order of their', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Constructing G= (Gt)T\\nt=1.We inductively construct the sets Gtin the order of their\\nindices. We start by setting At=∅for all intervals Itwitht∈T. We deﬁne Yx,t=∅for each\\njobx∈Xiand each interval It. The preliminary value of the time τx,tis the minimum of the\\nstarting point τtof the interval Itand the release date rxofx, i.e.,τx,t:= min{τt,rx}. We\\nrefer to the step in the construction where Gtwas deﬁned by stept.\\nStarting with t= 1, letItbethe next interval to consider duringthe construction wit ht <\\nT. Depending on the cardinality of Ft∪At, we distinguish two cases. If |Ft∪At|≤ϕt, then\\nwe setGt=Ft∪At.\\nIf|Ft∪At|> ϕt, then we order the jobs in Ft∪Atin increasing order of completion times\\nin the optimal schedule. The ﬁrst ϕtjobs are assigned to Gtwhile the remaining |Ft∪At|−ϕt', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='in the optimal schedule. The ﬁrst ϕtjobs are assigned to Gtwhile the remaining |Ft∪At|−ϕt\\njobs are added to At+1. In this case, we might have to redeﬁne the times τx,t+1and the\\nsetsYx,t+1for the jobs xthat were newly added to At+1. Fix such a job x. If there is no\\njobzin the just deﬁned set Gtthat has a smaller release date than τx,t, we setτx,t+1=τx,t\\nandYx,t+1=Yx,t∪Gt. Otherwise let z∈Gtbe a job with rz< τx,tthat has the smallest\\ntimeτz,t. We set τx,t+1=τz,tandYx,t+1=Yz,t∪Gt.\\nFinally, we set GT=FT∪AT. We observe that uT<∞impliesϕT=∞becauseτT+1=\\n∞. Since this contradicts the assumption ϕt<∞for allt∈[T], this implies uT=∞. We', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='∞. Since this contradicts the assumption ϕt<∞for allt∈[T], this implies uT=∞. We\\nwill show that px≥uTfor allx∈GT. Hence, GT=∅. Therefore|GT|=ϕT= 0.\\nBounding the size of jobs in Gt.We consider the intervals again in increasing order of\\ntheirindicesandshowbyinductionthat anyjob xinGtsatisﬁespix≥utwhichimplies Gt=∅\\nifut=∞. Clearly, if x∈Ft∩Gt, fact 1 guarantees pix≥ut. Hence, in order to show the\\nlower bound on the processing time of x∈Gt, it is suﬃcient to consider jobs in Gt\\\\Ft⊂At.\\n16', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='To this end, we show that for such jobs (R), (C), and (P) are sat isﬁed. Thus, lemma 2\\nguarantees that pix≥uiτt=utby deﬁnition. Hence, At=∅ifut=∞by lemma 2.\\nBy construction, A1=∅. Hence, (R), (C), and (P) are satisﬁed for each job x∈A1.\\nSupposethat the Conditions (R), (C), and (P) are satisﬁed fo r allx∈Asfor all 1≤s < t.\\nHence, for s < t, the set Gsonly contains jobs xwithpix≥us. Fixx∈At. We want to show\\nthatpix≥ut. By the induction hypothesis and by fact 1, piy≥ut−1holds for all y∈Gt−1.\\nSincexdid not ﬁt in Gt−1anymore,|Gt−1|=ϕt−1.\\nWe distinguish two cases based on Gt−1. If there is no job z∈Gt−1withrz< τx,t−1,', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='We distinguish two cases based on Gt−1. If there is no job z∈Gt−1withrz< τx,t−1,\\nthenτx,t=τx,t−1, and (R) and (C) are satisﬁed by construction and by the induc tion hy-\\npothesis. For (P), consider\\n∑\\ny∈Yx,tpiy=∑\\ny∈Yx,t−1piy+∑\\ny∈Gt−1piy\\n≥ε\\nε−δ(τt−1−τx,t−1)+ut−1·ϕt−1\\n≥ε\\nε−δ(τt−1−τx,t−1)+ε\\nε−δ(τt−τt−1)\\n=ε\\nε−δ(τt−τx,t),\\nwhere the ﬁrst inequality holds due to the induction hypothe sis. By lemma 2, pix≥uτt=ut.\\nIf there is a job z∈Gt−1withrz< τx,t−1≤τt−1, thenz∈At−1. In step t−1, we chose z', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='If there is a job z∈Gt−1withrz< τx,t−1≤τt−1, thenz∈At−1. In step t−1, we chose z\\nwith minimal τz,t−1. Thus,ry≥τy,t−1≥τz,t−1for ally∈Gt−1andrx≥τx,t−1> rz≥τz,t−1\\nwhichisCondition(R)forthejobsin Gt−1. Moreover, bytheinductionhypothesis, ry≥τz,t−1\\nholds for all y∈Yz,t−1. Thus,τx,tandYx,tsatisfy (R). For (C), consider that C∗\\nx≥C∗\\nyfor\\nally∈Gt−1by construction and, thus, C∗\\nx≥C∗\\nz≥C∗\\nyalso holds for all y∈Yz,t−1due to\\nthe induction hypothesis. For (P), observe that\\n∑\\ny∈Yx,tpiy=∑\\ny∈Yz,t−1piy+∑\\ny∈Gt−1piy\\n≥ε', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='∑\\ny∈Yx,tpiy=∑\\ny∈Yz,t−1piy+∑\\ny∈Gt−1piy\\n≥ε\\nε−δ(τt−1−τz,t−1)+ut−1·ϕt−1\\n≥ε\\nε−δ(τt−1−τz,t−1)+ε\\nε−δ(τt−τt−1)\\n≥ε\\nε−δ(τt−τx,t).\\nHere, the ﬁrst inequality follows from the induction hypoth esis and the second from the\\ndeﬁnition of ut−1andϕt−1. Hence, lemma 2 implies pix≥uτt=ut.\\nWe note that pix≥utfor allx∈Gtand for all t∈[T].\\nBounding|Xi|.By construction, we know that⋃T\\nt=1Gt=Xi. We start with considering\\nintervals Itwithut=∞. Then,Ithas an unbounded threshold, i.e., uiτ=∞for allτ∈It,', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='t=1Gt=Xi. We start with considering\\nintervals Itwithut=∞. Then,Ithas an unbounded threshold, i.e., uiτ=∞for allτ∈It,\\nandFt=∅by fact 1. In the previous part we have seen that the condition s for lemma 2 are\\nsatisﬁed. Hence, Gt=∅ifut=∞. Fortwithut<∞, we have|Gt|≤ϕt=⌊ε\\nε−δτt+1−τt\\nut⌋\\n+1.\\nAs explained before, this bounds the number of jobs in Xi.\\n4.2 The blocking algorithm admits suﬃciently many jobs\\nHaving the powerful tool that we developed in the previous se ction at hand, it remains to\\nshow that the blocking algorithm admits suﬃciently many job s to achieve the competitive\\n17', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='ratio ofO(1\\nε−δ′)\\nwhereδ′=ε\\n2for commitment upon admission and δ′= max{ε\\n2,δ}\\nforδ-\\ncommitment. To this end, we show that the blocking algorithm belongs to the class of online\\nalgorithms considered in Section 4.1. Then, theorem 4 provi des a bound on the throughput\\nof an optimal non-migratory schedule.\\nWe begin by showing that the blocking algorithm satisﬁes Pro perties (P1) to (P2). The\\nﬁrst property is clearly satisﬁed by the deﬁnition of the blo cking algorithm. For the second\\nand the third property, we observe that a new job j⋆is only admitted to a machine iduring\\nthe scheduling interval of another job jadmitted to the same machine if pij⋆< γpij. Further,\\nthe time point of admission must not be blocked by a similar- o r smaller-size job kpreviously\\nadmitted during the scheduling interval of j. This leads to the bound pij⋆<1\\n2pikfor any\\njobkwhose blocking period contains the current time point. Comb ining these observations', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='admitted during the scheduling interval of j. This leads to the bound pij⋆<1\\n2pikfor any\\njobkwhose blocking period contains the current time point. Comb ining these observations\\nleads to a machine-dependent threshold ui,τ∈[0,∞] satisfying (P2).\\nMore precisely, ﬁx a machine iand a time point τ. Using j→ito denote that jwas\\nadmitted to machine i, we deﬁne ui,τ:= min j:j→i,τ∈S(j)γpijif there is no job kadmitted\\nto machine iwithτ∈B(k), with min∅=∞. Otherwise, we set ui,τ:=1\\n2pik. We note\\nthat the function u(i)is piece-wise constant and right-continuous due to our choi ce of right-\\nopen intervals for deﬁning scheduling intervals and blocki ng periods. Moreover, the points\\nof discontinuity of u(i)correspond to the admission of a new job, the end of a scheduli ng\\ninterval, and the start as well as the end of a blocking period of jobs admitted to machine i.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='of discontinuity of u(i)correspond to the admission of a new job, the end of a scheduli ng\\ninterval, and the start as well as the end of a blocking period of jobs admitted to machine i.\\nSince we only consider instances with a ﬁnite number of jobs, there are at most ﬁnitely many\\npoints of discontinuity of u(i). Hence, we can indeed apply theorem 4.\\nThen, the following theorem is the main result of this sectio n.\\nTheorem 5. An optimal non-migratory (oﬄine) algorithm can complete at most a factor\\nα+5more jobs on time than admitted by the blocking algorithm, wh ereα:=ε\\nε−δ(\\n2β+1+2δ\\nγ)\\n.\\nProof.We ﬁx an instance and an optimal solution Opt. We use Xto denote the set of\\njobs inOptthat the blocking algorithm did not admit. Without loss of ge nerality, we can\\nassume that all jobs in Optcomplete on time. If Jis the set of jobs admitted by the blocking\\nalgorithm, then X∪Jis a superset of the jobs successfully ﬁnished in the optimal solution.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='assume that all jobs in Optcomplete on time. If Jis the set of jobs admitted by the blocking\\nalgorithm, then X∪Jis a superset of the jobs successfully ﬁnished in the optimal solution.\\nHence, showing|X|≤(α+4)|J|suﬃces to prove theorem 5.\\nFor each machine i, we compare the throughput of the optimal solution to the thr oughput\\non machine iof the blocking algorithm. More precisely, let Xi⊆Xbe the jobs in Opt\\nscheduled on machine iand letJi⊆Jbe the jobs scheduled by the blocking algorithm on\\nmachine i. With theorem 4, we show |Xi|≤(α+ 4)|Ji|to bound the cardinality of Xin\\nterms of|J|.\\nTo this end, we retrospectively consider the interval struc ture created by the algorithm\\non machine i. LetIbe the set of maximal intervals It= [τt,τt+1) such that ui,τ=ui,τtfor\\nallτ∈It. We deﬁne ut=ui,τtfor each interval It. As discussed above, the time points τt\\nfort∈[T] correspond to the admission, the end of a scheduling interv al, and the start as well', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='fort∈[T] correspond to the admission, the end of a scheduling interv al, and the start as well\\nas the end of a blocking period of jobs admitted to machine 1. A s the admission of a job adds\\nat most three time points, we have that |I|≤3|Ji|+1.\\nAs the blocking algorithm satisﬁes Properties (P1) to (P2), we can apply theorem 4 to\\nobtain\\n|Xi|≤T∑\\nt=1ε\\nε−δτt+1−τt\\nut+|I|≤T∑\\nt=1ε\\nε−δτt+1−τt\\nut+(3|Ji|+1).\\n18', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='It remains to bound the ﬁrst part in terms of |Ji|. Ifut<∞, letjt∈Jibe thesmallest jobj\\nwithτt∈S(j)∪B(j). Then, at mostε\\nε−δτt+1−τt\\nut(potentially fractional) jobs will be charged\\nto jobjtbecause of interval It. By deﬁnition of ut, we have ut=γpijtifIt⊆S(jt), and\\nifIt⊆B(jt), we have ut=1\\n2pijt. The total length of intervals Itfor which j=jtholds sums\\nup to at most (1+2 δ)pijforIt⊆S(j) and to at most 2 βpijforIt⊆B(j). Hence, in total,\\nthe charging scheme assigns at mostε\\nε−δ(2β+1+2δ\\nγ) =αjobs inXito jobj∈Ji. Therefore,\\n|Xi|≤(\\nα+3)\\n|Ji|+1.\\nIfJi=∅, the blocking algorithm admitted all jobs scheduled on mach ineibyOpt, and|Xi|=', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='|Xi|≤(\\nα+3)\\n|Ji|+1.\\nIfJi=∅, the blocking algorithm admitted all jobs scheduled on mach ineibyOpt, and|Xi|=\\n0 =|Ji|follows. Otherwise, |Xi|≤(\\nα+4)\\n|Ji|, and we obtain\\n|Opt|≤|X∪J|=m∑\\ni=1|Xi|+|J|≤m∑\\ni=1(α+4)|Ji|+|J|≤(α+5)|J|,\\nwhich concludes the proof.\\n4.3 Finalizing the proof of Theorem 1\\nProof of theorem 1. InTheorem3weshowthattheblockingalgorithmcompletes al ladmitted\\njobsJon time. This implies that the blocking algorithm is feasibl e for the model commitment\\nupon admission. As no job j∈Jis admitted later than dj−(1+δ)pij, the blocking algorithm\\nalso solves scheduling with δ-commitment. In Theorem 5, we bound the throughput |Opt|\\nof an optimal non-migratory solution by α+ 5 times|J|, the throughput of the blocking\\nalgorithm, where α=ǫ\\nε−δ(2β+1+2δ', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='of an optimal non-migratory solution by α+ 5 times|J|, the throughput of the blocking\\nalgorithm, where α=ǫ\\nε−δ(2β+1+2δ\\nγ). Our choice of parameters β=16\\nδandγ=δ\\n16implies\\nthat the blocking algorithm achieves a competitive ratio of c∈O(ε\\n(ε−δ)δ)\\n. For commitment\\nupon arrival or for δ-commitment in the case where δ≤ε\\n2, we run the algorithm with δ′=ε\\n2.\\nHence,c∈O(1\\nε−δ′)\\n=O(1\\nε)\\n. Ifδ >ε\\n2, then we set δ′=δin our algorithm. Thus,ε\\nδ′∈O(1)\\nand, again, c∈O(1\\nε−δ′)\\n.\\n5 Scheduling without commitment\\nThis section considers online throughput maximization wit hout commitment requirements.\\nWe show how to exploit also in this setting our key lemma on the size of non-admitted jobs\\nfor a big class of online algorithms and the resulting upper b ound on the throughput of an\\noptimal (oﬄine) non-migratory algorithm from Section 4.1.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='for a big class of online algorithms and the resulting upper b ound on the throughput of an\\noptimal (oﬄine) non-migratory algorithm from Section 4.1.\\nWe consider the region algorithm that was designed by [10] for scheduling on a single\\nmachine and we generalize it to parallel identical machines . We prove that it has a compet-\\nitive ratio ofO(1\\nε)\\n, which is best possible on a single machine and improves subs tantially\\nupon the best previously known parallel-machine algorithm (for weighted throughput) with\\na competitive ratio of O(1\\nε2)\\nby Lucier et al. [30]. For a single machine, this matches the\\nguarantee proven in [10]. However, our new analysis is much m ore direct.\\n5.1 The region algorithm\\nOriginally, the region algorithm was designed for online sc heduling with and without com-\\nmitment on a single machine. We extend it to unrelated machin es by never migrating jobs\\n19', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='between machines and per machine using the same design princ iples that guide the admission\\ndecisions of the region algorithm, as developed in [10]. Sin ce we do not consider commit-\\nment in this section, we can signiﬁcantly simplify the expos ition of the region algorithm when\\ncompared to [10].\\nAs in the previous section, a job is only processed by the mach ine it initially was started\\non. We say the job has been admitted to this machine. Moreover, a running job can only\\nbe preempted by signiﬁcantly smaller-size jobs, i.e., smal ler by a factor of at leastε\\n4with\\nrespect to the processing time, and a job jcannot start for the ﬁrst time on machine iwhen\\nits remaining slack is too small, i.e., less thanε\\n2pij.\\nFormally, at any time τ, the region algorithm maintains two sets of jobs: admitted jobs ,\\nwhich have been started before or at time τ, andavailable jobs . A job jis available for\\nmachine iif it is released before or at time τ, is not yet admitted, and τis not too close to\\nits deadline, i.e., rj≤τanddj−τ≥(\\n1 +ε\\n2)\\npij. The intelligence of the region algorithm', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='its deadline, i.e., rj≤τanddj−τ≥(\\n1 +ε\\n2)\\npij. The intelligence of the region algorithm\\nlies in how it admits jobs. The actual scheduling decision th en is simple and independent\\nof the admission of jobs: at any point in time and on each machi ne, schedule the shortest\\njob that has been admitted to this machine and has not complet ed its processing time. In\\nother words, we schedule admitted jobs on each machine in Shortest Processing Time\\n(SPT) order. The region algorithm never explicitly conside rs deadlines except when deciding\\nwhether to admit jobs. In particular, jobs can even be proces sed after their deadline.\\nAt any time τ, when there is a job javailable for an idlemachine i, i.e.,iis not processing\\nany previously admitted job j′, the shortest available job j⋆is immediately admitted to\\nmachine iat timea⋆\\nj:=τ. Therearetwo events thattrigger adecision oftheregion al gorithm:\\nthe release of a job and the completion of a job. If one of these events occurs at time τ, the\\nregion algorithm invokes the preemption subroutine. This r outine iterates over all machines\\nand compares the processing time of the smallest job j⋆available for machine iwith the', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='region algorithm invokes the preemption subroutine. This r outine iterates over all machines\\nand compares the processing time of the smallest job j⋆available for machine iwith the\\nprocessing time of job jithat is currently scheduled on machine i. Ifpij⋆<ε\\n4piji, jobj⋆is\\nadmitted to machine iat timea⋆\\nj:=τand, by the above scheduling routine, immediately\\nstarts processing. We summarize the region algorithm in Fig ure 3.\\nThe proof of the analysis splits again naturally into two par ts: The ﬁrst part is to show\\nthat the region algorithm completes at least half of all admi tted jobs, and the second is to\\nuse theorem 5 to compare the number of admitted jobs to the thr oughput of an optimal\\nnon-migratory algorithm.\\n5.2 Completing suﬃciently many admitted jobs\\nThe main result of this section is the following theorem.\\nTheorem 6. Let0< ε≤1. Then the region algorithm completes at least half of all admi tted\\njobs before their deadline.\\nTheproofof theorem 6relies on two technical results that en able usto restrict toinstances\\nwith one machine and further only consider jobs that are admi tted by the region algorithm', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='jobs before their deadline.\\nTheproofof theorem 6relies on two technical results that en able usto restrict toinstances\\nwith one machine and further only consider jobs that are admi tted by the region algorithm\\nin this instance. Then, we can use the analysis of the region a lgorithm in [10] to complete\\nthe proof.\\nWe start with the following observation. Let Ibe an instance of online throughput\\nmaximization with the job set Jand letJ⊆Jbe the set of jobs admitted by the region\\nalgorithm at some point. It is easy to see that a job j /∈Jdoes not inﬂuence the scheduling\\n20', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Figure 3: Region algorithm\\nScheduling Routine: At any time τand on any machine i, run the job with shortest\\nprocessing time that has been admitted to iand has not yet completed.\\nEvent:Release of a new job at time τ\\nCall Threshold Preemption Routine.\\nEvent:Completion of a job at time τ\\nCall threshold preemption routine.\\nThreshold Preemption Routine:\\ni←1\\nj⋆←a shortest job available for machine iatτ, i.e.,j⋆∈argmin{pij|j∈ J,rj≤\\nτanddj−τ≥(1+ε\\n2)pij}\\nwhilei≤mdo\\nj←job processed on machine iat timeτ\\nifj=∅then\\nadmit job j⋆to machine i\\ncall Threshold Preemption Routine\\nelse ifpij⋆<ε\\n4pijthen\\nadmit job j⋆to machine i\\ncall Threshold Preemption Routine\\nelse\\ni←i+1\\nj⋆←a shortest job available for machine iatτ, i.e.,j⋆∈argmin{pij|j∈J,rj≤\\nτanddj−τ≥(1+ε', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='τanddj−τ≥(1+ε\\n2)pij}\\nend if\\nend while\\n21', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='or admission decisions of the region algorithm. The next lem ma formalizes this statement\\nand follows immediately from the just made observations.\\nLemma 3. For any instance Ifor which the region algorithm admits the job set J⊆J, the\\nreduced instanceI′containing only the jobs Jforces the region algorithm with consistent tie\\nbreaking to admit all jobs in Jand to create the same schedule as produced for the instance I.\\nThe proof of the main result compares the number of jobs ﬁnish ed on time, F⊆J, to the\\nnumber of jobs unﬁnished by their respective deadlines, U=J\\\\F. To further simplify the\\ninstance, we use that the region algorithm is non-migratory and restrict to single-machine\\ninstances. To this end, let F(i)andU(i)denote the ﬁnished and unﬁnished, respectively, jobs\\non machine i.\\nLemma 4. Leti∈{1,...,m}. There is an instance I′on one machine with job set J′=\\nF(i)∪U(i). Moreover, the schedule of the region algorithm for instanc eI′with consistent tie\\nbreaking is identical to the schedule of the jobs J′on machine i. In particular, F′=F(i)', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='breaking is identical to the schedule of the jobs J′on machine i. In particular, F′=F(i)\\nandU′=U(i).\\nProof.ByLemma3, wecanrestricttothejobsadmittedbytheregion a lgorithm. Hence, let I\\nbe such an instance with F(i)∪U(i)being admitted to machine i. As the region algorithm\\nis non-migratory, the sets of jobs scheduled on two diﬀerent m achines are disjoint. Let I′\\nconsist of the jobs in J′:=F(i)∪U(i)and one machine. We set p′\\nj=pijforj∈J′. The\\nregion algorithm on instance Iadmits all jobs in J. In particular, it admits all jobs in J′to\\nmachine i.\\nWe inductively show that the schedule for the instance I′is identical to the schedule on\\nmachine iin instanceI. To this end, we index the jobs in J′in increasing admission time\\npoints in instance I.\\nIt is obvious that job 1 ∈J′is admitted to the single machine at its release date r1\\nas happens in instance Isince the region algorithm uses consistent tie breaking. Su ppose', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='points in instance I.\\nIt is obvious that job 1 ∈J′is admitted to the single machine at its release date r1\\nas happens in instance Isince the region algorithm uses consistent tie breaking. Su ppose\\nthat the schedule is identical until the admission of job j⋆at timea⋆\\nj=τ. Ifj⋆does not\\ninterrupt the processing of another job, then j⋆will be admitted at time τinI′as well.\\nOtherwise, let j∈J′be the job that the region algorithm planned to process at tim eτ\\nbeforethe admission of job j⋆. Sincej⋆is admitted at time τinI,j⋆is available at time τ,\\nsatisﬁesp′\\nj⋆=pij⋆<ε\\n4pij=ε\\n4p′\\nj, and did not satisfy both conditions at some earlier time τ′\\nwith some earlier admitted job j′. Sincethe job set in I′is a subsetof the jobs in Iand we use\\nconsistent tie breaking, no other job j∗∈J′that satisﬁes both conditions is favored by the\\nregion algorithm over j⋆. Therefore, job j⋆is also admitted at time τby the region algorithm', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='region algorithm over j⋆. Therefore, job j⋆is also admitted at time τby the region algorithm\\nin instanceI′. Thus, the schedule created by the region algorithm for J′is identical to the\\nschedule ofJon machine iin the original instance.\\nFor proving theorem 6, we consider a worst-case instance for the region algorithm where\\n“worst” is with respect to the ratio between admitted and suc cessfully completed jobs. Since\\nthe region algorithm is non-migratory, there exists at leas t one machine in such a worst-case\\ninstance that “achieves” the same ratio as the whole instanc e. By the just proven lemma, we\\ncan ﬁnd a worst-case instance on a single machine. However, o n a single machine, the region\\nalgorithm algorithm in this paper is identical to the algori thm designed in [10]. Therefore,\\nwe simply follow the line of proof developed in [10] to show th eorem 6.\\nMore precisely, in [10] we show that the existence of a late jo bjimplies that the the set\\nof jobs admitted by jor by one of its children contains more ﬁnished than unﬁnishe d jobs.\\n22', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='LetFjdenote the set of jobs admitted by jor by one of its children that ﬁnish on time .\\nSimilarly, we denote the set of such jobs that complete after their deadlines, i.e., that are\\nunﬁnished at their deadline , byUj. We restate the following lemma, which was originally\\nshown in a single-machine environment but clearly also hold s for unrelated machines.\\nLemma 5 (Lemma 3 in [10]) .Consider some job jadmitted to some machine i∈{1,...,m}.\\nIfCj−aj≥(ℓ+1)pijforℓ >0, then|Fj|−|Uj|≥⌊4ℓ\\nε⌋.\\nProof of theorem 6. LetUbe the set of jobs that are unﬁnished by their deadline but who se\\nancestors have all completed on time. Every job j∈Uwas admitted by the algorithm at some\\ntimeajwithdj−aj≥(\\n1+ε\\n2)\\npij. Sincejis unﬁnished, we have Cj−aj> dj−aj≥(\\n1+ε\\n2)\\npij.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='1+ε\\n2)\\npij. Sincejis unﬁnished, we have Cj−aj> dj−aj≥(\\n1+ε\\n2)\\npij.\\nBy Lemma 5,|Fj|−|Uj|≥⌊4·ε/2\\nε⌋\\n= 2. Thus,\\n|Fj|+|Uj|≤2|Fj|−2<2|Fj|.\\nSince every ancestor of such a job jﬁnishes on time, this completes the proof.\\n5.3 The region algorithm admits suﬃciently many jobs\\nIn this section, we show the following theorem and give the pr oof of theorem 2.\\nTheorem 7. An optimal non-migratory (oﬄine) algorithm completes at mo st a factor(8\\nε+4)\\nmore jobs on time than admitted by the region algorithm.\\nProof.As in the previous section, ﬁx an instance and an optimal solu tionOpt. LetXbe\\nthe set of jobs in Optthat the region algorithm did not admit. We assume without lo ss\\nof generality that all jobs in Optﬁnish on time. Further, let Jdenote the set of jobs that', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='the set of jobs in Optthat the region algorithm did not admit. We assume without lo ss\\nof generality that all jobs in Optﬁnish on time. Further, let Jdenote the set of jobs that\\nthe region algorithm admitted. Then, X∪Jis a superset of the jobs in Opt. Thus,|X|≤(8\\nε+3)\\n|J|implies Theorem 7.\\nConsider an arbitrary but ﬁxed machine i. We compare again the throughput of the\\noptimal schedule on machine ito the throughput of the region algorithm on machine i.\\nLetXi⊆Xdenote the jobs in Optscheduled on machine iand letJidenote the jobs\\nscheduled by the region algorithm on machine i. Then, showing|Xi|≤(8\\nε+3)\\n|Ji|suﬃces to\\nprove the main result of this section. Given that the region a lgorithm satisﬁes Properties (P1)\\nand (P2), theorem 4 already provides a bound on the cardinali ty ofXiin terms of the\\nintervals correspondingtothescheduleonamchine i. Thus, it remainstoshow that theregion\\nalgorithm indeed qualiﬁes for applying theorem 4 and that th e bound developed therein can', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='intervals correspondingtothescheduleonamchine i. Thus, it remainstoshow that theregion\\nalgorithm indeed qualiﬁes for applying theorem 4 and that th e bound developed therein can\\nbe translated to a bound in terms of |Ji|.\\nWe start by showing that the region algorithm satisﬁes the as sumptions necessary for\\napplying theorem 4. Clearly, as the region algorithm only ad mits a job jat timeτifdj−τ≥(\\n1 +ε\\n2)\\npij, setting δ=ε\\n2proves that the region algorithm satisﬁes (P1). For (P2), we\\nretrospectively analyze the schedule generated by the regi on algorithm. For a time τ, letji\\ndenote the job scheduled on machine i. Then, setting ui,τ:=ε\\n4pijiorui,τ=∞if no such\\njobjiexists, indeed provides us with the machine-dependent thre shold necessary for (P2).\\nThis discussion also implies that u(i)has only countably many points of discontinuity as there\\nare only ﬁnitely many jobs in the instance, and that u(i)is right-continuous.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='This discussion also implies that u(i)has only countably many points of discontinuity as there\\nare only ﬁnitely many jobs in the instance, and that u(i)is right-continuous.\\nHence, letIdenote the set of maximal intervals It= [τt,τt+1) fort∈[T] of constant\\nthreshold uiτ. Thus, by theorem 4,\\n|Xi|≤T∑\\nt=1ε\\nε−δτt+1−τt\\nut+T. (4)\\n23', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='As the threshold ui,τis proportional to the processing time of the job currently s cheduled\\non machine i, the interval Iteither represents an idle interval of machine i(withuiτ=∞) or\\ncorresponds to the uninterrupted processing of some job jon machine i. We denote this job\\nbyjtif it exists. We consider now the set Ij⊆Iof intervals with jt=jfor some particular\\njobj∈Ji. As observed, these intervals correspond to job jbeing processed which happens\\nfor a total of pijunits of time. Combining with ut=ε\\n4pijforIt∈Ij, we get\\n∑\\nt:It∈Ijτt+1−τt\\nut=pij\\nε\\n4pij=4\\nε.\\nAsδ=ε\\n2, we additionally have thatε\\nε−δ= 2. Hence, we rewrite Equation (4) by\\n|Xi|≤8\\nε|Ji|+T.\\nItremains tobound Tinterms of|Ji|to concludetheproof. Tothis end, werecall that the\\nadmission of a job jto amachine interrupts theprocessing of at most one previou sly admitted', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Itremains tobound Tinterms of|Ji|to concludetheproof. Tothis end, werecall that the\\nadmission of a job jto amachine interrupts theprocessing of at most one previou sly admitted\\njob. Hence, the admission of |Ji|jobs to machine 1 creates at most 2 |Ji|+1 intervals.\\nIf theregion algorithm does not admit any job to machine i, i.e.,|Ji|= 0, then uiτ=∞for\\neach time point τ. Hence, there exists no job scheduled on machine ibyOptthat the region\\nalgorithm did not admit. In other words, Xi=∅and|Xi|= 0 =|Ji|. Otherwise, 2|Ji|+1≤\\n3|Ji|. Therefore,\\n|Xi|≤(8\\nε+3)\\n|Ji|.\\nCombining with the observation about XiandJipreviously discussed, we obtain\\n|Opt|≤|X∪J|=m∑\\ni=1|Xi|+|J|≤(8\\nε+3)m∑\\ni=1|Ji|+|J|=(8\\nε+4)\\n|J|,\\nwhich concludes the proof.\\n5.4 Finalizing the proof of Theorem 2', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='ε+3)m∑\\ni=1|Ji|+|J|=(8\\nε+4)\\n|J|,\\nwhich concludes the proof.\\n5.4 Finalizing the proof of Theorem 2\\nProof of Theorem 2. In Theorem 6 we show that the region algorithm completes at le ast\\nhalf of all admitted jobs Jon time. In Theorem 4, we bound the throughput |Opt|of an\\noptimal non-migratory solution by(8\\nε+ 4)\\n|J|. Combining these theorems shows that the\\nregion algorithm achieves a competitive ratio of c= 2·(8\\nε+4)\\n=16\\nε+8.\\n6 Conclusion\\nIn this paper, we close the problem of online single-machine throughput maximization with\\nand without commitment requirements. For both commitment s ettings, we give an optimal\\nonline algorithm. Further, our algorithms run in a multiple -machine environment, even on\\nheterogenous machines. Our algorithms compute non-migrat ory schedules on unrelated ma-\\nchines with thesamecompetitive ratio O(1\\nε)\\nas for asinglemachine andimprove substantially\\nupon the state of the art.\\nIt remains open whether the problem with a large number of mac hines admits an online', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='chines with thesamecompetitive ratio O(1\\nε)\\nas for asinglemachine andimprove substantially\\nupon the state of the art.\\nIt remains open whether the problem with a large number of mac hines admits an online\\nalgorithm with a better competitive ratio. Indeed, very rec ently, Moseley et al. [31] present\\n24', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='anO(1)-competitive algorithm for m≥2 parallel identical machines without commitment.\\nIt remains, however, unclear if this result can be lifted to o ther machine environments or any\\nof the commitment models.\\nThere are other examples in the literature in which the worst -case ratio for a scheduling\\nproblem improves with an increasing number of machines. Con sider, e.g., the non-preemptive\\noﬄine variant of our throughput maximization problem on ide ntical machines. There is an\\nalgorithm with approximation ratio of 1 .55 for any mwhich is improving with increasing\\nnumber of machines, converging to 1 as mtends to inﬁnity [19]. The second part of the result\\nalso holds for the weighted problem.\\nAnother interesting question asks whether randomization a llows for improved results.\\nRecall that there is an O(1)-competitive randomized algorithm for scheduling on a s ingle\\nmachinewithoutcommitment andwithoutslack assumption[2 5]. Thereforeis seemsplausible\\nthat randomization also helps designing algorithms with im proved competitive ratios for the\\ndiﬀerent commitment models, for which only weak lower bounds are known [10].\\nFurther, we leave migratory scheduling on unrelated machin es as an open problem. Al-\\nlowing migration in this setting means that, on each machine i, a certain fraction of the', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Further, we leave migratory scheduling on unrelated machin es as an open problem. Al-\\nlowing migration in this setting means that, on each machine i, a certain fraction of the\\nprocessing time pijis executed, and these fractions must sum to one. Generalizi ng the result\\nwe leverage for identical machines [24], it is conceivable t hat any migratory schedule can be\\nturned into a valid non-migratory schedule of the same jobs b y adding a constant number\\nof machines of each type . Such a result would immediately allow to transfer our compe titive\\nratios to the migratory setting (up to constant factors). De vanur and Kulkarni [13] show a\\nweaker result that utilizes speed rather than additional ma chines. Note that the strong im-\\npossibility result of Im and Moseley [21] does not rule out th e desired strengthening because\\nwe make the ε-slack assumption for every job and machine eligible for it. Further, we – as\\nwell as Devanur and Kulkarni [13] – assume that the processin g time of each job jsatisﬁes\\npij≤dj−rjon any eligible machine i, whereas the lower bound in [21] requires jobs that\\nviolate this reasonable assumption.\\nFurther research directions include generalizations such as weighted throughput maxi-', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='pij≤dj−rjon any eligible machine i, whereas the lower bound in [21] requires jobs that\\nviolate this reasonable assumption.\\nFurther research directions include generalizations such as weighted throughput maxi-\\nmization. While strong lower bounds exist for handling weig hted throughput with commit-\\nment [10], there remains a gap for the problem without. The kn own lower bound of Ω(1\\nε)\\nalready holds for unit weights [10]. A natural extension of t he region algorithm bases its\\nadmission decisions on the density, i.e., the ratio of the we ight of a job to its processing time.\\nThe result is an algorithm similar to the O(1\\nε2)\\n-competitive algorithm by Lucier et al. [30].\\nBoth algorithms only admit available jobs and interrupt cur rently running jobs if the new\\njob is denser by a certain factor. However, we can show that th ere is a lower bound of Ω(1\\nε2)\\non the competitive ratio of such algorithms. Hence, in order to improve the upper bound for\\nonline weighted throughput maximization, one needs to deve lop a new type of algorithm.\\n25', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='References\\n[1] K. Agrawal, J. Li, K. Lu, and B. Moseley. Scheduling paral lelizable jobs online to\\nmaximize throughput. In LATIN, volume 10807, pages 755–776. Springer, 2018.\\n[2] Y. Azar, I. Kalp-Shaltiel, B. Lucier, I. Menache, J. Naor , and J. Yaniv. Truthful online\\nscheduling with commitments. In EC, pages 715–732. ACM, 2015.\\n[3] N. Bansal, H. Chan, and K. Pruhs. Competitive algorithms for due date scheduling.\\nAlgorithmica , 59(4):569–582, 2011.\\n[4] A. Bar-Noy, S. Guha, J. Naor, and B. Schieber. Approximat ing the throughput of\\nmultiple machines in real-time scheduling. SIAM J. Comput. , 31(2):331–352, 2001.\\n[5] S. K. Baruah and J. R. Haritsa. Scheduling for overload in real-time systems. IEEE\\nTrans. Computers , 46(9):1034–1039, 1997.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='[5] S. K. Baruah and J. R. Haritsa. Scheduling for overload in real-time systems. IEEE\\nTrans. Computers , 46(9):1034–1039, 1997.\\n[6] S. K. Baruah, J. R. Haritsa, and N. Sharma. On-line schedu ling to maximize task\\ncompletions. In RTSS, pages 228–236. IEEE Computer Society, 1994.\\n[7] S.K.Baruah, G. Koren, D. Mao, B. Mishra, A. Raghunathan, L. E.Rosier, D. E.Shasha,\\nand F. Wang. On the competitiveness of on-line real-time tas k scheduling. Real-Time\\nSystems, 4(2):125–144, 1992.\\n[8] S. K. Baruah, G. Koren, B. Mishra, A. Raghunathan, L. E. Ro sier, and D. E. Shasha.\\nOn-linescheduling in the presenceof overload. In FOCS, pages 100–110. IEEE Computer\\nSociety, 1991.\\n[9] P. Berman and B. DasGupta. Improvements in throughout ma ximization for real-time', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Society, 1991.\\n[9] P. Berman and B. DasGupta. Improvements in throughout ma ximization for real-time\\nscheduling. In STOC, pages 680–687. ACM, 2000.\\n[10] L. Chen, F. Eberle, N. Megow, K. Schewior, and C. Stein. A general framework for\\nhandling commitment in online throughput maximization. Math. Prog. , 183:215–247,\\n2020.\\n[11] B. DasGupta and M. A. Palis. Online real-time preemptiv e scheduling of jobs with\\ndeadlines. In APPROX , volume 1913 of Lecture Notes in Computer Science , pages 96–\\n107. Springer, 2000.\\n[12] M. L. Dertouzos and A. K. Mok. Multiprocessor on-line sc heduling of hard-real-time\\ntasks.IEEE Trans. Software Eng. , 15(12):1497–1506, 1989.\\n[13] N. R. Devanur and J. Kulkarni. A uniﬁed rounding algorit hm for unrelated machines\\nscheduling problems. In C. Scheideler and J. T. Fineman, edi tors,SPAA, pages 283–290.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='scheduling problems. In C. Scheideler and J. T. Fineman, edi tors,SPAA, pages 283–290.\\nACM, 2018.\\n[14] J. Du and J. Y. Leung. Minimizing the number of late jobs o n unrelated machines. Oper.\\nRes. Lett. , 10(3):153–158, 1991.\\n[15] A. D. Ferguson, P. Bod´ ık, S. Kandula, E. Boutin, and R. F onseca. Jockey: Guaranteed\\njob latency in data parallel clusters. In EuroSys, pages 99–112. ACM, 2012.\\n26', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='[16] J. A. Garay, J. Naor, B. Yener, and P. Zhao. On-line admis sion control and packet\\nscheduling with interleaving. In INFOCOM , pages 94–103. IEEE Computer Society,\\n2002.\\n[17] M. H. Goldwasser. Patience is a virtue: The eﬀect of slack on competitiveness for\\nadmission control. J. Sched. , 6(2):183–211, 2003.\\n[18] M. H. Goldwasser and B. Kerbikov. Admission control wit h immediate notiﬁcation. J.\\nSched., 6(3):269–285, 2003.\\n[19] S. Im, S. Li, and B. Moseley. Breaking 1 - 1/e barrier for n on-preemptive throughput\\nmaximization. In F. Eisenbrand and J. K¨ onemann, editors, IPCO, volume 10328 of\\nLecture Notes in Computer Science , pages 292–304. Springer, 2017.\\n[20] S. Im, S. Li, and B. Moseley. Breaking 1 - 1/e barrier for n onpreemptive throughput\\nmaximization. SIAM J. Discret. Math. , 34(3):1649–1669, 2020.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='maximization. SIAM J. Discret. Math. , 34(3):1649–1669, 2020.\\n[21] S. Im and B. Moseley. General proﬁt scheduling and the po wer of migration on hetero-\\ngeneous machines. In SPAA, volume 10807 of Lecture Notes in Computer Science , pages\\n755–776. Springer, 2018.\\n[22] S. Jamalabadi, C. Schwiegelshohn, and U. Schwiegelsho hn. Commitment and slack for\\nonline load maximization. In SPAA, pages 339–348. ACM, 2020.\\n[23] B. Kalyanasundaram and K. Pruhs. Speed is as powerful as clairvoyance. J. ACM,\\n47(4):617–643, 2000.\\n[24] B. KalyanasundaramandK. Pruhs. Eliminating migratio n in multi-processor scheduling.\\nJ. Algorithms , 38(1):2–24, 2001.\\n[25] B. Kalyanasundaram and K. Pruhs. Maximizing job comple tions online. J. Algorithms ,\\n49(1):63–85, 2003.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='[25] B. Kalyanasundaram and K. Pruhs. Maximizing job comple tions online. J. Algorithms ,\\n49(1):63–85, 2003.\\n[26] G. Koren and D. E. Shasha. MOCA: A multiprocessor on-lin e competitive algorithm for\\nreal-time system scheduling. Theor. Comput. Sci. , 128(1&2):75–97, 1994.\\n[27] G. Koren and D. E. Shasha. Dover: An optimal on-line scheduling algorithm for over-\\nloaded uniprocessor real-time systems. SIAM J. Comput. , 24(2):318–339, 1995.\\n[28] E. Lawler. A dynamic programming algorithm for preempt ive scheduling of a single\\nmachine to minimize the number of late jobs. Ann. Oper. Res. , 26(1-4):125–133, 1990.\\n[29] E.L.Lawler. Recent resultsinthetheory ofmachinesch eduling. InA. Bachem, B. Korte,\\nand M. Gr¨ otschel, editors, Mathematical Programming The State of the Art , pages 202–\\n234. Springer, 1982.', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='and M. Gr¨ otschel, editors, Mathematical Programming The State of the Art , pages 202–\\n234. Springer, 1982.\\n[30] B. Lucier, I. Menache, J. Naor, and J. Yaniv. Eﬃcient onl ine scheduling for deadline-\\nsensitive jobs: Extended abstract. In SPAA, pages 305–314. ACM, 2013.\\n[31] B. Moseley, K. Pruhs, C. Stein, and R. Zhou. A competitiv e algorithm for throughout\\nmaximization on identical machines. CoRR, abs/2111.06564, 2021.\\n27', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='[32] K. Pruhsand C. Stein. How to schedule when you have to buy your energy. In APPROX ,\\nvolume 6302 of Lecture Notes in Computer Science , pages 352–365. Springer, 2010.\\n[33] K. Pruhs and G. J. Woeginger. Approximation schemes for a class of subset selection\\nproblems. Theor. Comput. Sci. , 382(2):151–156, 2007.\\n[34] C. Schwiegelshohn and U. Schwiegelshohn. The power of m igration for online slack\\nscheduling. In ESA, volume 57 of LIPIcs, pages 75:1–75:17. Schloss Dagstuhl - Leibniz-\\nZentrum f¨ ur Informatik, 2016.\\n[35] R. Sitters. Complexity of preemptive minsum schedulin g on unrelated parallel machines.\\nJournal of Algorithms , 57(1):37–48, 2005.\\n28', metadata={'pdf': 'https://arxiv.org/pdf/1912.10769', 'link': 'https://openalex.org/works/W3216068169', 'title': 'Online Throughput Maximization on Unrelated Machines: Commitment is No Burden'}),\n",
              " Document(page_content='Journal of Automated Reasoning (2021) 65:425–460\\nhttps://doi.org/10.1007/s10817-020-09578-5\\nHigher-Order Quantiﬁer Elimination, Counter Simulations\\nand Fault-Tolerant Systems\\nSilvio Ghilardi1·Elena Pagani2\\nReceived: 3 January 2019 / Accepted: 5 August 2020 / Published online: 29 August 2020\\n© The Author(s) 2020\\nAbstract\\nWe develop quantiﬁer elimination procedures for fragments of higher order logic arising\\nfrom the formalization of distributed systems (especially of fault-tolerant ones). Such pro-cedures can be used in symbolic manipulations like the computation of pre/post images andof projections. We show in particular that our procedures are quite effective in producingcounter abstractions that can be model-checked using standard SMT technology. In fact,\\nvery often in the current literature veriﬁcation tasks for distributed systems are accomplishedvia counter abstractions. Such abstractions can sometimes be justiﬁed via simulations andbisimulations. In this work, we supply logical foundations to this practice, by our techniquefor second order quantiﬁer elimination. We implemented our procedure for a simpliﬁed (but', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='still expressive) subfragment and we showed that our method is able to successfully handleveriﬁcation benchmarks from various sources with interesting performances.\\nKeywords 2nd order quantiﬁer elimination ·Satisﬁability Modulo theories ·Veriﬁcation of\\nparameterized distributed systems ·Counter abstractions\\n1 Introduction\\nThere is an increasing interest concerning algorithmic methods (and, in particular, quantiﬁer\\nelimination methods) applying to second order logic, as witnessed by recent dedicated work-shops [ 40]. Quoting from the textbook [ 25] “In recent years there has been an increasing use\\nof logical methods and signiﬁcant new developments have been spawned in several areasof computer science, ranging from artiﬁcial intelligence and software engineering to agent-\\nElectronic supplementary material The online version of this article ( https://doi.org/10.1007/s10817-020-\\n09578-5 ) contains supplementary material, which is available to authorized users.\\nB Elena Pagani\\nelena.pagani@unimi.it\\nSilvio Ghilardi\\nsilvio.ghilardi@unimi.it\\n1Università degli Studi di Milano, Via C. Saldini 50, 20133 Milan, Italy', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Silvio Ghilardi\\nsilvio.ghilardi@unimi.it\\n1Università degli Studi di Milano, Via C. Saldini 50, 20133 Milan, Italy\\n2Università degli Studi di Milano, Via G. Celoria 18, 20133 Milan, Italy\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='426 S. Ghilardi, E. Pagani\\nbased systems and the semantic web. In the investigation and application of logical methods\\nthere is a tension between: (i) the need for a representational language strong enough toexpress domain knowledge of a particular application, and the need for a logical formalismgeneral enough to unify several reasoning facilities relevant to the application, on the onehand, and (ii) the need to enable computationally feasible reasoning facilities, on the otherhand. Second-order logics are very expressive and allow us to represent domain knowledgewith ease, but there is a high price to pay for the expressiveness. Most second-order logicsare incomplete and highly undecidable. It is the quantiﬁers which bind relation symbols thatmake second-order logics computationally unfriendly. It is therefore desirable to eliminatethese second-order quantiﬁers, when this is mathematically possible; and often it is.”\\nHowever, most known applications of second-order quantiﬁer elimination concern modal-\\nlike logics or knowledge representation area (see again [ 25]), with limited - if not negligible\\nat all - impact on other areas of computer science, like formal methods. In this paper, weare partially ﬁlling this gap, by developing specialized second order elimination techniques', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='at all - impact on other areas of computer science, like formal methods. In this paper, weare partially ﬁlling this gap, by developing specialized second order elimination techniques\\napplying to the veriﬁcation of distributed (especially fault-tolerant) algorithms . In designing\\nthe fragments of second order logic to which our algorithms apply, we are strictly guided byour intended main applications, although we feel that our contribution could be interestingalso in a general logical context.\\n1.1 The Challenge of Verification of Distributed Systems\\nThe automated, formal veriﬁcation of distributed algorithms is a crucial, although challeng-ing, task. The processes executing these algorithms communicate with one another, theiractions depend on the messages received, and their number is arbitrary. These character-istics are captured by so called reactive parameterized systems. The task of validating orrefuting properties of these systems is daunting, due to the difﬁculty of limiting the possibleevolutions, thus having to deal with genuinely inﬁnite-state systems.\\nBuilding accurate declarative models of these systems requires powerful formalisms,\\ninvolving arrays [ 28], [29] and, in the fault-tolerant case, also some fragment of higher-order\\nlogic [ 21], [4] (this is needed in order to have some form of comprehension to play with', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='logic [ 21], [4] (this is needed in order to have some form of comprehension to play with\\ncardinalities of deﬁnable sets). On the other hand, for a long time, it has been observed thatcounter systems [18,19,22] can be sufﬁcient to specify many problems (like cache coherence\\nor broadcast protocols) in the distributed algorithms area. Recently, counter abstractions havebeen effectively used also in the veriﬁcation of fault-tolerant distributed protocols [ 3,34,35,\\n38]. It should be noticed that, unlike what happens in the old framework of [ 18,19,22],\\nthese new applications are often (although not always) based on abstractions that can onlysimulate the original algorithms and such simulation may sometimes be the result of an a-\\npriori reasoning on the characteristics of the algorithm, embedded into the model. Despitethis fact, all runs from the original speciﬁcations are represented in the simulations withcounter systems (this is in fact the formal content of the notion of a ‘simulation’), thus forinstance safety certiﬁcations for the simulating model apply also to the original model. Theadvantage of this approach is that, as it is evident e.g. from the experiments in [ 3],veriﬁcation', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='of counter systems is very well supported by the existing technology . In fact, although basic\\nproblems about counter systems are themselves undecidable, the sophisticated machinery(predicate abstraction [ 24], IC3 [ 17,32], etc.) developed inside the SMT community leads\\nto impressively performing tools like μZ[33],nuXmv [13],SeaHorn [31].... which are', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='to impressively performing tools like μZ[33],nuXmv [13],SeaHorn [31].... which are\\nnowadays being used to solve many veriﬁcation problems regarding counter systems.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 427\\nBeing conscious that building simulations requires in any case some human interaction, we\\ntried to build in this paper a uniform framework. Our framework relies on recent powerfultechniques for deciding cardinality and array constraints [ 4,6,43]; we shall exploit these\\ntechniques in order to obtain quantiﬁer elimination results in a higher order context . Via these\\nquantiﬁer elimination results, we shall show how to automatically build the best possible\\ncounter simulations users can obtain once they ﬁx (i) the speciﬁcation of the system, (ii)\\npossibly some helpful invariants and (iii) the counter variables involved in the projectedsimulation (such variables are cardinality counters for deﬁnable sets). We demonstrate theeffectiveness of our approach by producing, for some common benchmarks, counter systemssimulations which are effectively model-checked by current SMT-based tools.\\n1.2 A Toy Example\\nLet us begin by illustrating our methodology via a ﬁrst example, the MESI protocol (thesame simple technique applies to all examples from e.g. [ 2]). The MESI protocol is a cache', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Let us begin by illustrating our methodology via a ﬁrst example, the MESI protocol (thesame simple technique applies to all examples from e.g. [ 2]). The MESI protocol is a cache\\ncoherence protocol; here we analyze the simpliﬁed version reported in the extended versionof [2] (in Appendix A.3 in the supplementary material we shall make a detailed analysis of\\nthe original algorithm from [ 47]). We have a ﬁnite set Proc ofNidentical processes; each\\nprocess ican take a local state L(i)within the enumerated set\\nData ={(m)odified ,(e)xclusive ,(s)hared ,(i)nvalid }.\\nInitially all processes are in state iand the system can evolve from LtoL\\n′according to one\\nof the four nondeterministic rules:\\n(τ1)∃i(L(i)=e∧L′(i)=m∧∀j̸=iL′(j)=L(j))\\n(τ2)∃i(L(i)=i∧L′(i)=s∧\\n∀j̸=i(L(j)=i=L′(j)∨(L(j)̸=i∧L′(j)=s)))', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='∀j̸=i(L(j)=i=L′(j)∨(L(j)̸=i∧L′(j)=s)))\\n(τ3)∃i(L(i)=s∧L′(i)=e∧∀j̸=iL′(j)=i)\\n(τ4)∃i(L(i)=i∧L′(i)=e∧∀j̸=iL′(j)=i)\\nThis speciﬁcation of the system involves a function variable L:Proc −→Data and\\nwe want to simulate it using only integer variables. To this aim, we introduce counters\\nzi,zs,ze,zmfor the deﬁnable sets\\n{i|L(i)=i},{i|L(i)=s},{i|L(i)=e},{i|L(i)=m},\\nrespectively. In other words, the formulæ (τ1)−(τ4)are modiﬁed by adding to them the 8\\nequations below as further conjuncts\\nzi=♯{i|L(i)=i},zs=♯{i|L(i)=s},', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='equations below as further conjuncts\\nzi=♯{i|L(i)=i},zs=♯{i|L(i)=s},\\nze=♯{i|L(i)=e},zm=♯{i|L(i)=m},(1)\\nz′\\ni=♯{i|L′(i)=i},z′\\ns=♯{i|L′(i)=s},\\nz′\\ne=♯{i|L′(i)=e}, z′\\nm=♯{i|L′(i)=m}(2)\\nFori=1,..., 4, we let (τ+\\ni)be the conjunction of (τi)with the 8 equalities ( 1)–(2) above.\\nA similar transformation is done for the formula (ι),expressing the system initialization,\\nnamely ∀iL(i)=i: this is modiﬁed to (ι+)by conjoining to it the ﬁrst 4 equations above\\n(namely the equations ( 1)).\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='428 S. Ghilardi, E. Pagani\\nNow, observe that the safety property we are interested in, namely that processes in state m\\ncannot coexist with processes in state s, can be expressed in terms of arithmetic properties of\\nour counters as zm>0→zs=0. Thus, from an observational point of view, only counter\\narithmetics is relevant.\\nHow to approximate the whole speciﬁcation of the system using just the above counters?\\nThe idea is to existentially quantify and then eliminate the higher order variable L from the\\nformulæ (ι+), (τ+\\n1)−(τ+\\n4): we shall see that this is possible in this and in many cases. In\\nour case, after applying the quantiﬁer elimination procedure, we get\\n(˜ι)zi=N∧zs=0∧ze=0∧zm=0\\n(˜τ1)ze>0∧z′\\ne=ze−1∧z′\\nm=zm+1∧z′\\ni=zi∧z′\\ns=zs\\n(˜τ2)zi>0∧z′\\ni=zi−1∧z′\\nm=0∧z′\\ne=0∧z′\\ns=zs+zm+ze+1', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='i=zi−1∧z′\\nm=0∧z′\\ne=0∧z′\\ns=zs+zm+ze+1\\n(˜τ3)zs>0∧z′\\ns=0∧z′\\nm=0∧z′\\ni=zi+zs−1+ze+zm∧z′\\ne=1\\n(˜τ4)zi>0∧z′\\ns=0∧z′\\nm=0∧z′\\ni=zi−1+zs+ze+zm∧z′\\ne=1\\nIn this new system, the only variables are the arithmetic variables zi,zs,ze,zm; we will show\\nthat the new system simulates the old system ‘in the best possible way’ (in the sense formally\\nexplained in Sect. 4.1) using the variables zi,zs,ze,zm.1Since the property to be checked\\nis a safety property, we can hope to check it for the new (simpler) system: if we succeed, weget the desired safety certiﬁcation for the original system. This is in fact what happens: anSMT-based tool like μZornuXmv (among others) is able to solve the new safety problem', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='instantaneously.\\n1.3 Our Four-Steps Plan\\nIt should now be clear what is our general strategy:\\n(1) system speciﬁcations are formulated in higher order logic, i.e. using a declarative for-\\nmalism which is sufﬁciently expressive and close to informal speciﬁcations;\\n(2) counters for deﬁnable sets are added by the user to the system speciﬁcation, in such a way\\nthat the observationally relevant properties can be reformulated as arithmetic propertiesof these counters;\\n(3) higher order variables are eliminated, by applying an automatic procedure;(4) the resulting system is ﬁnally model-checked by using an SMT-based tool for counter\\nsystems.\\nIn this plan, only steps (1)–(2) require manual intervention (we shall better discuss these\\nsteps in Sect. 7); step (3) is effective every time the syntactic restrictions for our quantiﬁer', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='In this plan, only steps (1)–(2) require manual intervention (we shall better discuss these\\nsteps in Sect. 7); step (3) is effective every time the syntactic restrictions for our quantiﬁer\\nelimination procedures are matched; step (4) is subject to two risks, namely the fact thatmodel-checkers may not terminate on such (often undecidable) arithmetical problems andthe fact that simulations may introduce spurious traces. Non-termination, giving the actualstate of the art (much progress has been made both at the theoretical and at the practicallevel) is less frequent than one can imagine. There are positive theoretical results: besidesclassical achievements [ 1,28] showing that backward search terminates for coverability prob-\\nlems whenever system states carry a wqo ordering, additional recent results [ 39] show that\\nthe system diameter may be (unexpectedly!) ﬁnite, thus reducing search to bounded modelchecking. Concerning the second risk, notice that if spurious traces arise, they can be rec-ognized because SMT-tools supply concrete numerical values for counterexamples; then,\\n1Actually, this example is quite simple and the counters simulation is in fact a bisimulation.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 429\\none can try to go back to step (2) and to reﬁne the abstraction by adding more counters\\nfor deﬁnable sets. In fact, the design of a good counter abstraction for a speciﬁc propertyto be veriﬁed requires some manual ingenuity, because it is true that our results guaranteethe existence of a best counter abstraction once the integer variables are ﬁxed, but one canget better and better counter abstractions by adding further integer variables expressing thecardinality of deﬁnable ﬁnite sets. One should not however exceed with the number of thesevariables: adding a full set of counters for e.g. nBoolean ﬂags requires an exponential number\\nof counters, which may be unfeasible and cause SMT-based model checkers to get in troublein the ﬁnal veriﬁcation phase. In principle, it might also be the case that no invariant involvingjust arithmetic counters exists (in which case all attempts relying on counter abstractions arebound to fail), but both theoretical results and practical experiments show that very oftencounter abstractions are successful.\\n1.4 Structure of the Paper', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='1.4 Structure of the Paper\\nThe paper is structured as follows: in Sect. 2we supply syntactic background and in Sect. 3we\\nstate and prove our quantiﬁer elimination results. In Sect. 4we introduce our formalism for\\nsystem speciﬁcations and show how quantiﬁer elimination can be used to compute arithmeticprojections (i.e. best counter simulations). Section 5shows how a restricted (more tractable)\\nformat for system speciﬁcations can be handled inside our tool ArcaSim ; Sect. 6describes\\nthe set of benchmarks used in our experiments and report ArcaSim performances. Finally,\\nin Sect. 7we discuss related and future work. In the electronic Appendix A in the supple-\\nmentary material we run three representative examples in full detail; the electronic Appendixis available on the publisher website. Preliminary versions of the material included in thispaper were presented in the Workshops [ 26,27].\\n2 Higher Order Logic and Flat Constraints\\nIn order to have enough expressive power, we use higher order logic, more speciﬁcally\\nChurch’s type theory (see e.g. [ 7] for an introduction to the subject).2It should be noticed,\\nhowever, that our primary aim is to supply a framework for model-checking and not to build', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Church’s type theory (see e.g. [ 7] for an introduction to the subject).2It should be noticed,\\nhowever, that our primary aim is to supply a framework for model-checking and not to build\\na deductive system . Thus we shall introduce below only suitable languages (via higher order\\nsignatures) and a semantics for such languages - such semantics can be speciﬁed e.g. insideany classical foundational system for set theory. In addition, as typical for model-checking,we want to constrain our semantics so that certain sorts have a ﬁxed meaning: the primitivesort Zhas to be interpreted as the (standard) set of integers, the sort Ωhas to be interpreted\\nas the set of truth values {tt,ff}; moreover, some primitive sorted operations like +,0,S\\n(addition, zero, successor for natural numbers) and ∧,∨,→,¬(Boolean operations for truth\\nvalues) must have their natural interpretation. Some sorts might be enumerated , i.e. they must\\nbe interpreted as a speciﬁc ﬁnite ‘set of values’ {a\\n0,..., ak},w h e r et h e ai’s are mentioned', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='be interpreted as a speciﬁc ﬁnite ‘set of values’ {a\\n0,..., ak},w h e r et h e ai’s are mentioned\\namong the constants of the language and are assumed to be distinct. Finally, we may askfor a primitive sort to be interpreted as a ﬁnite set (by abuse, we shall call such sorts ﬁnite ):\\nfor instance, we shall constrain in this way the sort Proc modeling the set of processes in a\\ndistributed system. In addition, if a sort is interpreted into a ﬁnite set, we may constrain somenumerical parameter (typically, the parameter we choose for this is named N) to indicate the\\n2Some notation we use might look slightly non-standard; it is similar to the notation of [ 44].\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='430 S. Ghilardi, E. Pagani\\ncardinality of such ﬁnite set. The notion of constrained signature below incorporates all the\\nabove requirements in a general framework.\\nAconstrained signature Σconsists of a set of (primitive) sorts and of a set of (primitive)\\nsorted function symbols,3together with a class CΣofΣ-structures, called the models ofΣ.\\nUsing primitive sorts, types can be built up using exponentiation (= functions type); terms\\ncan be built up using variables, function symbols, as well as λ-abstraction and functional\\napplication.\\nRemark 1 In the standard model-checking literature, CΣis a singleton; here we must allow\\nmany structures in CΣ, because our model-checking problems are parametric : the sort mod-', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='application.\\nRemark 1 In the standard model-checking literature, CΣis a singleton; here we must allow\\nmany structures in CΣ, because our model-checking problems are parametric : the sort mod-\\neling the set of processes of our system speciﬁcations must be interpreted onto a ﬁnite setwhose cardinality is not a priori ﬁxed. Our deﬁnition of a ‘constrained signature’ is analogousto the deﬁnition of a ‘theory’ in SMT literature; in fact, in SMT literature, a ‘theory’ is justa pair given by a signature and a class of structures. When transferred to a higher order con-text, such deﬁnition coincides with that of a ‘constrained signature’ above (thus our formalframework is very similar to e.g. that of [ 51]).\\nOur constrained signatures always include the sort Ωof truth-values; terms of type Ωare\\ncalled formulae (we use greek letters α ,β,...,φ,ψ,... for them). For a type S, the type\\nS→Ωis indicated as ℘(S)and called the power set ofS;i fSis constrained to be interpreted', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='S→Ωis indicated as ℘(S)and called the power set ofS;i fSis constrained to be interpreted\\nas a ﬁnite set, Σmight contain a cardinality operator ♯:℘(S)−→ Z, whose interpretation\\nis assumed to be the intended one ( ♯sis the number of the elements of s-a ss u c hi ti sa l w a y s\\na nonnegative number). If φis a formula and Sat y p e ,w eu s e {x\\nS|φ}or just {x|φ}for\\nλxSφ. We assume to have binary equality predicates for each type; universal and existential\\nquantiﬁers for formulæ can be introduced by standard abbreviations (see e.g. [ 44]). We shall\\nuse the roman letters x,y,..., i,j,...,v,w,... for variables (of course, each variable is\\nsuitably typed, but types are left implicit if confusion does not arise). Bold letters like v(or\\nunderlined letters like x) are used for tuples of free variables; below, we indicate with t(v)\\nthe fact that the term thas free variables included in the list v(whenever this happens, we say', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='underlined letters like x) are used for tuples of free variables; below, we indicate with t(v)\\nthe fact that the term thas free variables included in the list v(whenever this happens, we say\\nthat tis a v-term ,o ra v-formula if it has type Ω). The result of a simultaneous substitution\\nof the tuple of variables vby the tuple of (type matching) terms uintis denoted by t(u/v)\\nor directly as t(u).\\nGiven a tuple of variables v,aΣ-interpretation ofvin a model M∈CΣis a function\\nImapping each variable onto an element of the correponding type (as interpreted in M).\\nThe evaluation of a term t(v)according to Iis recursively deﬁned in the standard way and\\nis written as tM,I.AΣ-formula φ(v)istrue under M,Iiff it evaluates to tt(in this case,\\nwe may also say that vM,Isatisﬁes φ);φisvalid iff it is true for all models M∈CΣand\\nall interpretations Iofvover M. We write |/equal1Σφ(or just |/equal1φ) to mean that φis valid and', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='all interpretations Iofvover M. We write |/equal1Σφ(or just |/equal1φ) to mean that φis valid and\\nφ|/equal1Σψ(or just φ|/equal1ψ) to mean that φ→ψis valid; we say that φandψareΣ-equivalent\\n(or just equivalent) iff φ↔ψis valid.\\n2.1 Flat Cardinality Constraints\\nLet us ﬁx a constrained signature Σfor the remaining part of the paper. Such Σshould be\\nadequate for modeling parameterized systems, hence we assume that Σconsists of:\\n(i) the integer sort Z, together with some parameters (i.e. free individual constants) as well\\nas all operations and predicates of linear arithmetic (namely, 0 ,1,+,−,=,< ,≡n);\\n3These include 0-ary function symbols, called constants; constants of sort Zwill be called (arithmetic)\\nparameters .\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 431\\n(ii) the enumerated truth value sort Ω, with the constants tt,ffand the Boolean operations\\non them;\\n(iii) a ﬁnite sort Proc , whose cardinality is constrained to be equal to the arithmetic parameter\\nN(in the applications, this sort is used to represent the processes acting in our distributed\\nsystems);\\n(iv) a further sort Data , with appropriate operations, modeling local data; we assume that (a)\\nﬁrst-order quantiﬁer elimination holds for Data , meaning that all ﬁrst-order formulæ\\nbuilt up from Data -atoms (i.e. from variables of type Data using operations and pred-\\nicates relative to the sort Data ) are equivalent to quantiﬁer-free ones; (b) ground (i.e.\\nvariable-free) Data -atoms are equivalent to ⊥or to⊤.\\nIn principle, we could consider having ﬁnitely many signatures for data instead of just one, but\\nthis generalization is only apparent because one can use product sorts and recover componentsorts via suitable pairing and projection operations.\\nIfData is an enumerated sort, we call Σﬁnitary ; the subsignature Σ', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='this generalization is only apparent because one can use product sorts and recover componentsorts via suitable pairing and projection operations.\\nIfData is an enumerated sort, we call Σﬁnitary ; the subsignature Σ\\n0ofΣobtained by\\nrestricting to sorts and operations in (i)–(ii) is called the arithmetic subsignature of Σ.\\nIn the syntactic deﬁnitions below, we freely take inspiration from [ 4], however the present\\nframework is greatly simpliﬁed because we do not view Proc as a subsort of Z, like in [ 4];\\nin addition, notice that Σdoes not contain operations or relation symbols speciﬁc to the sort\\nProc (apart from equality) - this restriction reduces terms of sort Proc to just variables.\\nBelow, besides integer variables (namely variables of sort Z),data variables (namely\\nvariables of sort Data )a n d index variables (namely variables of sort Proc ), we use\\ntwo other kinds of variables, that we call array-ids and matrix-ids . An array-id is a vari-\\nable of type Proc →Data or of type Proc → Zand a matrix-id is a variable of type\\nProc →(Proc →Data)or of type Proc →(Proc → Z). Array-ids and matrix-ids of', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Proc →(Proc →Data)or of type Proc →(Proc → Z). Array-ids and matrix-ids of\\ncodomain sort Zare called arithmetical array-ids or matrix-ids; if Data is enumerated,\\narray-ids and matrix-ids of codomain sort Data are called ﬁnitary .I fMis a matrix-id and\\ni,yare index variables, we may write Mi(y)orM(i,y)instead of M(i)(y).\\nLet us now introduce some useful classes of formulæ.\\n–Open formulæ : these are built up from atomic formulæ containing arithmetic parameters\\nand the above mentioned variables, using Boolean connectives only (no binders, i.e. noλ-abstractors and no quantiﬁers).\\n–1-Flat formulæ : these are formulæ of the kind φ(♯{x|ψ\\n1}/z1,...,♯ {x|ψn}/zn),\\nwhere φ(z1,..., zn), ψ 1,...,ψ nare open and xis a variable of type Proc .\\n– Given an index variable i, a formula φis said to be i-uniform with respect to a matrix-id', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='– Given an index variable i, a formula φis said to be i-uniform with respect to a matrix-id\\nM(resp. an array-id a)i f f iis not used as a bounded variable in φand the only terms\\noccurring in φcontaining an occurrence of M(resp. of a) are of the kind Mi(y)(resp.\\na(i)) for a variable y.\\nNotice that, some quantiﬁed formulæ can be rewritten as 1-ﬂat formulæ: for instance\\n∀x(a(x)=c→b(x)=d)is the same as ♯{x|a(x)=c→b(x)=d}=N,a n d\\nsimilarly ∃x(a(x)=c)can be re-written as ♯{x|a(x)=c}>0. Such rewriting however\\nis not possible for nested quantiﬁers: ∀i♯{x|a(x)=b(i)}>0 (semantically equivalent to\\n∀i∃xa(x)=b(i)) is not 1-ﬂat because it cannot be obtained by replacing terms of the kind\\n{x|ψj}(with open ψj) for free arithmetic variables inside an open formula φ.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='{x|ψj}(with open ψj) for free arithmetic variables inside an open formula φ.\\nRemark 2 1-Flat formulæ of this paper are slightly different from the ﬂat formulæ of [ 4,5]\\n(they roughly correspond to the ﬂat formulæ of degree 1 of [ 5]); the deﬁnition here is not\\nrecursive and is simpliﬁed by the fact that we do not have nonvariable terms of type Proc ;\\non the other hand, we allow matrix-ids to occur in our formulæ, whereas the syntax of [ 4,5]\\nis restricted to array-ids.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='432 S. Ghilardi, E. Pagani\\nRemark 3 In the applications, we typically use matrix-ids M(i,x)in the ﬁnitary case where\\nData is the set of Boolean truth values: M(i,x)asserts for instance that xsent a message\\nof a certain type to i. This allows to count the number of such messages received by ivia the\\nterm♯{x|M(i,x)}(according to our notational conventions, this is the term ♯{x|Mi(x)}).\\nThe deﬁnition of a i-uniform formula is meant precisely to make such terms available: they\\nare used in order to formalize standard benchmarks like the byzantine broadcast primitiveprotocol (see Appendix A.1 in the supplementary material).\\n3 Quantiﬁer Elimination\\nIn this technical section we state and prove the quantiﬁer elimination results we need. Letus ﬁx a constrained signature Σlike in Sect. 2.1. We ﬁrst investigate in a closer way our\\nopen formulæ. Notice ﬁrst that if an open formula is pure (i.e. it does not contain array-ids\\nor matrix-ids), then it is a Boolean combination of arithmetic, index or data atoms, where:', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='or matrix-ids), then it is a Boolean combination of arithmetic, index or data atoms, where:\\n– arithmetic atoms are built up from variables of sort Z, parameters (i.e free constants of\\nsort Z), by using =,< ,≡\\nnas predicates and +,−,0,1 as function symbols;\\n– index atoms are of the kind i=j,w h e r e i,jare variables of sort Proc (we do not\\nconsider further operations and predicates for this sort - apart from equality - in thispaper);\\n– data atoms are built up from variables of sort Data by applying some speciﬁc set of\\npredicates and operations (predicates include equality, all arguments of such predicatesand operations are of type Data ).\\nBy assumption (see Sect. 2.1), quantiﬁer elimination holds for ﬁrst-order Data -formulæ,\\nbut this result extends very easily to all pure ﬁrst-order formulæ. We state this formally as aLemma:\\nLemma 1 Any pure ﬁrst-order formula is equivalent to an open pure ﬁrst-order formula.\\nProof Using prenex formula transformations, it is sufﬁcient to show how to eliminate a', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Proof Using prenex formula transformations, it is sufﬁcient to show how to eliminate a\\nquantiﬁer ∃xα,w h e r e αis open and pure. Actually, using disjunctive normal forms, we can\\nassume that αis a conjunction of literals. Pushing the existential quantiﬁer inside, we can\\nassume that such literals are all arithmetic, all index or all data literals, depending on thesort of x. The case of arithmetic literals is covered by Presburger quantiﬁer elimination [ 49],\\nwhereas the case of data literals is covered by our assumption. It remains to consider thecase of index literals; excluding trivial cases where the existential quantiﬁer is redundant oreliminable by substitution, we are left with the case where αisx̸=y\\n1∧···∧ x̸=yn.B y\\nintroducing a disjunction of cases (and by distributing the existential quantiﬁer over suchdisjunction and removing redundant variables), we reduce to a disjunction of formulæ of thekind\\n∃x(x̸=y\\n1∧···∧ x̸=yn′∧⋀\\ni̸=jyi̸=yj)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='∃x(x̸=y\\n1∧···∧ x̸=yn′∧⋀\\ni̸=jyi̸=yj)\\nThe latter is equivalent to N>¯n′∧⋀\\ni̸=jyi̸=yj,w h e r e ¯n′is 1+···+ 1(n′-times). ⊓⊔\\nIn case array-ids and matrix-ids do not occur, 1-ﬂat formulæ can also be trivialized:4\\n4If the sort Proc is identiﬁed with a deﬁnable ﬁnite subset of Z, the result still holds but is much less trivial:\\nto get it, one must apply results from Presburger arithmetic with counting quantiﬁers [ 52].\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 433\\nLemma 2 A 1-ﬂat formula without array-ids and matrix-ids is equivalent to a pure formula.\\nProof Let us eliminate subterms tof the kind ♯{x|α}(with pure α) inside a pure formula φ.\\nWe can ﬁrst remove from αarithmetic and data atoms, as well as index atoms not containing\\nx, by the following equivalence (let Abe the atom to be removed):\\nφ↔([A∧φ(⊤/A)]∨[ ¬ A∧φ(⊥/A)]).\\nBy Venn regions decomposition, we can assume that αis a conjunction of literals: in fact,\\nif{α1,...,α k}is a Venn regions decomposition of α,t h e n ♯{x|α}is sematically equal to∑k\\nj=1♯{x|αj}. In addition, if tis of the kind ♯{x|x=i∧α}, we can remove it using the\\nequivalence:', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='j=1♯{x|αj}. In addition, if tis of the kind ♯{x|x=i∧α}, we can remove it using the\\nequivalence:\\nφ↔([α(i/x)∧φ(1/t)]∨[ ¬ α(i/x)∧φ(0/t)]).\\nThus we are left only with the case in which tis♯{x|⋀n\\ns=1x̸=is}; we can also assume\\nthatφentails⋀\\ns̸=s′is̸=is′(otherwise we can force this by making φa disjunction of case\\ndistinctions). Then we can remove tusing\\nφ↔(N≥¯n∧φ(N−¯n/t))∨(N<¯n∧φ(0/t)) .\\nOnce all tare removed (one by one), the statement is proved. ⊓⊔\\nIt is now convenient to introduce a notation for open (not necessarily pure) formulæ (from\\nnow on we shall reserve the letters α ,β,... to ﬁrst-order pure formulæ, to recognize them).', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='It is now convenient to introduce a notation for open (not necessarily pure) formulæ (from\\nnow on we shall reserve the letters α ,β,... to ﬁrst-order pure formulæ, to recognize them).\\nConsidering that there are no operation symbols of sort Proc , the only new terms that might\\narise in open non pure formulæ (wrt pure formulæ) are of the kind a(i)orMi(j),w h e r e ais\\nan array-id, Mis a matrix-id and i,jare variables of sort Proc . Thus we may write an open\\nformula φas the formula obtained by replacing in a pure formula some arithmetic variables\\nwith terms of the kind a(i)orMi(j). If our open φdoes not contain matrix-ids, we can write\\nit as\\nα(z,k,a(k)/e,d)or simply as α(z,k,a(k),d) (3)\\nwhere α(z,k,e,d)is pure, zis a tuple of arithmetic variables, kis a tuple of index variables,\\ndis a tuple of data variables, ais a tuple of array-ids (the emight be arithmetic or Data -', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='dis a tuple of data variables, ais a tuple of array-ids (the emight be arithmetic or Data -\\nvariables depending on the types of the a); if a=a1,..., anandk=k1,..., km,t h e n a(k)\\nis the tuple\\na1(k1) ,..., a1(km) ,..., an(k1) ,..., an(km)\\nso that the matching tuple of arithmetic or data variables ecan be indexed as e11,..., enm.\\nA 1-ﬂat formula without matrix-ids is then written as\\nα(z,k,a(k),d,♯{x|β1(z,x,k,a(x),a(k),d)},...,♯ {x|βs(z,x,k,a(x),a(k),d)})\\nor (with some abuse of notation) shortly as\\nα(z,k,a(k),d,♯{x|β(z,x,k,a(x),a(k),d)}) (4)\\nwhere βis a tuple of formulæ (we use the convention that ♯{x|β}stands for the tuple of', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='where βis a tuple of formulæ (we use the convention that ♯{x|β}stands for the tuple of\\nterms♯{x|β1},...,♯ {x|βs}).\\nDisplaying 1-ﬂat formulæ with matrix-ids requires an even more complex notation, that\\nwe will not use though. These notations are apparently cumbersome but have the merit ofdisplaying the essential information on how our formulæ are built up from pure formulæ.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='434 S. Ghilardi, E. Pagani\\nLemma 3 Ifφis an open formula and d′are arithmetic and data variables, then ∃d′φis\\nequivalent to an open formula.\\nProof Letφbeα(z,k,a(k),d)\\nas in ( 3)a n dl e t d′be data variables.5Suppose that d=d′d′′;t h e n ∃d′α(z,k,e,d),b y\\nLemma 1, is equivalent to a pure formula β(z,k,e,d′′),s ot h a t ,\\napplying a substitution, ∃d′α(z,k,a(k)/e,d)is equivalent to β(z,k,a(k)/e,d′′),w h i c h\\nis as desired. The case in which dare arithmetic variables is treated similarly. ⊓⊔\\nWe now state a ﬁrst quantiﬁer elimination result (this is essentially Theorem 4 from [ 5],\\nwe nevertheless report the proof for the sake of completeness):\\nTheorem 1 Suppose that φis a 1-ﬂat formula containing the array ids a,a′(and not con-', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='we nevertheless report the proof for the sake of completeness):\\nTheorem 1 Suppose that φis a 1-ﬂat formula containing the array ids a,a′(and not con-\\ntaining matrix-ids); then the formula ∃a′φis equivalent to a formula ∃eψ,w h e r et h ee are\\narithmetic and data variables, ψis 1-ﬂat and contains only the array-ids a.\\nProof We start with a formula having the form\\n∃a′α(z,k,a(k),a′(k),d,♯{x|β(z,x,k,a(x),a′(x),a(k),a′(k),d)}) (5)\\nwhere kare index variables, zarithmetic variables and ddata variables. We can ﬁrst get\\nrid of the terms a(k),a′(k), as follows. Suppose that a=a1,..., an,a′=a′\\n1,..., a′\\nn′and\\nk=k1,..., km; we introduce new variables\\ne=e11,..., enm,e′\\n11,..., e′\\nn′m\\nand rewrite ( 5)a s\\n∃e.⋀', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='e=e11,..., enm,e′\\n11,..., e′\\nn′m\\nand rewrite ( 5)a s\\n∃e.⋀\\ni,jai(kj)=eij∧∃ a′⎛\\n⎜⎝⋀\\ni,j♯{x|x=ki∧a′\\nj(x)=e′\\nij}=1∧\\n∧α(z,k,e,d,♯{x|β(z,x,k,a(x),a′(x),e,d)})⎞\\n⎟⎠\\nThus it will be sufﬁcient to eliminate the ∃a′from formulæ of the kind\\n∃a′γ0(z,k,d′,♯{x|β(z,x,k,a(x),a′(x),d′)}) (6)\\n(here the d′include the old dand the e- the latter are existentially quantiﬁed and will remain\\nsuch in the ﬁnal outcome).\\nIf we suppose that βisβ1,...,β t, we can set K:=℘({1,..., t})and introduce for every', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='such in the ﬁnal outcome).\\nIf we suppose that βisβ1,...,β t, we can set K:=℘({1,..., t})and introduce for every\\nr∈Ka new existentially quantiﬁed arithmetic variable ur, thus rewriting ( 6)a s\\n∃u,a′.⋀\\nrur=♯{x|βr(z,x,k,a(x),a′(x),d′)}∧γ(z,k,d′,u) (7)\\nwhere uis the tuple formed by the ur’s (varying r)a n dβris the ‘Venn region’⋀\\nl∈rβl∧⋀\\nl/∈r¬βl; the formula γis obtained from γ0by replacing, for all l,t h et e r m ♯{x|βl}with∑\\nl∈rur. Notice that at this point γis pure and the new βr’s are a partition (i.e. they are\\nmutually inconsistent and⋁\\nrβris valid).\\nTo continue, following the technique in [ 4], we need a further ‘Venn region decomposition’', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='mutually inconsistent and⋁\\nrβris valid).\\nTo continue, following the technique in [ 4], we need a further ‘Venn region decomposition’\\nδS.F o re v e r y S∈℘(K)letδS(z,x,k,a(x),d′)be the pure formula\\n⋀\\nr∈S∃yβr(z,x,k,a(x),y,d′)∧⋀\\nr/∈S¬∃yβr(z,x,k,a(x),y,d′)\\n5In (3), there are no matrix-ids; if there were also matrix-ids, then the argument would be the same (we do\\nnot insist, because we shall need the lemma only for formulæ without matrix-ids).\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 435\\n(here data quantiﬁers ∃ycan be eliminated using Lemma 3). We claim that the formula ( 7)\\nis equivalent to the formula obtained by preﬁxing the existential quantiﬁers ∃ur(varying\\nr∈K),∃uS(varying S∈℘(K))a n d\\n∃ur,S(varying S∈℘(K)andr∈K) to the formula\\n⋀\\nS∈℘(K)uS=♯{x|δS(z,x,k,a(x),d′)}∧⋀\\nS∈℘(K)(\\nuS=∑\\nr∈Sur,S)\\n∧\\n∧⋀\\nr∈K⎛\\n⎝ur=∑\\nS∈℘(K),r∈Sur,S⎞\\n⎠∧⋀\\nr∈S∈℘(K)ur,S≥0∧γ(z,k,d′,u)(8)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='⎠∧⋀\\nr∈S∈℘(K)ur,S≥0∧γ(z,k,d′,u)(8)\\nSuppose that (8)is satisﬁed under the assignment Ito the free variables occurring in it\\n(for simplicity, we use the same name for a free variable and for the integer assigned to it by\\nI). Let us assume that Proc is interpreted (up to a ﬁnite sets bijection) as the interval [0,N);\\nwe need to deﬁne for all i∈[0,N)the tuple a′(i)- namely a′\\ns(i),f o ra l l s=1,..., n′.F o r\\nevery r=1,..., Kthis must be done in such a way that there are exactly urelements taken\\nfrom[0,N)satisfying βr(z,x,k,a(x),a′(x),d′). The interval [0,N)can be partioned by\\nassociating with each i∈[0,N)the set iS={r∈K|∃yβr(z,i,k,a(i),y,d′)holds under', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='associating with each i∈[0,N)the set iS={r∈K|∃yβr(z,i,k,a(i),y,d′)holds under\\nI}. From the fact that ( 8) is true, we know that for every S∈℘(K)the number of the i’s such\\nthatiS=SisuS;f o re v e r y r∈S,p i c k ur,Samong them and, for these selected i,l e tt h e s-tuple\\na′(i)be equal to an s-tuple ysuch that βr(z,i,k,a(i),y,d′)holds (for this tuple y, since the\\nβr’s are a partition, βh(z,i,k,a(i),y,d′)does not hold, if h̸=r). Since uS=∑\\nr∈Sur,Sand\\nsince∑\\nSuSis equal to N(because the formulæ⋀\\nr∈S∃yβr∧⋀\\nr/∈S∀y¬βrare a partition),', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='SuSis equal to N(because the formulæ⋀\\nr∈S∃yβr∧⋀\\nr/∈S∀y¬βrare a partition),\\nthe deﬁnition of the a′is complete. The formula ( 7) is true by construction.\\nOn the other hand suppose that the matrix of (7)is satisﬁable under an assignment I;\\nwe need to ﬁnd I(uS),I(ur,S)(we again indicate them simply as uS,ur,S)s ot h a t( 8)i s\\ntrue (the urare already given since ( 7)i st r u e ) .F o r uSthere is no choice, since uS=♯{x|\\nδS(z,x,k,a(x),d′)}must hold; for ur,S, we take it to be the cardinality of the set of the isuch\\nthatβr(z,i,k,a(i),a′(i),d′)holds under Iand S={h∈K|∃yβh(z,i,k,a(i),y,d′)\\nholds under I}. In this way, for every S, the equality uS=∑', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='holds under I}. In this way, for every S, the equality uS=∑\\nr∈Sur,Sholds and for every\\nr, the equality ur=∑\\nS∈℘(K),r∈Sur,Sholds too. Thus the formula ( 8) becomes true under\\nour extended I. ⊓⊔\\nThe following Corollary follows from Theorem 1and Lemmas 2,1:\\nCorollary 1 Suppose that φis a 1-ﬂat formula containing the array ids a(and not containing\\nmatrix-ids); then the formula ∃aφis equivalent to an open pure formula.\\nNotice that the above result (as it happens with all our quantiﬁer elimination results) imme-\\ndiately implies that 1-ﬂat formulæ not containing matrix-ids are decidable for satisﬁability.\\nIf the sort Data is enumerated and all array-ids are ﬁnitary, we can improve Corollary 1\\nabove by including an extra quantiﬁed variable, as shown in the following Theorem (theTheorem is useful for some benchmarks, see Appendix A in the supplementary material foran example):\\nTheorem 2 Let the sort Data be enumerated and let the 1-ﬂat formula φcontain only the', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Theorem 2 Let the sort Data be enumerated and let the 1-ﬂat formula φcontain only the\\nﬁnitary array ids a(and no matrix-ids); then the formula\\n∃a∀i∃y\\nφ (9)\\n(where i is an index variable and the y are arithmetic and data variables) is equivalent to\\nan open pure formula.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='436 S. Ghilardi, E. Pagani\\nProof LetData be enumerated as {a0,..., ak};l e t zbe the arithmetic variables occurring\\nfreely in ( 9)a n dl e t k=k1,..., knbe the index variables occurring freely in ( 9) (thus iis\\nnot among the kand the yare not among the z). We can assume that the yare arithmetic\\nvariables because, since Data is enumerated, existential data variables can be elimitated via\\ndisjunctions. For simplicity, we assume that ( 9) contains only one array-id, let it be a.6\\nBefore working on the formula ( 9), it is better to make some preprocessing steps. Our ﬁnal\\naim is to produce a formula logically equivalent to ( 9), which is a disjunction of existentially\\nquantiﬁed formulæ whose matrices are pure open formulæ: in this way the extra existentiallyquantiﬁed variables we introduce can be eliminated in the very end using Lemma 1.W en e e d\\nalso to introduce extra information to complete ( 9): this extra information is achieved by\\nrewriting ( 9) as a disjunction (each disjunct formalizes a suitable guess) and by operating on\\neach disjunct separately.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='rewriting ( 9) as a disjunction (each disjunct formalizes a suitable guess) and by operating on\\neach disjunct separately.\\nConcretely, we shall freely assume that ∀i∃y\\nφin (9) is of the kind\\nDiff(k)∧⋀\\ni(a(ki)=ali)∧⋀\\nj(uj=♯{x|a(x)=aj})∧\\n∧∀i∃yφ′(z,y,i,k,a(i), ♯{x|β(z,y,x,i,k,a(x),a(i))})(10)\\nwhere\\n•the formula Diff(k)says that the kare pairwise distinct (i.e. it is⋀\\ni̸=jki̸=kj): this\\ncan be assumed without loss of generality, because one can guess a partition (introducinga disjunction over all partitions) and make the appropriate replacements so as to keeponly one representative for each equivalence class of variables;\\n•since Data is enumerated we can guess (via a disjunction) for each k\\nithealiwhich is\\nthe value of a(ki)(then, all occurrences of the term in the remaining part of the formula', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='•since Data is enumerated we can guess (via a disjunction) for each k\\nithealiwhich is\\nthe value of a(ki)(then, all occurrences of the term in the remaining part of the formula\\ncan be replaced by this ali);\\n•theujare fresh arithmetic variables indicating the cardinality of the set of indices whose\\na-value is aj(these ujare the extra existentially quantiﬁed variables to be eliminated in\\nthe very end by Lemma 1);\\n•βare open formulæ as displayed and φ′is a 1-ﬂat formula as displayed (notice that\\nthe terms a(ki)do not occur anymore here, because we can assume that they have been\\nreplaced by the corresponding ali).\\nWe now operate further transformations on the subformula ∀i∃yφ′:w ew a n tt os h o w\\nthat this formula is equivalent to a 1-ﬂat formula (hence without the quantiﬁer ∀i), so that\\nthe claim of the Theorem follows from an application of Corollary 1and Lemma 1-b y\\nthese results in fact all quantiﬁed variables in ( 9) can be eliminated in favor of a pure open', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='the claim of the Theorem follows from an application of Corollary 1and Lemma 1-b y\\nthese results in fact all quantiﬁed variables in ( 9) can be eliminated in favor of a pure open\\nformula in which only the k,zoccur. When manipulating ∀i∃yφ′below, we assume all the\\ninformation we have from ( 10), namely that the kare all distinct and that the values of the\\na(ki)are known.\\nAs a ﬁrst step, we can distinguish the case in which iis equal to some of the kfrom the\\ncase in which it is different from all of them; in the latter case, we can also guess the valueofa(i). This observation shows that ∀iφ\\n′is equal to the conjunction of an open formula\\n(expressing what happens if iis equal to any of the k) with the conjunctions (varying ajin\\nour enumerated data)\\n∀i.Diff(i,k)∧a(i)=aj→∃ yφ′′(z,y,i,k,♯{x|β′(z,y,x,i,k,a(x))}) (11)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='6This is without loss of generality: since Data is enumerated and the aare ﬁnitary, one may take a product\\nofData and replace the tuple awith a single array with values in such a product.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 437\\nwhere the φ′′,β′are obtained from the φ′,βby replacing a(i)withaj. Again, it will be\\nsufﬁcient to show that ( 11) is equivalent to an open formula.\\nFirst observe that φ′′is obtained from a pure formula by replacing arithmetic variables\\nwith the terms ♯{x|β′(z,y,x,i,k,a(x))}; since equality is the only predicate of sort Proc\\n(and there are no function symbols of sort Proc ), the only atoms of sort Proc that might\\noccur in a pure formula are of the kind i=ks,ks=ks′for some s̸=s′, but these can all be\\nreplaced by ⊥because we have Diff(i,k)in the antecedent of the implication of ( 11). As\\na consequence φ′′can be displayed as φ′′(z,y,♯{x|β′(z,x,i,k,a(x))}).\\nA similar observation applies also to the β′, however here we must take into consideration\\nalso atoms of the kind x=i,x=ks. Thus, the β′are built up using Boolean connectives', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='A similar observation applies also to the β′, however here we must take into consideration\\nalso atoms of the kind x=i,x=ks. Thus, the β′are built up using Boolean connectives\\nfrom atoms of the kind x=i,x=ks, from arithmetic atoms A(z,y)and from Data -atoms\\nthat might contain the term a(x). We can disregard arithmetic atoms, because for each such\\natoms A(z,y)we may rewrite φ′′as\\n[A(z,y)∧φ′′(z,y,♯{x|β′(⊤/A)})]∨[ ¬ A(z,y)∧φ′′(z,y,♯{x|β′(⊥/A)})].(12)\\nThus the β′can be displayed as β′(x,i,k,a(x)).\\nWhen x=iorx=ks(for some s)t h eβ′can be simpliﬁed to ⊤or⊥because we know\\nthe values of a(i),a(ks)(and as a consequence the numbers ♯{x|x=i∧β′},♯{x|x=', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='the values of a(i),a(ks)(and as a consequence the numbers ♯{x|x=i∧β′},♯{x|x=\\nks∧β′}are 0/1-tuples). In conclusion we have that, for some tuple of numbers m7that can\\nbe computed, we have that ( 11) is equivalent to\\n∀i.Diff(i,k)∧a(i)=aj→∃ yφ′′(z,y,¯m+♯{x|Diff(x,i,k)∧β′′(a(x))})(13)\\nwhere β′′is obtained from β′by replacing the atoms x=i,x=kswith⊥. Fix now some\\nβ′′\\nsfrom the tuple β′′; for every enumerated data ak, each of the formulæ β′′\\ns(ak)simplify to\\neither ⊤or⊥and, since we know that uk=♯{x|a(x)=ak}from ( 10), we can deduce that\\n♯{x|Diff(x,i,k)∧a(x)=ak∧β′′\\ns(ak)}is equal to either 0 (in case β′′', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='♯{x|Diff(x,i,k)∧a(x)=ak∧β′′\\ns(ak)}is equal to either 0 (in case β′′\\ns(ak)simpliﬁes\\nto⊥)o rt o uk−nk,w h e r e nkis the number of the k,ifor which we know that a(k),a(i)\\nis equal to ak. As a consequence ♯{x|Diff(x,i,k)∧β′′(a(x))}is equal to∑\\nk(uk−nk)\\n(where the sum extends to all ksuch that β′′\\ns(ak)simpliﬁes to ⊤).\\nAll this can be summarized by saying that we can rewrite ( 13)a s\\n∀i.Diff(i,k)∧a(i)=aj→∃ yθj(y,z,u) (14)\\nwhere the formulæ θjare pure (the tuple uis the tuple of the ujfrom ( 10)). By Presburger\\nquantiﬁer elimination, we can drop the ∃y, thus getting\\n∀i.Diff(i,k)∧a(i)=aj→θ′', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='quantiﬁer elimination, we can drop the ∃y, thus getting\\n∀i.Diff(i,k)∧a(i)=aj→θ′\\nj(z,u) (15)\\nSince now θ′\\njdoes not contain occurrences of i, we can rewrite this as\\n∃i(Diff(i,k)∧a(i)=aj)→θ′\\nj(z,u) (16)\\nand ﬁnally as\\n♯{x|Diff(x,k)∧a(x)=aj}>0→θ′\\nj(z,u) (17)\\nThis is a 1-ﬂat formula. To sum up, our original formula ( 9) is equivalent to a formula of\\nthe kind ∃a∃uϑ,w h e r e ϑis 1-ﬂat. Then (after swapping the quantiﬁers ∃a∃u) we can ﬁrst\\nuse Theorem 1to remove ∃aand then Lemma 1to produce an equivalent pure open formula\\n(involving just the arithmetic variables zand the index variables k). ⊓⊔', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='use Theorem 1to remove ∃aand then Lemma 1to produce an equivalent pure open formula\\n(involving just the arithmetic variables zand the index variables k). ⊓⊔\\n7This tuple depends on j,i . e .o nt h e ajused in the antecedent of ( 11) (we do not indicate this dependency\\nfor simplicity).\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='438 S. Ghilardi, E. Pagani\\nIn case we have uniformity, we can further extend the above result to cover formulæ in\\nwhich arithmetic array-ids and matrix-ids occur.\\nRemark 4 Let us continue the considerations we made in Remark 3.W es a wt h e r et h a t ,\\nwhen building i-uniform (also 1-ﬂat) formulae, we can employ terms counting the messages\\nreceived by a process i. Suppose that in our protocol we want to say for instance that all\\nprocesses ihaving received enough messages (e.g. messages from some qualiﬁed majority\\nof the network) are allowed to change their status into some ‘accepting’ status: to express this,we need a formula of the kind ∀iφ,w h e r e φisi-uniform 1-ﬂat (this is the case for instance\\nof the examples of Appendix A in the supplementary material). Next Theorem guaranteesthat we can indeed eliminate the higher order quantiﬁers over array-ids and matrix-ids from(a slight generalized set of) such formulae.\\nTheorem 3 Let the sort Data be enumerated and let i be an index variable; suppose that', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Theorem 3 Let the sort Data be enumerated and let i be an index variable; suppose that\\nall matrix-ids Moccurring in the 1-ﬂat formula φare i-uniform and that all array-ids a\\noccurring in φare either ﬁnitary or i-uniform. Then the formula\\n∃a∃M∀i∃y\\nφ (18)\\n(where the y are arithmetic and data variables) is equivalent to an open pure formula.\\nProof T h eﬁ r s ts t e pi st or e m o v e ∃Mfor each M∈M, using uniformity. In fact, by uniformity,\\nMoccurs in φonly inside terms of the kind Mi(y)(for some index variable y); thus, applying\\na reverse skolemization step, we can rewrite ( 18)a s\\n∃a∀i∃b∃yφ(···b/Mi···) (19)\\n(here the bare existentially quantiﬁed array-ids: formula ( 18) is the skolemization of ( 19)).\\nThen we swap the existential quantiﬁers ∃b∃yand apply Theorem 1to the subformula', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Then we swap the existential quantiﬁers ∃b∃yand apply Theorem 1to the subformula\\n∃bφ(···b/Mi···), thus obtaining a formula of the kind ∃a∀i∃y∃eψwhere the eare\\nfurther arithmetic or data variables, ψis 1-ﬂat and contains only the array-id a.L e tu s\\nnow split the aasa′,a′′,w h e r et h e a′′arei-uniform and the a′are ﬁnitary (notice that\\nthe syntactic transformations of Theorem 1maintain the i-uniformity of the a′′). We can\\napply the same anti-skolemization argument to the a′′and rewrite ∃a′a′′∀i∃y∃eψas\\n∃a′∀i∃z∃y∃eψ(z/a′′(i)),w h e r et h e zare fresh arithmetic variables replacing the terms\\na′′(i)inψ.N o wT h e o r e m 2can be used to eliminate the a′. ⊓⊔\\n4 System Speciﬁcations and Simulations', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='a′′(i)inψ.N o wT h e o r e m 2can be used to eliminate the a′. ⊓⊔\\n4 System Speciﬁcations and Simulations\\nWe now turn to veriﬁcation applications. The behavior of a system can be modeled through\\natransition system , which is a tuple\\nT=(W,W0,R,AP,V)\\nsuch that (i) Wis the set of possible conﬁgurations, (ii) W0⊆Wis the set of initial conﬁgu-\\nrations, (iii) APis a set of ‘atomic propositions’, (iv) V:W−→ APis a function labeling\\neach state with the set of propositions ‘true in it’, (v) R⊆W×Wis the transition relation:\\nw1Rw2describes how the system can ‘evolve in one step’.\\nDeﬁnition 1 We say that the transition system T′=(W′,W′\\n0,R′,AP,V′)simulates the\\ntransition system T=(W,W0,R,AP,V)(notice that APis the same in the two systems)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='0,R′,AP,V′)simulates the\\ntransition system T=(W,W0,R,AP,V)(notice that APis the same in the two systems)\\niff there is a relation ρ⊆W×W′(called simulation ) such that\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 439\\n(i) for all w∈Wthere is w′∈W′such that wρw′;\\n(ii) if wρw′andw∈W0,t h e nw′∈W′\\n0;\\n(iii) if wρw′andwRv, then there is v′∈W′such that w′R′v′andvρv′;\\n(iv) if wρw′,t h e n V(w)=V′(w′);\\nIf the converse ρopofρis also a simulation, then ρis said to be a bisimulation and T′and\\nTare said to be bisimilar .\\nBisimilar systems are equivalent in the sense that the properties expressible in common\\ntemporal logic speciﬁcations (e.g. in CTL,LTL,CTL∗, etc.) are invariant under bisim-\\nulations; simulation is also useful as important properties (like safety properties, or moregenerally properties expressible in sublogics like ACT L ) can be transferred from a system\\nto the systems simulated by it (but not vice versa).\\nWe write', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='to the systems simulated by it (but not vice versa).\\nWe write\\nT≤T′iffW⊆W′and the inclusion is a simulation. This relation is a partial\\norder and notice that if T′simulates Tand T′≤T′′,t h e n T′′also simulates T; in this case,\\nthe simulation supplied by T′is said to be stronger orbetter (in fact, one has more chances\\nof establishing an ACT L -property of Tby using T′than by using T′′).\\nThe above formalism of transition systems is often too poor, because it cannot cover rich\\nfeatures arising in concrete applications. That is why we need higher order logic, namelyconstrained signatures as introduced in Sect. 2. Constrained signatures are used for our system\\nspeciﬁcations as follows:\\nDeﬁnition 2 Asystem speciﬁcation\\nSis a tuple\\nS=(Σ, v,Φ,ι,τ, AP)\\nwhere (i) Σis a constrained signature, (ii) vis a tuple of variables, (iii) Φ,ι are v-formulæ\\nand APis a set of v-formulæ, (iv) τis a(v,v′)-formula (here the v′are renamed copies of\\nthe v) such that', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='and APis a set of v-formulæ, (iv) τis a(v,v′)-formula (here the v′are renamed copies of\\nthe v) such that\\nι(v)|/equal1ΣΦ(v), Φ( v)∧τ(v,v′)|/equal1ΣΦ(v′). (20)\\nIn the above deﬁnition, the vare meant to be the variables specifying the system status,\\nιis meant to describe initial states, τis meant to describe the transition relation and the\\nAPare the ‘observable propositions’ we are interested in. The v-formula Φ, as it is evident\\nfrom ( 20), describes an invariant of the system (known to the user). Of course, since in our\\nexpressive type theory higher order quantiﬁers are available, it would be easy to write downthe ‘best possible’ invariant describing in a precise way the set of reachable states; however,the v-formula for such invariant might involve logical constructors lying outside the tractable\\nfragments we plan to use. On the other hand, invariants are quite useful - and often essential- in concrete veriﬁcation tasks, that is why we included them in Deﬁnition 2.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='fragments we plan to use. On the other hand, invariants are quite useful - and often essential- in concrete veriﬁcation tasks, that is why we included them in Deﬁnition 2.\\nIt is now clear how to associate a transition system with any system speciﬁcation:\\nDeﬁnition 3 The transition system associated with the system speciﬁcation\\nS=(Σ, v,\\nΦ,ι,τ, AP)is the transition system TSgiven by\\n(WS,WS\\n0,RS,APS,VS)\\nwhere: (i) the set of states WSis the set of the tuples vM,Isatisfying Φ(v), varying M,I\\namong the Σ-models and Σ-interpretations of v; (ii) WS\\n0is the set of states satisfying ι(v);\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='440 S. Ghilardi, E. Pagani\\n(iii) RScontains the couples of states vM,I,v′\\nM,I′8satisfying τ(v,v′);( i v ) APSisAP;\\n(v) for φ(v)∈APS,w eh a v et h a t V(φ)contains precisely the states satisfying φ(v).\\n4.1 Simulations\\nModel-checking a transition system like TSmight be a terribly difﬁcult task, that is why it\\nmight be useful to replace it with a (bi)similar, simpler system: in our applications, we shalltry to replace\\nSby some S′whose variables are all integer variables. To this aim, we ‘project’\\nSonto a subsystem S′, i.e. onto a system comprising only some of the variables of S.\\nIn order to give a precise deﬁnition of what we have in mind, we must ﬁrst consider\\nsubsignatures: here a subsignature Σ0ofΣis a signature obtained from Σby dropping\\nsome symbols of Σand taking as Σ0-models the class CΣ0of the restrictions M|Σ0to the\\nΣ0-symbols of the structures M∈CΣ.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='some symbols of Σand taking as Σ0-models the class CΣ0of the restrictions M|Σ0to the\\nΣ0-symbols of the structures M∈CΣ.\\nDeﬁnition 4 Let S=(Σ, v,Φ,ι,τ, AP)be a system speciﬁcation; a sub-system speciﬁca-\\ntion of it is a system speciﬁcation S0=(Σ0,v0,Φ0,ι0,τ0,AP0)where Σ0is a subsignature\\nofΣ,v0⊆v,AP0=APand we have\\nΦ(v)|/equal1ΣΦ0(v0), ι( v)|/equal1ι0(v0), Φ( v)∧τ(v,v′)|/equal1τ0(v0,v′\\n0) (21)\\nThe following fact is immediate:\\nProposition 1 Let S0be a sub-system speciﬁcation of Slike in Deﬁnition 4; then the map\\nπS0associating', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='The following fact is immediate:\\nProposition 1 Let S0be a sub-system speciﬁcation of Slike in Deﬁnition 4; then the map\\nπS0associating\\n(v)M|Σ0,I|v0tovM,Iis a simulation of TSbyTS0(called a projection simulation over\\nΣ0,v0).\\nProjection simulations are ordered according to the ordering of the simulations of Sthey\\nproduce, i.e. we say that S0isstronger orbetter than S′\\n0iffTS0≤TS′\\n0.O n c e Σ0,v0are\\nﬁxed, one may wonder whether there exists the best projection simulation over Σ0,v0.T h e\\nfollowing easy result supplies a (practically useful) sufﬁcient condition:\\nProposition 2 Let S=(Σ, v,Φ,ι,τ, AP)be a system speciﬁcation, let Σ0be a sub-\\nsignature of Σand let v0⊆ vbeΣ0-variables. Suppose that there exist Σ0-formulæ\\nΦ0(v0), ι0(v0), τ0(v0,v′', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Φ0(v0), ι0(v0), τ0(v0,v′\\n0)such that (let v:=v0,v1):\\n(i)|/equal1ΣΦ0(v0)↔∃ v1Φ(v0,v1);\\n(ii)|/equal1Σι0(v0)↔∃ v1ι(v0,v1);\\n(iii)|/equal1Στ0(v0,v′\\n0)↔∃ v1∃v′\\n1(Φ( v0,v1)∧τ(v0,v1,v′\\n0,v′\\n1)).\\nIf we let S0be the subsystem speciﬁcation (Σ0,v0,Φ0,ι0,τ0,AP), then the projection sim-\\nulation πS0is the best projection simulation over Σ0,v0.\\nProof That S0=(Σ0,v0,Φ0,ι0,τ0,AP)is a subsystem speciﬁcation of Sis clear; let us\\nnow pick another subsystem speciﬁcation S′=(Σ0,v0,Φ′,ι′,τ′,AP)ofSinducing a', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='now pick another subsystem speciﬁcation S′=(Σ0,v0,Φ′,ι′,τ′,AP)ofSinducing a\\nprojection simulation over the same subsignature Σ0and the same sub-tuple of variables v0.\\nA c c o r d i n gt o( 21), we have\\nΦ(v)|/equal1ΣΦ′(v0), ι( v)|/equal1ι′(v0), Φ( v)∧τ(v,v′)|/equal1τ′(v0,v′\\n0)\\n8Notice that Mis the same in vM,Iand in v′\\nM,I′. In principle, WSmight be a proper class, but if one\\nwants to avoid this, it is sufﬁcient to ask for the set of models CΣof the constrained signature Σto be a set,\\nnot a proper class.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 441\\nthat is\\nΦ0(v0)|/equal1ΣΦ′(v0), ι 0(v0)|/equal1ι′(v0), τ 0(v,v′)|/equal1τ′(v0,v′\\n0)\\nwhich guarantees that TS0≤TS′\\n0. ⊓⊔\\nTo understand the meaning of the above proposition, one should keep in mind that there\\nis no reason why the Σ-formulæ ∃v1Φ,∃v1ιand∃v1∃v′\\n1(Φ∧τ)should be equivalent to\\nΣ0-formulæ (in our applications, Σ0contains only the sort and the symbols of linear ﬁrst-\\norder arithmetic, so no higher-order variables are allowed in Σ0-formulæ). Thus, the road\\nmap to apply Proposition 2is to prove some quantiﬁer-elimination results in order to ﬁnd\\nΣ0-formulæ equivalent to ∃v1Φ,∃v1ι,∃v1∃v′\\n1(Φ∧τ).', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Σ0-formulæ equivalent to ∃v1Φ,∃v1ι,∃v1∃v′\\n1(Φ∧τ).\\nSuch quantiﬁer elimination results will supply the best possible projected simulation onto\\nthe set of the selected variables, as informally mentioned in the toy example of Sect. 1.2.\\n4.2 Bisimulations\\nFor the sake of completeness, we make a little digression on bisimulations (in fact, in some\\nlucky cases, the best projection simulation is also a bisimulation). The content of this digres-sion will not be used in the rest of the paper.\\nFor considerations involving bisimulations, it is useful to consider special kinds of sub-\\nsignatures, those whose models are quite close to the models of the original signature:\\nwe say that Σ\\n0is acore subsignature iff every Σ0-model is the restriction of a unique (up\\nto isomorphism) Σ-model. As a typical example (used in our applications) of this situation,\\nconsider a signature Σcontaining the sorts Z,Ω(with the usual operations), some enumer-\\nated sorts, and a ﬁnite sort Proc whose cardinality is constrained by a parameter N(we do', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='consider a signature Σcontaining the sorts Z,Ω(with the usual operations), some enumer-\\nated sorts, and a ﬁnite sort Proc whose cardinality is constrained by a parameter N(we do\\nnot have operations on Proc , just the cardinality function ♯on℘(Proc)). Suppose that now\\nwe consider the subsignature Σ0containing just ZandΩ(with inherited operations) and the\\nparameter N: this is evidently a core subsignature, because the interpretation of enumerated\\nsorts and of the sort Proc is uniquely determined—up to isomorphism—by the Σ0-reduct.\\nProposition 3 Let S0be a core sub-system speciﬁcation of S(Sand S0are as displayed in\\nDeﬁnition 4) and let v:=v0,v1.T h e n πS0is a bisimulation iff the following conditions\\n(i)|/equal1ΣΦ0(v0)↔∃ v1Φ(v0,v1);\\n(ii)′ι0(v0)|/equal1Σ∀v1(Φ( v0,v1)→ι(v0,v1));', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='(ii)′ι0(v0)|/equal1Σ∀v1(Φ( v0,v1)→ι(v0,v1));\\n(iii)′Φ0(v0)∧τ0(v0,v′\\n0)|/equal1Σ∀˜v1(Φ( v0,˜v1)→∃ v′\\n1τ(v0,˜v1,v′\\n0,v′\\n1))\\nare satisﬁed.\\nProof We need to show that assuming the four conditions of Deﬁnition 1for both πS0and\\nits converse relation is the same as assuming the three conditions above. First notice thatcondition (iv) of Deﬁnition 1is trivially satisﬁed (both for π\\nS0and its converse relation)\\nbecause the formulæ in APare v0-formulæ in the signature Σ0according to the deﬁnition\\nof a subsystem speciﬁcation (Deﬁnition 4). Similarly, conditions (i)–(iii) of Deﬁnition 1are\\nalso guaranteed for πS0by Deﬁnition 4, so that such conditions are relevant only for the', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='also guaranteed for πS0by Deﬁnition 4, so that such conditions are relevant only for the\\nconverse of πS0.\\nSince S0is a core sub-system speciﬁcation of S,a s k i n gt h a t“ e v e r y (v0)M0,I0satisfying\\nΦ0comes (by restriction to Σ0,v0) from some (v)M,Isatisfying Φ”9is the same as asking\\n9This is the relevant content of condition (i) of Deﬁnition 1in our case, where the simulation relation is the\\nconverse of the projection function πS0.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='442 S. Ghilardi, E. Pagani\\ncondition (i) above: the only possible candidate for Mis the unique extension of M0toΣ,\\nhence the above statement under quotation marks holds just in case Φ0(v0)↔∃ v1Φ(v0,v1)\\nis valid in all Σ-models.\\nSimilarly, it is now evident that condition (ii) of Deﬁnition 1for the converse of πS0is\\nthe same as condition (ii)′above and condition (iii) of Deﬁnition 1for the converse of πS0is\\nthe same as condition (iii)′above. ⊓⊔\\nNotice that condition (i) is the same in Proposition 2and in Proposition 3. Moreover, using\\nsuch condition (i) (and the fact that ι0(v0)|/equal1Σ0Φ0(v0), see Deﬁnition 2) it is not difﬁcult\\nto see that condition (ii)′of Proposition 3is stronger than the corresponding condition (ii) of\\nProposition 2; the same observation applies also to conditions (iii)′and (iii) in case we make\\nthe additional mild and obvious assumption that τ0(v0,v′', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Proposition 2; the same observation applies also to conditions (iii)′and (iii) in case we make\\nthe additional mild and obvious assumption that τ0(v0,v′\\n0)|/equal1ΣΦ0(v0).\\n4.3 Arithmetic Projections\\nLet now S=(Σ, v,Φ,ι,τ, AP)be a system speciﬁcation based on a signature Σas\\ndiscussed in Sect. 4.1.T h ev a r i a b l e s vofSinclude some integer variables v0and in addition\\nvariables for arrays and matrices. If ais an array variable, then a(y)represents a local status\\nof the process y;i fMis a matrix variable, then Mi(y)represents the content of a message\\nreceived by ifrom y(or, in other words, sent by ytoi).10Let us suppose that v=v0v1,\\nwhere v1is the tuple of array and matrix variables and the v0are all the integer variables\\nof the system. We suppose also that the formulæ in AP—namely the formulæ expressing\\nobservable properties—are all open v0-formulæ (in particular, they are all Σ0-formulæ, where', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='observable properties—are all open v0-formulæ (in particular, they are all Σ0-formulæ, where\\nΣ0is the arithmetic subsignature of Σ).\\nLet S=(Σ, v0v1,Φ,ι,τ, AP)be as above; a subsystem speciﬁcation of the kind S0=\\n(Σ0,v0,Φ0,ι0,τ0,AP)is called a counter abstraction ofS; as usual, counter abstractions\\nare ordered according to the ordering of the simulations of Sthey produce, i.e. we say that\\nS0is stronger than S′\\n0iffTS0≤TS′\\n0. We are interested in sufﬁcient conditions on Φ,ι,τ\\nensuring the existence of a strongest counter abstraction.\\nTheorem 4 IfΦ,ι,τ do not contain matrix-ids and are of the kind ∃k1···∃ knφfor a\\n1-ﬂat formula φand for index variables k 1,..., kn, then the system speciﬁcation S=\\n(Σ, v0v1,Φ,ι,τ, AP)has a strongest (effectively computable) counter abstraction.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='(Σ, v0v1,Φ,ι,τ, AP)has a strongest (effectively computable) counter abstraction.\\nProof We apply Proposition 2. Let us rename the arithmetic variables v0asz;t h e n v1is the\\ntuple of array-ids a; we also abbreviate k1,..., knask. We need to show that a formula of\\nthe kind\\n∃a∃kα(z,k,a(k), ♯{x|β(z,x,k,a(x),a(k))}) (22)\\nis equivalent to a pure arithmetic formula.11But this is indeed the case: just swap the exis-\\ntential quantiﬁers and apply Corollary 1and Lemma 1. The result follows because there are\\nno ground index atoms and all ground data atoms are equivalent to ⊤or to⊥, according to\\nour assumptions from Sect. 2.1. ⊓⊔\\nNext result concerns speciﬁcations using matrix-ids in a ﬁnitary signature.\\n10A conventional value may be employed to specify that no message has been sent at all. We do not model\\ntime passing and message scheduling in this paper.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='10A conventional value may be employed to specify that no message has been sent at all. We do not model\\ntime passing and message scheduling in this paper.\\n11In view of condition (iii) of Proposition 2, we need also the observation that formulæ of the kind ∃kφ(for\\n1-ﬂatφ) are closed under conjunctions.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 443\\nTheorem 5 Let the sort Data be enumerated and let Φ,ι,τ be disjunctions of formulæ of\\nthe kind\\n∃k∀i∃yφ (23)\\nwhere φis 1-ﬂat, k are index variables, y are arithmetic and data variables and i is an\\nindex variable such that all matrix variables and all non-ﬁnitary array variables from vare\\ni-uniform in φ;t h e n S=(Σ, v0v1,Φ,ι,τ, AP)has a strongest (effectively computable)\\ncounter abstraction.\\nProof Similar to the proof of Theorem 4,u s i n gT h e o r e m 3instead of Corollary 1.⊣⊓⊔\\nStrongest counter abstractions (typically computed via Theorems 4,5) will be called arith-\\nmetic projections .\\nIn the next section, we describe the infrastructure we deployed, leveraging the presented\\nformal results, so as to model distributed fault-tolerant algorithms and to verify their proper-ties.\\n5 Implementation\\nThe quantiﬁer elimination procedures relying on Theorems 1,2,3are very expensive: the', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='5 Implementation\\nThe quantiﬁer elimination procedures relying on Theorems 1,2,3are very expensive: the\\nprocedure of Theorem 1requires a double exponential blow-up and includes as subprocedures\\nother expensive algorithms, like quantiﬁer elimination in Presburger arithmetic. Although wefeel that the above results are needed if one wants to build and then process some formalprecise declarative models derived out of the original pseudo-code of fault-tolerant algorithms(see our detailed analysis in Appendix A in the supplementary material for an example ofwhat we mean), from a practical point of view it is often possible to build coarser modelsrequiring a less expressive language. For instance, one trick that is often used in the literature(see e.g. [ 46]) is to replace a Boolean-valued matrix-id M(i,x)by an arithmetic array a(i)\\nrepresenting the term ♯{x|M(i,x)}(the intended meaning is that, in this way, we only\\ncount the number of the M-messages received by process i, disregarding the source of these\\nmessages). Quite often, the loss of expressivity due to such abstractions does not prevent thepossibility of formalizing the dynamics of the evolution of the whole system in a satisfactoryway.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='messages). Quite often, the loss of expressivity due to such abstractions does not prevent thepossibility of formalizing the dynamics of the evolution of the whole system in a satisfactoryway.\\nFor the above reasons, we designed a restricted input speciﬁcation language for our tool\\nArcaSim : we describe below such a language and we supply a milder quantiﬁer elimination\\nprocedures applying to it. In the experimental Sect. 6below, we shall see that such restricted\\nlanguage is sufﬁcient to handle benchmarks from different sources.\\n5.1 The ARCA SIMTool\\nArcaSim accepts system speciﬁcations matching the syntactic format explained below and\\nproduces as output a ﬁle in the Horn SMT_Lib format, ready to be model-checked e.g.\\nbyμZ[33], the ﬁxpoint engine of the SMT solver Z3. In successful cases, μZproduces\\nan invariant (entirely expressed in terms of our counters) which guarantees the safety of theoriginal system.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='444 S. Ghilardi, E. Pagani\\nA speciﬁcation ﬁle for ArcaSim should ﬁrst contain declarations for\\n– parameters,\\n– integer variables,– arithmetic array-ids,\\n– enumerated array-ids.\\nParameters include a symbol Ndenoting the (ﬁnite but unknown) number of processes acting\\nin the system; moreover, with each enumerated array-id, a number mis associated, whose\\nmeaning is that of telling the tool that the values of such array-id are taken into the set{0,..., m−1}.\\nThen counters deﬁnitions are introduced: these must have the form of equalities z\\ni=\\n♯{x|ψi(x)},w h e r e ψiis a Boolean combination of data atoms (in the restricted ArcaSim\\nlanguage the constrained signature Σis assumed to be ﬁnitary, i.e. that the sort Data is\\nenumerated).\\nThe system transition is given as a single (index variable) universally quantiﬁed disjunction\\nof cases of the form\\n∀i⋁\\nj(φj1∧φj2) (24)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='of cases of the form\\n∀i⋁\\nj(φj1∧φj2) (24)\\nwhere: (i) φj1(a(i)/y,z)is obtained from a conjunction of arithmetic atoms φj1(y,z)by\\nreplacing some arithmetic variables ywith terms of the kind a(i)(notice that the above\\nintroduced counters for deﬁnable sets may occur here);\\n(ii)φj2(i)is a Boolean combination of data formulæ containing the free variable i.\\nNotice that primed arithmetic array-ids cannot occur in φj1, whereas both primed and\\nunprimed enumerated array-ids can occur in φj2.\\nTheinitial formula follows the same syntax as the transition formula (but only one disjunct\\nis allowed), whereas the formula expressing the (negation of the) safety property must be an\\narithmetic formula containing only counters, integer variables and parameters.\\nWe underline that the above limitations to the formats of transitions, initial and safety\\nformulae are due to an implementation choice : our theoretical results from Sects. 3and4are\\nmuch richer, however we realized that most standard benchmarks can be formalized in theabove restricted ArcaSim language.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='formulae are due to an implementation choice : our theoretical results from Sects. 3and4are\\nmuch richer, however we realized that most standard benchmarks can be formalized in theabove restricted ArcaSim language.\\nIn order to produce a ﬁle for μZ,ArcaSim applies the following simpliﬁed procedure\\nfor quantiﬁer elimination.\\n(i) First, it eliminates (from the arithmetic part φ\\ni1of each transition case) the arithmetic\\narray-ids by reverse skolemization and Presburger quantiﬁer elimination: the formal jus-tiﬁcation for this is that, for an arithmetic array-id a,w eh a v et h a t ∃a∀i⋁\\nj(φj1(a(i))∧\\nφj2)is equivalent to ∀i∃z⋁\\nj(φj1(z)∧φj2)and ﬁnally to ∀i⋁\\nj(∃zφj1(z)∧φj2)-i n\\nthis last formula the ∃zcan be eliminated via Presburger quantiﬁer elimination.\\n(ii) Then, the whole transition is rewritten as a disjunction of formulæ of the kind', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='this last formula the ∃zcan be eliminated via Presburger quantiﬁer elimination.\\n(ii) Then, the whole transition is rewritten as a disjunction of formulæ of the kind\\n⋀\\nk(zk=♯{x|ψk(x)})∧α∧∀xθ(x) (25)\\nwhere we have, besides the counter deﬁnitions zk=♯{x|ψk(x)}, a Boolean assignment\\nα(seen as a conjunction of literals) to the arithmetic atoms occurring in the problem,\\nand a single-variable universally quantiﬁed formula ∀xθ(x)built up from data atoms\\nonly: the formal justiﬁcation for this is that an arithmetic assignment can be guessedand that, in presence of it, arithmetic atoms can be everywhere replaced by ⊤or⊥.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 445\\n(iii) Auxiliary counters are now introduced: we have one counter zffor each function f\\nassociating values to enumerated array-ids and their primed copies. In detail, zfcounts\\nthe cardinality of the set\\n{x|⋀\\naa(x)=fa∧⋀\\naa′(x)=fa′}. (26)\\nThe set of counters zfis much richer than the set of the user-deﬁned original coun-\\nters. There are two reasons for that: ﬁrst, the user might have decided to introduceonly a relatively small set of counters, the set of counters he feels it could be suf-ﬁcient to get an appropriate simulation. Second (more important!), the user canonly introduce static counters , whereas the z\\nfaredynamic counters : they count\\nhow many processes make each possible change of values for their enumeratedarray-ids.\\n12The original counters are expressed as linear combinations of these new\\ndynamic counters; in addition, in each disjunct ( 25), the universally quantiﬁed formula\\n∀xθ(x)is replaced by the equation N=∑ϵfzf,w h e r e ϵfis 0 or 1 depending', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='∀xθ(x)is replaced by the equation N=∑ϵfzf,w h e r e ϵfis 0 or 1 depending\\non whether the formula deﬁning the set ( 26) counted by zfis consistent or not\\nwithθ.\\n(iv) In the ﬁnal steps, all arithmetic atoms involving old and new counters are collected for\\neach disjunct ( 25); the new dynamic counters are eliminated by quantiﬁer elimination\\nand the resulting formulæ give the disjuncts of the transition of the desired arithmeticprojection of the input system.\\nContrary to what one might expect, the quantiﬁer elimination steps in (i) and (iv) are\\nnot so problematic, because of the special shapes of the arithmetic formulæ arising fromthe benchmarks we analyzed. In fact, we did not even use a full Presburger quantiﬁerelimination module in ArcaSim for the reasons we are going to explain. In our exam-\\nples, the quantiﬁer elimination problems in (i) involve just easy (‘difference bounds’-like)constraints and those in (iv) are usually solved by a substitution (in other words, the for-mula where a variable zneeds to be eliminated from, always contains an equality like', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='z=t).\\n13Notice also that, in case a difﬁcult integer quantiﬁer elimination problem arises,\\nshifting to the (better behaved from the complexity viewpoint) Fourier-Motzkin real arith-metic quantiﬁer elimination procedure is a sound strategy: this is because, in the end, thetool needs to produce just a simulation (i.e. an abstraction). Although ArcaSim was pre-\\npared to make such a shifting to Fourier-Motzkin procedure, it never applied it during ourexperiments.\\nThe step (ii) basically amounts to an “all sat” problem (i.e. to the problem of listing all\\nBoolean assignments satisfying a formula), which is difﬁcult but can be handled efﬁciently.The real bottleneck seems to be the need of introducing in (iii) a large amount of auxiliary‘dynamic’ counters: future work should concentrate on improving heuristics here.\\n12If, for instance, there are two array-ids a1,a2each of them taking values from the set {1,2,3},t h e nw eh a v e', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='12If, for instance, there are two array-ids a1,a2each of them taking values from the set {1,2,3},t h e nw eh a v e\\none dynamic counter for every 4-tuple from {1,2,3}: a 4-tuple is seen as a function ffrom{a1,a2,a′\\n1,a′\\n2}\\ninto{1,2,3}and the corresponding counter zfcounts the number of the processes xsuch that a1(x)=\\nfa1,a2(x)=fa2,a′\\n1(x)=fa′\\n1,a′\\n2(x)=fa′\\n2.\\n13In case a maximum choice of static counters is made by the user, one can even formally prove that this is\\nalways the case.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='446 S. Ghilardi, E. Pagani\\n6 Our Experiments\\nIn this section we report our experiments; the source ﬁles for the benchmarks are available at\\nhttps://homes.di.unimi.it/~pagae/ARCASIM/ , while the ArcaSim executables are available\\nat the link http://users.mat.unimi.it/users/ghilardi/arca_tools/ .\\n6.1 Classes of Problems Considered\\nWe analyzed several benchmarks representative of different classes of problems. In the fol-\\nlowing, we analyze the peculiarities and complexity of modeling the algorithms belongingto each class. In Appendix A in the supplementary material, three models are described indetail. Most of the veriﬁed algorithms are synchronous and round-based, i.e. they assumethat within a round both each process performs the computation of the algorithm for thatround, and messages sent in the round are delivered to their destinations by the end of thesame round. The few exceptions are highlighted. Only safety properties of the algorithms\\nare veriﬁed with the proposed tool; liveness properties are considered just when they can berewritten as safety properties (one way to get such a safety reformulation is to strenghten aliveness property by asking that a desired event must happen within a speciﬁed number ofrounds).', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='All experiments have been conducted on a PC equipped with Intel Core i7-7700 processor\\n3.60 GHz and operating system Linux Ubuntu 18.04 (64 bits).\\n6.1.1 Agreement Algorithms with Either Omission or Malicious Failures.\\nThe algorithms of this class consider a set of Nprocesses residing on different hosts and\\ncommunicating through a data network. Processes must reach an agreement about somevalue, in spite of possibile failures of some of them. Faulty processes may either (i)omit to\\nsend or receive some of the messages considered by the algorithm ( benign failures), or (ii)\\nmaliciously fail ( byzantine failures) reporting fake information. In the latter case, malicious\\nprocesses might also coalesce in order to fool honest processes. In the former case, a processmay also fail crash, that is, from a certain point on no message is anymore sent or received.\\nIn order to express our problems within the restricted language explained in Sect. 5(i.e.\\nin the ArcaSim format), all the models just consider the behavior of correct processes, while\\nfaulty ones are\\nabstracted away. (This is a technique used also in [ 34,35,37–39]).\\nBoth omission and byzantine failures are modeled by using a global variable f, whose', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='faulty ones are\\nabstracted away. (This is a technique used also in [ 34,35,37–39]).\\nBoth omission and byzantine failures are modeled by using a global variable f, whose\\nvalue may be upper bounded by e.g. the algorithm resilience t. The number of correct pro-\\ncesses is thus N−f, and every message sent by a correct process is received by all other\\ncorrect processes. Using the counter abstraction, we disregard the identities of processessending a certain message; we simply impose that—if cmis the number of correct processes\\nsending a certain kind of message—then each correct process receives in between cmand\\ncm+fmessages of that kind, where cmis the worst case of all faulty processes actually\\nfailing, and cm+fis the best case of all faulty processes behaving correctly. As far as\\nomission failures are considered, faulty processes may or may not send their messages. Asfar as byzantine failures are concerned, independently of their state faulty processes may sendwhatever message they want (or none at all), and even send different messages to differentdestinations.\\nThe veriﬁcation results for this set of algorithms are reported in Table 1,w h e r ew es h o w\\nthe considered algorithm, the property to be veriﬁed and the conditions under which it is\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 447\\nveriﬁed, the number of transitions produced by ArcaSim and its running time, the running\\ntime of Z3to process the ﬁle produced by ArcaSim and the outcome of the veriﬁcation. In\\norder to properly understand the results in the Table, recall that when the μZmodule of Z3\\ngives a sat answer, this means that there exists a safety invariant for the abstracted counter\\nsystem (so that the original system is also safe); on the contrary, an unsat answer by Z3\\nmeans that the safety condition for the abstracted counter system is violated (which is likely- but not necessarily - implying that the original is not safe).\\n14\\nThe One-Third (OT) algorithm [ 11] solves the Consensus problem in case of benign\\nfailures. Formally, the problem is deﬁned as follows: each process starts with its own initialvalue. By the end of the algorithm, processes must decide for one of those values so that thefollowing properties are satisﬁed:\\nAgreement whenever two processes have reached a decision, the values they have decided\\non must be equal.\\nIntegrity - Weak Validity if all processes propose the same initial value, they must decide\\non that value.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Agreement whenever two processes have reached a decision, the values they have decided\\non must be equal.\\nIntegrity - Weak Validity if all processes propose the same initial value, they must decide\\non that value.\\nIrrevocability if a process has decided on a value it does not revoke its decision later.\\nNo upper bound is needed on the number of faulty processes. As for all other Consensus\\nalgorithms considered in this work, we limited the set of possibile initial values to {0,1}(this\\nis often not a limitation, see the 0-1 theorems from [ 46]).\\nThe Irrevocability property requires to check that never in the future a revocation occurs.\\nFor OT and the other Consensus algorithms mentioned in the sequel, we veriﬁed it by re-formulating Irrevocability as a safety property: an integer global variable decis used, which\\nis initialized to 0, and whose value becomes 1 whenever a process having already decided forav a l u e vtakes a decision for a value\\nv̸=v. The unsafe condition is dec>0 and—through\\nbackward search—we check whether a state with dec=1 can be reached from the initial\\ncondition with all processes undecided and with no constraint on their initial values.\\nFormal veriﬁcation highlighted something that was not evident in the original formula-', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='condition with all processes undecided and with no constraint on their initial values.\\nFormal veriﬁcation highlighted something that was not evident in the original formula-\\ntion of some problems, that is, it allowed to discover that some properties in the problemsenunciations are indeed “trivial”; in fact, they cannot be violated for any number of faultyprocesses. This is the case for the Weak Validity property of OT: if all processes own thesame initial value, there is no way to decide for a different value, considering that processescannot lie.\\nThe Uniform V oting algorithm (UV) [ 16] similarly solves the Consensus problem in the\\npresence of benign failures. The solved problem is analogous to that deﬁned for OT, refor-mulating the Integrity property as follows: “Any decision value is the initial value of someprocess” (which is also indicated as\\nStrong Validity ). In order to guarantee the Agreement and\\nIrrevocability property, UV requires the system to satisfy a Pnosplit condition that imposes\\nthat communication failures must not partition the network, that is, there cannot exist twosubsets of processes such that processes belonging to the same subset communicate amongstthemselves, but processes belonging to different subsets not. We omitted to include the\\nPnosplit property in our models because—by abstracting away the processes identities, and', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Pnosplit property in our models because—by abstracting away the processes identities, and\\njust counting both the number of processes performing a certain action and the number ofmessages received whatever are their sources—we cannot represent the identities of com-municating processes and thus there is no way to model the property within the restricted\\n14It may happen that the counter abstraction employed in our model is too coarse (more counters should be', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='14It may happen that the counter abstraction employed in our model is too coarse (more counters should be\\nintroduced) or even that there is no way of certifying the safety of the original system by using just countersprojections. For some benchmarks, one can prove ofﬂine that the employed counter abstraction is not just asimulation but actually a bisimulation: in such cases, an unsat outcome by Z3correponds to the effective\\nunsafety of the original system.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='448 S. Ghilardi, E. PaganiTable 1 Agreement algorithms with either benign or malicious failures\\nAlgorithm Property Conditions arca _sim Z3\\n#Trans. Time (s) Time (s) Answer\\nOT [ 11] Agreement t≥2N/3 11 0.58 0.50 sat\\nOT [ 11] Agreement t<2N/3 14 0.80 0.01 unsat\\nOT [ 11] Weak Validity t≥2N/3 11 0.62 0.01 sat\\nOT [ 11] Weak Validity t<2N/3 14 0.81 0.01 sat\\nOT [ 11] Irrevocability t≥2N/3 22 1.61 0.87 sat\\nOT [ 11] Irrevocability t<2N/3 28 2.23 0.07 unsat\\nBBP [ 55] Correctness t<N/3 7 0.43 0.04 sat\\nBBP [ 55] Correctness t≤N/3 7 0.41 0.03 sat\\nBBP [ 55] Unforgeability t<N/3 7 0.40 0.03 sat\\nBBP [ 55] Unforgeability t≤N/3 7 0.41 0.02 unsat\\nBBP [ 55] Relay (I) t<N/3 7 0.42 0.01 sat', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='BBP [ 55] Unforgeability t≤N/3 7 0.41 0.02 unsat\\nBBP [ 55] Relay (I) t<N/3 7 0.42 0.01 sat\\nBBP [ 55] Relay (I) t≤N/3 7 0.42 0.01 sat\\nBBP [ 55] Relay (II) t<N/3 6 0.38 0.03 sat\\nBBP [ 55] Relay (II) t≤N/3 6 0.39 0.03 sat\\nUV [ 16] Integrity – 21 15.36 0.07 sat\\nUV [ 16] Agreement no Pnosplit 21 19.85 0.03 unsat\\nUV [ 16] Irrevocability no Pnosplit 36 28.62 0.16 unsat\\nCoUV [ 16] Integrity – 15 288.66 0.14 sat\\nCoUV [ 16] Agreement no Pnosplit 15 333.29 0.10 sat\\nCoUV [ 16] Irrevocability no Pnosplit 23 408.05 0.04 unsat\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 449Table 1 continued\\nAlgorithm Property Conditions arca _sim Z3\\n#Trans. Time (s) Time (s) Answer\\nSiCoUV [ 16] Integrity – 11 257.81 0.04 sat\\nSiCoUV [ 16] Agreement no Pnosplit 11 284.13 0.06 sat\\nSiCoUV [ 16] Irrevocability no Pnosplit 19 410.09 1.04 sat\\nUT,E,α[10] Integrity α=0∧¬ Psaf e 17 7.95 0.04 unsat\\nUT,E,α[10] Integrity α=0∧Psaf e 30 13.14 0.10 sat\\nUT,E,α[10] Integrity α=1∧¬ Psaf e 14 6.74 0.05 unsat\\nUT,E,α[10] Integrity 1 ≤α< N/2∧¬ Psaf e 14 6.75 0.06 unsat\\nUT,E,α[10] Integrity α=1∧Psaf e 26 11.52 0.13 sat\\nUT,E,α[10] Integrity 1 ≤α< N/2∧Psaf e 26 11.52 0.21 sat', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='UT,E,α[10] Integrity 1 ≤α< N/2∧Psaf e 26 11.52 0.21 sat\\nUT,E,α[10] Agreement α=0∧¬ Psaf e 17 10.73 0.10 unsat\\nUT,E,α[10] Agreement α=0∧Psaf e 30 17.66 0.90 sat\\nUT,E,α[10] Agreement α=1∧¬ Psaf e 14 8.99 0.12 unsat\\nUT,E,α[10] Agreement 1 ≤α< N/2∧¬ Psaf e 14 8.86 0.06 unsat\\nUT,E,α[10] Agreement α=1∧Psaf e 26 15.25 0.56 sat\\nUT,E,α[10] Agreement 1 ≤α< N/2∧Psaf e 26 15.29 0.85 sat\\nSRBP [ 54] Correctness t<N/2∧≥(f+1)inits 9 1.25 0.02 sat\\nSRBP [ 54] Correctness t<N/2∧≥ finits 9 1.25 0.01 unsat\\nSRBP [ 54] Unforgeability t<N/2∧≥(f+1)inits 9 1.25 0.02 sat', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='SRBP [ 54] Unforgeability t<N/2∧≥(f+1)inits 9 1.25 0.02 sat\\nSRBP [ 54] Relay (I) t<N/2∧no echo 9 1.26 0.02 sat\\nSRBP [ 54] Relay (II) t<N/2∧1 echo 9 1.61 0.02 sat\\nBen-Or [ 9] Validity t<N/5 13 0.56 0.02 sat\\nBen-Or [ 9] Validity t≤N/3 21 0.89 0.13 unsat\\nBen-Or [ 9] Agreement t<N/5 13 0.83 0.08 sat\\nBen-Or [ 9] Agreement t≤N/3 21 1.30 0.23 unsat\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='450 S. Ghilardi, E. Pagani\\nlanguage of ArcaSim . As a consequence, the models veriﬁcations expectedly result in an\\nunsafe outcome.\\nThe Coordinated UV algorithm (CoUV) [ 16] derives from UV and solves the same\\nproblem under the same conditions. Differently from UV—which adopts a distributed com-munication pattern where each process communicates with all the others—CoUV adopts arotating coordinator paradigm such that at each round a process behaves as coordinator, towhich other processes send their values and which tries to help them decide. The SimpliﬁedCoUV (SiCoUV) [ 16] shortens the algorithm execution with slight modiﬁcations of the pro-\\ncess computation that allow to reduce the number of rounds needed to decide. In both cases,the rotating coordinators have been modeled by using a local variable C[x]that assumes three\\nvalues indicating whether xalready has been, currently is, or never was so far a coordinator.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='values indicating whether xalready has been, currently is, or never was so far a coordinator.\\nAt the beginning of each round, a coordinator is nondeterministically taken from the yetunelected processes.These two algorithms show the impact of central coordination on correctness. Both satisfyAgreement also in the presence of partitions: processes in the same partition as the coordinatordecide according to its indications, while partitioned processes do not decide. Yet, in CoUV ,they may retain some value different from that chosen by the coordinator. If partitions changelater and the new coordinator is a previously partitioned process with a value different fromthat disseminated by the previous coordinator, then a process may change its decision, thusviolating Irrevocability. By contrast, in SiCoUV , the simpliﬁcation—consisting in voting justfor the value received by the coordinator of the current phase or for no value at all—preventsprocesses owning values from previous coordinators to vote for those values, thus possiblyinducing inconsistent decisions for stale values.\\nUT,E,α[10] solves the Consensus problem without the Irrevocability property, in the\\npresence of byzantine failures. It requires the system to fulﬁll two properties, namely that thenumber of malicious messages received by each process in each round is ≤α< N/2(\\nPα', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='presence of byzantine failures. It requires the system to fulﬁll two properties, namely that thenumber of malicious messages received by each process in each round is ≤α< N/2(\\nPα\\nproperty), and that the total number of received correct messages is >N/2(Psaf e property).\\nVarious combinations of both αand Psaf e have been considered in our veriﬁcations.\\nIn [9], an algorithm is proposed to solve Consensus in asynchronous systems with byzan-\\ntine failures and a resilience t<N/5. Such an algorithm may also work in synchronous\\nsystems if the number of faulty processes is upper bounded by O(√\\nN). In this case, we\\nmodeled an asynchronous system in that no time quantization is reproduced, but just a divi-\\nsion in phases as in the original algorithm. In the ﬁrst phase, a process waits till it receivesat least N−tmessages; it decides the value to diffuse subsequently and switches to the\\nnext phase. In the second phase, a process waits till it receives at least N−tmessages and', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='next phase. In the second phase, a process waits till it receives at least N−tmessages and\\ntries to decide. If this is not possible, the process goes back to the ﬁrst phase. Leveragingthe backward search, we started from the conﬁgurations in which the considered property isviolated. The algorithm runs in which the sufﬁcient number of messages is not received—which do not lead to any action—are unimportant; we veriﬁed whether the cases in whichactions are undertaken by the processes can lead to an unsafe state. As a resilience value weused t<N/5 as in the original paper, which actually leads to a\\nsafe result. Moreover—since\\nthe article ignores the lower bound on the resilience for Byzantine failures ( t<N/3[48]) –\\nwe considered the case of violation of this lower bound which correctly gives unsafe results.\\nThe Byzantine Broadcast Primitive (BBP) [ 55] aims at achieving agreement among the\\nprocesses about the messages to deliver. This algorithm tolerates byzantine failures andrequires that the number tof faulty processes is such that N>3t. BBP is a round-based', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='processes about the messages to deliver. This algorithm tolerates byzantine failures andrequires that the number tof faulty processes is such that N>3t. BBP is a round-based\\nalgorithm operating in synchronous systems. It fulﬁlls the following properties:\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 451\\nCorrectness If correct process pbroadcasts (p,m,k)in round k, then every correct process\\naccepts (p,m,k)in the same round.\\nUnforgeability If process pis correct and does not broadcast (p,m,k), then no correct\\nprocess ever accepts (p,m,k).\\nRelay If a correct process accepts (p,m,k)in round r>k, then every other correct process\\naccepts (p,m,k)in round r+1 or earlier.\\nThe Relay property asks to check all the states reachable from the conﬁgurations satisfying\\nthe hypothesis; as this is not possibile, we had to re-write this property as two separate safetyproperties sequentially veriﬁed. In Appendix A.1 in the supplementary material, we explainin detail this procedure.\\nFormal veriﬁcation reveals that Correctness and Relay properties cannot be violated for any', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Formal veriﬁcation reveals that Correctness and Relay properties cannot be violated for any\\nnumber of faulty processes. The Correctness property cannot be violated since the thresholdfor acceptance is equal to the minimum number of correct processes, and the initial broadcastis performed by a correct process and thus received by all correct processes; hence, thereis no way for a correct process to not receive enough echo’s. The Relay property cannot beviolated because a correct accepting process must have received at least N−2techo’s from\\ncorrect processes; those echo’s are received by each correct process, all correct processessend their own echo, and as a consequence there are N−tcorrect echo’s around that allow\\neach correct process to decide.\\nThe Send Receive Broadcast Primitive (SRBP) algorithm from [ 54] is proposed as a basis\\nfor clock synchronization in systems affected by benign failures. It requires an upper boundton the number fof faulty processes, i.e., N>2tand t≥f. The algorithm satisﬁes the\\nsame properties as BBP, with the broadcast message consisting in a time signal (round k ).', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='same properties as BBP, with the broadcast message consisting in a time signal (round k ).\\nThe same two-steps veriﬁcation of the Relay property is adopted as for BBP. In this case aswell, formal veriﬁcation shows that Unforgeability and Relay properties cannot be violated.The former trivially follows from the fact that no message is around and faulty processescannot lie. The latter follows from considerations similar to the case of BBP.\\n6.1.2 Agreement and Reliable Multicast Algorithms with Crash Failures\\nThe algorithms considered for this category have in common a failure model such thatprocesses behave correctly until they possibly fail, but from the failure on no action is anymoretaken, nor any message is sent or received (fail-stop model). Crash failures may\\npartially\\ndisrupt the broadcast transmission of a message in the sense that the message may reach justa subset of its destinations.\\nAlthough counter-intuitive, these failures are harder to model than both omission and\\nbyzantine failures. We describe the state of each process with a local variable Fthat can', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Although counter-intuitive, these failures are harder to model than both omission and\\nbyzantine failures. We describe the state of each process with a local variable Fthat can\\nassume three values, indicating if the process is (so far) correct, if it crashed in the past,or if it is crashing in the current algorithm step and it will send only part of the messagesscheduled to be transmitted currently. In the last case, by the end of the step the process ismoved to the crashed processes and it will do nothing in the future. At every step, the sumof both crashing and crashed processes must not exceed the algorithm resilience.\\nThe results for these algorithms are reported in Table 2.\\nFloodSet [ 45] is a Consensus algorithm that satisﬁes the same properties as OT, with no\\nresilience and terminating after f+1 rounds with fthe number of crashed processes in the\\ncurrent run. Processes circulate the values received in the previous rounds; in the last round,processes decide either for the unique value they received, or for a default value if morevalues have been observed.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='452 S. Ghilardi, E. Pagani\\nTable 2 Agreement and Reliable multicast algorithms with crash failures\\nAlgorithm Property Conditions arca _sim Z3\\n#Trans. Time (s) Time (s) Answer\\nFloodSet [ 45] Weak Validity – 11 4.43 0.02 sat\\nFloodSet [ 45] Agreement – 11 5.18 0.03 sat\\nFloodMin [ 45] Weak Validity k=1∧|V|=2 9 1.37 0.01 sat\\nFloodMin [ 45] Strong Validity k=1∧|V|=2 9 1.42 0.01 sat\\nFloodMin [ 45] k-Agreement k=1∧|V|=2 9 1.59 0.03 sat\\nFloodMin [ 45] Weak Validity k=1∧|V|=3 17 11.84 0.05 sat\\nFloodMin [ 45] Strong Validity k=1∧|V|=3 17 10.30 0.02 sat\\nFloodMin [ 45] k-Agreement k=1∧|V|=3 17 13.03 0.08 sat\\nFloodMin [ 45] Weak Validity k=2∧|V|=3 17 11.78 0.06 sat', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='FloodMin [ 45] Weak Validity k=2∧|V|=3 17 11.78 0.06 sat\\nFloodMin [ 45] Strong Validity k=2∧|V|=3 17 10.31 0.02 sat\\nFloodMin [ 45] k-Agreement k=2∧|V|=3 17 13.06 0.05 sat\\nFC [ 50] (Strong) Validity |V|=2 9 13.92 0.03 sat\\nFC [ 50] Agreement |V|=2 9 15.29 0.07 sat\\nEDAC [ 15] (Weak) Validity |V|=2 35 46.95 0.03 sat\\nEDAC [ 15] Agreement |V|=2 35 49.66 0.02 sat\\nUTRB1 [ 8] Validity – 2 0.13 0.06 sat\\nUTRB1 [ 8] Unif.Agreem. – 2 0.19 0.0015sat\\nUTRB1 [ 8] Integrity (I) – 2 0.16 0.0015sat\\nUTRB1 [ 8] Integrity (II) – 2 0.15 0.0015sat\\nFloodMin [ 45] is a Consensus algorithm that solves the k-agreement problem: the algo-', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='UTRB1 [ 8] Integrity (II) – 2 0.15 0.0015sat\\nFloodMin [ 45] is a Consensus algorithm that solves the k-agreement problem: the algo-\\nrithm runs for ⌊f/k⌋+1 rounds—with fdeﬁned as before—after which it is requested that\\nthe values decided upon by the processes are in a set of cardinality at most k. This reduces to\\nclassical Consensus for k=1. FloodMin guarantees both the Weak Validity and the Strong\\nValidity properties deﬁned before. We performed experiments with two values of k, and with\\nas e t Vof initial values of cardinality either 2 or 3.\\nFC [ 50] is a Consensus algorithm that guarantees both Agreement and Strong Validity as\\ndeﬁned above; it terminates at round t+1 with t<Nthe algorithm resilience, and f≤t\\nnumber of actually crashed processes; the decision is the smallest received value.\\nEDAC [ 15] as well solves Consensus, but it considers the Weak Validity property. This\\nalgorithm is early-deciding in the sense that—if a process does not detect new failures in', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='EDAC [ 15] as well solves Consensus, but it considers the Weak Validity property. This\\nalgorithm is early-deciding in the sense that—if a process does not detect new failures in\\nthe current round—it decides, differently from the above three algorithms.The problemof modeling this algorithm is that it would require each process to record the observedcrashes (a process is assumed having crashed when no expected message is received fromit in the current round), which should be modeled with bi-dimensional arrays, not avail-able in ArcaSim . Considering the syntactic constraints of ArcaSim , the fact that (i)no\\nmessage is anymore received from a process after it crashes and (ii)a crashed process\\nis detected within at most the following round by all alive processes, we abstracted thispart of the algorithm by using a global variable cnum that counts the crashed processes\\nand is incremented for all processes as soon as a new crash is observed by the ﬁrst pro-cess.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 453\\nUTRB1 [ 8] solves the Uniform Timed Reliable Broadcast problem, which guarantees the\\nfollowing properties:15\\nValidity: If a correct process broadcasts a message m, then all correct processes eventually\\ndeliver m.\\nIntegrity: For any message m, each process delivers mat most once and only if some process\\nactually broadcasts m.\\nUniform Agreement: If any process delivers a message mthen all correct processes eventually\\ndeliver m.\\nTimeliness: There exists a known constant Δsuch that if the broadcast of a message mis\\ninitiated at time t, no process delivers mafter t+Δ.\\nFollowing the pen-and-paper correctness proof of UTRB1, we applied the Timeliness prop-\\nerty to instantiate the “eventual” attribute and veriﬁed that both uniform agreement andvalidity are reached by round f+1. As far as Integrity is concerned, we separately checked\\nits two components, by verifying that (i)if no process broadcasts mthen no process delivers\\nit, and (ii)each process delivers mat most once; both conditions are checked at round f+1\\nwhen the algorithm run terminates.\\n6.1.3 Cache Coherence and Mutual Exclusion Algorithms', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='it, and (ii)each process delivers mat most once; both conditions are checked at round f+1\\nwhen the algorithm run terminates.\\n6.1.3 Cache Coherence and Mutual Exclusion Algorithms\\nThe MESI [ 47]a n dM O E S I[ 53] algorithms have been designed to guarantee cache coherence.\\nThis problem affects shared-memory multi-processors systems where more than one processat a time may access the same memory location and copy the content to its processor’s cache,butthe algorithms must guarantee that at most one process at a time is allowed to modify its\\ncopy , and successive read operations to the same location must return the most updated value.\\nThe problem of verifying these algorithms w.r.t. the safety property above lies in the fact thatthere may be more processes in the same state—and thus satisfying the same guard—but justone of them is allowed to ﬁre at a time; this feature differentiates the algorithms in questionfrom pure counter-based algorithms. In order to model this characteristic, we used both aglobal variable fl a g that is initialized to 0, becomes 1 when one of the processes in either\\nthe invalid or the shared state prepares to ﬁre, and returns to 0 after the process has performedits operation, and a local array variable F[x]that is initialized to 0, becomes 1 for a process', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='the invalid or the shared state prepares to ﬁre, and returns to 0 after the process has performedits operation, and a local array variable F[x]that is initialized to 0, becomes 1 for a process\\nin either invalid or shared state that is selected to ﬁre, and returns to 0 when that processﬁres. We constrain the system such that # {x|F[x]= 1}≤ 1, that is, at most one process at\\na time—in one between the invalid and the shared state—may be selected to perform someoperation. By contrast, in the system just one process at a time may be in either the modiﬁedor the exclusive state, and hence the constraint is not applied to those processes.\\nDekker [ 20] is a classical mutual exclusion algorithm that guarantees that no more than\\none process is in critical section. We used local variables T[x]to record what process has the\\nturn, and WE[x]as the local ﬂag to record that process xwants to enter the critical section.\\nAs before, we use a constraint imposing that # {x|T[x]= 1}≤ 1, that is, it is the turn of\\nat most one process at a time; this way T[x]takes the place of the global variable turn in', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='at most one process at a time; this way T[x]takes the place of the global variable turn in\\nDekker’s algorithm. A variable ST[x]records whether xis currently in the critical section.\\nThe results achieved with these algorithms are shown in Table 3.\\n15The time spent by Z3 was not measurable because it is below the clock tick.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='454 S. Ghilardi, E. Pagani\\nTable 3 Cache coherence and mutual exclusion algorithms\\nAlgorithm Property Conditions arca _sim Z3\\n#Trans. Time (s) Time (s) Answer\\nMESI [ 47] Cache coherence – 15 0.21 0.05 sat\\nMOESI [ 53] Cache coherence – 20 0.41 0.07 sat\\nDekker [ 20] Mutual exclusion – 5 0.04 0.00 sat\\n6.2 Qualitative Comparison with Other Tools\\nOther tools in the literature aim at verifying safety properties for distributed algorithms. In\\n[46], Consensus algorithms are considered, a speciﬁcation language ConsL is proposed, and\\ncutoff bounds are supplied to reduce the parameterized veriﬁcation to a setting with ﬁnitenumber of processes. Amongst the algorithms studied in [ 46], there are the algorithms OT,\\nUV , CoUV , SiCoUV and Ben-Or described above, whose safety we veriﬁed for an unlimitednumber of processes using ArcaSim . Although the time spent by ArcaSim for veriﬁcation\\nwas greater than that obtained by ConsL–ConsL latency is on the order of tens of millisecondsfor the cited algorithms—it succeeded in performing the computation and within reasonabletime.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='was greater than that obtained by ConsL–ConsL latency is on the order of tens of millisecondsfor the cited algorithms—it succeeded in performing the computation and within reasonabletime.\\nIn this section, we present a qualitative comparison between ArcaSim and ByMC [ 38],\\nwhich is a veriﬁcation framework proposed for the validation of threshold algorithms, thatis, algorithms where an action is performed when a certain number of messages are received,regardless of who generated them. The comparison was performed by manually “transcript-ing” some ByMC examples—provided by the virtual machine version 2.4.0 downloadedfrom [ 36]—into ArcaSim . The transcription was conducted trying to maintain maximum\\nﬁdelity to the ByMC models, by developing ArcaSim models that use the same variables\\nand counters as the equivalent ByMC model, deﬁne arithmetic assertions equivalent to theassumptions in the ByMC model, and include one transition for each computation step inthe ByMC model. For the sake of better comparison, ByMC was run using Z3 as underlyingSMT solver. Clearly, ByMC and ArcaSim are two really different approaches to the veriﬁ-\\ncation of distributed algorithms: ByMC considers asynchronous algorithms while ArcaSim', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='cation of distributed algorithms: ByMC considers asynchronous algorithms while ArcaSim\\nis more oriented to model synchronicity and some properties are modeled by introducinga bound—usually provided in the original algorithms’ descriptions—on the time at whichsafety must be checked; the two underlying logical paradigm have different expressiveness.Yet, we were interested in investigating whether ArcaSim is able to deal with the same\\nbenchmarks as ByMC. Table 4reports the results; the ByMC time was obtained by adding\\nthe displayed system and user times.\\nThe considered algorithms are as follows: STRB [ 55] is the same as the previously\\ndescribed BBP algorithm (we adopt here the ByMC nomenclature to emphasize that thisis a different model mimicking the ByMC one). ABA (Asynchronous Byzantine Agreement)[12] slightly modiﬁes the Agreement problem deﬁnition supplied before, and satisﬁes the\\nfollowing properties:\\nCorrectness If the transmitter is correct, all the correct processes decide on its value.\\nUnforgeability If the transmitter is malicious, then either no correct process will decide or\\nthey will all decide on the same value.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 455\\nTable 4 Comparison with ByMC\\nAlgorithm Property Condition arca _sim Z3 ByMC\\n#Trans. Time (s) Time (s) Answer Time (s)\\nSTRB [ 55] Correctness N>3t 7 0.73 0.05 sat 0.23\\nSTRB [ 55] Unforgeability N>3t 7 0.74 0.03 sat 0.16\\nABA [ 12] Correctness N>3t 6 1.79 0.01 sat 15.68\\nABA [ 12] Unforgeability N>3t 6 1.79 0.01 sat 0.95\\nNBAC [ 30] Agreement N>f 5 0.14 0.01 sat 5.01\\nNBAC [ 30] Abort-validity N>f 5 0.14 0.01 sat 4.81\\nNBAC [ 30] Commit-validity N>f 5 0.15 0.01 sat 4.89\\nFRB [ 23] Unforgeability N>f 4 0.59 0.01 sat 0.14\\nFRB [ 23] Correctness N>f 4 0.73 0.01 sat 0.18\\nABA tolerates <N/3 malicious failures; it may work in asynchronous systems, which are', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='FRB [ 23] Correctness N>f 4 0.73 0.01 sat 0.18\\nABA tolerates <N/3 malicious failures; it may work in asynchronous systems, which are\\nmodeled with processes that wait until a sufﬁcient number of messages is received to performsome action.\\nNBAC (Non-blocking atomic commitment) [ 30] aims at reaching an agreement amongst\\nprocesses about an action to perform, and satisﬁes the following properties:\\nAgreement No two processes decide differently.\\nTermination Every correct process eventually decides.\\nAbort-validity Abort is the only possible decision if some process votes no.\\nCommit-validity Commit is the only possible decision if every process votes yes and no\\nprocess crashes.\\nWe did not consider the Termination property as it is a liveness property that cannot be\\nmanaged by ArcaSim .\\nFRB (Folklore Reliable broadcast) [ 23] is an algorithm aiming at distributing a message to\\nall alive processes in a system; it works in asynchronous systems and tolerates just crash fail-\\nures. It satisﬁes both a Correctness and an Unforgeability property equal to those previouslydeﬁned for BBP.\\nTo sum up, we believe that the main strength of our approach lies in its declarative', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='To sum up, we believe that the main strength of our approach lies in its declarative\\n(thus expressive and ﬂexible) nature: nevertheless, our ﬁrst ArcaSim implementation for the\\nrestricted fragment of Sect. 5shows that many benchmarks from disparate literature can be\\neffectively handled in our uniform framework with reasonable performances.\\n7 Conclusions and Related Work\\nWe introduced a plain technique for automatically building counter simulations of system\\nspeciﬁcations: the technique consists of modeling system speciﬁcations in higher order logic,then of introducing counters for deﬁnable sets and ﬁnally of exploiting quantiﬁer eliminationresults to get rid of higher order variables. Such technique is quite ﬂexible and since, wheneverit applies, it always supplies the best simulation, it should be in principle capable to cover\\nall results obtainable via counter abstractions. We underline some further important speciﬁcfeatures of our approach.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='456 S. Ghilardi, E. Pagani\\nFirst of all, the approach is purely declarative : our starting point is the informal description\\nof the algorithms (e.g. in some pseudo-code) and the ﬁrst step we propose is a direct translationinto a standard logical formalism (typically, classical Church type theory), without relyingfor instance on ad hoc automata devices or on ad hoc speciﬁcation formalisms. We believethat this choice can ensure ﬂexibility and portability of our methods.\\nSecondly, the amount of human interaction we require is nevertheless conﬁned to design\\nchoices : although the ﬁnal outcome of our investigations should be the integration of our tech-\\nniques into some logical framework, the key leading to their success relies almost entirely onresults (satisﬁability and quantiﬁer elimination algorithms) belonging to the realm of decisionprocedures. In fact, the quantiﬁer elimination results presented in this paper (Theorems 1,2,3)\\nare of interest by themselves and go far beyond the well-known case of Boolean Algebraswith Presburger Arithmetic (BAPA) [ 42], because they are not conﬁned to fragments where\\nsets are uninterpreted.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='sets are uninterpreted.\\nAlthough we are claiming that the fully declarative approach is the main merit of our', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='approach, we are aware that a full automation is, in the present status of the art, far fromreachable. In particular, contrarily to what happens in other veriﬁcation areas, a uniformestablished standard for the speciﬁcation of distributed system is not available. Moreover,even when some form of pseudo-code for an algorithm is supplied in the original sourcepapers, its translation into higher order logic is not completely obvious and requires a carefulanalysis. In principle, higher order logic is a quite powerful and expressive formalism, sothat one might claim that “everything” is expressible in it; however, designing a detailedtranslation from some fragment of pseudo-code into transition systems expressed in higherorder logic is far from obvious and surely requires deep speciﬁc work, to be attacked inquite differently oriented papers. In this paper, we just made a syntactic classiﬁcation ofhigher-order speciﬁcations to which quantiﬁer elimination applies; the question whether agiven higher-order speciﬁcation can be symbolically tranformed up to logical equivalenceinto a speciﬁcation falling within the syntactic shape to which our theorems apply, is another,terribly difﬁcult, question to which only very limited answers can be provided. All in all,manual intervention is required even in this', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='falling within the syntactic shape to which our theorems apply, is another,terribly difﬁcult, question to which only very limited answers can be provided. All in all,manual intervention is required even in this stage, especially if one wants to go beyond strictsyntactic matching. However, in concrete cases our approach can be really effective: in theonline available supplementary material to this paper, we made a careful detailed analysisof three concrete examples, starting from informal description, to pseudo-code speciﬁcation,to translation into higher-order transition systems, to mechanical veriﬁcation via counterabstractions.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='A potentially weak point to be taken care is the complexity of our algorithms: in fact, the\\nprocedure for quantiﬁer elimination used in the proof of Theorems 1,2,3produces super-\\nexponential blow-up of the formulæ it is applied to. Notice however that, when buildinga counters simulation of a concrete algorithm, such a heavy procedure is applied to eachinstruction (or to each block of instructions) separately, i.e. not to the whole code instance.Moreover, it is not difﬁcult to realize (going through e.g. the computation details from theonline available suplementary material) that it is hardly the case that the quantiﬁer eliminationprocedure is applied in its full generality: in fact, it is always applied to smaller fragments,where complexity presumably drastically reduces (similarly to what happens for satisﬁabil-ity algorithms, compare e.g. Theorems 2 and 3 in [ 4]). The same observation applies also', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='to the instances of the Presburger quantiﬁer elimination procedure that are invoked in ourmanipulations: usually, they are conﬁned to difference bounds formulæ or to formulæ wherequantiﬁers can be eliminated by simple instantiations. The identiﬁcation of such small frag-ments and the study of the related complexities is important for future work and preliminaryto any implementation effort.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 457\\nAnother delicate point is related to the syntactic limitations we require on the formulæ\\ndescribing system speciﬁcations (see the statements of Theorems 4and 5): such syntactic\\nlimitations are needed to ensure higher order quantiﬁer elimination. Although it seems thata signiﬁcant amount of benchmarks are captured despite such limitations, it is essential todevelop techniques applying in more general cases. To this aim, we observe that just over-approximations are needed to build simulations and that, even if the best simulation may notexist, still practically useful simulations might be produced. In fact, quantiﬁer elimination isjust an extreme solution to symbol elimination problems. Symbol elimination and interpo-lation are well-known techniques to build invariants, abstractions and over-approximations,and for this reason their investigation has deserved considerable attention in the automatedreasoning literature [ 41]; still, extensions to higher-order fragments need to be attacked and\\nmight be useful in our context.\\nTo conclude, we mention some recent work on the veriﬁcation of fault-tolerant distributed\\nsystems, starting from our own previous contributions. The additional original contributionswith respect to our previous paper [ 4] and its journal version [ 5] are due to the fact that', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='systems, starting from our own previous contributions. The additional original contributionswith respect to our previous paper [ 4] and its journal version [ 5] are due to the fact that\\nwe are moving from bounded model-checking and invariant checking to the much morechallenging task of full model-checking via invariant synthesis . As discussed in [ 5] (Sect.\\n7), standard model-checking techniques are difﬁcult to apply in the present context of fault-tolerant distributed systems because Pre- and Post-image computations are very expensiveand lead to fragments for which full decision procedures seem not to be available. That iswhy we tried here a different approach, via counter simulations. While developing such adifferent approach, we established further new quantiﬁer elimination results for higher-order\\nfragments (Theorems 2and3above): we believe that these new results, although tailored to\\nour speciﬁc applications, are of some independent interest from a logical and a technicalpoint of view.\\nPapers [ 34,35,37,39] represent a very interesting and effective research line (summarized\\nin [38]), where cardinality constraints are not directly handled but abstracted away using\\ncounters. In this sense, this research line looks similar to the methodology we applied in thispaper (and in contrast to the alternative methodology we adopted in our previous paper [ 4]);', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='counters. In this sense, this research line looks similar to the methodology we applied in thispaper (and in contrast to the alternative methodology we adopted in our previous paper [ 4]);\\nhowever, abstraction in [ 38] and in related papers is not obtained via logical formalizations and\\nquantiﬁer elimination, but via a special speciﬁcation language (‘parametric Promela’) and/orvia special devices, called ‘threshold automata’. A comparison with the counter systemswe obtain is not immediate and not always possible because the authors of [ 38]w o r ko n\\nasynchronous (not round-based) versions of the algorithms and because their method suffersof some lack of expressiveness whenever local counters are unavoidable. On the other hand,they are able to certify also liveness properties, whereas at the actual stage we can only do thatby making reductions to safety or bounded model checking problems (we applied this methodin our experiments, usually taking bounds for reductions from the literature on distributedalgorithms—such bounds are often trivially suggested by the round-based structure of ourbenchmarks).\\nPaper [ 11] directly handles cardinality constraints for interpreted sets by employing', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Paper [ 11] directly handles cardinality constraints for interpreted sets by employing\\nspeciﬁcally tailored abstractions and some incomplete inference schemata at the level ofthe decision procedures. Nontrivial invariant properties are synthesized and checked, basedon Horn constraint solving technology; this is the same technology we rely on in our ﬁnalstep, however the counter systems we get are ‘as accurate as possible’, in the sense stated inour main Theorems 4and5.', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Paper [ 21] introduces an expressive logic, speciﬁcally tailored to handle consensus prob-\\nlems (whence the name ‘consensus logic’ CL). Such logic employs arrays with values into\\npower set types, hence it is naturally embedded in a higher order logic context. Paper [ 21]i s\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='458 S. Ghilardi, E. Pagani\\nnot concerned with simulations and bisimulations, rather it uses an incomplete algorithm in\\norder to certify invariants. A smaller fragment (identiﬁed via several syntactic restrictions)is introduced in the ﬁnal part of the paper and a decidability proof for it is sketched.\\nCutoff approaches are often employed in the literature on veriﬁcation of distributed sys-\\ntems: in such approaches, problems involving unboundly many processes are reduced toparticular cases where only a ﬁnite number of processes has to be considered (as soon assuch number is determined, ﬁnite state model checking techniques apply). For a recent paperin the area, speciﬁcally tailored to fault-tolerant distributed algorithms, see [ 46].\\nFinally, we mention the effort made by the interactive theorem proving community in\\nformalizing and verifying fault-tolerant distributed algorithm (see e.g. [ 14]); such approach\\nis a natural complement to ours.\\nFunding Open access funding provided by Università degli Studi di Milano within the CRUI-CARE Agree-', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='is a natural complement to ours.\\nFunding Open access funding provided by Università degli Studi di Milano within the CRUI-CARE Agree-\\nment. The work was conducted in the framework of SEED Project “Situational awareness in criticalInfrastructure Environment (SENTINEL)” funded by the Università degli Studi di Milano.\\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which\\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give\\nappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence,\\nand indicate if changes were made. The images or other third party material in this article are included in thearticle’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material isnot included in the article’s Creative Commons licence and your intended use is not permitted by statutoryregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/ .\\nReferences', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='References\\n1. Abdulla, P.A., Cerans, K., Jonsson, B., Tsay, Y .-K.: General decidability theorems for inﬁnite-state sys-\\ntems. In: Proceedings of LICS, pp. 313–321 (1996)\\n2. Abdulla, P.A., Delzanno, G., Henda, N.B., Rezine, A.: Regular model checking without transducers. In:\\nTACAS, volume 4424 of LNCS, pp. 721–736 (2007)\\n3. Alberti, F., Ghilardi, S., Orsini, A., Pagani, E.: Counter abstractions in model checking of distributed\\nbroadcast algorithms: Some case studies. In: Proceedings of CILC, CEUR Proceedings, pp. 102–117(2016)\\n4. Alberti, F., Ghilardi, S., Pagani, E.: Counting constraints in ﬂat array fragments. In: Proceedings of the\\nIJCAR, volume 9706 of Lecture Notes in Computer Science, pp. 65–81 (2016)\\n5. Alberti, F., Ghilardi, S., Pagani, E.: Cardinality constraints for arrays (decidability results and applica-\\ntions). Formal Methods in System Design (2017)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='5. Alberti, F., Ghilardi, S., Pagani, E.: Cardinality constraints for arrays (decidability results and applica-\\ntions). Formal Methods in System Design (2017)\\n6. Alberti, F., Ghilardi, S., Sharygina, N.: Decision procedures for ﬂat array properties. J. Autom. Reason.\\n54(4), 327–352 (2015)\\n7. Andrews, P.B.: An introduction to mathematical logic and type theory: to truth through proof. Applied\\nLogic Series, vol. 27, 2nd edn. Kluwer, Dordrecht (2002)\\n8. Babaoglu, O., Toueg, S.: Non-blocking atomic commitment. In: Distributed Systems, 2nd edn., pp. 147–\\n168, Sape Mullender Ed., Addison-Wesley (1993)\\n9. Ben-Or, M.: Another advantage of free choice: completely asynchronous agreement protocols. In: Pro-\\nceedings of the PODC, pp. 27–30 (1983)\\n10. Biely, M., Charron-Bost, B., Gaillard, A., Hutle, M., Schiper, A., Widder, J.: Tolerating corrupted com-\\nmunication. In: Proceedings of the PODC, pp. 244–253 (2007)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='munication. In: Proceedings of the PODC, pp. 244–253 (2007)\\n11. Bjørner, N., von Gleissenthall, K., Rybalchenko, A.: Cardinalities and universal quantiﬁers for verify-\\ning parameterized systems. In: Proceedings of the 37th ACM SIGPLAN Conference on ProgrammingLanguage Design and Implementation (PLDI) (2016)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='ing parameterized systems. In: Proceedings of the 37th ACM SIGPLAN Conference on ProgrammingLanguage Design and Implementation (PLDI) (2016)\\n12. Bracha, G., Toueg, S.: Asynchronous consensus and broadcast protocols. JACM 32(4), 824–840 (1985)\\n13. Cavada, R., Cimatti, A., Dorigatti, M., Griggio, A., Mariotti, A., Micheli, A., Mover, S., Roveri, M.,\\nTonetta, S.: The nuXmv symbolic model checker. In: CA V , pp. 334–342 (2014)\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Higher-Order Quantiﬁer Elimination, Counter Simulations and… 459\\n14. Charron-Bost, B., Debrat, H., Merz, S.: Formal veriﬁcation of consensus algorithms tolerating malicious\\nfaults. In: Stabilization, Safety, and Security of Distributed Systems, LNCS. pp. 120–134. Springer, Berlin(2011)\\n15. Charron-Bost, B., Schiper, A.: Uniform consensus is harder than consensus. J. Algorithms 51(1), 15–37\\n(2004)\\n16. Charron-Bost, B., Schiper, A.: The heard-of model: computing in distributed systems with benign faults.\\nIn: Distributed Computing, pp. 49–71 (2009)\\n17. Cimatti, A., Griggio, A.: Software model checking via IC3. In: CA V , pp. 277–293 (2012)\\n18. Delzanno, G.: Constraint-based veriﬁcation of parameterized cache coherence protocols. Form. Methods\\nSyst. Design 23(3), 257–301 (2003)\\n19. Delzanno, G., Esparza, J., Podelski, A.: Constraint-based analysis of broadcast protocols. In: Proceedings', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Syst. Design 23(3), 257–301 (2003)\\n19. Delzanno, G., Esparza, J., Podelski, A.: Constraint-based analysis of broadcast protocols. In: Proceedings\\nof CSL, volume 1683 of LNCS, pp. 50–66 (1999)\\n20. Dijkstra, E.W.: Cooperating sequential processes. In: Genuys, F. (ed.) Programming Languages. Academic\\nPress, New York (1968)\\n21. Dragoj, C., Henzinger, T., Veith, H., Widder, J., Zufferey, D.: A logic-based framework for verifying\\nconsensus algorithms. In: Proceedings of the VMCAI (2014)\\n22. Esparza, J., Finkel, A., Mayr, R.: On the veriﬁcation of broadcast protocols. In: Proceedings of LICS, pp.\\n352–359. IEEE Computer Society (1999)\\n23. Fisman, D., Kupferman, O., Lustig, Y .: On verifying fault tolerance of distributed protocols. In: Pro-\\nceedings of the TACAS, 2008. Full paper at https://www.researchgate.net/publication/220852375_On_\\nVerifying_Fault_Tolerance_of_Distributed_Protocols', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Verifying_Fault_Tolerance_of_Distributed_Protocols\\n24. Flanagan, C., Qadeer, S.: Predicate abstraction for software veriﬁcation. In: POPL, pp. 191–202 (2002)25. Gabbay, D.M., Schmidt, R., Szalas, A.: Second Order Quantiﬁer Elimination: Foundations, Computational\\nAspects and Applications. ACM Digital Library (2008)\\n26. Ghilardi, S., Pagani, E.: Counter simulations via higher order quantiﬁer elimination: a preliminary report.\\nIn: Proceedings of the Fifth Workshop on Proof eXchange for Theorem Proving, PxTP 2017, Brasília,Brazil, 23–24 Sept. 2017, pp. 39–53 (2017)\\n27. Ghilardi, S., Pagani, E.: Second order quantiﬁer elimination: towards veriﬁcation applications. In: Pro-\\nceedings of the Workshop on Second-Order Quantiﬁer Elimination and Related Topics (SOQE 2017),Dresden, Germany, December 6–8, 2017, pp. 36–50 (2017)\\n28. Ghilardi, S., Ranise, S.: Backward reachability of array-based systems by SMT solving: termination and', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='28. Ghilardi, S., Ranise, S.: Backward reachability of array-based systems by SMT solving: termination and\\nInvariant Synthesis. Log. Methods Comput. Sci. 1, 2 (2010). https://doi.org/10.2168/LMCS-6(4:10)2010\\n29. Ghilardi, S., Ranise, S.: MCMT: a model checker modulo theories. In: IJCAR, pp. 22–29 (2010)30. Guerraoui, R.: On the hardness of failure-sensitive agreement problems. Inf. Process. Lett. 79, 99–104\\n(2001)\\n31. Gurﬁnkel, A., Kahsai, T., Komuravelli, A., Navas, J.A.: The SeaHorn veriﬁcation framework. In: CA V ,\\npp. 343–361 (2015)\\n32. Hoder, K., Bjørner, N.: Generalized property directed reachability. In: SAT, pp. 157–171 (2012)33. Hoder, K., Bjørner, N., de Moura, L.: μZ—an efﬁcient engine for ﬁxed points with constraints. In: CA V ,\\npp. 457–462 (2011)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='pp. 457–462 (2011)\\n34. John, A., Konnov, I., Schmid, U., Veith, H., Widder, J.: Parameterized model checking of fault-tolerant\\ndistributed algorithms by abstraction. In: Proceedings of International Conference on Formal Methods inComputer-Aided Design (FMCAD), pp. 201–209 (2013, Aug)\\n35. John, A., Konnov, I., Schmid, U., Veith, H., Widder, J.: Towards modeling and model checking fault-\\ntolerant distributed algorithms. In: Proceedings of the International SPIN Symposium on Model Checkingof Software, volume 7976 of Lecture Notes in Computer Science, pp. 209–226. Springer, Berlin (2013,July)\\n36. Konnov, I.: ByMC: Byzantine Model Checker. http://forsyte.at/software/bymc/ , last visit: July 17 (2018)\\n37. Konnov, I., Veith, H., Widder, J.: On the completeness of bounded model checking for threshold-based', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='37. Konnov, I., Veith, H., Widder, J.: On the completeness of bounded model checking for threshold-based\\ndistributed algorithms: reachability. In: Proceedings of CONCUR, LNCS, pp. 125–140 (2014)\\n38. Konnov, I.V ., Veith, H., Widder, J.: What you always wanted to know about model checking of fault-\\ntolerant distributed algorithms. In: Perspectives of System Informatics—10th International Andrei ErshovInformatics Conference, PSI 2015, in Memory of Helmut Veith, Kazan and Innopolis, Russia, August24–27, 2015, Revised Selected Papers, pp. 6–21 (2015)\\n39. Konnov, I.V ., Veith, H., Widder, J.: On the completeness of bounded model checking for threshold-based\\ndistributed algorithms: reachability. Inf. Comput. 252, 95–109 (2017)\\n40. Koopmann, P., Rudolph, S., Schmidt, R.A., Wernhard, C. (eds.): Proceedings of the Workshop on Second-\\nOrder Quantiﬁer Elimination and Related Topics (SOQE 2017), Dresden, Germany, December 6–8, 2017,volume 2013 of CEUR Workshop Proceedings. CEUR-WS.org (2017)\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='460 S. Ghilardi, E. Pagani\\n41. Kovács, L., V oronkov, A.: Interpolation and symbol elimination. In: Automated Deduction—CADE-\\n22. In: 22nd International Conference on Automated Deduction, Montreal, Canada, August 2–7, 2009.Proceedings, pp. 199–213 (2009)\\n42. Kuncak, V ., Nguyen, H.H., Rinard, M.: Deciding boolean algebra with Presburger arithmetic. J. Autom.\\nReas. 36(3), 213–239 (2006)\\n43. Kuncak, V ., Nguyen, H.H., Rinard, M.: An Algorithm for deciding BAPA: boolean algebra with Presburger\\narithmetic. In: Proceedings of CADE-20, volume 3632 of LNCS (July 2005)\\n44. Lambek, J., Scott, P.J.: Introduction to higher order categorical logic, volume 7 of Cambridge Studies in\\nAdvanced Mathematics. Cambridge University Press, Cambridge, 1988. Reprint of the 1986 original\\n45. Lynch, N.A.: Distributed Algorithms. Morgan Kaufmann, Burlington (1996)46. Maric, O., Sprenger, C., Basin, D.A.: Cutoff bounds for consensus algorithms. In: Computer Aided', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Veriﬁcation—29th International Conference, CA V 2017, Heidelberg, July 24–28, 2017, Proceedings,Part II, pp. 217–237 (2017)\\n47. Papamarcos, M.S., Patel, J.H.: A low-overhead coherence solution for multiprocessors with private cache\\nmemories. In: Proceedings of the ISCA (1984). https://dl.acm.org/citation.cfm?id=808204\\n48. Pease, M., Shostak, R., Lamport, L.: Reaching agreement in the presence of faults. JACM 27(2), 228–234\\n(1980)\\n49. Presburger, M.: Über die V ollständigkeit eines gewissen Systems der Arithmetik ganzer Zahlen, in\\nwelchem die Addition als einzige Operation hervortritt. Kluwer, Warszawa (1929)\\n50. Raynal, M.: Fault-tolerant Agreement in Synchronous Message-Passing Systems. Morgan & Claypool—\\nSynthesis Lectures on Distributed Computing Theory series (2010)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='50. Raynal, M.: Fault-tolerant Agreement in Synchronous Message-Passing Systems. Morgan & Claypool—\\nSynthesis Lectures on Distributed Computing Theory series (2010)\\n51. Reynolds, A., Deters, M., Kuncak, V ., Tinelli, C., Barrett, C.W.: Counterexample-guided quantiﬁer instan-\\ntiation for synthesis in SMT. In: Proceedings of the CA V , pp. 198–216 (2015)\\n52. Schweikhart, N.: Arithmetic, ﬁrst-order logic, and counting quantiﬁers. In: ACM TOCL, pp. 1–35 (2004)\\n53. Solihin, Y .: Fundamentals of Parallel Computer Architecture Multichip and Multicore Systems. Solihin\\nPublishing & Consulting LLC, Raleigh (2008)\\n54. Srikanth, T.K., Toueg, S.: Optimal clock synchronization. JACM 34(3), 626–645 (1987)\\n55. Srikanth, T.K., Toueg, S.: Simulating authenticated broadcasts to derive simple fault-tolerant algorithms.\\nDistrib. Comput. 2(2), 80–94 (1987)', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='55. Srikanth, T.K., Toueg, S.: Simulating authenticated broadcasts to derive simple fault-tolerant algorithms.\\nDistrib. Comput. 2(2), 80–94 (1987)\\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and\\ninstitutional afﬁliations.\\n123', metadata={'pdf': 'https://link.springer.com/content/pdf/10.1007/s10817-020-09578-5.pdf', 'link': 'https://openalex.org/works/W3081978399', 'title': 'Higher-Order Quantifier Elimination, Counter Simulations and Fault-Tolerant Systems'}),\n",
              " Document(page_content='Clique Is Hard on Average for Regular Resolution\\nAlbert Atserias\\nUniversitat Politècnica de Catalunya\\nDepartment of Computer Science\\nBarcelona, Spain\\natserias@cs.upc.eduIlario Bonacina\\nUniversitat Politècnica de Catalunya\\nDepartment of Computer Science\\nBarcelona, Spain\\nbonacina@cs.upc.eduSusanna F. de Rezende\\nKTH Royal Institute of Technology\\nSchool of Electrical Engineering and\\nComputer Science\\nStockholm, Sweden\\nsfdr@kth.se\\nMassimo Lauria\\nSapienza Università di Roma\\nDepartment of Statistical Sciences\\nRome, Italy\\nmassimo.lauria@uniroma1.itJakob Nordström\\nKTH Royal Institute of Technology\\nSchool of Electrical Engineering and\\nComputer Science\\nStockholm, Sweden\\njakobn@kth.seAlexander Razborov\\nUniversity of Chicago\\nChicago, USA\\nrazborov@math.uchicago.edu\\nSteklov Mathematical Institute\\nMoscow, Russia\\nrazborov@mi.ras.ru\\nABSTRACT\\nWe prove that for k≪4√nregular resolution requires length nΩ(k)\\nto establish that an Erdős–Rényi graph with appropriately cho-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='ABSTRACT\\nWe prove that for k≪4√nregular resolution requires length nΩ(k)\\nto establish that an Erdős–Rényi graph with appropriately cho-\\nsen edge density does not contain a k-clique. This lower bound\\nis optimal up to the multiplicative constant in the exponent, and\\nalso implies unconditional nΩ(k)lower bounds on running time for\\nseveral state-of-the-art algorithms for finding maximum cliques in\\ngraphs.\\nCCS CONCEPTS\\n•Theory of computation →Proof complexity ;•Mathemat-\\nics of computing →Random graphs;\\nKEYWORDS\\nProof complexity, regular resolution, k-clique, Erdős-Rényi random\\ngraphs\\nACM Reference Format:\\nAlbert Atserias, Ilario Bonacina, Susanna F. de Rezende, Massimo Lauria,\\nJakob Nordström, and Alexander Razborov. 2018. Clique Is Hard on Aver-\\nage for Regular Resolution . In Proceedings of 50th Annual ACM SIGACT\\nSymposium on the Theory of Computing (STOC’18). ACM, New York, NY,\\nUSA, 12pages. https://doi.org/10.1145/3188745.3188856\\n1 INTRODUCTION', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='USA, 12pages. https://doi.org/10.1145/3188745.3188856\\n1 INTRODUCTION\\nDeciding whether a graph has a k-clique is one of the most basic\\ncomputational problems on graphs, and has been extensively stud-\\nied in computational complexity theory ever since it appeared in\\nKarp’s list of 21NP-complete problems [ 15]. Not only is this prob-\\nlem widely believed to be infeasible to solve exactly—unless P=NPthere does not even exist any polynomial-time algorithm for ap-\\nproximating the maximal size of a clique to within a factor n1−ϵ\\nfor any constant ϵ>0, where nis the number of vertices in the\\ngraph [ 13,34]. Furthermore, the problem appears to be hard not\\nonly in the worst case but also on average in the Erdős-Rényi ran-\\ndom graph model—we know of no efficient algorithms for finding\\ncliques of maximum size asymptotically almost surely on random\\ngraphs with appropriate edge densities [16, 31].\\nIn terms of upper bounds, the k-clique problem can clearly be\\nsolved in time roughly nksimply by checking if any of the\\x00n\\nk\\x01', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='graphs with appropriate edge densities [16, 31].\\nIn terms of upper bounds, the k-clique problem can clearly be\\nsolved in time roughly nksimply by checking if any of the\\x00n\\nk\\x01\\nmany sets of vertices of size kforms a clique, which is polynomial\\nifkis constant. This can be improved slightly to O(nωk/3)using\\nalgebraic techniques [ 26], whereω≤2.373is the matrix multipli-\\ncation exponent, although in practice such algebraic algorithms are\\noutperformed by combinatorial ones [33].\\nThe motivating problem behind this work is to determine the\\nexact time complexity of the clique problem when kis given as a\\nparameter. As noted above, all known algorithms require time nΩ(k).\\nIt appears quite likely that some dependence on kis needed in the\\nexponent, since otherwise we have the parameterized complexity\\ncollapse FPT=W[1] [11]. Even more can be said if we are willing\\nto believe the Exponential Time Hypothesis (ETH) [ 14]—then the\\nexponent has to depend linearly on k[8], so that the trivial upper\\nbound is essentially tight.\\nObtaining such a lower bound unconditionally would, in par-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='exponent has to depend linearly on k[8], so that the trivial upper\\nbound is essentially tight.\\nObtaining such a lower bound unconditionally would, in par-\\nticular, imply P,NP, and so currently seems completely out of\\nreach. But is it possible to prove nΩ(k)lower bounds in restricted\\nbut nontrivial models of computation? For circuit complexity, this\\nchallenge has been met for circuits that are of bounded depth [ 30]\\nor are monotone [ 32]. In this paper we focus on computational', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='but nontrivial models of computation? For circuit complexity, this\\nchallenge has been met for circuits that are of bounded depth [ 30]\\nor are monotone [ 32]. In this paper we focus on computational\\nmodels that are powerful enough to capture algorithms that are\\nused in practice.\\nWhen analysing such algorithms, it is convenient to view the\\nexecution trace as a proof establishing the maximal clique size\\nfor the input graph. In particular, if this graph does not have a\\nk-clique, then the trace provides an efficiently verifiable proof of\\nthe statement that the graph is k-clique -free. If one can establish a\\nlower bound on the length of such proofs, then this implies a lowerDefinitive Version in the ACM Digital Library:\\nhttps://dl.acm.org/citation.cfm?\\ndoid=3188745.3188856', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='bound on the running time of the algorithm, and this lower bound\\nholds even if the algorithm is a non-deterministic heuristic that\\nsomehow magically gets to make all the right choices. This brings\\nus to the topic of proof complexity [9], which can be viewed as the\\nstudy of upper and lower bounds in restricted nondeterministic\\ncomputational models.\\nUsing a standard reduction from k-clique to SAT, we can trans-\\nlate the problem of k-cliques in graphs to that of satisfiability of\\nformulas in conjunctive normal form (CNF). If an algorithm for\\nfinding k-cliques is run on a graph Gthat is k-clique -free, then we\\ncan extract a proof of the unsatisfiability of the corresponding CNF\\nformula—the k-clique formula on G—from the execution trace of\\nthe algorithm. Is it possible to show any non-trivial lower bound\\non the length of such proofs? Specifically, does the resolution proof\\nsystem—the method of reasoning underlying state-of-the-art SAT\\nsolvers [ 2,23,25]—require length nΩ(k), or at least nωk(1), to prove\\nthe absence of k-cliques in a graph? This question was asked in,\\ne.g., [7] and remains open.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='the absence of k-cliques in a graph? This question was asked in,\\ne.g., [7] and remains open.\\nThe hardness of k-clique formulas for resolution is also a problem\\nof intrinsic interest in proof complexity, since these formulas escape\\nknown methods of proving resolution lower bounds for a range\\nof interesting values of kincluding k=O(1). In particular, the\\ninterpolation technique [ 18,28], the random restriction method [ 4],\\nand the size-width lower bound [5] all seem to fail.\\nTo make this more precise, we should mention that some previ-\\nous works do use the size-width method, but only for very large k.\\nIt was shown in [ 3] that for n5/6≪k≤n/3resolution requires\\nlength exp\\x00nΩ(1)\\x01to certify that a dense enough Erdős-Rényi ran-\\ndom graph is k-clique-free. The constant hidden in the Ω(1)in-\\ncreases with the density of the graph and, in particular, for very\\ndense graphs and k=n/3the length required is 2Ω(n). Also, for\\na specially tailored CNF encoding, where the ith member of the', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='dense graphs and k=n/3the length required is 2Ω(n). Also, for\\na specially tailored CNF encoding, where the ith member of the\\nclaimed k-clique is encoded in binary by lognvariables, a lower\\nbound of nΩ(k)fork≤logncan be extracted from a careful read-\\ning of [ 21]. However, in the more natural unary encodings, where\\nindicator variables specify whether a vertex is in the clique, the\\nsize-width method cannot yield more than a 2Ω(k2/n)lower bound\\nsince there are resolution proofs of width O(k). This bound becomes\\ntrivial when k≤√n.\\nIn the restricted subsystem of tree-like resolution , optimal nΩ(k)\\nlength lower bounds were established in [ 6] for k-clique formulas\\non complete(k−1)-partite as well as on average for Erdős-Rényi\\nrandom graphs of appropriate edge density. There is no hope to get\\nhard instances for general resolution from complete (k−1)-partite\\ngraphs, however—in the same paper it was shown that all instances\\nfrom the more general class of (k−1)-colourable graphs are easy\\nfor resolution. A closer study of these resolution proofs reveals that', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='graphs, however—in the same paper it was shown that all instances\\nfrom the more general class of (k−1)-colourable graphs are easy\\nfor resolution. A closer study of these resolution proofs reveals that\\nthey are regular, meaning that if the proof is viewed as a directed\\nacyclic graph (DAG), then no variable is eliminated more than once\\non any source-to-sink path.\\nMore generally, regular resolution is an interesting and non-\\ntrivial model to analyse for the k-clique problem since it captures\\nthe reasoning used in many state-of-the-art algorithms used in prac-\\ntice (for a survey, see, e.g., [ 24,27]). Nonetheless, it has remained\\nconsistent with state-of-the-art knowledge that for k≤n5/6regularresolution might be able to certify k-clique -freeness in polynomial\\nlength independent of the value of k.\\nOur contribution. We prove optimal nΩ(k)average-case lower\\nbounds for regular resolution proofs of unsatisfiability for k-clique\\nformulas on Erdős-Rényi random graphs.\\nTheorem 1.1 (Informal). For any integer k≪4√n, given an', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='formulas on Erdős-Rényi random graphs.\\nTheorem 1.1 (Informal). For any integer k≪4√n, given an\\nn-vertex graph Gsampled at random from the Erdős-Rényi model\\nwith the appropriate edge density, regular resolution asymptotically\\nalmost surely requires length nΩ(k)to certify that Gdoes not contain\\nak-clique.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='with the appropriate edge density, regular resolution asymptotically\\nalmost surely requires length nΩ(k)to certify that Gdoes not contain\\nak-clique.\\nIn order to make this formal, we need to define how the prob-\\nlem is encoded: depending on the formula considered, the exact\\nstatement of what we can prove differs. In this conference paper\\nwe consider the simpler encoding for which we can prove an nΩ(k)\\nlower bound for k≪√n. For a stronger encoding, which in par-\\nticular captures this simpler one, we prove the above result in the\\nfull-length version of this paper.\\nAt a high level, the proof is based on a bottleneck counting\\nargument in the style of [ 12] with a slight twist that was introduced\\nin [29]. In its classical form, such a proof takes four steps. First,\\none defines a distribution of random source-to-sink paths on the\\nDAG representation of the proof. Second, a subset of the vertices\\nof the DAG is identified—the set of bottleneck nodes —such that\\nany random path must necessarily pass through at least one such\\nnode. Third, for any fixed bottleneck node, one shows that it is very\\nunlikely that a random path passes through this particular node.\\nGiven this, a final union bound argument yields the conclusion that', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='node. Third, for any fixed bottleneck node, one shows that it is very\\nunlikely that a random path passes through this particular node.\\nGiven this, a final union bound argument yields the conclusion that\\nthe DAG must have many bottleneck nodes, and so the resolution\\nproof must be long.\\nThe twist in our argument is that, instead of single bottleneck\\nnodes, we need to define bottleneck pairs of nodes. We then argue\\nthat any random path passes through at least one such pair but\\nthat few random paths pass through any fixed pair; the latter part\\nis based on Markov chain-type reasoning similar to [ 29, Theorems\\n3.2, 3.5]. Furthermore, it crucially relies on that the graph satisfies\\na certain combinatorial property, which captures the idea that the\\ncommon neighbourhood of a small set of vertices is well distributed\\nacross the graph. Identifying this combinatorial property is a key\\ncontribution of our work. In a separate argument (that, surprisingly,\\nturned out to be much more elaborate than most arguments of\\nthis kind) we then establish that Erdős-Rényi random graphs of\\nthe appropriate edge density satisfy this property asymptotically\\nalmost surely. Combining these two facts yields our average-case\\nlower bound.\\nAnother contribution of this paper is a relatively simple ob-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='the appropriate edge density satisfy this property asymptotically\\nalmost surely. Combining these two facts yields our average-case\\nlower bound.\\nAnother contribution of this paper is a relatively simple ob-\\nservation that not only is regular resolution powerful enough to\\ndistinguish graphs that contain k-cliques from(k−1)-colourable\\ngraphs [ 6], but it can also distinguish them from graphs that have\\na homomorphism to any fixed graph Hwith no k-cliques.\\nPaper outline. The rest of this paper is organized as follows. Sec-\\ntion 2presents some preliminaries. We show that some nontrivial\\nk-clique instances are easy for regular resolution in Section 3. Sec-\\ntion4contains the formal statement of the lower bounds we prove\\nfor Erdős-Rényi random graphs. In Section 5we define a combina-\\ntorial property of graphs and show that clique formulas on such', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='graphs are hard for regular resolution, and the proof that Erdős-\\nRényi random graphs satisfy this property asymptotically almost\\nsurely is in Section 6. We conclude in Section 7with a discussion\\nof open problems.\\n2 PRELIMINARIES\\nWe write G=(V,E)to denote a graph with vertices Vand edges E,\\nwhere Gis always undirected, without loops and multiple edges.\\nGiven a vertex v∈V, we write N(v)={u|there exists v∈V\\nsuch that{u,v}∈E}to denote the set of neighbours of v. For a\\nset of vertices R⊆Vwe write bN(R)=Ñ\\nv∈RN(v)to denote the\\nset of common neighbours of R. For two sets of vertices R⊆V\\nandW⊆Vwe write bNW(R)=bN(R)∩Wto denote the set of\\ncommon neighbours of Rinside W. For a set U⊆Vwe denote by\\nG[U]the subgraph of Ginduced by the set U. For n∈N+we write', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='common neighbours of Rinside W. For a set U⊆Vwe denote by\\nG[U]the subgraph of Ginduced by the set U. For n∈N+we write\\n[n]={1, . . . , n}. We say that V1.∪V2.∪···.∪Vk=Vis abalanced\\nk-partition of Vif for all i,j∈[k]it holds that|Vi|≤|Vj|+1. All\\nlogarithms are natural (base e) if not specified otherwise.\\nProbability and Erdős-Rényi random graphs. We denote random\\nvariables in boldface and write X∼Dto denote that Xis sampled\\nfrom the distribution D. Ap-biased coin, or a Bernoulli variable, is\\nthe outcome of a coin flip that yields 1with probability pand0with\\nprobability 1−p. We use the special case of Markov’s inequality\\nsaying that if Xis non-negative, then Pr[X≥1]≤E[X]. We also\\nneed the following special case of the multiplicative Chernoff bound:\\nifXis a binomial random variable (i.e., the sum of i.i.d. Bernoulli', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='need the following special case of the multiplicative Chernoff bound:\\nifXis a binomial random variable (i.e., the sum of i.i.d. Bernoulli\\nvariables) with expectation µ=E[X], then Pr[X≤µ/2]≤ e−µ/8.\\nWe consider the Erdős-Rényi distribution G(n,p)of random\\ngraphs on a fixed set Vofnvertices. A random graph sampled from\\nG(n,p)is produced by placing each potential edge {u,v}indepen-\\ndently with probability p,0≤p≤1(the edge probability pmay\\nbe a function of n). A property of graphs is said to hold asymptot-\\nically almost surely onG(n,p(n))if it holds with probability that\\napproaches 1asnapproaches infinity.\\nFor a positive integer k, letXkbe the random variable that\\ncounts the number of k-cliques in a random graph from G(n,p). It\\nfollows from Markov’s inequality that asymptotically almost surely\\nthere are no k-cliques in G(n,p)whenever pandkare such that\\nE[Xk]=p(k\\n2)\\x00n', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='there are no k-cliques in G(n,p)whenever pandkare such that\\nE[Xk]=p(k\\n2)\\x00n\\nk\\x01approaches 0asnapproaches infinity. This is the\\ncase, for example, if p=n−2η/(k−1)fork≥2andη>1.\\nCNF formulas and resolution. Aliteral over a Boolean variable x\\nis either the variable xitself (a positive literal ) or its negation¬x(a\\nnegative literal ). Aclause C=a1∨···∨ awis a disjunction of literals;\\nwe say that the width ofCisw. The empty clause will be denoted\\nby⊥. ACNF formula F=C1∧···∧ Cmis a conjunction of clauses.\\nWe think of clauses as sets of literals and of CNF formulas as sets\\nof clauses, so that order is irrelevant and there are no repetitions.\\nFor a formula Fwe denote by Vars(F)the set of variables of F.\\nAresolution derivation from a CNF formula Fis as an ordered\\nsequence of clauses π=(D1, . . . , DL)such that for each i∈[L]', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Aresolution derivation from a CNF formula Fis as an ordered\\nsequence of clauses π=(D1, . . . , DL)such that for each i∈[L]\\neither Diis a clause in For there exist j<iandk<isuch that Di\\nis derived from DjandDkby the resolution rule\\nB∨x C∨¬x\\nB∨C, (1)Di=B∨C,Dj=B∨x,Dk=C∨¬x. We refer to B∨Cas the\\nresolvent ofB∨xandC∨¬xover x, and to xas the resolved variable.\\nThelength (orsize) of a resolution derivation π=(D1, . . . , DL)isL\\nand it is denoted by |π|. Aresolution refutation ofF, orresolution\\nproof for (the unsatisfiability of) F, is a resolution derivation from F\\nthat ends in the empty clause ⊥.\\nA resolution derivation π=(D1, . . . , DL)can also be viewed as\\na labelled DAG with set of nodes {1, . . . , L}and edges(j,i),(k,i)for\\neach application of the resolution rule deriving Difrom DjandDk.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='a labelled DAG with set of nodes {1, . . . , L}and edges(j,i),(k,i)for\\neach application of the resolution rule deriving Difrom DjandDk.\\nEach node iin this DAG is labelled by its associated clause Di, and\\neach non-source node is also labelled by the resolved variable in its\\nassociated derivation step in the refutation. A resolution refutation\\nis called regular if along any source-to-sink path in its associated\\nDAG every variable is resolved at most once.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='associated derivation step in the refutation. A resolution refutation\\nis called regular if along any source-to-sink path in its associated\\nDAG every variable is resolved at most once.\\nFor a partial assignment ρwe say that a clause Crestricted\\nbyρ, denoted C↾ρ, is the trivial 1-clause if any of the literals\\ninCis satisfied by ρor otherwise is Cwith all falsified literals\\nremoved. We extend this definition to CNFs in the obvious way:\\n(C1∧. . .∧Cm)↾ρ=C1↾ρ∧. . .∧Cm↾ρ. Applying a restriction pre-\\nserves (regular) resolution derivations. To see this, observe that in\\nevery application of the resolution rule the restricted consequence\\nis either killed (becomes identically 1) or obtained, as before, by\\nresolving the two restricted premises or it is a copy of one of them.\\nThus, we have:\\nFact 2.1. Letπbe a (regular) resolution refutation of a CNF for-\\nmula F. For any partial assignment ρto the variables of Fthere is\\nan efficiently constructible (regular) resolution refutation π↾ρof the', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='mula F. For any partial assignment ρto the variables of Fthere is\\nan efficiently constructible (regular) resolution refutation π↾ρof the\\nCNF formula F↾ρ, so that the length of π↾ρis at most the length of π.\\nBranching programs. A branching program on variables x1, . . . , xn\\nis a DAG that has one source node and where every non-sink node\\nis labelled by one of the variables x1, . . . , xnand has exactly two\\noutgoing edges labelled 0and1. The size of a branching program\\nis the total number of nodes in the graph. In a read-once branching\\nprogram it holds in addition that along every path every variable\\nappears as a node label at most once.\\nFor each node ain a branching program, let X(a)denote the\\nvariable that labels a, and let a0anda1be the nodes that are reached\\nfrom athrough the edges labelled 0and1, respectively. A truth-\\nvalue assignment σ:{x1, . . . , xn}→{ 0,1}determines a path in\\na branching program in the following way. The path starts at the\\nsource node. At an internal node a, the path is extended along the', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='a branching program in the following way. The path starts at the\\nsource node. At an internal node a, the path is extended along the\\nedge labelled σ(X(a))so that the next node in the path is aσ(X(a)).\\nThe path ends when it reaches a sink. We write path(σ)for the\\npath determined by σ. When extending the path from a node ato\\nthe node aσ(X(a)), we say that the answer to the query X(a)atais\\nσ(X(a))and that the path setsthe variable X(a)to the value σ(X(a)).\\nFor each node aof the branching program, let β(a)be the maximal\\npartial assignment that is contained in any assignment σsuch that\\npath(σ)passes through a. Equivalently, this is the set of all those\\nσ(xi)=γfor which the query xiis made, and answered by γ,\\nalong every consistent path from the source to a. If the program is\\nread-once, the consistency condition becomes redundant.\\nThefalsified clause search problem for an unsatisfiable CNF for-\\nmula Fis the task of finding a clause C∈Fthat is falsified by a\\ngiven truth value assignment σ. A branching program Pon the', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Thefalsified clause search problem for an unsatisfiable CNF for-\\nmula Fis the task of finding a clause C∈Fthat is falsified by a\\ngiven truth value assignment σ. A branching program Pon the\\nvariables Vars(F)solves the falsified clause search problem for F', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='if each sink is labelled by a clause of Fsuch that for every assign-\\nmentσ, the clause that labels the sink reached by path(σ)is falsified\\nbyσ. The minimal size of any regular resolution refutation of an\\nunsatisfiable CNF formula Fis exactly the same as the minimal size\\nof any read-once branching program solving the falsified clause\\nsearch problem for F. This can be seen by taking the refutation\\nDAG and reversing the edges to get a branching program or vice\\nversa. For a formal proof see, e.g., [19, Theorem 4.3].\\nThek-clique formula. In order to analyse the complexity of res-\\nolution proofs that establish that a given graph does not contain\\nak-clique we must formulate the problem as a propositional for-\\nmula in conjunctive normal form (CNF). We consider two distinct\\nencodings for the clique problem originally defined in [3].\\nThe first propositional encoding we present, Clique(G,k), is\\nbased on mapping of vertices to clique members. This formula\\nis defined over variables xv,i(v∈V,i∈[k])and consists of the\\nfollowing set of clauses:', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='based on mapping of vertices to clique members. This formula\\nis defined over variables xv,i(v∈V,i∈[k])and consists of the\\nfollowing set of clauses:\\n¬xu,i∨¬xv,j i,j∈[k],i,j,u,v∈V,{u,v}<E, (2a)\\nÜ\\nv∈Vxv,i i∈[k], (2b)\\n¬xu,i∨¬xv,i i∈[k],u,v∈V,u,v, (2c)\\nWe refer to (2a)asedge axioms, (2b)asclique axioms and(2c)as\\nfunctionality axioms. Note that Clique(G,k)is satisfiable if and only\\nifGcontains a k-clique, and that this is true even if clauses (2c)are\\nomitted—we write Clique∗(G,k)to denote this formula with only\\nclauses (2a) and (2b).\\nThe second version of clique formulas that we consider is the\\nblock encoding Clique block(G,k). This formula differs from the pre-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='clauses (2a) and (2b).\\nThe second version of clique formulas that we consider is the\\nblock encoding Clique block(G,k). This formula differs from the pre-\\nvious ones in that it requires a k-clique that has a certain “block-\\nrespecting” structure. Let V1Û∪V2Û∪. . .Û∪Vk=Vbe a balanced k-\\npartition of V. This formula, defined over variables xv, encodes the\\nfact that the graph contains a transversal k-clique , that is, a k-clique\\nin which each clique member belongs to a different block. Formally,\\nfor any positive kandn, the formula Clique block(G,k)consists of\\nthe following set of clauses:\\n¬xu∨¬xv u,v∈V,u,v,{u,v}<E, (3a)\\nÜ\\nv∈Vixv i∈[k], (3b)\\n¬xu∨¬xv i∈[k],u,v∈Vi,u,v. (3c)\\nNote that a graph can contain a k-clique but contain no transver-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='¬xu∨¬xv i∈[k],u,v∈Vi,u,v. (3c)\\nNote that a graph can contain a k-clique but contain no transver-\\nsalk-clique for a given partition. Intuitively it is clear that proving\\nthat a graph does not contain a transversal k-clique should be easier\\nthan proving it does not contain any k-clique, since any proof of\\nthe latter fact must in particular establish the former. We make this\\nintuition formal below.\\nLemma 2.2 ([ 3]).For any graph Gand any k∈N+, the size of\\na minimum regular resolution refutation of Clique(G,k)is bounded\\nfrom below by the size of a minimum regular resolution refutation of\\nClique block(G,k).This lemma was proven in [ 3] for tree-like and for general reso-\\nlution via a restriction argument, and it is straightforward to see\\nthat the same proof holds for regular resolution.\\n3 EASY GRAPHS FOR REGULAR RESOLUTION\\nBefore proving our main nΩ(k)lower bound, in this section we\\nexhibit classes of graphs whose clique formulas have regular reso-\\nlution refutations of fixed-parameter tractable length, i.e., length', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='exhibit classes of graphs whose clique formulas have regular reso-\\nlution refutations of fixed-parameter tractable length, i.e., length\\nf(k)·nO(1)for some function f. This illustrates the strength of\\nregular resolution for the k-clique problem. We note that the upper\\nbounds claimed in this section hold not only for Clique(G,k)but\\neven for the subformula Clique∗(G,k)that omits the functionality\\naxioms (2c).\\nThe first example is the class of (k−1)-colourable graphs. Such\\ngraphs are hard for tree-like resolution [ 6], and the known algo-\\nrithms that distinguish them from graphs that contain k-cliques\\nare highly non-trivial [ 17,22]. The second example is the class of\\ngraphs that have a homomorphism into a fixed k-clique free graph.\\nRecall that a homomorphism from a graph G=(V,E)into a\\ngraph G′=(V′,E′)is a mapping h:V→V′that maps edges\\n{u,v}∈Einto edges{h(u),h(v)}∈ E′. A graph is(k−1)-colourable', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='{u,v}∈Einto edges{h(u),h(v)}∈ E′. A graph is(k−1)-colourable\\nif and only if it has a homomorphism into the (k−1)-clique, which\\nis of course k-clique free. Therefore our second example is a gener-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='{u,v}∈Einto edges{h(u),h(v)}∈ E′. A graph is(k−1)-colourable\\nif and only if it has a homomorphism into the (k−1)-clique, which\\nis of course k-clique free. Therefore our second example is a gener-\\nalization of the first one (but the function f(k)becomes larger).\\nBoth upper bounds follows from a generic procedure, based on\\nAlgorithm 1, that builds read-once branching programs for the\\nfalsified clause search problem for Clique∗(G,k).\\nGiven a k-clique free graph Gdefine\\nI(G)=\\x08\\nG\\x02bN(R)\\x03\\n:Ris a clique in G\\t\\n. (4)\\nProposition 3.1. There is an efficiently constructible read-once\\nbranching program for the falsified clause search problem on formula\\nClique∗(G,k)of size at most|I(G)|·k2·|V(G)|2.\\nProof. We build the branching program recursively, following\\nthe strategy laid out by Algorithm 1. For the base case k=1,G\\nmust be the graph with no vertices. The branching program is a', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Proof. We build the branching program recursively, following\\nthe strategy laid out by Algorithm 1. For the base case k=1,G\\nmust be the graph with no vertices. The branching program is a\\nsingle sink node that outputs the clique axiom of index 1, i.e., the\\nempty clause.\\nFork>1, fix n=|V(G)|and an ordering v1, . . . ,vnof the\\nvertices in V(G). We first build a decision tree Tby querying the\\nvariables xv1,k,xv2,k, . . .in order, until we get an answer 1, or until\\nall variables with second index khave been queried. If xvj,k=0\\nfor all j∈[n]then the kth clique axiom (2b)is falsified by the\\nassignment (see line 14). Otherwise, let vbe the first vertex in\\nthe order where xv,k=1. The decision tree now queries xw,i\\nfor all w<N(v)and all i<kto check whether an edge axiom\\ninvolvingvis falsified (lines 4–6). If any of these variables is set\\nto1the branching stops and the leaf node is labelled with the', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='involvingvis falsified (lines 4–6). If any of these variables is set\\nto1the branching stops and the leaf node is labelled with the\\ncorresponding edge axiom ¬xv,k∨¬xw,i.\\nThe decision tree Tbuilt so far has at most kn2nodes, and we\\ncan identify n“open” leaf nodes av1,av2, . . . , avn, where aviis the\\nleaf node reached by the path that sets xvi,k=1and that does\\nyet determine the answer to the search problem. Let us focus on\\na specific node avfor somev∈V(G). The partial assignment\\npath( av)setsvto be the kth member of the clique and no vertex\\ninV(G)\\\\N(v)to be in the clique. Let Gvbe the subgraph induced', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Algorithm 1 Read-once branching program for the falsified clause\\nsearch problem on Clique∗(G,k).\\nInput k∈N+, ak-clique free graph G, an assignment\\nα:{xv,iforv∈V(G),i∈[k]}→{ 0,1}\\nOutput A clause of Clique∗(G,k)falsified by α\\n1:procedure Search( G,k,α)\\n2: forv∈V(G)do\\n3: ifα(xv,k)=1then\\n4: forw<N(v)andi<kdo\\n5: ifα(xw,i)=1then\\n6: return edge axiom¬xv,k∨¬xw,i(2a).\\n7: end if\\n8: end for\\n9: G′←G[N(v)]\\n10: α′←αrestricted to variables xw,jforw∈V(G′)\\nand1≤j≤k−1\\n11: return Search( G′,k−1,α′)\\n12: end if\\n13: end for\\n14: return thekth clique axiom (2b).\\n15:end procedure', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='11: return Search( G′,k−1,α′)\\n12: end if\\n13: end for\\n14: return thekth clique axiom (2b).\\n15:end procedure\\nonGbyN(v), letSvbe the set of variables xw,iforw∈N(v)and\\ni<k, and letρvbe the partial assignment setting xw,i=0for\\nw<N(v)andi<k. Clearlyρv⊆path( av).\\nBy the inductive hypothesis there exists a branching program Bv\\nthat solves the search problem on Clique∗(Gv,k−1)querying\\nonly variables in Sv. This corresponds to the recursive call for the\\nsubgraph Gvandk−1(lines 9–11). If we attach each Bvtoavwe\\nget a complete branching program for Clique∗(G,k). This is read-\\nonce because Bvonly queries variables in Svand these variables\\nare not in path( av).\\nTo prove that the composed program is correct we consider\\nan assignment σto the variables in Svand show that the clause\\noutput by Bvonσis also a valid output for the search problem', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='are not in path( av).\\nTo prove that the composed program is correct we consider\\nan assignment σto the variables in Svand show that the clause\\noutput by Bvonσis also a valid output for the search problem\\nonClique∗(G,k), i.e., it is falsified by the assignment path( av)∪σ.\\nActually we show the stronger claim that it is falsified by ρv∪σ,\\nwhich is a subset of path( av)∪σ. To this end, note that if the output\\nofBvonσis an edge axiom of Clique∗(Gv,k−1), this must be\\nsome¬xu,i∨¬xw,jfori,j<k, which is also an edge axiom of\\nClique∗(G,k)and is falsified by σ⊆ρv∪σ. Now if the output\\nofBvonσis the ith clique axiom of Clique∗(Gv,k−1), thenσ\\nfalsifiesÔ\\nw∈N(v)xv,i, and therefore ρv∪σfalsifies the ith clique\\naxiom in formula Clique∗(G,k).\\nThe construction so far is correct but produces a very large', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='axiom in formula Clique∗(G,k).\\nThe construction so far is correct but produces a very large\\nbranching program (in particular, a tree-like one). In order to create\\na smaller branching program, we observe that if u,v∈V(G)are\\nsuch that N(u)=N(w)then Gu=Gw,Bu=Bwandρu=ρw. In\\nthis case, we can identify nodes auandaw, resulting in a node we\\ndenote a∗, and identify the branching programs BuandBw. The\\ncorrectness of this new program is due to the fact that even after\\nthe identification of vertices ρu⊆path( a∗)andρw⊆path( a∗).\\nThis process leads to having only one subprogram for each distinct\\ninduced subgraph at each level of the recursion.In order to bound the size of this program, we decompose it\\ninto klevels. The source is at level zero and corresponds to the\\ngraph G. At level ithere are nodes corresponding to all subgraphs\\ninduced by the common neighbourhood of cliques of size i. Each\\nnode in the ith level connects to the nodes of the (i+1)th level by\\na branching program of size at most kn2. Notice that an induced', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='induced by the common neighbourhood of cliques of size i. Each\\nnode in the ith level connects to the nodes of the (i+1)th level by\\na branching program of size at most kn2. Notice that an induced\\nsubgraph in I(G)cannot occur twice in the same layers, so the\\ntotal size of the final branching program is at most |I(G)|·k2n2\\nnodes. □\\nWe now proceed to prove the upper bounds mentioned previ-\\nously. A graph Gthat has a homomorphism into a small k-clique\\nfree graph Hmay still have a large set I(G), making Proposition 3.1\\ninefficient. The first key observation is that if Ghas a homomor-\\nphism into a graph Hthen it is a subgraph of a blown up version\\nofH, namely, of a graph obtained by transforming each vertex of H\\ninto a “cloud” of vertices where a cloud does not contain any edge,\\ntwo clouds corresponding to two adjacent vertices in Hhave all\\npossible edges between them, and two clouds corresponding to two\\nnon-adjacent vertices in Hhave no edges between them. A second\\ncrucial point is that if G′is a blown up version of Hthen it turns out', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='possible edges between them, and two clouds corresponding to two\\nnon-adjacent vertices in Hhave no edges between them. A second\\ncrucial point is that if G′is a blown up version of Hthen it turns out\\nthat|I(G′)|=|I(H)|, making Proposition 3.1effective for G′. The\\nupper bound then follows from observing that the task of proving\\nthatGisk-clique free should not be harder than the same task for\\na supergraph of G. Indeed Fact 3.2formalises this intuition. It is\\ninteresting to observe that the constructions in Proposition 3.1and', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='thatGisk-clique free should not be harder than the same task for\\na supergraph of G. Indeed Fact 3.2formalises this intuition. It is\\ninteresting to observe that the constructions in Proposition 3.1and\\nin Fact 3.2are efficient. The non-constructive part is guessing the\\nhomomorphism to H.\\nFact 3.2. LetG=(V,E)andG′=(V′,E′)be graphs with no\\nk-clique such that V⊆V′andE⊆E′∩\\x00V\\n2\\x01. IfClique∗(G′,k)has a\\n(regular) refutation of length L, then Clique∗(G,k)also has a (regular)\\nrefutation of length L.\\nProof. Consider the partial assignment ρthat sets xv,i=0for\\neveryv<Vandi∈[k]. The restricted formula Clique∗(G′,k)↾ρis\\nisomorphic to Clique∗(eG,k), where V(eG)=VandE(eG)=E′∩\\x00V\\n2\\x01,\\nand thus, by Fact 2.1, has a (regular) refutation πof length at most L.\\nRemoving edges from a graph only introduces additional edge', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='2\\x01,\\nand thus, by Fact 2.1, has a (regular) refutation πof length at most L.\\nRemoving edges from a graph only introduces additional edge\\naxioms (2a)in the corresponding formula, therefore Clique∗(eG,k)⊆\\nClique∗(G,k)andπis a valid refutation of Clique∗(G,k)as well. □\\nIt was shown in [ 6] that the k-clique formula of a complete (k−1)-\\npartite graph on nvertices has a regular resolution refutation of\\nlength 2knO(1), although the regularity is not stressed in that paper.\\nSince it is instructive to see how this refutation is constructed in\\nthis framework, we give a self-contained proof.\\nProposition 3.3 ([ 6, Proposition 5.3]). IfGis a(k−1)-colourable\\ngraph on nvertices, then Clique∗(G,k)has a regular resolution refu-\\ntation of length at most 2kk2n2.\\nProof. LetV=V(G)and let V1Û∪V2Û∪. . .Û∪V(k−1)be a partition', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='tation of length at most 2kk2n2.\\nProof. LetV=V(G)and let V1Û∪V2Û∪. . .Û∪V(k−1)be a partition\\nofVinto colour classes. Define the graph G′=(V,E′)where the\\nedge set E′has an edge between any pair of vertices belonging to\\ntwo different colour classes. Clearly Gis a subgraph of G′. Observe\\nthat any clique RinG′has at most one vertex in each colour class,\\nand that the common neighbours of Rare all the vertices in the\\ncolour classes not touched by R.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Therefore, there is a one-to-one correspondence between the\\nmembers of I(G′)and the subsets of [k−1]. By Proposition 3.1\\nthere is a read-once branching program for the falsified clause\\nsearch problem on formula Clique∗(G′,k)of size at most 2kk2n2.\\nThis read-once branching program corresponds to a regular resolu-\\ntion refutation of Clique∗(G′,k)of the same size. By Fact 3.2there\\nmust be a regular resolution refutation of size at most 2kk2n2for\\nClique∗(G,k)as well. □\\nNext we generalize Proposition 3.3to graphs Gthat have a ho-\\nmomorphism to a k-clique free graph H.\\nProposition 3.4. IfGis a graph on nvertices that has a homomor-\\nphism into a k-clique free graph Honmvertices, then Clique∗(G,k)\\nhas a regular resolution refutation of length at most mkk2n2.\\nProof. Fix a homomorphism h:V(G)→V(H)and an ordering', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='has a regular resolution refutation of length at most mkk2n2.\\nProof. Fix a homomorphism h:V(G)→V(H)and an ordering\\nu1, . . . , umof the vertices of H. LetV1Û∪V2Û∪. . .Û∪Vmbe the partition\\nofV(G)such that Viis the set of vertices of Gmapped to uibyh.\\nWe define the graph G′=(V,E′)where\\nE′=Ø\\n{ui,uj}∈E(H)Vi×Vj, (5)\\nthat is, G′is a blown up version of Hthat contains Gas a subgraph.\\nTo prove our result we note that, by Proposition 3.1, there is a read-\\nonce branching program for the falsified clause search problem on\\nClique∗(G′,k)—and hence also a regular resolution refutations of\\nthe same formula—of size at most |I(G′)|·k2n2. This implies that,\\nby Fact 3.2, there is a regular resolution refutation of Clique∗(G,k)\\nof at most the same size.\\nTo conclude the proof it remains only to show that |I(G′)|≤mk.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='of at most the same size.\\nTo conclude the proof it remains only to show that |I(G′)|≤mk.\\nBy construction, hmaps injectively a clique R⊆V(G′)into a clique\\nRH⊆V(H)of the same size. Moreover, note that if U=bN(RH),\\nthenbN(R)=∪ui∈UVi. Therfore, for any clique R′⊆V(G′)that\\nis mapped by htoRHit holds that bN(R)=bN(R′), i.e.,bN(R′)is\\ncompletely characterized by the clique in Hit is mapped to. Thus\\nI(G)has at most one element for each clique in Hand we have that\\n|I(G′)|=|I(H)|. Finally, note that|I(H)|≤mksince, being k-clique\\nfree, Hcannot have more than mkcliques. □\\n4 RANDOM GRAPHS ARE HARD\\nThe main result of this paper is an average case lower bound of\\nnΩ(k)for regular resolution for the k-clique problem. As we saw in\\nSection 2, the k-clique problem can be encoded in different ways', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='nΩ(k)for regular resolution for the k-clique problem. As we saw in\\nSection 2, the k-clique problem can be encoded in different ways\\nand depending on the preferred formula the range of kfor which\\nwe can obtain a lower bound differs. In this section we present a\\nsummary of our results for the different encodings.\\nTheorem 4.1. For any real constant ϵ>0, any sufficiently large\\ninteger n, any positive integer k≤n1/4−ϵ, and any real ξ>1, if\\nG∼G(n,n−2ξ/(k−1))is an Erdős-Rényi random graph, then, with\\nprobability at least 1−exp(−√n), any regular resolution refutation\\nofClique block(G,k)has length at least nΩ(k/ξ2).\\nThe parameter ξdetermines the density of the graph: the larger ξ\\nthe sparser the graph and the problem of determining whether G\\ncontains a k-clique becomes easier. For constant ξ, where the edge\\nprobability is somewhat close to the threshold for containing ak-clique, the theorem yields a nΩ(k)lower bound which is tight up', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='probability is somewhat close to the threshold for containing ak-clique, the theorem yields a nΩ(k)lower bound which is tight up\\nto the multiplicative constant in the exponent. The lower bound\\ndecreases smoothly with the edge density and is non-trivial for\\nξ=o(√\\nk).\\nA problem which is closely related to the problem we consider is\\nthat of distinguishing a random graph sampled from G(n,p)from\\na random graph from the same distribution with a planted k-clique.\\nThe most studied setting is when p=1/2. In this scenario the\\nproblem can be solved in polynomial time with high probability\\nfork≈√n[1,20]. It is still an open problem whether there exists\\na polynomial time algorithm solving this problem for logn≪\\nk≪√n. ForG∼G(n,1/2), Theorem 4.1implies that to refute\\nClique block(G,k)asymptotically almost surely regular resolution\\nrequires nΩ(logn)size for k=O(logn)and super-polynomial size\\nfork=o(log2n).\\nAn interesting question is whether Theorem 4.1holds for larger', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='requires nΩ(logn)size for k=O(logn)and super-polynomial size\\nfork=o(log2n).\\nAn interesting question is whether Theorem 4.1holds for larger\\nvalues of k. We show that for the formula Clique(G,k)(recall that\\nby Lemma 2.2this encoding is easier for the purpose of lower', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='An interesting question is whether Theorem 4.1holds for larger\\nvalues of k. We show that for the formula Clique(G,k)(recall that\\nby Lemma 2.2this encoding is easier for the purpose of lower\\nbounds) we can prove the lower bound for k≤n1/2−ϵas long as\\nthe edge density of the graph is close to the threshold for containing\\nak-clique.\\nTheorem 4.2. For any real constant ϵ>0, any sufficiently large\\ninteger n, any positive integer k, and any real ξ>1such that kp\\nξ≤\\nn1/2−ϵ, ifG∼G(n,n−2ξ/(k−1))is an Erdős-Rényi random graph,\\nthen, with probability at least 1−exp(−√n), any regular resolution\\nrefutation of Clique(G,k)has length at least nΩ(k/ξ2).\\nIn this extended abstract we prove Theorem 4.2and we refer to\\nthe upcomming full-length version of this paper for the proof of\\nTheorem 4.1. We note, however, that both proofs are very similar\\nand having seen one it is an easy exercise to obtain the other. The', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='the upcomming full-length version of this paper for the proof of\\nTheorem 4.1. We note, however, that both proofs are very similar\\nand having seen one it is an easy exercise to obtain the other. The\\nproof of Theorem 4.2is deferred to Section 6and is based on a\\ngeneral lower bound technique we develop in Section 5.\\n5 CLIQUE-DENSENESS IMPLIES HARDNESS\\nIn this section we define a combinatorial property of graphs, which\\nwe call clique-denseness, and prove that if a k-clique -free graph Gis\\nclique-dense with the appropriate parameters, then this implies a\\nlower bound nΩ(k)on the length of any regular resolution refutation\\nof the k-clique formula on G.\\nIn order to argue that regular resolution has a hard time certi-\\nfying the k-clique -freeness of a graph G, one property that seems\\nuseful to have is that for every small enough clique in the graph\\nthere are many ways of extending it to a larger clique. In other\\nwords, if R⊆Vforms a clique and Ris small, we would like the\\ncommon neighbourhood bNV(R)to be large. This motivates the\\nfollowing definitions.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='words, if R⊆Vforms a clique and Ris small, we would like the\\ncommon neighbourhood bNV(R)to be large. This motivates the\\nfollowing definitions.\\nDefinition 5.1 (Neighbour-dense set). Given a graph G=(V,E)\\nandq,r∈R+, a set W⊆Visq-neighbour-dense for R⊆Vif\\x0c\\x0cbNW(R)\\x0c\\x0c≥q. We say that Wis(r,q)-neighbour-dense if it is q-neigh-\\nbour-dense for every R⊆Vof size|R|≤r.\\nIfWis an(r,q)-neighbour-dense set, then we know that any\\nclique of size rcan be extended to a clique of size r+1in at least q\\ndifferent ways by adding some vertex of W. Note, however, that', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='the definition of(r,q)-neighbour-dense is more general than this\\nsince Ris not required to be a clique.\\nWe next define a more robust notion of neighbour-denseness.\\nFor some settings of randqof interest to us it is too much to\\nhope for a set Wwhich is q-neighbour-dense for every R⊆Vof\\nsize at most r. In this case we would still like to be able to find a\\n“mostly neighbour-dense” set Win the sense that we can “localize”\\nbad sets R⊆Vof size|R|≤r, i.e., those for which Wfails to be\\nq-neighbour-dense.\\nDefinition 5.2 (Mostly neighbour-dense set). Given G=(V,E)\\nandr′,r,q′,s∈R+with r′≥r, a set W⊆Vis(r′,r,q′,s)-mostly\\nneighbour-dense if there exists a set S⊆Vof size|S|≤ssuch that\\nfor every R⊆Vwith|R|≤r′for which Wis not q′-neighbour-\\ndense, it holds that |R∩S|≥r.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='for every R⊆Vwith|R|≤r′for which Wis not q′-neighbour-\\ndense, it holds that |R∩S|≥r.\\nIn what follows, it might be helpful for the reader to think of r′\\nandras linear in kandqandsas polynomial in n, where we also\\nhave that s≪q.\\nNow we are ready to define a property of graphs that makes it\\nhard for regular resolution to certify that graphs with this property,\\nbut without k-cliques, are indeed k-clique-free.\\nDefinition 5.3 (Clique-dense graph). Given k∈N+andt,s,ε∈R+,\\n1≤t≤k, we say that a graph G=(V,E)is(k,t,s,ε)-clique-dense\\nif there exist r,q∈R+,r≥4k/t2, such that\\n(1)Vis(tr,tq)-neighbour-dense, and\\n(2)every(r,q)-neighbour-dense set W⊆Vis(tr,r,q′,s)-mostly\\nneighbour-dense for q′=3εks1+εlogs.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='neighbour-dense for q′=3εks1+εlogs.\\nTheorem 5.4. Given k∈N+andt,s,ε∈R+if the graph Gis\\n(k,t,s,ε)-clique-dense, then every regular resolution refutation of the\\nCNF formula Clique(G,k)has length at least1√\\n2sεk/t2.\\nThe value of q′in Definition 5.3is tailored so that Theorem 4.2\\nholds for k≪n1/2on graphs with edge density close to the thresh-\\nold for having a k-clique. Setting q′=εrs1+εlogsand making the\\nnecessary modifications in the proof would yield Theorem 4.2for a\\nlarger range of edge densities but only for k≪n2/5.\\nWe will spend the rest of this section establishing Theorem 5.4.\\nFixr,q∈R+witnessing that Gis(k,t,s,ε)-clique-dense as per\\nDefinition 5.3. We first note that we can assume that tr≤ksince\\notherwise, by property 1of Definition 5.3,Gcontains a k-clique\\nand the theorem follows immediately.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Definition 5.3. We first note that we can assume that tr≤ksince\\notherwise, by property 1of Definition 5.3,Gcontains a k-clique\\nand the theorem follows immediately.\\nBy the discussion in Section 2it is sufficient to consider read-once\\nbranching programs, since they are equivalent to regular resolution\\nrefutations, and so in what follows this is the language in which\\nwe will phrase our lower bound. Thus, for the rest of this section\\nletPbe an arbitrary, fixed read-once branching program that solves\\nthe falsified clause search problem for Clique(G,k). We will use the\\nconvention of referring to “vertices” of the graph Gand “nodes” of\\nthe branching program Pto distinguish between the two.\\nRecall that for a node aofP,β(a)denotes the maximal partial\\nassignment that is contained in any assignment σsuch that the path\\npath(σ)passes through a. For any partial assignment βwe writeβ1\\nto denote the partial assignment that contains exactly the variables\\nthat are set to 1inβ. Clearly, if βfalsifies an edge axiom or a func-\\ntionality axiom, then so does β1. Furthermore, for any β′⊆β1, ifβ′', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='tionality axiom, then so does β1. Furthermore, for any β′⊆β1, ifβ′\\nfalsifies an edge axiom or a functionality axiom, so does β1. We willuse this monotonicity property of partial assignments throughout\\nthe proof.\\nFor each node aofPand each index i∈[k]we define two sets\\nof vertices\\nV0\\ni(a)={v∈V|β(a)setsxv,ito0} (6a)\\nV1\\ni(a)={v∈V|β(a)setsxv,ito1} (6b)\\nofG. Observe that for β=β(a)the set of vertices referenced by\\nvariables in β1isÐ\\niV1\\ni(a).\\nIntuitively, one can think of V0\\ni(a)andV1\\ni(a)as the sets of vertices\\nvfor which the variable xv,iis assigned 0and1, respectively, that\\nare guaranteed to be “remembered” at the node a(in the language\\nof resolution, they correspond to negative and positive occurrences\\nof variables in the clause Daassociated with the node a). Other\\nassignments to variables xu,iforu<V0\\ni(a)∪V1', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='of resolution, they correspond to negative and positive occurrences\\nof variables in the clause Daassociated with the node a). Other\\nassignments to variables xu,iforu<V0\\ni(a)∪V1\\ni(a)encountered\\nalong some path to ahave been “forgotten” and may not be queried\\nany more on any path starting at a. Formally, we say that a vari-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='assignments to variables xu,iforu<V0\\ni(a)∪V1\\ni(a)encountered\\nalong some path to ahave been “forgotten” and may not be queried\\nany more on any path starting at a. Formally, we say that a vari-\\nable xv,iisforgotten at aif there is a path from the source of P\\ntoapassing through a node bwhere xv,iis queried, but vis not\\ninV0\\ni(a)nor in V1\\ni(a). Furthermore, we say index iis forgotten at a\\nif for some vertex vthe variable xv,iis forgotten at a. Of utter\\nimportance is the fact that these notions are persistent: if a variable\\nor an index is forgotten at a node a, then it will also be the case\\nfor any node reachable from aby a path. We say that a path in P\\nends in the ith clique axiom if the clause that labels its last node\\nis the clique axiom (2b)ofClique(G,k)with index i. The above\\nobservation implies that the index icannot be forgotten at any\\nnode along such a path.\\nWe establish our lower bound via a bottleneck counting argu-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='observation implies that the index icannot be forgotten at any\\nnode along such a path.\\nWe establish our lower bound via a bottleneck counting argu-\\nment for paths in P. To this end, let us define a distribution Dover\\npaths in Pby the following random process. The path starts at the\\nsource and ends whenever it reaches a sink of P. At an internal\\nnode awith successor nodes a0anda1, reached by edges labelled 0\\nand1respectively, the process proceeds as follows.\\n(1)IfX(a)=xu,iandiis forgotten at athen the path proceeds\\nvia the edge labelled 0toa0.\\n(2)IfX(a)=xu,iandβ(a)∪{ xu,i=1}falsifies an edge ax-\\niom(2a)or a functionality axiom (2c), then the path proceeds\\ntoa0.\\n(3)Otherwise, an independent (rs−(1+ε)/2ek)-biased coin is tossed\\nwith outcome γ∈{0,1}and the random path proceeds to aγ.\\nWe say that in cases (1)and(2)the answer to the query X(a)is\\nforced. Note that any path αin the support of Dmust end in a clique', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='We say that in cases (1)and(2)the answer to the query X(a)is\\nforced. Note that any path αin the support of Dmust end in a clique\\naxiom since αdoes not falsify any edge or functionality axiom by\\nconstruction. Moreover, a property that will be absolutely crucial is\\nthat only answers 0can be forced—answers 1are always the result\\nof a coin flip.\\nClaim 5.5. Every path in the support of Dsets at most kvariables\\nto1.\\nProof. Letαbe a path in the support of D. We argue that for\\neach i∈[k]at most one variable with second index iis set to 1\\nonα. Let aandbbe two nodes that appear in this order in α. If for\\nsome i∈[k], and for some u,v∈V,xu,iis set to 1byαat node a\\nandxv,iis queried at b, thenv,uby regularity and, by definition\\nofD, the answer to query xv,iwill be forced to 0, either to avoid', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='violating a functionality or an edge axiom, or because iis forgotten\\natb. □\\nLet us call a pair(a,b)of nodes of Puseful if there exists an\\nindex isuch that V1\\ni(b)=∅,iis not forgotten at b, and the set\\nV0\\ni(b)\\\\V0\\ni(a)is(r,q)-neighbour-dense. For each useful pair (a,b),\\nleti(a,b)be an arbitrary but fixed index witnessing that (a,b)is\\nuseful. A path is said to usefully traverse a useful pair (a,b)if it\\ngoes through aandbin that order and sets at most ⌈k/t⌉variables\\nto1between aandb(with aincluded and bexcluded).\\nAs already mentioned, the proof of Theorem 5.4is based on a\\nbottleneck counting argument in the spirit of [ 12], with the twist\\nthat we consider pairs of bottleneck nodes. To establish the theorem\\nwe make use of the following two lemmas which will be proven\\nsubsequently.\\nLemma 5.6. Every path in the support of Dusefully traverses a\\nuseful pair.\\nLemma 5.7. For every useful pair (a,b), the probability that a', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='subsequently.\\nLemma 5.6. Every path in the support of Dusefully traverses a\\nuseful pair.\\nLemma 5.7. For every useful pair (a,b), the probability that a\\nrandom αchosen from Dusefully traverses(a,b)is at most 2s−εr/2.\\nCombining the above lemmas, it is immediate to prove Theo-\\nrem5.4. By Lemma 5.6the probability that a random path αsam-\\npled from Dusefully traverses some useful pair is 1. By Lemma 5.7,\\nfor any fixed useful pair (a,b), the probability that a random α\\nusefully traverses (a,b)is at most 2s−εr/2. By a standard union\\nbound argument, it follows that the number of useful pairs is\\nat least1\\n2sεr/2, so the number of nodes in Pcannot be smaller\\nthan1√\\n2sεr/4≥1√\\n2sεk/t2.\\nTo conclude the proof it remains only to establish Lemmas 5.6\\nand5.7.\\nProof of Lemma 5.6.Consider any path in the support of D.\\nBy the definition of our random process this path ends in the i∗th', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='and5.7.\\nProof of Lemma 5.6.Consider any path in the support of D.\\nBy the definition of our random process this path ends in the i∗th\\nclique axiom for some i∗∈[k]. By Claim 5.5, the path sets at most k\\nvariables to 1and hence we can split it into tpieces by nodes\\na0,a1, . . . , at(a0is the source, atthe sink) so that between aj\\nandaj+1at most⌈k/t⌉variables are set to 1. It remains to prove\\nthat for at least one j∈[t]the set\\nWj=V0\\ni∗(aj)\\\\V0\\ni∗(aj−1) (7)\\nis(r,q)-neighbour-dense. Note that this will prove Lemma 5.6since\\nby construction(aj−1,aj)is then a pair that is usefully traversed\\nby the path.\\nTowards contradiction, assume instead that no Wjis(r,q)-neigh-\\nbour-dense, i.e., that for all j∈[t]there exists a set of vertices', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Towards contradiction, assume instead that no Wjis(r,q)-neigh-\\nbour-dense, i.e., that for all j∈[t]there exists a set of vertices\\nRj⊆Vwith|Rj|≤rsuch that\\x0c\\x0cbNWj(Rj)\\x0c\\x0c≤q. Let R=Ð\\nj∈[t]Rj.\\nSince the path ends in the i∗th clique axiom we have V0\\ni∗(at)=V,\\nand since i∗is not forgotten along the path, it holds that V0\\ni∗(aj−1)⊆\\nV0\\ni∗(aj)for each j∈[t]. It follows that the sets W1, . . . , Wtin(7)\\nform a partition of V, and therefore\\n\\x0c\\x0cbNV(R)\\x0c\\x0c=Õ\\nj∈[t]\\x0c\\x0cbNWj(R)\\x0c\\x0c≤Õ\\nj∈[t]\\x0c\\x0cbNWj(Rj)\\x0c\\x0c≤tq. (8)\\nSince|R|≤Í\\nj∈[t]|Rj|≤trthis contradicts the assumption that V', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Since|R|≤Í\\nj∈[t]|Rj|≤trthis contradicts the assumption that V\\nis(tr,tq)-neighbour-dense. Lemma 5.6follows. □Proof of Lemma 5.7.Fix a useful pair(a,b). LetEdenote the\\nevent that a random path sampled from Dusefully traverses(a,b).\\nLeti∗=i(a,b),V1(a)=Ð\\nj∈[k]V1\\nj(a), and W=V0\\ni∗(b)\\\\V0\\ni∗(a).\\nNotice that Wis guaranteed to be (r,q)-neighbour-dense by our\\ndefinition of i(a,b). Since Gis(k,t,s,ε)-clique-dense by assumption,\\nthis implies that Wis(tr,r,q′,s)-mostly neighbour-dense, and we\\nletSbe the set that witnesses this as per Definition 5.2. We bound\\nthe probability of the event Eby a case analysis based on the size\\nof the set V1(a). We remark that all probabilities in the calculations\\nthat follow are over the choice of α∼D.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='the probability of the event Eby a case analysis based on the size\\nof the set V1(a). We remark that all probabilities in the calculations\\nthat follow are over the choice of α∼D.\\nCase 1 (|V1(a)|>r/2): In this case, we simply prove that already\\nthe probability of reaching ais small. By definition of |V1(a)|, we\\nhave that|β1(a)|=|V1(a)|. Recall that every answer 1is necessarily\\nthe result of a(rs−(1+ε)/2ek)-biased coin flip, and that all these\\ndecisions are irreversible. That is, if a path ever decides to set a\\nvariable in V1(a)to 0, then its case is lost and it is guaranteed to\\nmiss a. Thus we can upper bound the probability of the event Eby\\nthe probability that a random αpasses through a, and, in particular,\\nby the probability of setting all variables in β1(a)to1as follows:\\nPr[E]≤ Pr[αpasses through a] (9)', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='the probability that a random αpasses through a, and, in particular,\\nby the probability of setting all variables in β1(a)to1as follows:\\nPr[E]≤ Pr[αpasses through a] (9)\\n≤\\x00rs−(1+ε)/2ek\\x01|β1(a)|(10)\\n≤s−ε|β1(a)|(11)\\n=s−ε|V1(a)|(12)\\n≤2s−εr/2, (13)\\nwhere for (11)we use the fact that r≤k, which follows from tr≤k\\nandt≥1.\\nCase 2 (|V1(a)|≤ r/2): For every path α, letR(α)denote the\\nset of vertices ufor which the path αsets some variable xu,ito1\\nat some node between aandb(with aincluded and bexcluded);\\nnote that R(α)=∅ifαdoes not go through aandb, and that\\n|R(α)|≤⌈ k/t⌉for all paths αthat satisfy the event E. For the sets', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='|R(α)|≤⌈ k/t⌉for all paths αthat satisfy the event E. For the sets\\nR0={R:|R|≤⌈k/t⌉and\\x0c\\x0cbNW(R∪V1(a))\\x0c\\x0c<q′} (14a)\\nR1={R:|R|≤⌈k/t⌉and\\x0c\\x0cbNW(R∪V1(a))\\x0c\\x0c≥q′} (14b)\\nwe have that\\nPr[E] =Pr[E andR(α)∈R 0]+Pr[E andR(α)∈R 1].(15)\\nThe first term in (15)is bounded from above by the probability of\\nR(α)∈R 0. Note that|R|≤⌈k/t⌉≤2k/t≤rt/2(since r≥4k/t2)\\nforR∈R 0. Hence we have|R∪V1(a)|≤rt/2+r/2≤rtand there-\\nfore|(R∪V1(a))∩S|≥rby the choice of S. Thus, the probability', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='fore|(R∪V1(a))∩S|≥rby the choice of S. Thus, the probability\\nofR(α)∈R 0is bounded by the probability that |R(α)∩S|≥r/2\\nsince|V1(a)|≤ r/2. But since Sis small, we can now apply the', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='union bound and conclude that\\nPr[E andR(α)∈R 0]≤Pr[R(α)∈R 0] (16)\\n≤Pr[|R(α)∩S|≥r/2] (17)\\n≤\\x12|S|k\\nr/2\\x13 \\nrs−(1+ε)\\n2ek!r/2\\n(18)\\n≤\\x122e|S|k\\nr\\x13r/2 \\nrs−(1+ε)\\n2ek!r/2\\n(19)\\n≤s−εr/2. (20)\\nWe now bound the second term in (15). First note that, by defini-\\ntion of W, ifαis a path that passes through aandbin this order,\\nthen all variables xu,i∗with u∈Wmust be set to 0inαat some\\nnode between aandb. For each path in the support of Dthat passes\\nthrough aandb, some of the variables xu,i∗with u∈Wwill be set\\nto zero as a result of a coin flip and others will be forced choices.\\nFix a pathαcontributing to the second term in (15). We claim', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='to zero as a result of a coin flip and others will be forced choices.\\nFix a pathαcontributing to the second term in (15). We claim\\nthat along this path at least q′variables xu,i∗(u∈W)are set to 0\\nas a result of a coin flip.\\nIndeed, since V1\\ni∗(b)=∅andi∗is not forgotten at b, by the mono-\\ntonicity property the same holds for every node along αbefore b.\\nThis implies that the answer to a query of the form xu,i∗(u∈W)\\nmade along αcannot be forced by neither item (1)(forgetfulness)\\nin the definition of Dnor by a functionality axiom. Moreover, since\\nV1(c)⊆R(α)∪V1(a)for any node con the path αbetween aandb,\\nit holds that all variables xu,i∗with u∈bNW(R(α)∪V1(a))can not\\nbe forced to 0 by an edge axiom either. Since there are at least q′of\\nthem, this proves the claim.\\nNow the analysis of the second term in (15)is completed by\\nthe same Markov chain argument as in Case 1 above (noting that', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='them, this proves the claim.\\nNow the analysis of the second term in (15)is completed by\\nthe same Markov chain argument as in Case 1 above (noting that\\nirreversibility of decisions still takes place):\\nPr[E andR(α)∈R 1]\\n≤Pr[αflips≥q′coins and gets all 0s] (21)\\n≤\\x001−rs−(1+ε)/2ek\\x01q′(22)\\n≤s−εr/2. (23)\\nAdding (20) and (23) we obtain the lemma. □\\n6 RANDOM GRAPHS ARE CLIQUE-DENSE\\nIn this section we show that asymptotically almost surely an Erdős-\\nRényi random graph G∼G(n,p)is(k,t,s,ε)-clique-dense for the\\nright choice of parameters.\\nTheorem 6.1. For any real constant ε∈(0,1/2), any sufficiently\\nlarge integer n, any positive integer kand any real ξ>1such that\\nkp\\nξ≤n1/2−ε, ifG∼G(n,n−2ξ/(k−1))is an Erdős-Rényi random', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='kp\\nξ≤n1/2−ε, ifG∼G(n,n−2ξ/(k−1))is an Erdős-Rényi random\\ngraph then with probability at least 1−exp(−√n)it holds that Gis\\n(k,t,s,ε)-clique-dense with t=64ξ/εands=(n/ξ)1/2.\\nAs a corollary of Theorem 5.4and Theorem 6.1we obtain Theo-\\nrem4.2, the main result of this paper.\\nProof of Theorem 4.2.Clearly t≥128≥1as required by Def-\\ninition 5.3. We can also assume w.l.o.g. that t≤ksince otherwisek/ξ2≤64/(ξϵ)≤O(1)and the bound becomes trivial. By plugging\\nin the parameters given by Theorem 6.1to Theorem 5.4we imme-\\ndiately get the stated lower bound on the length of any regular\\nrefutationπofClique(G,k)\\n|π|≥1√\\n2sεk/t2≥nΩ(k/ξ2), (24)', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='refutationπofClique(G,k)\\n|π|≥1√\\n2sεk/t2≥nΩ(k/ξ2), (24)\\nfor which we have to note that s≥n1/4sinceξ≤t≤k≤n1/2.□\\nWe will spend the rest of this section proving Theorem 6.1. Let\\nδ=2ξ/(k−1). We show that, with probability at least 1−e−√n,\\nthe random graph Gis(k,t,s,ε)-clique-dense for parameters as in\\nthe statement of the theorem, r=4k/t2andq=n1−tδr\\n4t.\\nRecall that q′=3εks1+εlogs. Let us argue that these parameters\\nsatisfy constraints\\ntδr≤ε\\n6, (25)\\ntrlogn≤n1−tδr\\n32·logn\\nn1/2, (26)\\nqn−tδrs\\n16tr≥n1+2ε/3\\n28, (27)\\nq′≤qn−tδr\\n4·3·29logn\\nnε/6, (28)', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='16tr≥n1+2ε/3\\n28, (27)\\nq′≤qn−tδr\\n4·3·29logn\\nnε/6, (28)\\ntr≤q\\n2, (29)\\nwhich will be used further on in the proof.\\nAs a first step note that for k≥4\\ntδr=8ξk\\nt(k−1)≤ε\\n6, (30)\\nand hence (25)holds. Equation (26)follows from the chain of in-\\nequalities\\ntrlogn=4klogn\\nt≤n1/2−εlogn\\n32≤n1−tδr\\n32·logn\\nn1/2. (31)\\nTo obtain (27) observe that\\nqn−tδrs\\n16tr=n1−2tδr+1/2\\n28kξ1/2≥n1−2tδr+ε\\n28≥n1+2ε/3\\n28.(32)\\nTo see that (28) holds, note that\\nq′=3εks1+εlogs (33)\\n≤3εkn(1+ε)/2logn\\n2ξ1/2(34)', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='To see that (28) holds, note that\\nq′=3εks1+εlogs (33)\\n≤3εkn(1+ε)/2logn\\n2ξ1/2(34)\\n=3·25·kξ1/2n(1+ε)/2logn\\nt(35)\\n≤3·29·n1−ε/2logn\\n16t(36)\\n≤qn−tδr\\n4·3·29logn\\nnε/6. (37)\\nFinally, for (29), we just observe that\\ntr=4k\\nt≤4k2\\nt2≤n1−2ε\\n16t≤q\\n2, (38)\\nwhere we use that k≥tandt≥64.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='We must now prove that asymptotically almost surely Gis\\n(k,t,s,ε)-clique-dense for the chosen parameters; all probabilities\\nin this section are over the choice of G. Let V=V(G).\\nThe fact that asymptotically almost surely Vis(tr,tq)-neigh-\\nbour-dense is quite immediate. First, for any R⊆Vwith|R|≤tr,\\nE\\x02\\x0c\\x0cbN(R)\\x0c\\x0c\\x03\\n=|V\\\\R|n−δ|R|(39)\\n≥(n−tr)n−δtr(40)\\n≥\\x10\\nn−q\\n2\\x11\\nn−δtr(41)\\n≥n1−δtr\\n2, (42)\\nwhere (42)follows from (29)and the trivial fact that q≤n. Hence,\\nwe can bound the probability that Vis not(tr,tq)-neighbour-dense\\nby\\nPrh\\n∃R⊆V,|R|≤tr∧\\x0c\\x0cbN(R)\\x0c\\x0c≤tqi\\n≤trÕ\\nj=1\\x12n\\nj\\x13\\nmax\\nRPrh\\x0c\\x0cbN(R)\\x0c\\x0c≤tqi\\n(43)', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='≤trÕ\\nj=1\\x12n\\nj\\x13\\nmax\\nRPrh\\x0c\\x0cbN(R)\\x0c\\x0c≤tqi\\n(43)\\n≤ntrmax\\nRPr\"\\n\\x0c\\x0cbN(R)\\x0c\\x0c≤n1−tδr\\n4#\\n(44)\\n≤ntrexp \\n−n1−tδr\\n16!\\n(45)\\n≤exp \\n−n1−tδr\\n32·\\x12\\n2−logn\\nn1/2\\x13!\\n(46)\\n≤e−√n. (47)\\nWe note that (43)is a union bound, (44)follows from the definition\\nofq,(45)is the multiplicative form of Chernoff bound (note that\\nthe events v∈bN(R)(v∈V\\\\R)are mutually independent), (46)\\nfollows from (26), and (47)holds for large enough nby(25)and the\\nfact thatε<1/2.\\nAll that is left to prove is that asymptotically almost surely G\\nsatisfies property 2in Definition 5.3, that is that every (r,q)-neigh-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='fact thatε<1/2.\\nAll that is left to prove is that asymptotically almost surely G\\nsatisfies property 2in Definition 5.3, that is that every (r,q)-neigh-\\nbour-dense set W⊆Vis(tr,r,q′,s)-mostly neighbour-dense. For\\nshortness let Pbe the event that Gsatisfies this property. We wish\\nto show that Pr[¬P]≤ e−Ω(n).\\nGiven an(r,q)-neighbour-dense set W⊆Vwe will define a\\nsetSWwhich will be a “candidate witness” of the fact that Wis\\n(tr,r,q′,s)-mostly neighbour-dense. First observe that, since Wis\\n(r,q)-neighbour-dense and q′≤qby(28), any set R⊆Vwith\\n|R|≤trand\\x0c\\x0cbNW(R)\\x0c\\x0c≤q′must be such that|R|>r. We will use a\\nsequence of such sets Rand construct SWin a somewhat greedy\\nfashion. To this end, the following definition will be useful. A tuple', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='sequence of such sets Rand construct SWin a somewhat greedy\\nfashion. To this end, the following definition will be useful. A tuple\\nof sets(R1, . . . , Rm)is said to be r-disjoint if\\x0c\\x0cRi∩\\x00Ð\\nj<iRj\\x01\\x0c\\x0c≤r\\nfor every i∈[m].\\nFix an arbitrary ordering of the subsets of V. Define®RW=\\n(R1, . . . , Rm)to be a maximally long tuple such that, for every\\ni=1, . . . , m, the set Riis the first in the ordering such that |Ri|≤tr,\\x0c\\x0cbNW(Ri)\\x0c\\x0c≤q′and\\x0c\\x0cRi∩\\x00Ð\\nj<iRj\\x01\\x0c\\x0c≤r. Note that®RWisr-disjoint.\\nNow let SW=Ð\\ni≤mRi.Observe that, by maximality of ®RW, any set R⊆Vwith|R|≤tr\\nand\\x0c\\x0cbNW(R)\\x0c\\x0c≤q′must be such that|R∩S|>r. This implies that\\nif|SW|≤sthen SWwitnesses the fact that Wis(tr,r,q′,s)-mostly', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='if|SW|≤sthen SWwitnesses the fact that Wis(tr,r,q′,s)-mostly\\nneighbour-dense. Therefore we have that\\nPr[¬P]≤ Pr[∃( r,q)-neighbour-dense W⊆Vwith|SW|>s].(48)\\nLetQ(W)denote the event that Wis(r,q)-neighbour-dense.\\nMoreover, letWbe the collection of all pairs (W,®R)such that\\nW⊆V,®R=(R1, . . . , Rℓ)forℓ=⌈s/tr⌉,Rj⊆Vand0<|Rj|≤tr\\nfor each j∈ [ℓ], and®Risr-disjoint. Notice that if there exists\\nan(r,q)-neighbour-dense Wsuch that®RW=(R1, . . . , Rm)and\\n|SW|>s, then m≥ℓand(W,(R1, . . . , Rℓ))∈W . Furthermore,', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='|SW|>s, then m≥ℓand(W,(R1, . . . , Rℓ))∈W . Furthermore,\\nby definition of®RW, for every j∈[ℓ]it holds that\\x0c\\x0cbNW(Rj)\\x0c\\x0c≤q′.\\nHence we can conclude that\\nPr[¬P]\\n≤Pr\\x02\\n∃(W,®R)∈W Q(W)∧∀j∈[ℓ],\\x0c\\x0cbNW(Rj)\\x0c\\x0c≤q′\\x03\\n(49)\\n≤2nntrℓmax\\n(W,®R)∈WPr\\x02\\nQ(W)∧∀j∈[ℓ],\\x0c\\x0cbNW(Rj)\\x0c\\x0c≤q′\\x03\\n(50)\\n≤2nnsmax\\n(W,®R)∈WPr\\x02\\nQ(W)∧∀j∈[ℓ],\\x0c\\x0cbNW(Rj)\\x0c\\x0c≤q\\n4n−tδr\\x03\\n,(51)\\nwhere (51) follows for nlarge enough from the bound in (28).\\nNow fix(W,®R)∈W and let Rd\\nj(resp. Rc', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content=',(51)\\nwhere (51) follows for nlarge enough from the bound in (28).\\nNow fix(W,®R)∈W and let Rd\\nj(resp. Rc\\nj) be the subset of Rj\\ndisjoint from (resp. contained in)Ð\\nj′<jRj′. Since|Rc\\nj|≤rby defini-\\ntion, it holds that if Wis(r,q)-neighbour-dense then\\x0c\\x0cbNW(Rc\\nj)\\x0c\\x0c>q.\\nLetF(j)be the event that\\x0c\\x0cbNW(Rc\\nj)\\x0c\\x0c>qand\\x0c\\x0cbNW(Rj)\\x0c\\x0c≤q\\n4n−tδr.\\nNote that Pr\\x02\\nQ(W)∧∀j∈[ℓ],\\x0c\\x0cbNW(Rj)\\x0c\\x0c≤q\\n4n−tδr\\x03is at most\\nPr\\x02\\n∀j∈[ℓ],F(j)\\x03. LetF′(j)be the event that F(j′)holds for all\\nj′∈[j−1]. We have that\\nPr\\x02\\n∀j∈[ℓ],F(j)\\x03\\n=Ö', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='j′∈[j−1]. We have that\\nPr\\x02\\n∀j∈[ℓ],F(j)\\x03\\n=Ö\\nj∈[ℓ]Pr\\x02\\nF(j)\\x0c\\x0cF′(j)\\x03\\n. (52)\\nWe can consider the factors of the previous product separately and\\nbound each one by\\nPr\\x02\\nF(j)\\x0c\\x0cF′(j)\\x03\\n≤Õ\\nU⊆W\\n|U|≥qPrh\\x0c\\x0cbNU(Rd\\nj)\\x0c\\x0c≤q\\n4n−tδr\\x0c\\x0c\\x0cbNW(Rc\\nj)=U∧F′(j)i\\n·\\n·Prh\\nbNW(Rc\\nj)=U\\x0c\\x0c\\x0cF′(j)i\\n(53)\\n≤Õ\\nU⊆W\\n|U|≥qPrh\\x0c\\x0cbNU(Rd\\nj)\\x0c\\x0c≤q\\n4n−tδri\\n·Prh\\nbNW(Rc\\nj)=U\\x0c\\x0c\\x0cF′(j)i\\n(54)\\n≤Õ\\nU⊆W\\n|U|≥qexp \\n−qn−tδr\\n16!\\n·Prh', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='(54)\\n≤Õ\\nU⊆W\\n|U|≥qexp \\n−qn−tδr\\n16!\\n·Prh\\nbNW(Rc\\nj)=U\\x0c\\x0c\\x0cF′(j)i\\n(55)\\n=exp \\n−qn−tδr\\n16!\\n·Õ\\nU⊆W\\n|U|≥qPrh\\nbNW(Rc\\nj)=U\\x0c\\x0c\\x0cF′(j)i\\n(56)\\n≤exp \\n−qn−tδr\\n16!\\n. (57)', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Equation (54)follows from the independence of any two events\\nthat involve disjoint sets of potential edges and (55)follows from\\nthe multiplicative Chernoff bound and the fact that\\nE\\x02\\x0c\\x0cbNU(Rd\\nj)\\x0c\\x0c\\x03\\n=|U\\\\Rd\\nj|n−δ|Rd\\nj|(58)\\n≥(|U|−tr)n−δtr(59)\\n≥q\\n2n−δtr. (60)\\nSo, putting everything together, we have that\\nPr[¬P]≤ 2nnsexp \\n−qn−tδrℓ\\n16!\\n(61)\\n≤e(log 2) n+√nlogn−(n1+2ε/3)/28(62)\\n≤e−Ω(n), (63)\\nwhere the last inequality holds for nlarge enough, and the second\\nto last inequality follows immediately from the bound in (27). This\\nconcludes the proof of Theorem 6.1.\\n7 CONCLUDING REMARKS\\nIn this paper we prove optimal average-case lower bounds for reg-\\nular resolution proofs certifying k-clique-freeness of Erdős-Rényi', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='7 CONCLUDING REMARKS\\nIn this paper we prove optimal average-case lower bounds for reg-\\nular resolution proofs certifying k-clique-freeness of Erdős-Rényi\\ngraphs not containing k-cliques. These lower bounds are also strong\\nenough to apply for several state-of-the-art clique algorithms used\\nin practice.\\nThe most immediate and compelling question arising from this\\nwork is whether the lower bounds for regular resolution can be\\nstrengthened to hold also for general resolution. A closer study of\\nour proof reveals that there are several steps that rely on regularity.\\nHowever, there is no connection per se between regular resolution\\nand the abstract combinatorial property of graphs that we show\\nto be sufficient to imply regular resolution lower bounds. Thus,\\nit is tempting to speculate that this property, or perhaps some\\nmodification of it, might be sufficient to obtain lower bounds also\\nfor general resolution. If so, a natural next step would be to try to\\nextend the lower bound further to the polynomial calculus proof\\nsystem capturing Gröbner basis calculations.\\nAnother interesting question is whether the lower bounds we\\nobtain asymptotically almost surely for random graphs can also\\nbe shown to hold deterministically under the weaker assumption\\nthat the graph has certain pseudorandom properties. Specifically,', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Another interesting question is whether the lower bounds we\\nobtain asymptotically almost surely for random graphs can also\\nbe shown to hold deterministically under the weaker assumption\\nthat the graph has certain pseudorandom properties. Specifically,\\nis it possible to get an nΩ(logn)length lower bound for the class of\\nRamsey graphs? A graph on nvertices is called Ramsey if it has\\nno set of⌈2 log2n⌉vertices forming a clique or independent set.\\nIt is known that for sufficiently large na random graph sampled\\nfromG(n,1/2)is Ramsey with high probability. Is it true that for\\na Ramsey graph Gonnvertices the formula Clique(G,⌈2 log2n⌉)\\nrequires (regular) resolution refutations of length nΩ(logn)? Such\\na lower bound is known for tree-like resolution [ 21] and proving\\nit for general resolution would have interesting consequences in\\nother areas of proof complexity [10].ACKNOWLEDGEMENTS\\nThis work has been a long journey, and different subsets of the\\nauthors want to acknowledge fruitful and enlightening discus-\\nsions with different subsets of Christoph Berkholz, Olaf Beyers-', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='This work has been a long journey, and different subsets of the\\nauthors want to acknowledge fruitful and enlightening discus-\\nsions with different subsets of Christoph Berkholz, Olaf Beyers-\\ndorff, Nicola Galesi, Ciaran McCreesh, Toni Pitassi, Pavel Pudlák,\\nBen Rossman, Navid Talebanfard, and Neil Thapen. A special thanks\\nto Shuo Pang for having pointed out an inaccuracy in the proba-\\nbilistic argument in Section 6and having suggested a fix.\\nThe first, second, and fourth authors were supported by the\\nEuropean Research Council under the European Union’s Horizon\\n2020 Research and Innovation Programme / ERC grant agreement\\nno. 648276 AUTAR. The third and fifth authors were supported by\\nthe European Research Council under the European Union’s Sev-\\nenth Framework Programme (FP7/2007–2013) / ERC grant agree-\\nment no. 279611 as well as by Swedish Research Council grants\\n621-2012-5645 and2016-00782 , and the second author did part of\\nthis work while at KTH Royal Institute of Technology supported\\nby the same grants. The last author was supported by the Russian\\nFoundation for Basic Research.\\nREFERENCES', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='this work while at KTH Royal Institute of Technology supported\\nby the same grants. The last author was supported by the Russian\\nFoundation for Basic Research.\\nREFERENCES\\n[1]Noga Alon, Michael Krivelevich, and Benny Sudakov. 1998. Finding a large\\nhidden clique in a random graph. Random Structures and Algorithms 13, 3-4\\n(1998), 457–466.\\n[2]Roberto J. Bayardo Jr. and Robert Schrag. 1997. Using CSP Look-Back Techniques\\nto Solve Real-World SAT Instances. In Proceedings of the 14th National Conference', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='(1998), 457–466.\\n[2]Roberto J. Bayardo Jr. and Robert Schrag. 1997. Using CSP Look-Back Techniques\\nto Solve Real-World SAT Instances. In Proceedings of the 14th National Conference\\non Artificial Intelligence (AAAI ’97). 203–208.\\n[3]Paul Beame, Russell Impagliazzo, and Ashish Sabharwal. 2007. The Resolution\\nComplexity of Independent Sets and Vertex Covers in Random Graphs. Compu-\\ntational Complexity 16, 3 (Oct. 2007), 245–297. Preliminary version in CCC ’01.\\n[4]Paul Beame and Toniann Pitassi. 1996. Simplified and Improved Resolution Lower\\nBounds. In Proceedings of the 37th Annual IEEE Symposium on Foundations of\\nComputer Science (FOCS ’96). 274–282.\\n[5]Eli Ben-Sasson and Avi Wigderson. 2001. Short Proofs are Narrow—Resolution\\nMade Simple. J. ACM 48, 2 (March 2001), 149–169. Preliminary version in\\nSTOC ’99.\\n[6]Olaf Beyersdorff, Nicola Galesi, and Massimo Lauria. 2013. Parameterized Com-\\nplexity of DPLL Search Procedures. ACM Transactions on Computational Logic', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='[6]Olaf Beyersdorff, Nicola Galesi, and Massimo Lauria. 2013. Parameterized Com-\\nplexity of DPLL Search Procedures. ACM Transactions on Computational Logic\\n14, 3, Article 20 (Aug. 2013), 21 pages. Preliminary version in SAT ’11.\\n[7]Olaf Beyersdorff, Nicola Galesi, Massimo Lauria, and Alexander A. Razborov.\\n2012. Parameterized Bounded-Depth Frege Is not Optimal. ACM Transactions on\\nComputation Theory 4, 3 (Sept. 2012), 7:1–7:16. Preliminary version in ICALP ’11.\\n[8]Jianer Chen, Xiuzhen Huang, Iyad A. Kanj, and Ge Xia. 2004. Linear FPT reduc-\\ntions and computational lower bounds. In Proceedings of the 36th Annual ACM\\nSymposium on Theory of Computing (STOC ’04). 212–221.\\n[9]Stephen A. Cook and Robert Reckhow. 1979. The relative efficiency of proposi-\\ntional proof systems. Journal of Symbolic Logic 44, 1 (March 1979), 36–50.\\n[10] Stefan S. Dantchev, Barnaby Martin, and Stefan Szeider. 2011. Parameterized', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='tional proof systems. Journal of Symbolic Logic 44, 1 (March 1979), 36–50.\\n[10] Stefan S. Dantchev, Barnaby Martin, and Stefan Szeider. 2011. Parameterized\\nProof Complexity. Computational Complexity 20 (March 2011), 51–85. Issue 1.\\nPreliminary version in FOCS ’07.\\n[11] Rodney Downey and Michael R. Fellows. 1995. Fixed-Parameter Tractability\\nand Completeness II: Completeness for W[1]. Theoretical Computer Science A\\n141 (1995), 109–131. Preliminary versions of some of the results of this paper\\nwere presented at the 21st Manitoba Conference on Numerical Mathematics and\\nComputation, 1991.\\n[12] Armin Haken. 1985. The Intractability of Resolution. Theoretical Computer\\nScience 39, 2-3 (Aug. 1985), 297–308.\\n[13] Johan Håstad. 1999. Clique is Hard to Approximate within n1−ϵ.Acta Mathe-\\nmatica 182 (1999), 105–142. Preliminary version in FOCS ’96.\\n[14] Russell Impagliazzo and Ramamohan Paturi. 2001. On the Complexity of k-SAT .', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='[14] Russell Impagliazzo and Ramamohan Paturi. 2001. On the Complexity of k-SAT .\\nJ. Comput. System Sci. 62, 2 (March 2001), 367–375. Preliminary version in\\nCCC ’99.\\n[15] Richard M. Karp. 1972. Reducibility among Combinatorial Problems. In Com-\\nplexity of Computer Computations. Springer, 85–103.\\n[16] Richard M. Karp. 1976. The probabilistic analysis of some combinatorial search\\nalgorithms. In Algorithms and Complexity: New Directions and Recent Results.\\nAcademic Press, New York, 1–19.\\n[17] Donald E. Knuth. 1994. The sandwich theorem. The Electronic Journal of Combi-\\nnatorics 1, A1 (1994), 1–48.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='[18] Jan Krajíček. 1997. Interpolation Theorems, Lower Bounds for Proof Systems,\\nand Independence Results for Bounded Arithmetic. Journal of Symbolic Logic 62,\\n2 (June 1997), 457–486.\\n[19] Jan Krajíček. 1995. Bounded Arithmetic, Propositional Logic, and Complexity\\nTheory. Cambridge University Press, New York.\\n[20] Luděk Kučera. 1995. Expected complexity of graph partitioning problems. Discrete\\nApplied Mathematics 57, 2 (1995), 193–212.\\n[21] Massimo Lauria, Pavel Pudlák, Vojtěch Rödl, and Neil Thapen. 2017. The Com-\\nplexity of Proving That a Graph is Ramsey. Combinatorica 37, 2 (April 2017),\\n253–268. Preliminary version in ICALP ’13.\\n[22] László Lovász. 1979. On the Shannon capacity of a graph. IEEE Transactions on\\nInformation theory 25, 1 (Jan. 1979), 1–7.\\n[23] João P. Marques-Silva and Karem A. Sakallah. 1999. GRASP: A Search Algorithm', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Information theory 25, 1 (Jan. 1979), 1–7.\\n[23] João P. Marques-Silva and Karem A. Sakallah. 1999. GRASP: A Search Algorithm\\nfor Propositional Satisfiability. IEEE Trans. Comput. 48, 5 (May 1999), 506–521.\\nPreliminary version in ICCAD ’96.\\n[24] Ciaran McCreesh. 2017. Solving Hard Subgraph Problems in Parallel. Ph.D.\\nDissertation. University of Glasgow.\\n[25] Matthew W. Moskewicz, Conor F. Madigan, Ying Zhao, Lintao Zhang, and Sharad\\nMalik. 2001. Chaff: Engineering an Efficient SAT Solver. In Proceedings of the\\n38th Design Automation Conference (DAC ’01). 530–535.\\n[26] Jaroslav Nešetřil and Svatopluk Poljak. 1985. On the complexity of the subgraph\\nproblem. Commentationes Mathematicae Universitatis Carolinae 026, 2 (1985),415–419.\\n[27] Patrick Prosser. 2012. Exact Algorithms for Maximum Clique: A Computational\\nStudy. Algorithms 5, 4 (2012), 545–587.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='[27] Patrick Prosser. 2012. Exact Algorithms for Maximum Clique: A Computational\\nStudy. Algorithms 5, 4 (2012), 545–587.\\n[28] Pavel Pudlák. 1997. Lower Bounds for Resolution and Cutting Plane Proofs and\\nMonotone Computations. Journal of Symbolic Logic 62, 3 (Sept. 1997), 981–998.\\n[29] Alexander Razborov, Avi Wigderson, and Andrew Yao. 2002. Read-once branching\\nprograms, rectangular proofs of the pigeonhole principle and the transversal\\ncalculus. Combinatorica 22, 4 (2002), 555–574.\\n[30] Benjamin Rossman. 2008. On the Constant-Depth Complexity of k-Clique.\\nInProceedings of the 40th Annual ACM Symposium on Theory of Computing\\n(STOC ’08). 721–730.\\n[31] Benjamin Rossman. 2010. Average-Case Complexity of Detecting Cliques. Ph.D.\\nDissertation. Masschussets Institute of Technology.\\n[32] Benjamin Rossman. 2014. The Monotone Complexity of k-Clique on Random\\nGraphs. SIAM J. Comput. 43, 1 (2014), 256–279. Preliminary version in FOCS ’10.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='Graphs. SIAM J. Comput. 43, 1 (2014), 256–279. Preliminary version in FOCS ’10.\\n[33] Virginia Vassilevska. 2009. Efficient Algorithms for Clique Problems. Inform.\\nProcess. Lett. 109, 4 (Jan. 2009), 254–257.\\n[34] David Zuckerman. 2007. Linear Degree Extractors and the Inapproximability\\nof Max Clique and Chromatic Number. Theory of Computing 3, 6 (Aug. 2007),\\n103–128. Preliminary version in STOC ’06.', metadata={'pdf': 'https://upcommons.upc.edu/bitstream/2117/123124/1/clique-regular-resolution-STOC2018.pdf', 'link': 'https://openalex.org/works/W3173380426', 'title': 'Clique Is Hard on Average for Regular Resolution'}),\n",
              " Document(page_content='arXiv:2201.02929v2  [cs.IT]  18 Mar 2022i\\nOptimal Sampling for Data Freshness: Unreliable\\nTransmissions with Random Two-way Delay\\nJiayu Pan, Ahmed M. Bedewy, Yin Sun, Senior Member, IEEE, and Ness B. Shroff, Fellow, IEEE\\nAbstract —In this paper, we aim to design an optimal sampler\\nfor a system in which fresh samples of a signal (source) are\\nsent through an unreliable channel to a remote estimator, an d\\nacknowledgments are sent back over a feedback channel. Both the\\nforward and feedback channels could have random transmissi on\\ntimes due to time varying channel conditions . Motivated by\\ndistributed sensing, the estimator can estimate the real-t ime value\\nof the source signal by combining the signal samples receive d\\nthrough the channel and thenoisy signal observations collected\\nfrom a local sensor. We prove that the estimation error is a\\nnon-decreasing function of the Age of Information (AoI) for the\\nreceived signal samples and design an optimal sampling stra tegy\\nthat minimizes the long-term average estimation error subj ect\\nto a sampling rate constraint. The sampling strategy is also\\noptimal for minimizing the long-term average of general non -\\ndecreasing functions of the AoI. The optimal sampler design', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='to a sampling rate constraint. The sampling strategy is also\\noptimal for minimizing the long-term average of general non -\\ndecreasing functions of the AoI. The optimal sampler design\\nfollows a randomized threshold strategy: If the last transm ission\\nwas successful, the source waits until the expected estimat ion\\nerror upon delivery exceeds a threshold and then sends out a\\nnew sample. If the last transmission fails, the source immed iately\\nsends out a new sample without waiting. The threshold is the\\nroot of a ﬁxed-point equation and can be solved with low\\ncomplexity (e.g., by bisection search). The optimal sampli ng\\nstrategy holds for general transmission time distribution s of\\nthe forward and feedback channels. Numerical simulations a re\\nprovided to compare different sampling policies.\\nIndex Terms —Age of information, unreliable transmissions,\\ntwo-way delay, and sampling .\\nI. I NTRODUCTION\\nTimely updates are crucial in many applications such as\\nvehicular networks, wireless sensor networks, and UA V navi -\\ngations. To achieve timely updates, we require the destinat ion\\nto receive fresh information from the remote source as quick ly\\nas possible. The information freshness is measured by age of\\ninformation, or simply age, which has been widely explored', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='to receive fresh information from the remote source as quick ly\\nas possible. The information freshness is measured by age of\\ninformation, or simply age, which has been widely explored\\nin recent years (e.g., [2]–[23]). Age of information with th e\\nfunction of current time tis deﬁned as ∆t=t−Ut, whereUtis\\nthe generation time of the freshest information data. In sev eral\\ndifferent queueing systems, the Last-Generated, First-Served\\n(LGFS) policy is shown to achieve age-optimality [2]–[4].\\nThis paper was presented in part at IEEE INFOCOM 2022 [1].\\nThis work has been supported in part by NSF grants: 2112471, C NS-\\n2106932, CNS- 2106933, CNS-1955535, CNS-1901057, and CCF- 1813050,\\nand a grant from the Army Research Ofﬁce: W911NF-21-1-0244.\\nJ. Pan is with the Department of ECE, The Ohio State Universit y, Colum-\\nbus, OH 43210 USA (e-mail: pan.743@osu.edu).\\nA. M. Bedewy is with the Department of ECE, The Ohio State Univ ersity,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='bus, OH 43210 USA (e-mail: pan.743@osu.edu).\\nA. M. Bedewy is with the Department of ECE, The Ohio State Univ ersity,\\nColumbus, OH 43210 USA (e-mail: bedewy.2@osu.edu).\\nY . Sun is with the Department of ECE, Auburn University, Aubu rn, AL\\n36849 USA (e-mail: yzs0078@auburn.edu).\\nN. B. Shroff is with the Department of ECE and the Department o f\\nCSE, The Ohio State University, Columbus, OH 43210 USA (e-ma il:\\nshroff.11@osu.edu).Scheduling policies in various wireless networks are studi ed\\nto minimize age [5]–[9]. A literature review of recent works\\nin age of information is provided in [10].\\nIn [11] and [12], a connection between age of information\\nand remote estimation of time-varying processes (e.g., Wie ner\\nprocess or Ornstein-Uhlenbeck (OU) process) was establish ed.\\nOne of the remote estimation objectives in these early studi es\\nwas to design an optimal sampling policy to minimize the\\nlong-term average minimum mean square error (MMSE). The', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='One of the remote estimation objectives in these early studi es\\nwas to design an optimal sampling policy to minimize the\\nlong-term average minimum mean square error (MMSE). The\\nMMSE is a function of theage if the sampling policy is', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='was to design an optimal sampling policy to minimize the\\nlong-term average minimum mean square error (MMSE). The\\nMMSE is a function of theage if the sampling policy is\\nindependent of the signal being sampled [11]–[14]. Among\\nthese studies, the estimator obtains the exact signal sampl es\\nsubject to delay. However, the estimator neglects the insta nt\\nand inexact signal samples. For example, in vehicular net-\\nworks, the estimator can estimate a signal via both the exact\\nsignal samples from the remote sensor and the instant camera\\nstreaming from the close vehicle sensor over time. To consid er\\nboth the delayed and instant signal samples, we will apply\\nthe Kalman Filter [24, Chapter 7] and study the relationship\\nbetween the MMSE and age of information.\\nThe desire for timely updates and the study of the new re-\\nmote estimation problem necessitates considering general non-\\nlinear age functions in the development of optimal sampling\\npolicies. To reduce the age, we may require the source to\\nwait before submitting a new sample [15]. The study in [16]\\ngeneralized the result in [15], proposed an optimal samplin g\\npolicy under a Markov channel with sampling rate constraint ,\\nand observed that the zero-wait policy is far from optimal if ,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='generalized the result in [15], proposed an optimal samplin g\\npolicy under a Markov channel with sampling rate constraint ,\\nand observed that the zero-wait policy is far from optimal if ,\\nfor example, the transmission times are heavy-tail distrib uted\\nor positively correlated. In [17], the authors provided a su rvey\\nof the age penalty functions related to autocorrelation, re mote\\nestimation, and mutual information. The optimal sampling\\nsolution is a deterministic or randomized threshold policy\\nbased on the objective value and the sampling rate constrain t.\\nHowever, in real-time network systems, both the forward\\ndirection and the feedback direction have a random delay. Su ch\\na random two-way delay model was considered in e.g., [18],\\n[19]. In [18], the paper proposed a low complexity algorithm\\nwith a quadratic convergence rate to compute the optimal\\nthreshold. In [19], an optimal joint cost-and-AoI minimiza -\\ntion solution was provided for multiple coexisting source-\\ndestination pairs with heterogeneous AoI penalty function s.\\nAlthough the above studies have developed optimal sampling\\nstrategies, they assume that the transmission process is re liable.\\nHowever, due to the channel fading, the channel conditions a re\\ntime-varying, and thus the transmission process is unrelia ble.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='strategies, they assume that the transmission process is re liable.\\nHowever, due to the channel fading, the channel conditions a re\\ntime-varying, and thus the transmission process is unrelia ble.\\nRecent studies [20], [21] investigate sampling strategies\\nwhile considering unreliable transmissions. In [20], the authors', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='ii\\nconsidered quantization errors, noisy channel, and non-ze ro\\nreceiver processing time, and they established the relatio nship\\nbetween the MMSE and age. For general age functions, they\\nprovided optimal sampling policies, given that the sampler\\nneeds to wait before receiving feedback. When the sampler\\ndoes not need to wait, they provided enhanced sampling\\npolicies that perform better than previous ones. In [21], th e\\nauthors chose idle ortransmit at each time slot to minimize\\njoint age penalty and transmission cost. The optimality of a\\nthreshold-based policy is shown, and the policy’s threshol d\\nis computed efﬁciently. Nevertheless, in practice, transm ission\\ndelays are random rather than constant because of congestion ,\\nrandom sample sizes, etc, which is a critical challenge facing\\nthe design of sampling strategies.\\nTo address the aforementioned challenges, we investigate\\nhow to design optimal sampling strategies in wireless networks\\nunder the following more realistic (and general) condition s that\\nhave largely been unexplored: unreliable transmissions an d\\nrandom delay in both forward and feedback directions. Early\\nstudies on optimizing sampling assuming reliable channels\\nwith random delays have shown that the sampling problem is\\ndecomposed into a per-sample problem. The per-sample prob-', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='random delay in both forward and feedback directions. Early\\nstudies on optimizing sampling assuming reliable channels\\nwith random delays have shown that the sampling problem is\\ndecomposed into a per-sample problem. The per-sample prob-\\nlem can be further solved by optimization theory (e.g., [15] –\\n[18]) or optimal stopping rules (e.g., [11]–[13]). Similar ly, our\\nproblem assuming an unreliable channel is equivalent to a pe r-\\nepoch problem containing multiple samples until successfu l\\npacket delivery. Therefore, the per-epoch problem is a Mark ov\\nDecision Process (MDP) with an uncountable state space,\\nwhich is akey difference with past works, (e.g., [11]–[13],\\n[15]–[18]) and faces the curse of dimensionality.1The main\\ncontributions of this paper are stated as follows:\\n•We ﬁrst formulate the problem where the estimator esti-\\nmates a signal in real-time by combining noisy signal\\nobservations from a local sensor and accurate signal\\nsamples received from a remote sensor. We show that if\\nthe sampling policy is made independently of the signal\\nbeing sampled, the MMSE equals an increasing function\\nof the age of thereceived signal samples.\\n•For general nonlinear age functions, or simply age penalty', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='the sampling policy is made independently of the signal\\nbeing sampled, the MMSE equals an increasing function\\nof the age of thereceived signal samples.\\n•For general nonlinear age functions, or simply age penalty\\nfunctions, we provide an exact solution for minimizing\\nthese data freshness metrics. The optimal sampling policy\\nhas a simple threshold-type structure, and the threshold\\ncan be efﬁciently computed by bisection search and ﬁxed-\\npoint iterations. We uncover the following interesting\\nproperty: if the last transmission is successful, the op-\\ntimal policy may wait for a positive time period before\\ngenerating the next sample and sending it out; otherwise,\\nno waiting time should be added. The key technical\\napproach developed in our results is given as follows:\\n(i) The value function of the proposed policy is an exact\\nsolution to the Bellman equation. (ii) Under the contrac-\\ntion mapping assumption, the solution to the Bellman\\nequation is unique, which guarantees optimality of our\\nproposed threshold-based policy. Our results hold for (i)\\ngeneral non-decreasing age penalty functions, (ii) genera l\\n1We further compare our technical differences with past work s in Section\\nV-D.!\"#$%&\\'$%(&', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='general non-decreasing age penalty functions, (ii) genera l\\n1We further compare our technical differences with past work s in Section\\nV-D.!\"#$%&\\'$%(& \\n)%*\"+%&,(-.\\'$%(& Ot(Si,j ,O Si,j )\\nBt /(%#0 \\n12\\'&&\"34\\'567\\'-*+12\\'&&\"3\\n8\\'&*(.+!\"3\\'0 \\n98\"3%\\':3\";+<1=>/<1= \\n?(-7\\'-*+12\\'&&\"3\\n8\\'&*(.+!\"3\\'0 \\n9@&-\"3%\\':3\";+)\\'.A3\"- \\nFigure 1: System model.\\ndelay distributions of both the forward and feedback\\nchannels, (iii) sampling problems both with or without\\na sampling rate constraint. Therefore, our paper extends\\nprevious studies on sampling for optimizing age (e.g.,\\n[15]–[18], [20], [21]). Although our sampling problem\\nisincontinuous time, it can be easily reduced to be in\\ndiscrete time.\\n•When there is no sampling rate constraint, we provide\\nnecessary and sufﬁcient conditions on the optimality of', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='isincontinuous time, it can be easily reduced to be in\\ndiscrete time.\\n•When there is no sampling rate constraint, we provide\\nnecessary and sufﬁcient conditions on the optimality of\\nthe zero-wait sampling policy [10] based on the choice of', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='discrete time.\\n•When there is no sampling rate constraint, we provide\\nnecessary and sufﬁcient conditions on the optimality of\\nthe zero-wait sampling policy [10] based on the choice of\\nage penalty function, forward and feedback channels. Fi-\\nnally, numerical simulations show that our optimal policy\\ncan reduce the age compared with other approaches.\\nII. E STIMATION AND THE AOI\\nA. System Model\\nConsider a status update system that is composed of a\\nsource, a destination, a source-to-destination channel, a nd a\\ndestination-to-source channel, as is illustrated in Fig. 1 . The\\nsource process Otis sampled and delivered to the destination\\nvia the forward channel. The forward channel suffers from\\ni.i.d. transmission failures, where α∈[0,1)is the probability\\nof failure. Upon each delivery, the destination then sends a n\\n1-bit feedback message denoting whether the transmission is\\nsuccessful (ACK) or unsuccessful (NACK). The feedback is\\nsent via the feedback channel that is reliable with an i.i.d.\\nrandom delay.\\nTo clarify the system model, we set i∈ {1,2,...}as the\\nlabel of a successful delivery in chronological order. Let u s', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='random delay.\\nTo clarify the system model, we set i∈ {1,2,...}as the\\nlabel of a successful delivery in chronological order. Let u s\\ndenote the ithepoch to be the time period between the (i−1)th\\nand theith successful deliveries. We denote Mias the total\\nnumber of samples attempted during the ith epoch. Then, the\\nMi’s are i.i.d. and has a geometric distribution with paramete r\\n1−α. We use jto describe the indices of samples at the\\nith epoch, where we have 1≤j≤Mi. The case j= 1\\nimplies that the previous sample is successfully transmitt ed to\\nthe destimation. Upon delivery, the destination immediate ly\\nsends the feedback to the sampler and arrives at time Ai,j\\nvia the backward channel with an i.i.d. delay Xi,j, which\\nsatisﬁesE[Xi,j]<∞. Then, the jth sample in the ith epoch is\\ngenerated at Si,jand is delivered at Di,jthrough the forward\\nchannel with an i.i.d. delay Yi,j, which satisﬁes E[Yi,j]<∞.\\nWe assume that the backward delays Xi,j’s and forward', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='channel with an i.i.d. delay Yi,j, which satisﬁes E[Yi,j]<∞.\\nWe assume that the backward delays Xi,j’s and forward\\ndelaysYi,j’s are mutually independent. In addition, the source', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='iii\\n!!\\n\"\"#$\"\"%$#&!\"##\"%$#&!\"# #\"#$ \"\"#&!#\"#&!$\"\\'$#$$\"#$ #\"#&!%$%\\n&\"%$#&!\"#\\'\"#$(\"#$&\"#$$\"#&!\\n\\'\"#&!(\"#&!&\"#&!\\'\"\\'$#$\\nFigure 2: Evolution of the age ∆tover time. The ith epoch\\nstarts from Di−1,Mi−1toDi,Mi.\\ngenerates a sample after receiving the feedback of the previ ous\\nsample2, i.e.,Si,j≥Ai,j. In other words, we have a non-\\nnegative waiting time Zi,jfor all epoch iand sample j. Thus,\\nthe forward channel is always available for transmission at\\nSi,j, and the delivery time Di,jsatisﬁesDi,j=Si,j+Yi,j.\\nBy Wald’s equation, the total transmission delay needed in\\neach epoch has a ﬁnite expectation:\\nE\\uf8ee\\n\\uf8f0Mi∑\\nj=1(Xi,j+Yi,j)\\uf8f9\\n\\uf8fb=E[Xi,j+Yi,j]E[Mi]<∞.(1)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='\\uf8f0Mi∑\\nj=1(Xi,j+Yi,j)\\uf8f9\\n\\uf8fb=E[Xi,j+Yi,j]E[Mi]<∞.(1)\\nAge of information (or simply age) is the metric for evaluat-\\ning data freshness and is equal to the time elapsed between th e\\ncurrent time tand the generation time of the freshest delivered\\npacket [23]. Let Ut= max i{Si,Mi:Di,Mi≤t}. Note that\\nonly the Mith sample is successfully delivered for the ith\\nepoch. Then, the age of information ∆tat the current time\\ntis deﬁned as\\n∆t=t−Ut. (2)\\nWe plot the evolution of the age (2) in Fig. 2. Upon each\\nsuccessful delivery time Di,Mi, the age decreases to Yi,Mi,\\nthe transmission delay of the newly generated packet. At oth er\\ntime, the age increases linearly over time. The age is update d\\nat the beginning of each epoch and keeps increasing during\\nthe epoch. Hence, the age is also determined by\\n∆t=t−Si,Mi,ifDi,Mi≤t < Di+1,Mi+1. (3)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='the epoch. Hence, the age is also determined by\\n∆t=t−Si,Mi,ifDi,Mi≤t < Di+1,Mi+1. (3)\\n2This assumption arises from the stop-and-wait mechanism. W hen the\\nbackward delay Xi,j= 0, the policy that samples ahead of receiving feedback\\nis always suboptimal. The reason is that such a policy takes a new sample\\nwhen the channel is busy and can be replaced by another policy that samples\\nat the exact time of receiving feedback [17]. When Xi,j̸= 0, however, it\\nmay be optimal to transmit before receiving feedback, which is out of the\\nscope of this paper.B. Remote Estimation and Kalman Filter\\nWe ﬁrst introduce some notations. For any multi-\\ndimensional vector O, we denote OTas the transpose of O.\\nWe denote In×n,0n×mas then×nidentity matrix and n×m\\nzero matrix, respectively. For a given n×nmatrixN, we set\\ntr(N)as the trace of N, i.e., the summation of the diagonal\\nelements of N.\\nIn this subsection, the source process Otis ann-dimensional\\ndiffusion process that is deﬁned as the solution to the follo wing\\nstochastic differential equation:', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='elements of N.\\nIn this subsection, the source process Otis ann-dimensional\\ndiffusion process that is deﬁned as the solution to the follo wing\\nstochastic differential equation:\\ndOt=−ΘOtdt+ΣdWt, (4)\\nwhereΘandΣaren×nmatrices, and Wtis the\\nn-dimensional Wiener process such that E[WtWT\\ns] =\\nIn×nmin{s,t}for all0≤t,s≤ ∞ . The process Ot\\nrepresents the behavior of many physical systems such as the\\nmotion of a Brownian particle under friction and the motion\\nof the monomers in dilute solutions [25]. At the destination,\\nthere is an estimator that provides estimations according t o\\nthe received samples. One key difference from previous work s\\n(e.g., [11]–[13], [21]) is that the estimator not only recei ves\\nthe accurate samples OSi,jat timeSi,jbut also has an instant\\nnoisy observation Btof the process Ot, as is illustrated in Fig.\\n1. The observation process Btis anm-dimensional vector,\\nmodeled as\\nBt=HOt+Vt, (5)\\nwhereHis ann×mmatrix and Vtis a zero mean white', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='1. The observation process Btis anm-dimensional vector,\\nmodeled as\\nBt=HOt+Vt, (5)\\nwhereHis ann×mmatrix and Vtis a zero mean white\\nnoise process such that for all t,s≥0,\\nE[VtVT\\ns] ={Rt=s;\\n0m×mt̸=s,(6)\\nRis anm×mpositive deﬁnite matrix. We suppose that Wt\\nandVtare uncorrelated such that for all t,s≥0,E[WtVT\\ns] =\\n0n×m.\\nThe estimator provides an estimate ˆOtfor the minimum\\nmean squared error (MMSE) E[||Ot−ˆOt||2]based on the\\ncausally received information. Compared to [12], the MMSE\\nin our study can be reduced due to the additional observation\\nprocessBt. Using the strong Markov property of Ot[26,\\nEq. (4.3.27)] and the assumption that the sampling times are\\nindependent of Ot, as is shown in Appendix A, the MMSE\\nestimator is determined by\\nˆOt=E[\\nOt|{Bτ}Si,Mi≤τ≤t,OSi,Mi]', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='estimator is determined by\\nˆOt=E[\\nOt|{Bτ}Si,Mi≤τ≤t,OSi,Mi]\\n,t∈[Di,Mi,Di+1,Mi+1).\\n(7)\\nBy (7), we ﬁnd that ˆOtis equal to the estimate produced by the\\nKalman ﬁlter [24, Chapter 7]. Therefore, in this work, we use', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='ˆOt=E[\\nOt|{Bτ}Si,Mi≤τ≤t,OSi,Mi]\\n,t∈[Di,Mi,Di+1,Mi+1).\\n(7)\\nBy (7), we ﬁnd that ˆOtis equal to the estimate produced by the\\nKalman ﬁlter [24, Chapter 7]. Therefore, in this work, we use\\nthe Kalman ﬁlter as the estimator. At time t, the Kalman ﬁlter\\nutilizes both the exact sample OSi,Miand noisy observation\\nBtand provides the minimum mean squared error (MMSE)\\nestimation ˆOt. LetNt≜E[(Ot−ˆOt)(Ot−ˆOt)T]be the\\ncovariance matrix of the estimation error Ot−ˆOt. Hence,\\nE[||Ot−ˆOt||2] =tr(Nt).\\nAccording to (7), the estimation process works as follows:\\nOnce a sample is delivered to the Kalman ﬁlter at time Di,Mi,\\nthe Kalman ﬁlter re-initiates itself with the initial condi tion\\nNt=0n×nwhent=Si,Miand starts a new estimation', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='iv\\nsession. Then, during the time period [Di,Mi,Di+1,Mi+1), the\\nKalman ﬁlter uses the causal observations {Bτ:Si,Mi≤τ≤\\nt}to estimate the process Ot.\\nProposition 1. The MMSE tr(Nt)of the process Otis a\\nnon-decreasing function of the age ∆t.\\nProof. See Appendix B.\\nAs a result of Proposition 1, when the sampling times Si,j’s\\nare independent of Ot, the MMSE is still a non-decreasing\\nfunction of the age ∆t. WhenSi,j’s are correlated to Ot, the\\nMMSE is not necessary a function of ∆t.\\nIn the one-dimensional case, where n=m= 1, we use\\nscalarsθ,σ,h,r,n tto replace the matrices Θ,Σ,H,R,Nt,\\nrespectively. The Ornstein–Uhlenbeck (OU) process is deﬁn ed\\nas a one-dimensional special case of diffusion process (4)\\nwhereθ >0[27]. Then, we have\\nProposition 2. Suppose that n=m= 1 andθ >0. Then,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='as a one-dimensional special case of diffusion process (4)\\nwhereθ >0[27]. Then, we have\\nProposition 2. Suppose that n=m= 1 andθ >0. Then,\\nfort∈[Di,Mi,Di+1,Mi+1)andi= 0,1,2,..., the MMSE nt\\nof the OU process Otis given by\\nnt= ¯n−1\\nl+(1\\n¯n−l)\\ne2√\\nθ2+σ2h2\\nr∆t, (8)\\nwhere∆t=t−Si,Mi,\\n¯n=−θr+√\\n(θr)2+σ2rh2\\nh2, (9)\\nl=h2\\n2√\\n(θr)2+σ2rh2. (10)\\nMoreover, ntin(8)is a bounded and non-decreasing function\\nof the age ∆t.\\nProof. See Appendix C.\\nWhen the side observation has zero knowledge of Ot, i.e.,\\nh= 0fort≥0, then the estimator ˆOtis equal to that in [12].\\nTherefore, Proposition 2 reduces to [12, Lemma 4], i.e., the\\nMMSEntis given by\\nnt=σ2', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Therefore, Proposition 2 reduces to [12, Lemma 4], i.e., the\\nMMSEntis given by\\nnt=σ2\\n2θ(\\n1−e−2θ∆t)\\n, (11)\\nmoreover, ntforh= 0 is a bounded and non-decreasing\\nfunction of age ∆t.\\nIII. P ROBLEM FORMULATION FOR GENERAL AGE\\nPENALTY\\nThe function in Proposition 2 is not the only choice of non-\\nlinear age functions. In this paper, to achieve data freshne ss in\\nvarious applications, we consider a general type of age pena lty\\nfunction. The age penalty function p: [0,∞)→Ris assumed\\nto be non-decreasing and need not be continuous or convex.\\nWe further assume that E[∫δ+∑Mi\\nj=1(Xi,j+Yi,j)\\nδp(t)dt]\\n<∞\\nandE[\\np(\\nδ+∑Mi\\nj=1(Xi,j+Yi,j))\\ndt]\\n<∞for any given δ.\\nWe list another two categories of applications for the age\\npenalty functions. First, the age penalty functions can be linear,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='dt]\\n<∞for any given δ.\\nWe list another two categories of applications for the age\\npenalty functions. First, the age penalty functions can be linear,\\npolynomial, or exponential, depending on the dissatisfact ions\\nof the stale information updates in multiple practical sett ingssuch as the Internet of Things [28]. Second, some applications\\nare shown to be closely related to nonlinear age functions, s uch\\nas auto-correlation function of the source, remote estimat ion,\\nand information based data freshness metric [17].\\nWe then deﬁne the sampling policies below. We denote Hi,j\\nas the sample path of the history information previous to Ai,j,\\nincluding sampling times, forward channel conditions, and\\nchannels delays. We denote Πas the collection of sampling\\npolicies{Si,j}i,jsuch that Si,j≥Ai,jfor each (i,j), and\\nSi,j(dsi,j|Hi,j)is a Borel measurable stochastic kernel [29,\\nChapter 7] for any possible Hi,j. Further, we assume that\\nTi=Si,Mi−Si−1,Mi−1is a regenerative process: there\\nexists an increasing sequence 0≤k1< k2< ... of ﬁnite', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Ti=Si,Mi−Si−1,Mi−1is a regenerative process: there\\nexists an increasing sequence 0≤k1< k2< ... of ﬁnite\\nrandom variables such that the post- kjprocess{Tkj+i,i=\\n0,1,...}has the same distribution as the post- k1process\\n{Tk1+i,i= 0,1,...}and is independent of the pre- kjprocess\\n{Ti,i= 1,2,...,k j−1}; in addition, E[kj+1−kj]<∞,\\nE[\\nSk1,Mk1]\\n<∞and0<E[\\nSkj+1,Mkj+1−Skj,Mkj]\\n<∞,\\nj= 1,2,...3\\nThe authors in [13] have stated that: to reduce the estimatio n\\nerror related to the Wiener process, it may be optimal to wait\\non both the source and the destination before transmission.\\nHowever, in this paper, it is sufﬁcient to only wait at the sou rce\\nto minimize the age. To validate this statement, consider an y\\npolicy that waits on both the source and the destination. We\\nﬁrst remove the waiting time at the destination. Then, at the', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='to minimize the age. To validate this statement, consider an y\\npolicy that waits on both the source and the destination. We\\nﬁrst remove the waiting time at the destination. Then, at the\\nsource, we add up the removed waiting time. The replaced\\npolicy we propose has the same age performance as the former\\none.\\nOur objective in this paper is to optimize the long-term\\naverage expected age penalty under a sampling rate constrai nt:\\npopt= inf\\nπ∈Πlimsup\\nT→∞1\\nTE[∫T\\n0p(∆t)dt]\\n, (12)\\ns.t.limsup\\nT→∞1\\nTE[C(T)]≤fmax. (13)\\nHere,C(T)is the total number of samples taken by time', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='popt= inf\\nπ∈Πlimsup\\nT→∞1\\nTE[∫T\\n0p(∆t)dt]\\n, (12)\\ns.t.limsup\\nT→∞1\\nTE[C(T)]≤fmax. (13)\\nHere,C(T)is the total number of samples taken by time\\nT, andfmaxis the maximum allowed sampling rate. The\\nconstraint (13) is added because in practice, the sensor may\\nneed to keep working for a long time with limited amount of\\nenergy. To avoid triviality, the optimal objective value poptin\\n(12) satisﬁes popt<¯p, where¯p= limδ→∞p(δ).\\nA. An Additional Assumption and Its Rationale\\nWe will utilize the following assumption in this paper.\\nAssumption 1. Ifα >0, the backward delay Xi,j∈[0,¯x],\\nand the waiting time Zi,j∈[0,¯z]for alli,j. For any\\npositive¯x,¯z(that can be sufﬁciently large), there exists an\\nincreasing positive function v(δ)such that the function G(δ) =', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='positive¯x,¯z(that can be sufﬁciently large), there exists an\\nincreasing positive function v(δ)such that the function G(δ) =\\nE[∫δ+¯x+¯z+Yi,j\\nδ|p(t)|dt]\\nsatisﬁesmaxδ≥0|G(δ)/v(δ)|<∞.\\n3In this paper, we will optimize limsupT→∞(1/T)E[∫T\\n0p(∆t)dt]\\n.\\nHowever, a nicer objective is to optimize limn→∞E[∫Dn,Mn\\n0p(∆t)dt]\\n/E[Dn,Mn]. IfTiis a regenerative process, then the two objective functions\\nare equal [30], [31]. If no conditions are applied, they are d ifferent.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='v\\nIn addition, there exists ρ∈(0,1)and a positive integer m,\\nsuch that\\nαmE[\\nv(δ+m¯x+m¯z+∑m\\nj=1Yj)]\\nv(δ)≤ρ (14)\\nholds for all δ≥0, whereY1,...,Y mare an i.i.d. sequence\\nwith the same distribution as the Yi,j’s.\\nWhen the forward channel is reliable, i.e., α= 0, then\\nAssumption 1 is negligible by letting v(δ) =G(δ). Thus,\\nAssumption 1 restricts on the choices of age penalty p(·)when\\nα >0. Note that the optimal sampling policy of the cases\\nα= 0 andXi,j= 0 has been solved in [16], [17].\\nIn the following corollary, we provide a list of age penaltie s\\np(·)that Assumption 1 is satisﬁed for α >0.\\nCorollary 1. For any one of the following conditions, Assump-\\ntion 1 holds:\\n(a) The penalty function p(·)is bounded, i.e., ¯p <∞.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Corollary 1. For any one of the following conditions, Assump-\\ntion 1 holds:\\n(a) The penalty function p(·)is bounded, i.e., ¯p <∞.\\n(b) There exists n >0such that p(δ) =O(δn),4and the\\nYi,j’s have a ﬁnite n+1-moment, i.e., E[\\nYn+1\\ni,j]\\n<∞.\\n(c) There exists a >0andb <1such that∫\\np(δ)dδ=\\nO(eaδb)and theYi,j’s are bounded.\\nProof. See Appendix D.\\nMost of the literatures of MDP have shown that the value\\nfunction of an optimal policy is the solution to the Bellman\\nequation . In this paper, we ﬁgure out a policy and its value\\nfunction that is indeed the solution to the Bellman equation .\\nIf the Bellman equation has a unique solution, then our pro-\\nposed policy is optimal. Otherwise, we cannot guarantee the\\noptimality of our proposed policy. Assumption 1 arises from\\nthe contraction mapping assumption [32], [33] that guarant ees\\nthat the Bellman equation has a unique solution. In other', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='optimality of our proposed policy. Assumption 1 arises from\\nthe contraction mapping assumption [32], [33] that guarant ees\\nthat the Bellman equation has a unique solution. In other\\nwords, Assumption 1 is a sufﬁcient condition for the Bellman\\nequation to have a unique solution. Corollary 1 implies that\\nthere are a wide range of age penalty functions that satisfy\\nAssumption 1. For example, the age penalty function derived\\nin Proposition 2 satisﬁes Assumption 1. Indeed, Assumption 1\\nholds if the age penalty function grows exponentially at som e\\nbounded intervals. For all cases of the age penalty function s\\nwe have mentioned, the constants ¯z,¯xcan be sufﬁciently\\nlarge . Therefore, in this paper, we set the constants ¯z,¯xto\\nbe sufﬁciently large.\\nIV. O PTIMAL SAMPLING POLICY\\nIn this section, we provide an optimal solution to (12).\\nThe optimal solution is described by the waiting times Z′\\ni,js\\nthroughout this paper.\\nA. Optimal Sampling Policy without Sampling Rate Constrain t\\nWhen there is no sampling rate constraint, i.e., fmax=∞,\\nwe have the following result:', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='throughout this paper.\\nA. Optimal Sampling Policy without Sampling Rate Constrain t\\nWhen there is no sampling rate constraint, i.e., fmax=∞,\\nwe have the following result:\\nTheorem 1. Iffmax=∞,p(·)is non-decreasing, the Yi,j’s\\nare i.i.d. with ﬁnite mean E[Yi,j]<∞, theXi,j’s are i.i.d.\\n4We denote f(δ) =O(g(δ))if there exists some nonnegative constants c\\nandδ′such that |f(δ)| ≤c|g(δ)|for allδ > δ′.with ﬁnite mean E[Xi,j]<∞, theYi,j’s and the Xi,j’s\\nare mutually independent, and Assumption 1 holds, then the\\noptimal solution to (12) is given by\\nZi,1(β) = inf\\nz{\\nz≥0 :\\nEY′[\\np(Yi−1,Mi−1+Xi,1+z+Y′)⏐⏐Yi−1,Mi−1,Xi,1]\\n≥β}\\n,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='p(Yi−1,Mi−1+Xi,1+z+Y′)⏐⏐Yi−1,Mi−1,Xi,1]\\n≥β}\\n,\\n(15)\\nZi,j(β) = 0j= 2,3,..., (16)\\nY′=Yi,1+∑Mi\\nj=2(Xi,j+Yi,j),5andβis the unique solution\\nto\\nE[∫Yi−1,Mi−1+Xi,1+Zi,1(β)+Y′\\nYi−1,Mi−1p(t)dt]\\n−βE[Xi,1+Zi,1(β)+Y′] = 0. (17)\\nMoreover, β=poptis the optimal objective value of (12).\\nProof. See Section V.\\nIn Theorem 1, the case j= 1in (15) means that the previous\\ntransmission (of the Mi−1th sample in the (i−1)th epoch) is\\nsuccessful, and the system starts the new epoch from i−1to\\ni. Since the age drops to Yi−1,Mi−1at the successful delivery\\ntimeDi−1,Mi−1, the current age state at arrival time Ai,1is', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='i. Since the age drops to Yi−1,Mi−1at the successful delivery\\ntimeDi−1,Mi−1, the current age state at arrival time Ai,1is\\nYi−1,Mi−1+Xi,1. The case j= 2,3,... in (16) means that\\nthe previous transmission is unsuccessful, and the system s tays\\nwithin epoch i.\\nTheorem 1 provides an optimal policy with an interesting\\nstructure. First, by (15), in each epoch, the optimal waitin g\\ntime for the ﬁrst sample Zi,1(β)has a simple threshold type\\nstructure on the current age Yi−1,Mi−1+Xi,1. Since the\\nwaiting times for j= 2,3,... are zero, Y′is the remaining\\ntransmission delay needed for the next successful delivery .\\nNote that βis equal to the optimal objective value poptin\\nproblem (12). Therefore, the waiting time Zi,1(β)in (15) is', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='transmission delay needed for the next successful delivery .\\nNote that βis equal to the optimal objective value poptin\\nproblem (12). Therefore, the waiting time Zi,1(β)in (15) is\\nchosen such that the expected age penalty upon delivery is no\\nsmaller than popt. Second, by (16), the source sends the packet\\nas soon as it receives negative feedback, i.e., the previous\\ntransmission is not successful. This is quite different fro m most\\nof the previous works assuming reliable channels, e.g., [16 ]–\\n[19], where for all samples, the source may wait for some time\\nbefore transmitting a new sample.\\nWe call a sampling policy to be stationary if each sampling\\ntime is decided by the current age state and the previous\\nbackward delay. We call a sampling policy to be deterministic\\nif each sampling time chooses a value with probability 1\\n(w.p.1). We remind that the optimal policy we proposed in\\nTheorem 1 is stationary and deterministic . This stationary and\\ndeterministic policy depends only on the current age state a nd\\nthe previous backward delay, not on the sample index j. For\\nexample, when j= 1, the previous backward delay is Xi,1,\\nand the current age state is Yi−1,Mi−1+Xi,1. For general value', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='example, when j= 1, the previous backward delay is Xi,1,\\nand the current age state is Yi−1,Mi−1+Xi,1. For general value\\nofj, the previous backward delay is Xi,j, and we suppose that\\nthe current age state is ∆i,j+Xi,j. Then, the stationary and\\n5In this paper, we set the summation operator∑b\\nj=ato be0ifb < a for\\nany given integers a,b.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='vi\\ndeterministic policy, which has an equivalent form of (15), (16)\\nin Theorem 1, is as follows:\\nZi,j(β) =inf\\nz{\\nz≥0 :\\nEY′[\\np(∆i,j+Xi,j+z+Y′)⏐⏐∆i,j,Xi,j]\\n≥β}\\n.\\n(18)\\nAlgorithm 1: Bisection method for solving (17)\\n1Given functionf(β) =f1(β)−βf2(β).k1close top,\\nk2close to¯p,k1< k2, and tolerance ǫsmall.\\n2repeat\\n3β=1\\n2(k1+k2)\\n4 iff(β)<0:k2=β.elsek1=β\\n5untilk2−k1< ǫ\\n6returnβ\\nThe root of βin (17) can be solved efﬁciently. According to\\n(17), we can use a low complexity algorithm such as bisection\\nsearch and ﬁxed-point iterations to obtain the optimal obje ctive\\nvaluepopt. The bisection search approach to solving poptis\\nillustrated in Algorithm 1. For simplicity, we set', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='search and ﬁxed-point iterations to obtain the optimal obje ctive\\nvaluepopt. The bisection search approach to solving poptis\\nillustrated in Algorithm 1. For simplicity, we set\\nf1(β) =E[∫Yi−1,Mi−1+Xi,1+Zi,1(β)+Y′\\nYi−1,Mi−1p(t)dt]\\n,(19)\\nf2(β) =E[Xi,1+Zi,1(β)+Y′]. (20)\\nThen, the function f(β)≜f1(β)−βf2(β)satisﬁes the\\nfollowing mathematical property:\\nLemma 1. (1)f(β)is concave, and strictly decreasing in\\nβ∈[p,¯p)∩R, wherep=p(0)and¯p= limδ→∞p(δ).\\n(2) There exists a unique root β∈[p,¯p)∩Rsuch that\\nf(β) = 0 .\\nProof. See Appendix L.\\nTherefore, the solution to Algorithm 1 is unique.\\nOne common sampling policy is the zero-wait policy, which', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='f(β) = 0 .\\nProof. See Appendix L.\\nTherefore, the solution to Algorithm 1 is unique.\\nOne common sampling policy is the zero-wait policy, which\\nsamples the packet once it receives the feedback, i.e., Zi,j= 0\\nfor all(i,j)[10]. The zero-wait policy maximizes the through-\\nput and minimizes the delay. However, by Theorem 1, the\\nzero-wait policy may be suboptimal on age. The following\\nresult provides the necessary and sufﬁcient condition when\\nthe zero-wait policy is optimal.\\nCorollary 2. Iffmax=∞,p(·)is non-decreasing, the Yi,j’s\\nare i.i.d. with ﬁnite mean E[Yi,j]<∞, theXi,j’s are i.i.d.\\nwith ﬁnite mean E[Xi,j]<∞, theYi,j’s and the Xi,j’s are\\nmutually independent, and Assumption 1 holds, then the zero -\\nwait policy is optimal if and only if\\nessinfEY′[p(Y+X+Y′)|Y,X]≥E[∫Y+X+Y′', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='wait policy is optimal if and only if\\nessinfEY′[p(Y+X+Y′)|Y,X]≥E[∫Y+X+Y′\\nYp(t)dt]\\nE[X+Y′],\\n(21)\\nwhereY′=Yi,1+∑Mi\\nj=2(Xi,j+Yi,j),Y=Yi−1,Mi−1,X=\\nXi,1and we denote ess infE= inf{e:P(E≤e)>0}for\\nany random variable E.Proof. See Appendix M.\\nWhen the channel delays are constant, we can get from\\nCorollary 2 that\\nCorollary 3. Iffmax=∞,p(·)is non-decreasing and satisﬁes\\nAssumption 1, and the Yi,j’s,Xi,j’s are constants, then the\\nzero-wait policy is the solution to problem (12).\\nProof. See Appendix N.\\nTheorem 1 is an extension to [17], [18]. When the forward\\nchannel is reliable, i.e., Mi= 1for alliorα= 0, Theorem 1\\ncan be reduced to the result in [18]. Further, we extend [18] i n', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='channel is reliable, i.e., Mi= 1for alliorα= 0, Theorem 1\\ncan be reduced to the result in [18]. Further, we extend [18] i n\\ntwo folds: (i) The age penalty p(·)is allowed to be negative or\\ndiscontinuous. (ii) The channel delays Yi,1,Xi,1have a ﬁnite\\nexpectation and do not need to be bounded. Note that when\\nMi= 1, Assumption 1 is negligible. When Mi= 1, and there\\nis no backward delay ( Xi,1= 0), our result reduces to [17,\\nTheorem 1].\\nThe study in [20, Theorem 2] proves the optimality of\\nthe zero-wait policy among the deterministic policies unde r\\nan unreliable forward channel. This result corresponds to\\nCorollary 3, a special case of Theorem 1. Our paper extends\\n[20] in two folds: (i) We allow the policy space Πto be ran-\\ndomized. Among randomized policies, due to the disturbance s\\non the previous sampling times, the current sampling time\\nis dependent on the previous ones, which is different from\\n[20]. (ii) We consider random two-way delays, extending the\\nconstant one-way delay in [20].', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='is dependent on the previous ones, which is different from\\n[20]. (ii) We consider random two-way delays, extending the\\nconstant one-way delay in [20].\\nB. Optimal Sampling Policy with Sampling Rate Constraint\\nFor general values of fmax, we propose the following result\\nthat extends Theorem 1:\\nTheorem 2. Ifp(·)is non-decreasing, the Yi,j’s are i.i.d.\\nwith ﬁnite mean E[Yi,j]<∞, theXi,j’s are i.i.d. with ﬁnite\\nmeanE[Xi,j]<∞, theYi,j’s and the Xi,j’s are mutually\\nindependent, and Assumption 1 holds, then (15)-(17) is the\\noptimal solution to (12), if the following condition holds:\\nE[Xi,1+Zi,1(β)+Y′]>1\\nfmax(1−α), (22)\\nwhereY′=Yi,1+∑Mi\\nj=2(Xi,j+Yi,j). Otherwise, an optimal\\nsolution is as follows:\\nZi,1(β) ={\\nZmin(β)w.p.λ,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='j=2(Xi,j+Yi,j). Otherwise, an optimal\\nsolution is as follows:\\nZi,1(β) ={\\nZmin(β)w.p.λ,\\nZmax(β)w.p.1−λ.(23)\\nZi,j= 0, j= 2,3,...,M i, (24)\\nZmin(β)andZmax(β)are described as follows:\\nZmin(β) = inf\\nz{\\nz≥0 :\\nEY′[\\np(Yi−1,Mi−1+Xi,1+z+Y′)⏐⏐Yi−1,Mi−1,Xi,1]\\n≥β}\\n,\\n(25)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Zi,1(β) ={\\nZmin(β)w.p.λ,\\nZmax(β)w.p.1−λ.(23)\\nZi,j= 0, j= 2,3,...,M i, (24)\\nZmin(β)andZmax(β)are described as follows:\\nZmin(β) = inf\\nz{\\nz≥0 :\\nEY′[\\np(Yi−1,Mi−1+Xi,1+z+Y′)⏐⏐Yi−1,Mi−1,Xi,1]\\n≥β}\\n,\\n(25)\\nZmax(β) = inf\\nz{\\nz≥0 :\\nEY′[\\np(Yi−1,Mi−1+Xi,1+z+Y′)⏐⏐Yi−1,Mi−1,Xi,1]\\n> β}\\n.\\n(26)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='vii\\nβis determined by\\nE[Xi,1+Zmin(β)+Y′]≤1\\nfmax(1−α)\\n≤E[Xi,1+Zmax(β)+Y′]. (27)\\nThe probability λis given by\\nλ=E[Xi,1+Zmax(β)+Y′]−1\\nfmax(1−α)\\nE[Zmax(β)−Zmin(β)]. (28)\\nProof. See Section V.\\nAccording to Theorem 2, the proposed optimal policy may\\nbe randomized or deterministic. When p(·)is strictly increas-\\ning, we have Zmin(β) =Zmax(β). Similar to Theorem 1, the\\noptimal policy is stationary and deterministic in current a ge\\nand previous backward delay. When p(·)is not strictly increas-\\ning,Zmin(β)andZmax(β)may be different, so the optimal\\npolicy at j= 1 is a random mixture of two deterministic\\nsampling times. Note that when Zmin(β)andZmax(β)may be\\ndifferent, the random optimal policy may be nonstationary .\\nIn addition, we can solve (27) via low complexity algorithms\\nsuch as bisection search.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='different, the random optimal policy may be nonstationary .\\nIn addition, we can solve (27) via low complexity algorithms\\nsuch as bisection search.\\nWhenMi= 1(orα= 0) andXi,j= 0, Theorem 2 reduces\\nto [17, Theorem2]. Combined with the discussions in Section\\nIV-A, we conclude that our paper is an extension to some\\nrecent studies on sampling for optimizing age, e.g., [15]–[ 18],\\n[20], [21].\\nV. P ROOF OF THE MAINRESULT\\nIn this section, we provide the proof of our main results:\\nTheorem 1 and Theorem 2. In Section V-A, we utilize the\\nLagrangian dual problem of the original long-term average\\nproblem and reformulate the Lagrangian dual problem into a\\nper-epoch MDP problem. In Section V-B, we solve the per-\\nepoch MDP problem by formulating an exact optimal value\\nfunction to the Bellman Equation, which is the key challenge\\nto this paper. In Section V-C, we established zero duality ga p\\nto the Lagrangian problem, which ends our proof. Finally, in\\nSection V-D, we summarize our technical contribution and\\ncompare it with some related works.\\nA. Reformulation of Problem (12)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='to the Lagrangian problem, which ends our proof. Finally, in\\nSection V-D, we summarize our technical contribution and\\ncompare it with some related works.\\nA. Reformulation of Problem (12)\\nIn this subsection, we decompose the original problem to a\\nper-epoch problem. The idea is motivated by recent studies t hat\\nreformulate the average problem into a per-sample problem\\n[11], [12], [16]–[18].\\nSince{Si,Mi}ifollows a regenerative process, by renewal\\ntheory, [30, Section 6.1], [34],\\nlimsup\\nT→∞1\\nTE[∫T\\n0p(∆t)dt]\\n(29)\\n= lim\\nn→∞E[∫Dn,Mn\\n0p(∆t)dt]\\nE[Dn,Mn](30)\\n= lim\\nn→∞∑n\\ni=1E[∫Di,Mi\\nDi−1,Mi−1p(∆t)dt]\\n∑n\\ni=1E[\\nDi,Mi−Di−1,Mi−1]. (31)In addition,\\nlimsup\\nT→∞1\\nTE[C(T)] = lim\\nn→∞E[∑n', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Di,Mi−Di−1,Mi−1]. (31)In addition,\\nlimsup\\nT→∞1\\nTE[C(T)] = lim\\nn→∞E[∑n\\ni=1Mi]\\nE[Sn,Mn](32)\\n= lim\\nn→∞n\\n(1−α)E[Dn,Mn]. (33)\\nFrom (29)-(33), the original problem (12) is equivalent to\\npopt= inf\\nπ∈Πlim\\nn→∞∑n\\ni=1E[∫Di,Mi\\nDi−1,Mi−1p(∆t)dt]\\n∑n\\ni=1E[\\nDi,Mi−Di−1,Mi−1], (34)\\ns.t.lim\\nn→∞1\\nnn∑\\ni=1E[\\nDi,Mi−Di−1,Mi−1]\\n≥1\\nfmax(1−α).\\n(35)\\nWe consider the following MDP with a parameter c∈R:\\nh(c) = inf\\nπ∈Πlim\\nn→∞1\\nnn∑\\ni=1E[∫Di,Mi\\nDi−1,Mi−1p(∆t)dt\\n−c(', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='π∈Πlim\\nn→∞1\\nnn∑\\ni=1E[∫Di,Mi\\nDi−1,Mi−1p(∆t)dt\\n−c(\\nDi,Mi−Di−1,Mi−1)]\\n, (36)\\ns.t.lim\\nn→∞1\\nnn∑\\ni=1E[\\nDi,Mi−Di−1,Mi−1]\\n≥1\\nfmax(1−α).\\n(37)\\nBy Dinkelbach’s method [35], we have\\nLemma 2. [17, lemma 2]\\n(i)h(c)⪋0if and only if popt⪋c.\\n(ii) The solution to (34) and(36) are equivalent.\\nWe deﬁne the Lagrangian with c=popt:\\nL(π;γ) = lim\\nn→∞1\\nnn∑\\ni=1E[∫Di,Mi\\nDi−1,Mi−1p(∆t)dt (38)\\n−(popt+γ)(\\nDi,Mi−Di−1,Mi−1)]\\n+γ\\nfmax(1−α),\\n(39)\\nwhereγ≥0is the dual variable. The primal problem is', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Di,Mi−Di−1,Mi−1)]\\n+γ\\nfmax(1−α),\\n(39)\\nwhereγ≥0is the dual variable. The primal problem is\\nl(γ)≜inf\\nπ∈ΠL(π;γ). (40)\\nThe dual problem is\\nd≜max\\nγ≥0l(γ). (41)\\nWeak duality theorem [36], [37] implies that d≤h(popt). We\\nwill later show that the duality gap is 0, i.e.,d=h(popt). Note\\nthat\\nDi,Mi−Di−1,Mi−1=Mi∑\\nj=1(Xi,j+Zi,j+Yi,j), (42)\\nE[∫Di,Mi\\nDi−1,Mi−1p(∆t)dt]\\n(43)\\n=E[∫Yi−1,Mi−1+∑Mi\\nj=1(Xi,j+Zi,j+Yi,j)\\nYi−1,Mi−1p(t)dt]\\n. (44)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='viii\\nRecall that the age decreases to Yi−1,Mi−1at timeDi−1,Mi−1.\\nNote that Yi−1,Mi−1is independent of the history information\\nby the sampling time Si−1,Mi−1. Thus, the age evolution at\\ntheithepoch is independent of the sampling decisions from\\nthe previous epochs 0,1,2,...,i−1. Therefore, to solve (40),\\nminimizing each epoch separately is sufﬁcient. We deﬁne\\nthe policy space Πias the collection of sampling decisions\\n(Zi,1,Zi,2,...)at epoch isuch that the stochastic kernel\\nZi,j(dzi,j|yi−1,Mi−1,xi,1,zi,1,yi,1,...,z i,j−1,yi,j−1,xi,j)\\nis Borel measurable. The difference between ΠiandΠis that\\nthe sampling decisions in Πido not depend on the history\\ninformation from previous epochs (except Yi−1,Mi−1). Hence,\\nit is easy to ﬁnd that Πi⊂Π.\\nThen, by the analysis of the previous paragraph, we have\\nthe following result:', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='it is easy to ﬁnd that Πi⊂Π.\\nThen, by the analysis of the previous paragraph, we have\\nthe following result:\\nLemma 3. An optimal solution to (40) satisﬁes\\ninf\\nπ∈ΠiE[∫Yi−1,Mi−1+∑Mi\\nj=1(Xi,j+Zi,j+Yi,j)\\nYi−1,Mi−1p(t)dt\\n−(popt+γ)Mi∑\\nj=1(Xi,j+Zi,j+Yi,j)⏐⏐⏐Yi−1,Mi−1,Xi,1]\\n.\\n(45)\\nThus, for any epoch i, we will solve Zi,1,Zi,2,...according\\nto (45).\\nB. Solution to the Per-epoch Problem (45)\\nWe will solve problem (45) given that Yi−1,Mi−1=δand\\nXi,1=x, whereδ≥0andx≥0. Since the epoch number\\nidoes not affect problem (45), in this subsection, we will\\nremove the subscription ifromMi,Xi,j,Yi,j,Zi,jand replace', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='idoes not affect problem (45), in this subsection, we will\\nremove the subscription ifromMi,Xi,j,Yi,j,Zi,jand replace\\nthem byM,Xj,Yj,Zjfor the ease of descriptions. In addition,\\nsince we want to ﬁnd out a solution to (34), we need to avoid\\nthatl(γ) =−∞. Thus, we assume that γsatisﬁesinfz≥0{z:\\np(z)> p opt+γ}<∞.6\\nDifferent from [11], [12], [16], [17], the per-epoch proble m\\n(45) is an MDP with multiple samples and cannot be reduced\\nto the per-sample problem in the sense that the age is not\\nrefreshed under failed transmissions. According to (45), w e\\ndeﬁne the value function Jπ,γunder a policy π∈Πiwith an\\ninitial age state δ≥0(at delivery time) and backward delay\\nx≥0:\\nJπ,γ(δ,x) =E[∫δ+∑M\\nj=1(Xj+Zj+Yj)\\nδp(t)dt\\n−(popt+γ)M∑', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='j=1(Xj+Zj+Yj)\\nδp(t)dt\\n−(popt+γ)M∑\\nj=1(Xj+Zj+Yj)⏐⏐⏐X1=x]\\n(46)\\n=E\\uf8ee\\n\\uf8f0M∑\\nj=1gγ(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x\\uf8f9\\n\\uf8fb,\\n(47)\\n6Ifinfz≥0{z:p(z)> p opt+γ}=∞, this subsection implies that waiting\\nfor arbitrary large time can optimize (40). If such a policy o ptimizes (36), we\\nhavepopt= ¯p, which contradicts to our assumption that popt<¯p.where the instant cost function gγ(δ,x,z)with state (δ,x)and\\nactionzis deﬁned as\\ngγ(δ,x,z)\\n=EY[∫δ+x+z+Y\\nδp(t)dt−(popt+γ)(x+z+Y)]\\n,(48)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='=EY[∫δ+x+z+Y\\nδp(t)dt−(popt+γ)(x+z+Y)]\\n,(48)\\nwhereYhas the same delay distribution as the Yj’s and the\\nage state evolution is described as\\n∆j+1= ∆j+Xj+Zj+Yj, j= 1,2,...M−1,(49)\\nwith initial age state ∆1=δand initial backward delay x.\\nAlso, the policy π∈Πihas a Borel measurable stochastic\\nkernelZj(dzj|δ1,x1,z1,...,δ j,xj), and thus Jπ,γ(δ,x)is\\nBorel measurable [29, Chapter 9]. The above settings imply\\nthat problem (45) is equivalent to a shortest path MDP\\nproblem. Solving (45) is equivalent to solving\\nJγ(δ,x) = inf\\nπ∈ΠiJπ,γ(δ,x). (50)\\nWhen the channel state is reliable, i.e., α= 0 orM= 1,\\nproblem (45) (or equivalently, (50)) becomes a single-samp le\\nproblem, and there is no bound restriction to the instant cos t', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='problem (45) (or equivalently, (50)) becomes a single-samp le\\nproblem, and there is no bound restriction to the instant cos t\\nfunction gγ(δ,x,z). However, in the unreliable transmission\\ncase where α >0, problem (45) contains multiple samples. In\\nthe case of multiple samples, most of the literature of dynam ic\\nprogramming e.g., [29], [32], [33], [38]–[42] requires tha t the\\ninstant cost function gγ(δ,x,z)is bounded from below. We\\nhave such a requirement.\\nLemma 4. There exists a value ηsuch that gγ(δ,x,z)≥ −η\\nandJπ,γ(δ,x)≥ −η/(1−α)for all(δ,x,z)and any policy\\nπ∈Πi.\\nProof. See Appendix E.\\nUsing Lemma 4 and Appendix F, Jπ,γ(δ,x)deﬁned in (47)\\nalso equals to a discounted sum with discount factor α:\\nJπ,γ(δ,x) =∞∑\\nj=1αj−1E[', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='also equals to a discounted sum with discount factor α:\\nJπ,γ(δ,x) =∞∑\\nj=1αj−1E[\\ngγ(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x]\\n.\\n(51)\\nNote that (51) is motivated by [38, Chapter 5], illustrating\\nthat the discounted problem is equivalent to a special case o f\\nshortest path problem.\\nRecall that uncountable inﬁmum of Borel measurable func-\\ntions is not necessary Borel measurable. Problem (45) has\\nan uncountable state space. Thus, the optimal value functio n', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='shortest path problem.\\nRecall that uncountable inﬁmum of Borel measurable func-\\ntions is not necessary Borel measurable. Problem (45) has\\nan uncountable state space. Thus, the optimal value functio n\\nJγ(δ,x)deﬁned in (50) may not be Borel measurable7, despite\\nthatJπ,γ(δ,x)is Borel measurable for all π∈Πi. Then, some\\nwell known theories may not satisfy, such as the optimality\\nof the Bellman equation among Πi. One of the methods to\\novercome this challenge is to enlarge the policy spaces. We\\ndeﬁne a collection of policies Π′\\nisuch that the stochastic\\nkernelZj(dZj|δ1,x1,z1,...,δ j,xj)is universally measurable\\n[29]. Note that every Borel measurable stochastic kernel is a\\nuniversally measurable stochastic kernel, so we have Πi⊂Π′\\ni.\\n7see [29], [32] for counterexamples. In discrete-time syste m where the\\nsystem time is slotted, we do not have this challenge.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='ix\\nNote that if π∈Π′\\ni, we also denote Jπ,γ(δ,x)as the\\ndiscounted cost of πgiven in (51). For all given age state\\nδand delay x, we deﬁne\\nJ′\\nγ(δ,x) = inf\\nπ∈Π′\\niJπ,γ(δ,x). (52)\\nIt is easy to see that J′\\nγ(δ,x)≤Jγ(δ,x). In this subsection,\\nwe will ﬁnally show that J′\\nγ(δ,x) =Jγ(δ,x).\\nBy Lemma 4, it is easy to show that Jπ,γ≥ −η/(1−α)\\nfor allπ∈Π′. UsingJπ,γ≥ −η/(1−α)and [29, Corollary\\n9.4.1],J′(δ,x)is lower semianalytic [29]. Note that any real-\\nvalued Borel measurable function is lower semianalytic. Th is\\nallows us to consider the Bellman operator based on a general\\nlower semianalytic function u(δ,x). For any deterministic and', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='valued Borel measurable function is lower semianalytic. Th is\\nallows us to consider the Bellman operator based on a general\\nlower semianalytic function u(δ,x). For any deterministic and\\nstationary policy π∈Πiwith Borel measurable decisions\\nπ(δ,x), we deﬁne an operator Tπ,γon a function u:\\nTπ,γu(δ,x)\\n=gγ(δ,x,π(δ,x))+αEY,X[u(δ+x+π(δ,x)+Y,X)],\\n(53)\\nwhereYandXhave the same distribution as the i.i.d. forward\\ndelayYj’s and backward delay Xj’s, respectively. We also\\ndeﬁne the Bellman operator Tγon the function u:\\nTγu(δ,x) = inf\\nz∈[0,¯z]g(δ,x,z)+αEY,X[u(δ+x+z+Y,X)].\\n(54)\\nAs is described in Assumption 1, the bound ¯zis taken\\nsufﬁciently large. Note that if the function u(δ,x)is Borel', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='(54)\\nAs is described in Assumption 1, the bound ¯zis taken\\nsufﬁciently large. Note that if the function u(δ,x)is Borel\\nmeasurable, Tγu(δ,x)is not necessary Borel measurable in the\\nsense that uncountable inﬁmum of Borel measurable function s\\nis not necessary Borel measurable. However, if we extend\\nu(δ,x)to be lower semianalytic, then Tγu(δ,x)is also lower\\nsemianalytic [29, Proposition 7.47], i.e., Tγis well-deﬁned\\nunder lower semianalytic functions. Note that the expectat ion\\non a lower semianalytic function has the same deﬁnition with\\nthe expectation on a Borel measurable function. In all, we ha ve\\nLemma 5. Ifu(δ,x)is lower semianalytic, then Tπ,γu(δ,x)\\nandTγu(δ,x)are both lower semianalytic.\\nProof. See Appendix G.\\nWe denote u1=u2ifu1(δ,x) =u2(δ,x)for allδ,x∈', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Proof. See Appendix G.\\nWe denote u1=u2ifu1(δ,x) =u2(δ,x)for allδ,x∈\\n[0,∞). Using the deﬁnition of Tπ,γandTγ, the discounted\\nproblem (52) has the following properties [29, Chapter 9.4] :\\nLemma 6. Ifp(·)is non-decreasing, the Yj’s are i.i.d. with\\nﬁnite mean E[Yj]<∞, theXj’s are i.i.d. with ﬁnite mean\\nE[Xj]<∞, theYj’s and the Xj’s are mutually indepen-\\ndent, then the optimal value function J′\\nγ(δ,x)deﬁned in (52)\\nsatisﬁes the Bellman equation:\\nJ′\\nγ=TJ′\\nγ, (55)\\ni.e., the optimal value function J′\\nγis a ﬁxed point of Tγ.\\nTo derive an optimal policy, we ﬁrst provide two stationary\\nand deterministic policies called µmin,γandµmax,γ. Then we', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='γis a ﬁxed point of Tγ.\\nTo derive an optimal policy, we ﬁrst provide two stationary\\nand deterministic policies called µmin,γandµmax,γ. Then we\\nwill show that both µmin,γandµmax,γare the solution to\\nproblem (45).Deﬁnition 1. The stationary and deterministic policies µmin,γ\\nandµmax,γare deﬁned as\\nµmin,γ(δ,x) = max{bmin,γ−δ−x,0}, (56)\\nµmax,γ(δ,x) = max{bmax,γ−δ−x,0}, (57)\\nbmin,γ= inf\\nc{c≥0 :E[p(c+Y′)]≥popt+γ}, (58)\\nbmax,γ= inf\\nc{c≥0 :E[p(c+Y′)]> p opt+γ}, (59)\\nY′≜Y1+M∑\\nj=2(Xj+Yj). (60)\\nA randomized policy ˜µλ,γ={Z1,Z2,...}withλ∈[0,1]\\nsatisﬁes', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='j=2(Xj+Yj). (60)\\nA randomized policy ˜µλ,γ={Z1,Z2,...}withλ∈[0,1]\\nsatisﬁes\\nZ1={µmin,γ(δ,x)w.p.λ,\\nµmax,γ(δ,x)w.p.1−λ.(61)\\nZj= 0, j= 2,3,...,M i. (62)\\nUsing the deﬁnition of Πi, we have µmin,γ,µmax,γ∈Πi, and\\n˜µλ,γ∈Πifor allλ∈[0,1][29, Chapter 7].\\nUpon delivery of the ﬁrst sample, age of µmin,γandµmax,γ\\nincrease to ∆2=δ+x+µmin,γ(δ,x) +Y1andδ+x+\\nµmax,γ(δ,x) +Y1, which are larger than max{δ+x,b min,γ},\\nmax{δ+x,b max,γ}, respectively. Then, the waiting time for the', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='max{δ+x,b max,γ}, respectively. Then, the waiting time for the\\nsecond sample is µmin,γ(∆2,X2) = 0 andµmax,γ(∆2,X2) =\\n0, respectively. Thus, the waiting time at stage 2,... is0under\\nµmin,γandµmax,γ. Therefore, we have µmin,γ= ˜µ0,γand\\nµmax,γ= ˜µ1,γ. Note that when we do not consider sampling\\nrate constraint, then γ= 0, and the policy µmin,γis equivalent\\nto (15) and (16) in Theorem 1. It remains to show that µmin,γ\\nandµmax,γare indeed optimal to problem (45).\\nRecall that we denote Jπ,γ(δ,x)to be the value function\\nwith initial state δ,x under a policy π. Then, we have the\\nfollowing key result:\\nLemma 7. Ifp(·)is non-decreasing, the Yj’s are i.i.d. with\\nﬁnite mean E[Yj]<∞, theXj’s are i.i.d. with ﬁnite mean', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='ﬁnite mean E[Yj]<∞, theXj’s are i.i.d. with ﬁnite mean\\nE[Xj]<∞, theYj’s and the Xj’s are mutually independent,\\nthen the value functions Jµmin,γ(δ,x)andJµmax,γ(δ,x)satisfy\\nJµmin,γ=TγJµmin,γ=Jµmax,γ=TγJµmax,γ. (63)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='E[Xj]<∞, theYj’s and the Xj’s are mutually independent,\\nthen the value functions Jµmin,γ(δ,x)andJµmax,γ(δ,x)satisfy\\nJµmin,γ=TγJµmin,γ=Jµmax,γ=TγJµmax,γ. (63)\\nMoreover, for any λ∈[0,1], we have J˜µλ,γ=Jµmin,γ=\\nJµmax,γ.\\nProof. We provide the proof sketch of Jµmin,γ=TγJµmin,γhere\\nand replace µmin,γbyµfor simplicity. We relegate the detailed\\nproof in Appendix H.\\nWe deﬁne the q-function Qµ(δ,x,z)as the cost of starting\\nat state(δ,x), waiting for time zfor the ﬁrst sample, and then\\nfollowing policy µfor the remaining samples [38, Section 6]\\n[43, Chapter 3]. It is easy to ﬁnd that', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='following policy µfor the remaining samples [38, Section 6]\\n[43, Chapter 3]. It is easy to ﬁnd that\\nQµ(δ,x,z) =gγ(δ,x,z)+αE[Jµ(δ+x+z+Y,X)].(64)\\nFrom (64) and (54), showing Jµ=TγJµis equivalent to\\nshowing that Qµ(δ,x,z)≥Jµ(δ,x)for all the waiting time\\nz≥0, ageδandx. We have stated that µhas a nice\\nstructure: for any initial state, the waiting times of stage\\n2,3...are0. Thus, we can derive the closed form expression\\nofJµ(δ,x)according to (46) (where Zj= 0 forj≥2).', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='x\\nAlso, given the deﬁnition of Qµ(δ,x,z), we can derive the\\nexpression of Qµ(δ,x,z)with the similar form of (46). By\\ncomparing Qµ(δ,x,z)andJµ(δ,x), we can ﬁnally show that\\nQµ(δ,x,z)≥Jµ(δ,x)for all(δ,x,z).\\nLemma 7 tells that Jµmin,γ(or equivalently, Jµmax,γ) is a ﬁxed\\npoint ofTγ. From Lemma 6, the optimal value function J′\\nγ\\nis also a ﬁxed point of Tγ. To show that J′\\nγ=Jµmin,γ, it\\nremains to show that the ﬁxed point of Tγis unique. If the age\\npenaltyp(·)is bounded, Jπ,γ(δ,x)is bounded for any policy\\nπ∈Π′\\ni. Then, according to the contraction mapping theorem,\\nthe bellman equation (55) has a unique bounded solution [32] ,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='π∈Π′\\ni. Then, according to the contraction mapping theorem,\\nthe bellman equation (55) has a unique bounded solution [32] ,\\n[34], [42], i.e., Jµmin,γ=J′\\nγ. Note that there may be unbounded\\nsolutions to (55) [40], [41]. If p(·)is unbounded, we will\\nutilize Assumption 1 to show the uniqueness.\\nLet us denote Λ = [0,∞)×[0,¯x], where¯xis the bound of\\nXjmentioned in Assumption 1. In Assumption 1, we have\\ndeﬁned an increasing function v(δ) : [0,∞)→R+(also\\ncalled the weighted function ). The weighted sup-norm ∥u∥of\\na function u: Λ→Ris deﬁned as\\n∥u∥= max\\n(δ,x)∈Λ|u(δ,x)|\\nv(δ). (65)\\nLetB(Λ) denote the set of all lower semianalytic functions\\nu: Λ→Rsuch that ∥u∥<∞. Note that any real-valued\\nBorel measurable function is lower semianalytic. From [32, p.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='u: Λ→Rsuch that ∥u∥<∞. Note that any real-valued\\nBorel measurable function is lower semianalytic. From [32, p.\\n47], [29, Lemma 7.30.2], B(Λ)is complete under the weighted\\nsup-norm.\\nLemma 8. Ifp(·)is non-decreasing, the Yj’s are i.i.d. with\\nﬁnite mean E[Yj]<∞, theXj’s are i.i.d. with ﬁnite mean\\nE[Xj]<∞, theYj’s and the Xj’s are mutually independent,\\nand Assumption 1 holds, then for all π∈Πi,Jπ,γ∈B(Λ).\\nProof. See Appendix I.\\nThen, the following result shows the uniqueness of the\\nBellman equation Tγu=u.\\nLemma 9. Ifp(·)is non-decreasing, the Yj’s are i.i.d. with\\nﬁnite mean E[Yj]<∞, theXj’s are i.i.d. with ﬁnite mean', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='ﬁnite mean E[Yj]<∞, theXj’s are i.i.d. with ﬁnite mean\\nE[Xj]<∞, theYj’s and the Xj’s are mutually independent,\\nand Assumption 1 holds, the following conditions hold:\\n(a) For any lower semianalytic function u: Λ→R, ifu∈\\nB(Λ), thenTπ,γu∈B(Λ)for all deterministic and stationary\\npolicyπ∈Πi, andTγu∈B(Λ).\\n(b) The Bellman operator Tγhas anm-stage contraction\\nmapping with modulus ρ, i.e., for all u1,u2∈B(Λ),\\n∥Tm\\nγu1−Tm\\nγu2∥ ≤ρ∥u1−u2∥, (66)\\nwhere constants ρ∈(0,1)andmare mentioned in Assump-\\ntion 1, and the weighted sup-norm ∥·∥ is deﬁned in (65).\\n(c) There exists a unique function u∈B(Λ) such that\\nTγu=u.\\nProof. See Appendix J.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='(c) There exists a unique function u∈B(Λ) such that\\nTγu=u.\\nProof. See Appendix J.\\nFrom Lemma 8, Jµmin,γ∈B(Λ). From Lemma 9(c),\\nLemma 7 and Jµmin,γ∈B(Λ),Jµmin,γ(or equivalently, Jµmax,γ)\\nis the unique solution to Tγu=u. From Lemma 6, Jµmin,γ=\\nJ′\\nγ. Sinceµmin,γ,µmax,γ∈ΠiandΠi⊂Π′\\ni,µmin,γandµmax,γare the optimal policies in Πi. Note that µmin,γ= ˜µ0,γand\\nµmax,γ= ˜µ1,γ. Using Lemma 7, we immediately get the ﬁnal\\nresult:\\nLemma 10. A collection of optimal policies to problem (45)\\nis{˜µλ,γ:λ∈[0,1]}described in Deﬁnition 1.\\nC. Optimal Solution to (36) Whenc=popt\\nSection V-B provides the optimal solution to (45) given the', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='C. Optimal Solution to (36) Whenc=popt\\nSection V-B provides the optimal solution to (45) given the\\ninitial states Yi−1,Mi−1=δandXi,1=x. Using Lemma 10\\nand strong duality, we have the following result.\\nTheorem 3. Ifp(·)is non-decreasing, the Yi,j’s are i.i.d.\\nwith ﬁnite mean E[Yi,j]<∞, theXi,j’s are i.i.d. with ﬁnite\\nmeanE[Xi,j]<∞, theYi,j’s and the Xi,j’s are mutually\\nindependent, and Assumption 1 holds, then µmin,0described\\nin Deﬁnition 1 is an optimal solution to (36) withc=popt, if\\nthe following condition holds:\\nE[\\nXi,1+µmin,0(Yi−1,Mi−1,Xi,1)+Y′]\\n>1\\nfmax(1−α),\\n(67)\\nwhereY′=Yi,1+∑Mi\\nj=2(Xi,j+Yi,j). Otherwise, ˜µλ,γis an', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='fmax(1−α),\\n(67)\\nwhereY′=Yi,1+∑Mi\\nj=2(Xi,j+Yi,j). Otherwise, ˜µλ,γis an\\noptimal solution to (36) withc=popt, whereγis determined\\nby\\nE[\\nXi,1+µmin,γ(Yi−1,Mi−1,Xi,1)+Y′]\\n≤1\\nfmax(1−α)\\n≤E[\\nXi,1+µmax,γ(Yi−1,Mi−1,Xi,1)+Y′]\\n, (68)\\nand the probability λis given by\\nλ=E[\\nXi,1+µmax,γ(Yi−1,Mi−1,Xi,1)+Y′]\\n−1\\nfmax(1−α)\\nE[\\nµmax,γ(Yi−1,Mi−1,Xi,1)−µmin,γ(Yi−1,Mi−1,Xi,1)].\\n(69)\\nProof. See Appendix K.\\nBy taking β=popt+γ, Theorem 2is directly shown by\\nTheorem 3.\\nIn addition, note that Theorem 1 is directly shown by', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='(69)\\nProof. See Appendix K.\\nBy taking β=popt+γ, Theorem 2is directly shown by\\nTheorem 3.\\nIn addition, note that Theorem 1 is directly shown by\\nLemma 10, by taking β=poptandγ= 0. In other words,\\nµmin,0is an optimal solution to (12) when fmax=∞.\\nD. Discussion\\nMany existing studies on AoI sampling assume that the', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Lemma 10, by taking β=poptandγ= 0. In other words,\\nµmin,0is an optimal solution to (12) when fmax=∞.\\nD. Discussion\\nMany existing studies on AoI sampling assume that the\\ntransmission channel is error-free, i.e., Mi= 1 for alli, e.g.,\\n[11]–[13], [15]–[18]. Due to the renewal property, their or igi-\\nnal problems are reduced to a per-sample problem. Similarly ,\\nour result is equivalent to the per-epoch problem illustrat ed\\nin (45). If Mi= 1, problem (45) reduces to a per-sample\\nproblem, where there is only one decision Zi,1and is solved\\nusing convex optimization. However, when Mi̸= 1, problem\\n(45) is an MDP that contains multiple samples. This MDP\\ncannot be solved by convex optimization (e.g., [15]–[18]) o r\\noptimal stopping rules (e.g., [11]–[13]).\\nTherefore, one of the technical contributions in this paper\\nis to accurately solve the MDP in (45). We summarize the\\nhigh-level idea of solving (45): First, in Lemma 6, among\\nthe extended policy space Π′\\niwith universally measurable', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='is to accurately solve the MDP in (45). We summarize the\\nhigh-level idea of solving (45): First, in Lemma 6, among\\nthe extended policy space Π′\\niwith universally measurable\\nstochastic kernel [29, Chapter 7], the optimal policy satis ﬁes', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xi\\n1.5 2 2.5\\n1050010001500200025003000Average AoIOur Results\\nZero-wait\\n1-Way\\n2-WayEF\\n1-WayEF\\nFigure 3: Average AoI versus the parameter σ1of the forward\\nchannel, where σ2= 1.5andα= 0.8.\\n1.5 2 2.5\\n2050010001500200025003000Average AoIOur Results\\nZero-wait\\n1-Way\\n2-WayEF\\n1-WayEF\\nFigure 4: Average AoI versus the parameter σ2of the back-\\nward channel, where σ1= 1.5andα= 0.8.\\nthe Bellman equation (55). Then, in Lemma 7, we provide\\nthe exact value function that is the solution to the Bellman\\nEquation. Finally, under Assumption 1 and Lemma 9, the\\nuniqueness of the Bellman equation is guaranteed.\\nIn addition, although we focus on continuous-time systems\\nin this paper, our results can be easily reduced to the discre te-\\ntime systems by removing the content of measure theory.\\nVI. N UMERICAL RESULTS\\nIn this section, we compare our optimal sampling policy\\nwith the following sampling policies:\\n1. Zero-wait: Let Zi,j= 0 , i.e., the source transmits a', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='VI. N UMERICAL RESULTS\\nIn this section, we compare our optimal sampling policy\\nwith the following sampling policies:\\n1. Zero-wait: Let Zi,j= 0 , i.e., the source transmits a\\nsample once it receives the feedback.\\n2. One-way ( 1-way): It falsely assumes that the backward\\ndelayXi,j= 0 despite that Xi,jmay not be zero.\\n3. Two-way Error-free ( 2-wayEF) [18]: It assumes that the\\nforward channel’s probability of failure α= 0 despite that α\\nmay not be zero.\\n4. One-way Error-free ( 1-wayEF) [17]: It assumes that\\nXi,j= 0 andα= 0.\\nIn this section, we consider linear age penalty p(δ) = 2δ\\nand lognormal distributions on both forward and backward\\ndelay with scale parameters σ1,σ2, respectively. Note that the\\nlognormal random variable with scale parameter σis expressed\\naseσR, whereRis the standard normal random variable. The2 4 6 8 10\\n1/(1-)05001000150020002500Average AoIOur Results\\nZero-wait\\n1-Way\\n2-WayEF\\n1-WayEF', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='1/(1-)05001000150020002500Average AoIOur Results\\nZero-wait\\n1-Way\\n2-WayEF\\n1-WayEF\\nFigure 5: Average AoI versus 1/(1−α), whereσ1= 2.3and\\nσ2= 1.5.\\n2 4 6 8 10\\n1/(1-)05001000150020002500Average AoI Our Results\\nZero-wait\\n1-Way\\n2-WayEF\\n1-WayEF\\nFigure 6: Average AoI versus 1/(1−α), whereσ1= 1.5and\\nσ2= 2.3.\\nnumerical results below show that our proposed policy alway s\\nachieves the lowest average age.\\nFig. 3 and Fig. 4 illustrate the relationship between age and\\nσ1,σ2, respectively. In Fig. 3, we plot the evolution of average\\nage inσ1given that σ2= 1.5andα= 0.8. Asσ1increases,\\nthe lognormal distribution of the forward channel becomes\\nmore heavy tailed. We observe that Zero-wait policy evolves\\nmuch quicker than other policies in σ1. In addition, 2-wayEF\\nand1-wayEF policies grow faster than the optimal policy in', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='more heavy tailed. We observe that Zero-wait policy evolves\\nmuch quicker than other policies in σ1. In addition, 2-wayEF\\nand1-wayEF policies grow faster than the optimal policy in\\nσ1. In Fig. 4, we ﬁx σ1= 1.5and plot the average age of\\nthe listed policies in σ2. Unlike Fig. 3, 1-way and 1-wayEF\\npolicies perform poorly since they fail to take highly rando m\\nbackward delay into account.\\nFig. 5 and Fig. 6 depict the evolution of average age\\nin1/(1−α), where(σ1,σ2) = (2.3,1.5)and(σ1,σ2) =\\n(1.5,2.3), respectively. Note that 1/(1−α)is the average\\nnumber of samples attempted for a successful transmission. In\\nFig. 5 and Fig. 6, when 1/(1−α)increases, the gap between\\n2-wayEF policy and our optimal policy increases. In Fig. 6,\\nsinceσ2> σ1, the tail of backward delay is heavier than that\\nof forward delay. Thus, 1-way and 1-wayEF, which neglect\\nthe knowledge of backward delay, fail to improve the age\\nperformance.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='of forward delay. Thus, 1-way and 1-wayEF, which neglect\\nthe knowledge of backward delay, fail to improve the age\\nperformance.\\nIn summary, when either one of the channels is highly', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xii\\nrandom, (i) Zero-wait policy is far from optimal, (ii) the ag e\\nperformance of 1-wayEF or 2-wayEF policy gets worse if the\\nforward channel is more unreliable, (iii) 1-way and 1-wayEF\\npolices are far from optimal if the backward channel is highl y\\nrandom.\\nVII. C ONCLUSION\\nIn this paper, we design a sampling policy to optimize data\\nfreshness, where the source generates the samples and sends\\nto the remote destination via a fading forward channel, and t he\\nacknowledgements are sent back via a backward channel. We\\novercome the curse of dimensionality that arises from the ti me-\\nvarying forward channel conditions and the randomness of th e\\nchannel delays in both directions. We reveal that the optima l\\nsampling policy has a simple threshold based structure, and\\nthe optimal threshold is computed efﬁciently.\\nREFERENCES\\n[1] J. Pan, A. M. Bedewy, Y . Sun, and N. B. Shroff, “Optimizing sampling\\nfor data freshness: Unreliable transmissions with random t wo-way\\ndelay,” in Proc. IEEE INFOCOM , 2022.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='for data freshness: Unreliable transmissions with random t wo-way\\ndelay,” in Proc. IEEE INFOCOM , 2022.\\n[2] A. M. Bedewy, Y . Sun, and N. B. Shroff, “The age of informat ion in\\nmultihop networks,” IEEE/ACM Transactions on Networking , vol. 27,\\nno. 3, pp. 1248–1257, 2019.\\n[3] A. M. Bedewy, Y . Sun, and N. B. Shroff, “Minimizing the age of\\ninformation through queues,” IEEE Transactions on Information Theory ,\\nvol. 65, no. 8, pp. 5215–5232, 2019.\\n[4] Y . Sun, E. Uysal-Biyikoglu, and S. Kompella, “Age-optim al updates of\\nmultiple information ﬂows,” in IEEE INFOCOM WKSHPS , pp. 136–\\n141, IEEE, 2018.\\n[5] A. M. Bedewy, Y . Sun, S. Kompella, and N. B. Shroff, “Optim al\\nsampling and scheduling for timely status updates in multi- source\\nnetworks,” IEEE Transactions on Information Theory , vol. 67, no. 6,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='sampling and scheduling for timely status updates in multi- source\\nnetworks,” IEEE Transactions on Information Theory , vol. 67, no. 6,\\npp. 4019–4034, 2021.\\n[6] A. M. Bedewy, Y . Sun, R. Singh, and N. B. Shroff, “Low-powe r\\nstatus updates via sleep-wake scheduling,” IEEE/ACM Transactions on\\nNetworking , 2021.\\n[7] J. Pan, A. M. Bedewy, Y . Sun, and N. B. Shroff, “Minimizing age of in-\\nformation via scheduling over heterogeneous channels,” in Proceedings\\nof MobiHoc , pp. 111–120, 2021.\\n[8] Y . Zou, K. T. Kim, X. Lin, and M. Chiang, “Minimizing age-o f-\\ninformation in heterogeneous multi-channel systems: A new partial-\\nindex approach,” in Proceedings of MobiHoc , pp. 11–20, 2021.\\n[9] Z. Qian, F. Wu, J. Pan, K. Srinivasan, and N. B. Shroff, “Mi nimizing\\nage of information in multi-channel time-sensitive inform ation update', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='age of information in multi-channel time-sensitive inform ation update\\nsystems,” in IEEE INFOCOM , pp. 446–455, 2020.\\n[10] R. D. Yates, Y . Sun, D. R. Brown, S. K. Kaul, E. Modiano, an d\\nS. Ulukus, “Age of information: An introduction and survey, ”IEEE\\nJournal on Selected Areas in Communications , vol. 39, no. 5, pp. 1183–\\n1210, 2021.\\n[11] Y . Sun, Y . Polyanskiy, and E. Uysal, “Sampling of the Wie ner process\\nfor remote estimation over a channel with random delay,” IEEE Trans-\\nactions on Information Theory , vol. 66, no. 2, pp. 1118–1135, 2020.\\n[12] T. Z. Ornee and Y . Sun, “Sampling and remote estimation f or the\\nornstein-uhlenbeck process through queues: Age of informa tion and be-\\nyond,” IEEE/ACM Transactions on Networking , vol. 29, no. 5, pp. 1962–\\n1975, 2021.\\n[13] C.-H. Tsai and C.-C. Wang, “Unifying AoI minimization a nd remote', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='1975, 2021.\\n[13] C.-H. Tsai and C.-C. Wang, “Unifying AoI minimization a nd remote\\nestimation—optimal sensor/controller coordination with random two-\\nway delay,” in IEEE INFOCOM , pp. 466–475, 2020.\\n[14] K. Huang, W. Liu, M. Shirvanimoghaddam, Y . Li, and B. Vuc etic,\\n“Real-time remote estimation with hybrid ARQ in wireless ne tworked\\ncontrol,” IEEE Transactions on Wireless Communications , vol. 19, no. 5,\\npp. 3490–3504, 2020.\\n[15] R. D. Yates, “Lazy is timely: Status updates by an energy harvesting\\nsource,” in 2015 IEEE International Symposium on Information Theory\\n(ISIT) , pp. 3008–3012, 2015.\\n[16] Y . Sun, E. Uysal-Biyikoglu, R. D. Yates, C. E. Koksal, an d N. B. Shroff,\\n“Update or wait: How to keep your data fresh,” IEEE Transactions on', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='“Update or wait: How to keep your data fresh,” IEEE Transactions on\\nInformation Theory , vol. 63, no. 11, pp. 7492–7508, 2017.[17] Y . Sun and B. Cyr, “Sampling for data freshness optimiza tion: Non-', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='“Update or wait: How to keep your data fresh,” IEEE Transactions on\\nInformation Theory , vol. 63, no. 11, pp. 7492–7508, 2017.[17] Y . Sun and B. Cyr, “Sampling for data freshness optimiza tion: Non-\\nlinear age functions,” Journal of Communications and Networks , vol. 21,\\nno. 3, pp. 204–219, 2019.\\n[18] C.-H. Tsai and C.-C. Wang, “Age-of-information revisi ted: Two-way\\ndelay and distribution-oblivious online algorithm,” in 2020 IEEE In-\\nternational Symposium on Information Theory (ISIT) , pp. 1782–1787,\\n2020.\\n[19] C.-H. Tsai and C.-C. Wang, “Jointly minimizing AoI pena lty and\\nnetwork cost among coexisting source-destination pairs,” in2021 IEEE\\nInternational Symposium on Information Theory (ISIT) , pp. 3255–3260,\\n2021.\\n[20] A. Arafa, K. Banawan, K. G. Seddik, and H. V . Poor, “Sampl e, quantize,\\nand encode: Timely estimation over noisy channels,” IEEE Transactions', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='and encode: Timely estimation over noisy channels,” IEEE Transactions\\non Communications , vol. 69, no. 10, pp. 6485–6499, 2021.\\n[21] M. Kl¨ ugel, M. H. Mamduhi, S. Hirche, and W. Kellerer, “A oI-penalty\\nminimization for networked control systems with packet los s,” in IEEE\\nINFOCOM WKSHPS , pp. 189–196, 2019.\\n[22] J. Pan, A. M. Bedewy, Y . Sun, and N. B. Shroff, “Age-optim al scheduling\\nover hybrid channels,” submitted to IEEE Transactions on Mobile\\nComputing, eprint arXiv:2012.09403 , 2021.\\n[23] S. Kaul, R. Yates, and M. Gruteser, “Real-time status: H ow often should\\none update?,” in IEEE INFOCOM , pp. 2731–2735, 2012.\\n[24] H. V . Poor, An introduction to signal detection and estimation . Springer\\nScience & Business Media, 2013.\\n[25] H. C. ¨Ottinger, Stochastic processes in polymeric ﬂuids: tools and\\nexamples for developing simulation algorithms . Springer Science &', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Science & Business Media, 2013.\\n[25] H. C. ¨Ottinger, Stochastic processes in polymeric ﬂuids: tools and\\nexamples for developing simulation algorithms . Springer Science &\\nBusiness Media, 2012.\\n[26] G. Peskir and A. Shiryaev, Optimal stopping and free-boundary prob-\\nlems. Springer, 2006.\\n[27] S. Finch, “Ornstein-Uhlenbeck process,” 2004.\\n[28] T. Park, W. Saad, and B. Zhou, “Centralized and distribu ted age of\\ninformation minimization with nonlinear aging functions i n the internet\\nof things,” IEEE Internet of Things Journal , vol. 8, no. 10, pp. 8437–\\n8455, 2020.\\n[29] D. P. Bertsekas and S. Shreve, Stochastic optimal control: the discrete-\\ntime case . 2004.\\n[30] P. J. Haas, Stochastic petri nets: Modelling, stability, simulation .\\nSpringer Science & Business Media, 2006.\\n[31] R. G. Gallager, Stochastic processes: theory for applications . Cambridge\\nUniversity Press, 2013.\\n[32] D. P. Bertsekas, Dynamic programming and optimal control , vol. 2.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='[31] R. G. Gallager, Stochastic processes: theory for applications . Cambridge\\nUniversity Press, 2013.\\n[32] D. P. Bertsekas, Dynamic programming and optimal control , vol. 2.\\nAthena scientiﬁc Belmont, MA, 1995.\\n[33] D. P. Bertsekas, Abstract dynamic programming . Athena Scientiﬁc\\nNashua, NH, USA, 2018.\\n[34] S. M. Ross, J. J. Kelly, R. J. Sullivan, W. J. Perry, D. Mer cer, R. M.\\nDavis, T. D. Washburn, E. V . Sager, J. B. Boyce, and V . L. Brist ow,\\nStochastic processes , vol. 2. Wiley New York, 1996.\\n[35] W. Dinkelbach, “On nonlinear fractional programming, ”Management\\nscience , vol. 13, no. 7, pp. 492–498, 1967.\\n[36] D. Bertsekas, A. Nedic, and A. Ozdaglar, Convex analysis and optimiza-\\ntion, vol. 1. Athena Scientiﬁc, 2003.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='[36] D. Bertsekas, A. Nedic, and A. Ozdaglar, Convex analysis and optimiza-\\ntion, vol. 1. Athena Scientiﬁc, 2003.\\n[37] S. Boyd, S. P. Boyd, and L. Vandenberghe, Convex optimization .\\nCambridge university press, 2004.\\n[38] D. P. Bertsekas, Dynamic programming and optimal control , vol. 1.\\nAthena scientiﬁc Belmont, MA, 1995.\\n[39] M. L. Puterman, Markov decision processes: discrete stochastic dynamic\\nprogramming . John Wiley & Sons, 2014.\\n[40] L. I. Sennott, “A new condition for the existence of opti mum sta-\\ntionary policies in average cost Markov decision processes -unbounded\\ncost case,” in 1986 25th IEEE Conference on Decision and Control ,\\npp. 1719–1721, 1986.\\n[41] L. I. Sennott, “Average cost optimal stationary polici es in inﬁnite state\\nMarkov decision processes with unbounded costs,” Operations Research ,\\nvol. 37, no. 4, pp. 626–633, 1989.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Markov decision processes with unbounded costs,” Operations Research ,\\nvol. 37, no. 4, pp. 626–633, 1989.\\n[42] L. I. Sennott, “A new condition for the existence of opti mal station-\\nary policies in average cost Markov decision processes,” Operations\\nresearch letters , vol. 5, no. 1, pp. 17–23, 1986.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='[42] L. I. Sennott, “A new condition for the existence of opti mal station-\\nary policies in average cost Markov decision processes,” Operations\\nresearch letters , vol. 5, no. 1, pp. 17–23, 1986.\\n[43] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction .\\nMIT press, 2018.\\n[44] M.-A. Poubelle, R. R. Bitmead, and M. R. Gevers, “Fake al gebraic ric-\\ncati techniques and stability,” IEEE Transactions on Automatic Control ,\\nvol. 33, no. 4, pp. 379–381, 1988.\\n[45] S. Resnick, A probability path . Springer, 2019.\\n[46] D. P. Bertsekas, “Nonlinear programming,” Journal of the Operational\\nResearch Society , vol. 48, no. 3, pp. 334–334, 1997.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xiii\\n[47] D. Butnariu and A. N. Iusem, Totally convex functions for ﬁxed points\\ncomputation and inﬁnite dimensional optimization , vol. 40. Springer\\nScience & Business Media, 2000.\\n[48] W. Rudin, Principles of mathematical analysis , vol. 3. McGraw-hill\\nNew York, 1976.\\nAPPENDIX A\\nPROOF OF (7)\\nAt timet∈[Di,Mi,Di+1,Mi+1), the estimator has received\\nthe following information: (i) the sequence of the source\\nprocess{OSj,Mj}j≤i, (ii) the linear observations {Bτ}0≤τ≤t,\\nand (iii) the causal information of the channel delays that a re\\nprior toDi,Mi, denoted as Hremote\\nt for simplicity. Then, the\\nMMSEˆOtsatisﬁes\\nˆOt=E[\\nOt⏐⏐⏐{Bτ}0≤τ<Si,Mi,{Bτ}Si,Mi≤τ≤t,{OSj,Mj}j≤i,\\nHremote\\nt,Di,Mi,Di+1,Mi+1]\\n. (70)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Hremote\\nt,Di,Mi,Di+1,Mi+1]\\n. (70)\\nUsing the strong Markov property of Otand the assumption\\nthat channel delays and the processes Wt,Vtare independent\\nwithOt, we have\\nˆOt=E[\\nOt⏐⏐⏐{Bτ}Si,Mi≤τ≤t,OSi,Mi,Di,Mi,Di+1,Mi+1]\\n.\\n(71)\\nSince in this paper, we assume that the sampling deci-\\nsion is independent of Ot,Othas no correlation with\\nDi,Mi,Di+1,Mi+1. Therefore,\\nˆOt=E[\\nOt⏐⏐⏐{Bτ}Si,Mi≤τ≤t,OSi,Mi]\\n, (72)\\nwhich is the same as (7).\\nAPPENDIX B\\nPROOF OF PROPOSITION 1\\nFor any matrix N, we denote [N]i,jas theith row and\\njth column element of N. Similarly, for any vector X,[X]j\\nis thejth element of X. We denote N≥0ifNis positive', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='jth column element of N. Similarly, for any vector X,[X]j\\nis thejth element of X. We denote N≥0ifNis positive\\nsemideﬁnite. For a matrix function Nt, we denote dNt/dtas\\nthe matrix that takes derivation on tin each element of Nt.\\nAlso, we say Ntis non-decreasing in tif for any a < b ,\\nNb−Na≥0. Note that for any two matrices NaandNbin\\nRn×n, ifNb−Na≥0, thentr(Nb)≥tr(Na).\\nAccording to [24, Proposition VII.C.2] ,Ntfort∈\\n[Di,Mi,Di+1,Mi+1)satisﬁes the following Riccati differential\\nequation:\\ndNt\\ndt=ΘNt+NtΘT+ΣΣT−NtHTR−1HNt.(73)\\nNote that NSi,Mi=0n×n. Therefore, Ntis computed com-\\npletely from time Si,Mitot, provided some constant parameter\\nmatrices. Note that the age is deﬁned as ∆t=t−Si,Mi, so', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='pletely from time Si,Mitot, provided some constant parameter\\nmatrices. Note that the age is deﬁned as ∆t=t−Si,Mi, so\\nNtalong with tr(Nt)are a function of age ∆t.\\nIt remains to show that tr(Nt)is non-decreasing in ∆t.\\nSinceNSi,Mi=0n×n, by (73), it is easy to see that dNt/dt≥\\n0whent=Si,Mi. By using [44, theorem3], dNt/dt≥0\\nfort≥Si,Mi, andNtis non-decreasing in tfort≥Si,Mi.\\nThus, we conclude that the MMSE tr(Nt)is anon-decreasing\\nfunction of the age ∆t.APPENDIX C\\nPROOF OF PROPOSITION 2\\nIn one-dimensional case, the MMSE is equal to ntand the\\ndifferential equation (73) reduces to\\ndnt\\ndt=−2θnt+σ2−h2\\nrn2\\nt. (74)\\nDeﬁneµt=nt−¯n, thenµtsatisﬁes\\ndµt\\ndt=−(2θ+2h2', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='rn2\\nt. (74)\\nDeﬁneµt=nt−¯n, thenµtsatisﬁes\\ndµt\\ndt=−(2θ+2h2\\nr¯n)µt−h2\\nrµ2\\nt. (75)\\nThe differential Equation (75) is a Bernoulli equation and t he\\nclosed-from solution to (8) can be derived accordingly, wit h\\nthe initial condition nSi,Mi= 0, fort∈[Di,Mi,Di+1,Mi+1).\\nTherefore, in one-dimensional case, we can further solve th e\\nMMSEntin closed-form, which is proved below.\\nFor simplicity, let us deﬁne A=−h2\\nr,B=−2θ, andC=\\nσ2. Note that we only use the above deﬁnitions of A,B,C in\\nthis subsection (i.e., Appendix B). Hence, (74) is equivale nt\\nto\\ndnt\\ndt=An2\\nt+Bnt+C. (76)\\nWe deﬁne a function µtsuch that\\nnt= ¯n+µt, (77)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='to\\ndnt\\ndt=An2\\nt+Bnt+C. (76)\\nWe deﬁne a function µtsuch that\\nnt= ¯n+µt, (77)\\nwhereµtis a function of time t. Since¯nis a constant, we\\nhavednt/dt=dµt/dt. We get\\ndµt\\ndt=A¯n2+B¯n+C+2A¯nµt+Aµ2\\nt+Bµt. (78)\\nSince¯nis the steady state solution of (76), we have A¯n2+\\nB¯n+C= 0. Hence, we have\\ndµt\\ndt= (2A¯n+B)µt+Aµ2\\nt. (79)\\nDeﬁneηt= 1/µt. This implies that dµt/dt=−(1/η2\\nt)dηt/dt.\\nSubstitute by this in (79), we get\\ndηt\\ndt=−(2A¯n+B)ηt−A, (80)\\n⇐⇒d(ηt+A\\n2A¯n+B)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='dηt\\ndt=−(2A¯n+B)ηt−A, (80)\\n⇐⇒d(ηt+A\\n2A¯n+B)\\ndt=−(2A¯n+B)(ηt+A\\n2A¯n+B).(81)\\nThe general solution to (81) is\\nηt=−A\\n2A¯n+B+Ke−(2A¯n+B)(t−Si,Mi), (82)\\nwith a constant K. Substitute this back into µt, and then in\\n(77), we get\\nnt= ¯n+1\\n−A\\n2A¯n+B+Ke−(2A¯n+B)(t−Si,Mi). (83)\\nTo determine K, we substitute by our initial condition nSi=\\n0. This implies\\nK=A\\n2A¯n+B−1\\n¯n=l−1\\n¯n, (84)\\nwherelis deﬁned in (10) Substitute by this back into (83),\\nobserving that ∆t=t−Si,Miand replacing A,B, andCby\\ntheir relative quantities, we get (8). Note that 1/¯n−l >0, thus,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xiv\\nntis a non-decreasing function of the age ∆t. This completes\\nthe proof.\\nWhenh= 0 (i.e.,A= 0), Riccati differential equation in\\n(74) reduces to\\ndnt\\ndt=−2θnt+σ2, (85)\\n⇐⇒d(nt−σ2\\n2θ)\\ndt=−2θ(nt−σ2\\n2θ). (86)\\nUsing the same technique from (81) – (84) with initial\\ncondition nSi,Mi= 0, we get (11).\\nAPPENDIX D\\nPROOF OF COROLLARY 1\\nThe proof is to ﬁnd out the function v(δ)such that\\nAssumption 1 holds. Corollary (a) easily holds by taking\\nv(δ) = 1 . For Corollary 1 (b), note that by H¨ older’s inequality,\\nifE[\\nYn+1]\\n<∞, thenE[\\nYi]\\n<∞for alli≤n+ 1 [45,\\npp. 189]. We choose\\nv(δ) ={mn+1ifδ <¯m,\\nδn+1ifδ≥¯m,(87)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='pp. 189]. We choose\\nv(δ) ={mn+1ifδ <¯m,\\nδn+1ifδ≥¯m,(87)\\nwhere¯mis a value that satisﬁes\\nE[\\n(1+¯z+ ¯x\\n¯m+Y\\n¯m)n+1]\\n<ρ\\nα, (88)\\nwithρsatisfying α < ρ < 1. In other words, as long as\\nv(δ) = Θ(δ¯m)for¯m≥n+1, Assumption 1 is satisﬁed (by\\ntakingm= 1). Note that E[\\nYi]\\n<∞is also the sufﬁcient\\nand necessary condition that the function G(δ)is well-deﬁned.\\nFor Corollary 1 (c), note that by using mean value theorem,\\nlim\\n¯m→∞(¯m+ ¯z+ ¯x+ ¯y)b−mb= 0 (89)\\nThus (taking m= 1), we choose\\nv(δ) ={\\nea¯mbifδ <¯m,\\neaδbifδ≥¯m,(90)\\nwhere¯mis a value that satisﬁes', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='v(δ) ={\\nea¯mbifδ <¯m,\\neaδbifδ≥¯m,(90)\\nwhere¯mis a value that satisﬁes\\nea((¯m+¯z+¯x+¯y)b−¯mb)<ρ\\nα. (91)\\nAPPENDIX E\\nPROOF OF LEMMA 4\\nLet˜z≜x+zand deﬁne\\n˜gγ(δ,˜z)≜EY[∫δ+˜z+Y\\nδp(t)dt−(popt+γ)(˜z+Y)]\\n.\\nIt is easy to see that ˜gγ(δ,˜z) =gγ(δ,x,z). Note that gγ(δ,x,z)\\nis increasing in δ. Showing that gγ(δ,x,z)is bounded from\\nbelow is equivalent to showing that inf˜z≥0˜gγ(δ,˜z)>−∞.\\nThe one-sided derivatives of a function q(w)atwis deﬁned\\nas\\nδ+q(w)≜lim\\nǫ→0+q(w+ǫ)−q(w)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='as\\nδ+q(w)≜lim\\nǫ→0+q(w+ǫ)−q(w)\\nǫ. (92)\\nδ−q(w)≜lim\\nǫ→0+q(w)−q(w−ǫ)\\nǫ. (93)Let us denote k(δ,˜z,y) =∫δ+˜z+y\\nδp(t)dt. Then,k(δ,˜z,y)is\\nan integration of a non-decreasing function and is thus conv ex\\nin˜z. Thus,gγ(δ,˜z)is also convex in ˜z. Sincek(δ,˜z,y)and\\n˜gγ(δ,˜z)are both convex in ˜z, the one-sided derivatives of\\nk(δ,˜z,y)and˜gγ(δ,˜z)at˜zexist [46, p. 709]. Also, the function\\nǫ→[k(δ,˜z+ǫ,y)−k(δ,˜z,y)]/ǫis non-decreasing in ǫ∈', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='ǫ→[k(δ,˜z+ǫ,y)−k(δ,˜z,y)]/ǫis non-decreasing in ǫ∈\\n[−θ,0)or(0,θ]for someθ >0[47, Proposition 1.1.2(i)]. Note\\nthatk(δ,˜z±θ,Y)and one-sided derivatives of k(δ,˜z,Y)are\\nboth integrable8. By using Dominated Convergence Theorem\\n[45, Theorem 5.3.3], we have\\nδ+˜gγ(δ,˜z)\\n= lim\\nǫ→0+1\\nǫE[k(δ,˜z+ǫ,Y)−k(δ,˜z,Y)]−(popt+γ)(94)\\n=E[\\nlim\\nǫ→0+1\\nǫ(k(δ,˜z+ǫ,Y)−k(δ,˜z,Y))]\\n−(popt+γ)\\n=E[\\nlim\\n˜z′→˜z+p(δ+ ˜z′+Y)]\\n−(popt+γ)\\n= lim', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='−(popt+γ)\\n=E[\\nlim\\n˜z′→˜z+p(δ+ ˜z′+Y)]\\n−(popt+γ)\\n= lim\\n˜z′→˜z+E[p(δ+ ˜z′+Y)]−(popt+γ), (95)\\nSimilarly, for the other direction, we get\\nδ−˜gγ(δ,˜z) = lim\\n˜z′→˜z−E[p(δ+ ˜z′+Y)]−(popt+γ).(96)\\nTherefore, the solution to inf˜z≥0˜gγ(δ,˜z)is\\n˜z∗= inf{˜z≥0 :E[p(δ+ ˜z+Y)]≥popt+γ}. (97)\\nNote that ˜z∗≤inf{z≥0 :p(z)≥popt+γ}and thus is\\nﬁnite and irrelevant to δ,x. Also,gγ(δ,x,z)≥gγ(0,x,z).\\nTherefore, gγ(δ,x,z)is bounded from below by a constant\\n−η. Moreover,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Therefore, gγ(δ,x,z)is bounded from below by a constant\\n−η. Moreover,\\nJπ(δ,x)≥E\\uf8ee\\n\\uf8f0M∑\\nj=1−η\\uf8f9\\n\\uf8fb=−η\\n1−α. (98)\\nAPPENDIX F\\nPROOF OF (51)\\nWe have\\nJπ,γ(δ,x) (99)\\n=E\\uf8ee\\n\\uf8f0Mi∑\\nj=1gγ(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x\\uf8f9\\n\\uf8fb\\n=∞∑\\nm=1E\\uf8ee\\n\\uf8f0M∑\\nj=1gγ(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x,M=m\\uf8f9\\n\\uf8fb\\n×P(M=m)\\n(i)=∞∑\\nm=1E\\uf8ee\\n\\uf8f0m∑', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='\\uf8fb\\n×P(M=m)\\n(i)=∞∑\\nm=1E\\uf8ee\\n\\uf8f0m∑\\nj=1gγ(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x\\uf8f9\\n\\uf8fb\\n×P(M=m)\\n8In this paper, although we set p(δ)as a non-decreasing real-valued\\nfunction in [0,∞), we allow an exception that p(0) =−∞ . Ifp(0) =−∞ ,\\nwe will assume that there exists a small enough η >0such that P(Y+X <\\nη) = 0 , i.e.,δ+x≥ηwith probability 1. Therefore, ˜z >0whenδ= 0\\nand the one-sided derivatives of k(δ,˜z,Y)at˜zare always integrable.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xv\\n=∞∑\\nm=1m∑\\nj=1E[\\ngγ(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x]\\n×αm−1(1−α)\\n(ii)=∞∑\\nj=1∞∑\\nm=jE[\\ngγ(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x]\\n×αm−1(1−α)\\n=∞∑\\nj=1αj−1E[\\ngγ(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x]\\n.(100)\\nNote that step (i)occurs because the decisions Zj(j=\\n1,...m)only depend on the causal information δ1,x1,z1...\\nδj,xjand thus gγ(∆j,Xj,Zj)is independent of Mgiven\\nthatM≥j. Also, step (ii)is due to Lemma 4 and the\\nrearrangement of series in [48, Chapter 3].\\nAPPENDIX G', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='thatM≥j. Also, step (ii)is due to Lemma 4 and the\\nrearrangement of series in [48, Chapter 3].\\nAPPENDIX G\\nPROOF OF LEMMA 5\\nSinceδ+x+π(δ,x) +yis Borel measurable and\\nuis lower semianalytic, u(δ+x+π(δ,x) +y,x′)is\\nlower semianalytic in (δ,x,y,x′)[29, Lemma 7.30]. Thus,\\nEY,X[u(δ+π(δ,x)+Y,X)]is lower semianalytic in (δ,x)\\n[29, Proposition 7.48]. Since the function gγ(·)is Borel-\\nmeasurable and thus is lower semianalytic, Tπ,γ(δ,x)is thus\\nlower semianalytic. Since the inﬁmum of a lower semianalyti c\\nfunction is still lower semianalytic [29, Proposition 7.47 ],\\nTγu(δ,x)is lower semianalytic.\\nAPPENDIX H\\nPROOF OF LEMMA 7', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='function is still lower semianalytic [29, Proposition 7.47 ],\\nTγu(δ,x)is lower semianalytic.\\nAPPENDIX H\\nPROOF OF LEMMA 7\\nThe proofs of Jµmin,γ=TγJµmin,γandJµmax,γ=TγJµmax,γ\\nare the same. Therefore, we provide the proof of Jµmin,γ=\\nTγJµmin,γ. For simplicity, in this subsection, we denote µ=\\nµmin,γ,T=Tγ, andb=bmin,γ.\\nWe will show that JµsatisﬁesTJµ=Jµ. We deﬁne the\\nq-function Qµ(δ,x,z)as the discounted cost of starting at δ,\\nusingzat the ﬁrst stage and then using µfor the remaining\\nstages [38, Section 6] [43, Chapter 3]. It is easy to ﬁnd that\\nQµ(δ,x,z) =g(δ,x,z)+αEX,Y[Jµ(δ+z+Y,X)].(101)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Qµ(δ,x,z) =g(δ,x,z)+αEX,Y[Jµ(δ+z+Y,X)].(101)\\nThus, it is equivalent to show that for all state δ,x,Jµ(δ,x)≤\\nQµ(δ,x,z)for allz.\\nFrom (51), the discounted cost is equal to the stopping cost.\\nAccording to the deﬁnition of Qµ(δ,x,z)and (51), we can\\ndirectly provide the detailed expression of Qµ(δ,x,z)with\\nregard to the total cost like (47):\\nLemma 11. We have\\nQµ(δ,x,z) =E\\uf8ee\\n\\uf8f0M∑\\nj=1g(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x\\uf8f9\\n\\uf8fb,\\n(102)\\nwhere\\n∆j+1=Xj+∆j+Zj+Yjj= 1,2...M, (103)\\nZj={z ifj= 1,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='\\uf8fb,\\n(102)\\nwhere\\n∆j+1=Xj+∆j+Zj+Yjj= 1,2...M, (103)\\nZj={z ifj= 1,\\nµ(∆j,Xj)ifj= 2,...M.(104)! \"#$!\"#$!\\n#%\"#$\"& \"\\'!\\'( &\\n!\"#$!#)#$#\\n#%\"#)#% #\\nFigure 7: Evolution diagram of µatithepoch when δ+x < b .\\n!\"#$#% !\\n#&\"#%\"\\' \"(!#$ \\'\\n!\"#$#% !)#%#\\n#&!#*#& #\"#$#% !\\nFigure 8: Evolution diagram of the policy described in Lemma\\n11 when δ+x < b andw≥0.\\nLemma 11 implies that Qµ(δ,x,z)is equal to the stopping\\ncost such that it waits for zat stage1and follows the same\\ndecision as µfor the stage 2,...M .\\nFor simplicity, we denote\\nw=z−µ(δ,x) (105)\\nas the waiting time difference. Note that wis a simple function\\nofzwith a ﬁxed value µ(δ,x). Recall that bis the threshold of', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='as the waiting time difference. Note that wis a simple function\\nofzwith a ﬁxed value µ(δ,x). Recall that bis the threshold of\\nµgiven in (58). If the state addition δ+x < b , thenµ(δ,x) =\\nb−δ−x >0, otherwise µ(δ,x) = 0 . Note that if µ(δ,x) = 0 ,\\nw≥0since the waiting time z≥0. Thus, there are 3 different\\ncases based on δ+x, constant bandw:\\nCase (a)δ+x < b andw≥0,\\nCase (b) δ+x < b andw <0,\\nCase (c)δ+x≥b(as stated before, this implies w≥0).\\nCase (a) : Sinceδ+x < b , at stage 1,µ(δ,x) =b−δ−x,\\nand for the remaining stages, µchooses zero-wait. See Fig. 7\\nfor the diagram of evolution. According to (47),\\nJµ(δ,x) =E[∫b+Y1+∑M\\nj=2(Xj+Yj)\\nδp(t)dt', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Jµ(δ,x) =E[∫b+Y1+∑M\\nj=2(Xj+Yj)\\nδp(t)dt\\n−(popt+γ)(\\nb−δ+Y1+M∑\\nj=2(Xj+Yj))]\\n,(106)\\nwhereE=EM,Y1,X2,...,XM,YM.\\nSincew≥0in Case (a), the second age state ∆2+X2=\\nb+w+Y1+X2≥b, the waiting times at stage 2,3,...are\\nthus0(see Fig. 8 for the evolution diagram). This gives\\nQµ(δ,x,z) =E[∫b+w+Y1+∑M\\nj=2(Xj+Yj)\\nδp(t)dt\\n−(popt+γ)(\\nb−δ+w+Y1+M∑\\nj=2(Xj+Yj))]\\n.(107)\\nIt is obvious that Qµ(δ,x,µ(δ,x)) =Jµ(δ,x).\\nNote that in Case (b) and (c), Qµ(δ,x,z)does not satisfy', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Note that in Case (b) and (c), Qµ(δ,x,z)does not satisfy\\n(107). Thus, for convenience, we rewrite\\nq(w) =E[∫b+w+Y1+∑M\\nj=2(Xj+Yj)\\nδp(t)dt\\n−(popt+γ)(\\nb−δ+w+Y1+M∑\\nj=2(Xj+Yj))]\\n.(108)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xvi\\n! \"#$!%&%$\" \"%!#& \\'\\n!\"#$!#(#$#\\n#)$#(#) #\"#&#$ \"\\nFigure 9: Evolution diagram of the policy described in Lemma\\n11 when δ < b andw <0given that Yi,1<−w.\\nFor the ease of description, we denote Y′asY1+∑M\\nj=2(Xj+\\nYj). Then, we rewrite the function that is inside the expectatio n\\nofq(w)in (108):\\nf(w,Y′) =∫b+w+Y′\\nδp(t)dt−(popt+γ)(b−δ+w+Y′).\\n(109)\\nIt is obvious that q(0) =Jµ(δ,x). Function q(w)is the cost\\nof the policy that waits z=w+µ(δ,x)at stage1and does\\nnot wait at stage 2,...M where we allow w≤0in (108).\\nBy using the same technique in Appendix E, we have for\\nallw >−b(note that in case (a) and case (b), b >0), the\\none-sided derivatives of q(w)satisfy\\nδ+q(w) = lim', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='allw >−b(note that in case (a) and case (b), b >0), the\\none-sided derivatives of q(w)satisfy\\nδ+q(w) = lim\\nx→w+E[p(b+x+Y′)]−(popt+γ),(110)\\nδ−q(w) = lim\\nx→w−E[p(b+x+Y′)]−(popt+γ).(111)\\nSinceδ+x < b ,b >0. From the deﬁnition of threshold bin\\n(58) and b >0, we have\\nlim\\nw′→0+E[p(b+w′+Y′)]−(popt+γ)≥0, (112)\\nlim\\nw′→0−E[p(b+w′+Y′)]−(popt+γ)≤0. (113)\\nBy (110)-(113), w= 0 is the local minimum of q(w). Since\\nq(w)is convex, w= 0 is the global optimum of q(w)with\\nq(0) =Jµ(δ,x), andq(w)is non-decreasing at w≥0and', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='q(0) =Jµ(δ,x), andq(w)is non-decreasing at w≥0and\\nnon-increasing at w≤0. Thus,Qµ(δ,x,z) =q(w)≥Jµ(δ,x)\\nfor allw≥0(i.e.,z≥µ(δ)). This proves Case (a).\\nCase (b) : Sinceδ+x < b as well,Jµsatisﬁes (106). In Case\\n(a) where w≥0,Qµ(δ,x,z) =q(w). However, in Case (b)\\nwherew <0,Qµ(δ,x,z)is not equal to q(w); because there\\nis a probability that ∆2+X2=b+Y1+X2< b, which leads\\nto the waiting time at stage 2not0. This difference makes\\nour problem challenging. To show that Qµ(δ,x,z)≥Jµ(δ,x)\\nin Case (b), we will derive Qµ(δ,x,z)using the law of total\\nexpectation based on Y1+X2andM.\\nFirst, observe that', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='in Case (b), we will derive Qµ(δ,x,z)using the law of total\\nexpectation based on Y1+X2andM.\\nFirst, observe that\\nQµ(δ,x,z)−Jµ(δ,x)\\n=(Qµ(δ,x,z)−q(w))+(q(w)−Jµ(δ,x)). (114)\\nIn Case (a), we have already shown that q(w)−Jµ(δ,x)is\\npositive. Then, we focus on Qµ(δ,x,z)−q(w).We use law of iteration on Mand then iterate on Y1+X2\\ngiven that M >1, and we have\\nq(w) =E[\\nf(w,Y′)⏐⏐⏐M= 1]\\nP(M= 1) (115)\\n+E[\\nf(w,Y′)⏐⏐⏐M >1,Y1+X2≥ −w]\\n×P(M >1,Y1+X2≥ −w) (116)\\n+E[', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='×P(M >1,Y1+X2≥ −w) (116)\\n+E[\\nf(w,Y′)⏐⏐⏐M >1,Y1+X2<−w]\\n×P(M >1,Y1+X2<−w). (117)\\nNote that we denote Y′=Y1+∑M\\nj=2(Yj+Xj)for the ease\\nof descriptions.\\nNow, we analyse Qµ(δ,x,z). We rewrite Qµ(δ,x,z)in\\nLemma 11:\\nQµ(δ,x,z) =E\\uf8ee\\n\\uf8f0M∑\\nj=1g(∆j,Xj,Zj)⏐⏐⏐∆j=δ,X1=x\\uf8f9\\n\\uf8fb,\\nwith waiting time Zjto beµ(δ,x) +wat stagej= 1 and\\nµ(∆j,X2)for remaining stages.\\nWe write Qµ(δ,x,z)according to the same iterations as\\nparallel to (115) (116) (117):\\nQµ(δ,x,z)\\n=E\\uf8ee', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='parallel to (115) (116) (117):\\nQµ(δ,x,z)\\n=E\\uf8ee\\n\\uf8f0M∑\\nj=1g(∆j,Xj,Zj)⏐⏐⏐M= 1\\uf8f9\\n\\uf8fbP(M= 1) (118)\\n+E\\uf8ee\\n\\uf8f0M∑\\nj=1g(∆j,Xj,Zj)⏐⏐⏐M >1,Y1+X2≥ −w\\uf8f9\\n\\uf8fb\\n×P(M >1,Y1+X2≥ −w) (119)\\n+E\\uf8ee\\n\\uf8f0M∑\\nj=1g(∆j,Xj,Zj)⏐⏐⏐M >1,Y1+X2<−w\\uf8f9\\n\\uf8fb\\n×P(M >1,Y1+X2<−w). (120)\\nIfM= 1, then there is no sample from stage 2. Thus,\\nE\\uf8ee\\n\\uf8f0M∑', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='×P(M >1,Y1+X2<−w). (120)\\nIfM= 1, then there is no sample from stage 2. Thus,\\nE\\uf8ee\\n\\uf8f0M∑\\nj=1g(∆j,Xj,Zj)⏐⏐⏐∆1=δ,X1=x,M= 1\\uf8f9\\n\\uf8fb(121)\\n=g(δ,x,z) (122)\\n=E[\\nf(w,Y′)⏐⏐⏐M= 1]\\n. (123)\\nThis implies that the right hand side of (115) and the right\\nhand side of (118) are equal.\\nIfM >1andY1+X2≥ −w, then∆2+X2=b+w+\\nY1+X2≥b. From (104) in Lemma 11, ∆2+X2≥bimplies\\nthat the waiting time at stage 2,3,...is0. Thus, Case (b2) is\\nequivalent to Case (a), which gives\\nE\\uf8ee\\n\\uf8f0M∑', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='that the waiting time at stage 2,3,...is0. Thus, Case (b2) is\\nequivalent to Case (a), which gives\\nE\\uf8ee\\n\\uf8f0M∑\\nj=1g(∆j,Zj)⏐⏐⏐∆1=δ,M >1,Y1+X2≥ −w\\uf8f9\\n\\uf8fb\\n(124)\\n=E[\\nf(w,Y′)⏐⏐⏐M >1,Y1+X2≥ −w]\\n. (125)\\nThis implies that (116) and (119) are equal.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xvii\\nIfM >1andY1+X2<−w, then Lemma 11 implies that\\nthe waiting time at stage 2is equal to\\nµ(b+w+Y1,X2) =b−(b+w+Y1+X2) =−w−(Y1+X2),\\n(126)\\nwhich is strictly larger than 0.\\nNote that at stage 2, the policy has already added up the total\\ntime tob. Then, the waiting time for stage 3,4...is0because\\n∆3≥band age is increasing. See Fig. 9 for the diagram of\\nevolution. Thus, given that M >1andY1+X2<−w, the\\nexpression of Qµ(δ,x,z)in (120) and the waiting time (126)\\ntells that\\nE\\uf8ee\\n\\uf8f0M∑\\nj=1g(∆j,Xj,Zj)⏐⏐⏐M >1,Y1+X2<−w\\uf8f9\\n\\uf8fb(127)\\n=E[∫b+w+Y1+X2+(−w−Y1−X2)+Y2+∑M\\nj=3(Yj+Xj)\\nδp(t)dt', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='=E[∫b+w+Y1+X2+(−w−Y1−X2)+Y2+∑M\\nj=3(Yj+Xj)\\nδp(t)dt\\n−(popt+γ)(\\nb−δ+w+Y1+X2+(−w−Y1−X2)\\n+Y2+M∑\\nj=3(Yj+Xj))⏐⏐⏐M >1,Y1+X2<−w]\\n(128)\\n=E[∫b+Y2+∑M\\nj=3(Yj+Xj)\\nδp(t)dt−(popt+γ)(\\nb−δ+Y2\\n+M∑\\nj=3(Yj+Xj))⏐⏐⏐M >1,Y1+X2<−w]\\n(129)\\n=E[∫b+Y2+∑M\\nj=3(Yj+Xj)\\nδp(t)dt−(popt+γ)(\\nb−δ+Y2\\n+M∑\\nj=3(Yj+Xj))⏐⏐⏐M >1]\\n(130)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='b−δ+Y2\\n+M∑\\nj=3(Yj+Xj))⏐⏐⏐M >1]\\n(130)\\n(i)=E[∫b+Y2+∑M+1\\nj=3(Yj+Xj)\\nδp(t)dt−(popt+γ)(\\nb−δ+Y2\\n+M+1∑\\nj=3(Yj+Xj))]\\n(131)\\n(ii)=E[∫b+Y1+∑M\\nj=2(Yj+Xj)\\nδp(t)dt−(popt+γ)(\\nb−δ+Y1\\n+M∑\\nj=2(Yj+Xj))]\\n(132)\\n(iii)=Jµ(δ,x). (133)\\nNote that Mis geometric distributed and thus Mgiven that\\nM >1andM+1have the same distribution. This implies (i).\\nCondition (ii)is because Yj’s are i.i.d., and (iii)is directly\\nfrom the deﬁnition of Jµ(δ,x)in (106).', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Condition (ii)is because Yj’s are i.i.d., and (iii)is directly\\nfrom the deﬁnition of Jµ(δ,x)in (106).\\nHaving considered Case (b1)-(b3), to analyze Qµ(δ,x,z)−\\nq(w), we compare (115),(116),(117) with (123),(125),(133).Note that by Case (b1) and Case (b2), (115),(116) are can-\\ncelled out by (123),(125). We ﬁnally get\\nQµ(δ,x,z)−q(w)\\n=Jµ(δ,x)P(M >1,Y1+X2<−w)\\n−E\\uf8ee\\n\\uf8f0f(\\nw,Y1+M∑\\nj=2(Yj+Xj))⏐⏐⏐M >1,Y1+X2<−w\\uf8f9\\n\\uf8fb\\n×P(M >1,Y1+X2<−w). (134)\\nBy the deﬁnition of fin (109),\\nE\\uf8ee\\n\\uf8f0f(\\nw,Y1+M∑', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='By the deﬁnition of fin (109),\\nE\\uf8ee\\n\\uf8f0f(\\nw,Y1+M∑\\nj=2(Yj+Xj))⏐⏐⏐M >1,Y1+X2<−w\\uf8f9\\n\\uf8fb\\n≜E[∫b+w+Y1+∑M\\nj=2(Yj+Xj)\\nδp(t)dt−(popt+γ)(\\nb−δ\\n+w+Y1+M∑\\nj=2(Yj+Xj))⏐⏐⏐M >1,Y1+X2<−w]\\n(135)\\n(i)=E[∫b+w+Y1+∑M+1\\nj=2(Yj+Xj)\\nδp(t)dt−(popt+γ)(\\nb−δ\\n+w+Y1+M+1∑\\nj=2(Yj+Xj))⏐⏐⏐Y1+X2<−w]\\n(136)\\n=E[∫b+(w+Y1+X2)+Y2+∑M+1\\nj=3(Xj+Yj)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='(136)\\n=E[∫b+(w+Y1+X2)+Y2+∑M+1\\nj=3(Xj+Yj)\\nδp(t)dt\\n−(popt+γ)(\\nb−δ+(w+Y1+X2)\\n+Y2+M+1∑\\nj=3(Xj+Yj))⏐⏐⏐Y1+X2<−w]\\n(137)\\n(ii)=EY1,X2[\\nq(w+Y1+X2)⏐⏐⏐Y1+X2<−w]\\n. (138)\\nHere(i)is because Mhas geometric distribution, and thus M\\ngiven that M >1andM+1have the same distribution. Since\\nYj’s are independent, (ii)is because Y2+∑M+1\\nj=3(Yj+Xj)in\\n(137) and Y1+∑M\\nj=2(Yj+Xj)inside the deﬁnition of Jµ(δ)\\nin (108) have the same distributions. We have shown in Case\\n(a) thatq(w)is decreasing at w≤0. SinceY1+X2<−w', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='in (108) have the same distributions. We have shown in Case\\n(a) thatq(w)is decreasing at w≤0. SinceY1+X2<−w\\nandw <0, we have\\nw≤w+Y1+X2<0. (139)\\nThus,\\nq(w+Y1+X2)≤q(w). (140)\\nThen, (138) and (140) gives\\nE\\uf8ee\\n\\uf8f0f(\\nw,Y1+M∑\\nj=2(Yj+Xj))⏐⏐⏐M >1,Y1+X2<−w\\uf8f9\\n\\uf8fb\\n=EY1,X2[\\nq(w+Y1+X2)⏐⏐⏐Y1+X2<−w]\\n(141)\\n≤EY1,X2[\\nq(w)⏐⏐⏐Y1+X2<−w]\\n(142)\\n=q(w). (143)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xviii\\nThus, (134) and (143) give\\nQµ(δ,x,z)−q(w)\\n≥(Jµ(δ,x)−q(w))P(M >1,Y1+X2<−w). (144)\\nNote that q(w)−Jµ(δ,x)is already analyzed in Case (a) and\\nis positive. Finally, (114), (144), and q(w)−Jµ(δ,x)≥0give\\nQµ(δ,x,z)−Jµ(δ,x)\\n≥(Jµ(δ,x)−q(w))P(M >1,Y1+X2<−w)\\n+q(w)−Jµ(δ,x)\\n=(q(w)−Jµ(δ,x))(1−P(M >1,Y1+X2<−w))\\n≥0, (145)\\nwhich completes Case (b).\\nCase (c) Case (c) is similar with Case (a).\\nSinceδ+x≥b,µ(δ,x) = 0 , which means that the policy', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='which completes Case (b).\\nCase (c) Case (c) is similar with Case (a).\\nSinceδ+x≥b,µ(δ,x) = 0 , which means that the policy\\nµchooses zero wait all the stages j= 1,...M . Thus,\\nJµ(δ,x) =E[∫δ+x+Y1+∑M\\nj=2(Yj+Xj)\\nδp(t)dt\\n−(popt+γ)(\\nx+Y1+M∑\\nj=2(Yj+Xj))]\\n=q(δ+x−b). (146)\\nSinceµ(δ,x) = 0 ,w≥0. From Lemma 11, for all z≥0,\\nQµ(δ,x,z)is the cost that chooses zat stage1but does not\\nwait from stages 2,3,.... We can get\\nQµ(δ,x,z) =E[∫δ+x+w+∑M\\nj=1Yj\\nδp(t)dt\\n−(popt+γ)(\\nx+w+Y1+M∑\\nj=2(Yj+Xj))]', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='j=1Yj\\nδp(t)dt\\n−(popt+γ)(\\nx+w+Y1+M∑\\nj=2(Yj+Xj))]\\n=q(w+δ+x−b). (147)\\nSinceδ≥b,w+δ+x−b≥0for allw≥0. Using the\\nsame technique as in Appendix E, q(w+δ+x−b)is convex\\nand non-decreasing in w≥0. This gives q(w+δ+x−b)≥\\nq(δ+x−b)for allw≥0. From (146) and (147), we ﬁnally\\ngetQµ(δ,x,z)≥Jµ(δ,x)for allz.\\nBy considering Case (a)-(c), we have shown that\\nQµ(δ,x,z)≥Jµ(δ,x)for allz, which completes the proof\\nofTJµ=Jµ. Now, we return the notation Jµback toJµmin,γ,', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='ofTJµ=Jµ. Now, we return the notation Jµback toJµmin,γ,\\nJµmax,γ. By the deﬁnition of Jµin (106) and (110)-(113), it\\nis easy to show that Jµmin,γ(δ,x) =Jµmax,γ(δ,x). Moreover,\\nsimilar to (106), for any probability λ∈[0,1], we have\\nJ˜µλ,γ(δ,x) =λJµmin,γ(δ,x)+(1−λ)Jµmax,γ(δ,x). Therefore,\\nJ˜µλ,γ=Jµmin,γ=Jµmax,γ. In conclusion, we have completed\\nthe proof of Lemma 7.\\nAPPENDIX I\\nPROOF OF LEMMA 8\\nSinceπ∈Πi,Jπ,γ(δ,x)is Borel measurable [29] and thus\\nis lower semianalytic. It remains to show that Jπ,γ(δ,x)isbounded by v(δ). By Lemma 4, Jπ,γ(δ,x)≥ −η/(1−α)for', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='allδ,x. Also,v(δ)is increasing and v(0)>0. Thus,\\nJπ,γ(δ,x)\\nv(δ)≥ −η\\nv(0)(1−α)≥ −∞. (148)\\nThen, we will show that Jπ,γ(δ,x)/v(δ)is upper bounded.\\nFrom Assumption 1 (b) and vis increasing, for all n≥1,\\nE[v(∆n+m)]\\n=E[v(∆n+m−1+Xn+m−1+Zn+m−1+Yn+m−1)]\\n≤E[v(∆n+m−1+ ¯x+ ¯z+Yn+m−1)]\\n···\\n≤E[v(∆n+m¯x+m¯z+Yn+···+Yn+m−1)]\\n(i)\\n≤ρ\\nαmE[v(∆n)], (149)\\nwhere(i)is from Assumption 1, and that ∆nis independent\\nfromYn,···,Yn+m−1.\\nThen, we look at the nthterm in (51). Note that ∆1=δ', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='fromYn,···,Yn+m−1.\\nThen, we look at the nthterm in (51). Note that ∆1=δ\\nand the positive function G(δ)is denoted in Assumption 1.\\nAlso,gγ(δ,x,z)is upper bounded by G(δ)plus a constant\\n|popt+γ|(¯x+ ¯z+E[Y])≜cthat is not related to δ. From\\nAssumption 1 (a), there exists k >0such that G(δ)/v(δ)≤k.\\nFor alln≥1,\\nαn−1E[g(∆n,Xn,Zn)]\\n≤αn−1(E[G(∆n)]+c)\\n≤αn−1·(k·E[v(∆n)]+c)\\n≤αn−1·(\\nk·ρ\\nαmE[v(∆n−m)]+c)\\n···\\n≤k·ρ⌊n−1\\nm⌋+1\\nαmv(∆1)+αn−1cgiven that ∆1=δ.(150)\\nThus, from (51),', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='m⌋+1\\nαmv(∆1)+αn−1cgiven that ∆1=δ.(150)\\nThus, from (51),\\nJπ(δ,x) =∞∑\\nn=1αn−1E[\\ng(∆n,Xn,Zn)⏐⏐⏐∆1=δ,X1=x]\\n≤mkv(δ)\\nαm∞∑\\nn=1ρn+∞∑\\nn=1αn−1c\\n=mkρ\\nαm(1−ρ)v(δ)+c\\n1−α. (151)\\nThus,Jπ,γ(δ,x)/v(δ)is bounded from above. By (148) and\\n(151), we immediately get Jπ,γ∈B(Λ).\\nAPPENDIX J\\nPROOF OF LEMMA 9\\nThe proof of Lemma 9 is modiﬁed from [32]. While [32,\\nAssumption 1.5.1] assumes countable state space and action\\nspace, we show that Lemma 9 also holds in uncountable state\\nspace and action space.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xix\\nWe denote z≜π(δ,x). By Assumption 1, z≤¯zandx≤¯x.\\nNote that gγ(δ,x,z)≤G(δ)+c, wherec=|popt+γ|(¯x+¯z+\\nE[Y]). Then, for all u∈B(Λ),\\nTπ,γu(δ,x)\\n=gγ(δ,x,z)+αE[u(δ+x+z+Y,X)]\\n≤G(δ)+αE[⏐⏐⏐⏐u(δ+x+z+Y,X)\\nv(δ+x+z+Y)⏐⏐⏐⏐v(δ+x+z+Y)]\\n+c\\n≤G(δ)+α∥u∥E[v(δ+x+z+Y)]+c\\n(i)\\n≤G(δ)+ρ\\nαm−1∥u∥v(δ)+c, (152)\\nwhere(i)is from Assumption 1 and that v(δ)is increasing.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='≤G(δ)+ρ\\nαm−1∥u∥v(δ)+c, (152)\\nwhere(i)is from Assumption 1 and that v(δ)is increasing.\\nOn the other hand, since gγ(δ,x,z)≥ −λ, we have\\nTπ,γu(δ,x)\\n≥−η−αE[⏐⏐⏐⏐u(δ+x+z+Y,X)\\nv(δ+x+z+Y)⏐⏐⏐⏐v(δ+x+z+Y)]\\n≥−η−ρ\\nαm−1∥u∥v(δ). (153)\\nThus, divide v(δ)and take maximum over δin (152) and\\n(153), we ﬁnally get\\n∥Tπ,γu∥ ≤max{∥G∥+c\\nv(0),η\\nv(0)}+ρ\\nαm−1∥u∥<∞.\\n(154)\\nThus,Tπ,γu∈B(Λ).\\nWe then show that Tγu∈B(Λ):', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='αm−1∥u∥<∞.\\n(154)\\nThus,Tπ,γu∈B(Λ).\\nWe then show that Tγu∈B(Λ):\\nTγu(δ,x)\\n= inf\\nz∈[0,¯z]gγ(δ,x,z)+αE[u(δ+x+z+Y,X)]\\n≤sup\\nz∈[0,¯z]g(δ,x,z)\\n+ sup\\nz∈[0,¯z]αE[⏐⏐⏐⏐u(δ+x+z+Y,X)\\nv(δ+x+z+Y)⏐⏐⏐⏐v(δ+x+z+Y)]\\n≤G(δ)+α∥u∥sup\\nz∈[0,¯z]E[v(δ+x+z+Y)]+c\\n≤G(δ)+ρ\\nαm−1∥u∥v(δ)+c. (155)\\nSimilarly,\\nTγu(δ)≥ −η−ρ', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='≤G(δ)+ρ\\nαm−1∥u∥v(δ)+c. (155)\\nSimilarly,\\nTγu(δ)≥ −η−ρ\\nαm−1∥u∥v(δ). (156)\\nThus,\\n∥Tγu∥ ≤max{∥G∥+c\\nv(0),η\\nv(0)}+ρ\\nαm−1∥u∥<∞,\\n(157)\\nwhich shows that Tγu∈B(Λ).\\nFor allu(δ,x),u′(δ,x)∈B(Λ) and any deterministic\\nstationary policy π0,···πm−1∈Πi, along with Assumption\\n1,\\n∥Tπ0,γ···Tπm−1,γu−Tπ0,γ···Tπm−1u′∥\\n≤sup\\nδ|E[u(∆m+1,Xm+1)−u′(∆m+1,Xm+1)]|\\nv(δ)αm\\n≤sup\\nδE[\\nv(δ+m¯x+m¯z+∑m', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='v(δ)αm\\n≤sup\\nδE[\\nv(δ+m¯x+m¯z+∑m\\nj=1Yj)]\\nv(δ)·αm∥u−u′∥\\n≤ρ∥u−u′∥, (158)where the last inequality is from Assumption 1. This implies\\nthe contraction mapping property of Tπ0,γ···Tπm−1,γ. By\\n(158), we have\\nTπ0,γ···Tπm−1,γu(δ,x)\\nv(δ)(159)\\n≤Tπ0,γ···Tπm−1,γu′(δ,x)\\nv(δ)+ρ∥u−u′∥. (160)\\nTaking the minimum for left and right sides of (160) of\\nπ0,···πm−1, respectively, we have\\nTm\\nγu(δ,x)\\nv(δ)≤Tm\\nγu′(δ,x)\\nv(δ)+ρ∥u−u′∥. (161)\\nReversing uandu′in (161), we ﬁnally get ∥Tm\\nγu−Tm', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='v(δ)+ρ∥u−u′∥. (161)\\nReversing uandu′in (161), we ﬁnally get ∥Tm\\nγu−Tm\\nγu′∥ ≤\\nρ∥u−u′∥, i.e., the Bellman operator Tγhas anm-stage\\ncontraction mapping property with modulus ρ <1. Combined\\nwithB(Λ) being complete, the uniqueness of Tγu=uis\\nshown directly by [32, Proposition 1.5.4]. Thus, we complet e\\nthe proof of Lemma 9.\\nAPPENDIX K\\nPROOF OF THEOREM 3\\nAccording to [36, Proposition 6.2.5], the policy π∗along\\nwith the dual variable γ∗is the optimal solution to (36) if the\\nfollowing conditions hold:\\nlim\\nn→∞1\\nnn∑\\ni=1E[\\nDi,Mi−Di−1,Mi−1]\\n−1\\nfmax(1−α)≥0,\\n(162)\\nπ∗∈Π,γ∗≥0, (163)\\nL(π∗;γ∗) = inf\\nπ∈ΠL(π;γ∗), (164)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='π∗∈Π,γ∗≥0, (163)\\nL(π∗;γ∗) = inf\\nπ∈ΠL(π;γ∗), (164)\\nγ∗{\\nlim\\nn→∞1\\nnn∑\\ni=1E[\\nDi,Mi−Di−1,Mi−1]\\n−1\\nfmax(1−α)}\\n= 0.\\n(165)\\nAccording to Lemma 10, the optimal solution to the primal\\nproblem (164) for a given γis given by l(γ). Therefore, we\\nwill seek γ∗andπ∗∈l(γ∗)that satisﬁes (162), (163) and\\n(165). According to Lemma 10, for any optimal policy with\\nwaiting times Zi,j’s, we have\\nDi,Mi−Di−1,Mi−1=Xi,1+Zi,1+Y′, (166)\\nZi,1≥µmin,γ(Yi−1,Mi−1,Xi,1), (167)\\nZi,1≤µmax,γ(Yi−1,Mi−1,Xi,1), (168)\\nThis motivates us to consider the following two cases.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Zi,1≤µmax,γ(Yi−1,Mi−1,Xi,1), (168)\\nThis motivates us to consider the following two cases.\\nCase 1 If (67) holds, then we take γ∗= 0 andπ∗=µmin,0.\\nThen, (162)-(165) are satisﬁed.\\nCase 2 If the condition (67) does not hold, we will seek γ∗>0\\nandπ∗∈l(γ∗)such that\\nlim\\nn→∞1\\nnn∑\\ni=1E[\\nDi,Mi−Di−1,Mi−1]\\n−1\\nfmax(1−α)= 0.\\n(169)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xx\\nBy (166)-(168), we need to seek γ∗>0such that\\nlim\\nn→∞1\\nnn∑\\ni=1E[\\nXi,1+µmin,γ∗(Yi−1,Mi−1,Xi,1)+Y′]\\n≤1\\nfmax(1−α)\\n≤lim\\nn→∞1\\nnn∑\\ni=1E[\\nXi,1+µmax,γ∗(Yi−1,Mi−1,Xi,1)+Y′]\\n,\\n(170)\\nSince the Yi,j’s and the Xi,j’s are i.i.d., and Yi−1,Mi−1is\\nindependent of the sampling times at epoch 0,1,2,...,i−1,\\n(170) is equivalent to\\nE[\\nXi,1+µmin,γ∗(Yi−1,Mi−1,Xi,1)+Y′]\\n≤1\\nfmax(1−α)\\n≤E[\\nXi,1+µmax,γ∗(Yi−1,Mi−1,Xi,1)+Y′]\\n. (171)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='fmax(1−α)\\n≤E[\\nXi,1+µmax,γ∗(Yi−1,Mi−1,Xi,1)+Y′]\\n. (171)\\nIt is easy to see that µmin,γ(δ,x)andµmin,γ(δ,x)are non-\\ndecreasing in γ. It holds that for all γ0≥0,\\nlim\\nγ→γ0−µmax,γ(δ,x) =µmin,γ0(δ,x)≤µmax,γ0(δ,x)\\n= lim\\nγ→γ0+µmin,γ(δ,x). (172)\\nBy Monotone Convergence Theorem [45, Theorem 5.3.1], we\\nhave\\nlim\\nγ→γ0−E[\\nµmax,γ(Yi−1,Mi−1,Xi,1)]\\n=E[\\nµmin,γ0(Yi−1,Mi−1,Xi,1)]\\n≤E[\\nµmax,γ0(Yi−1,Mi−1,Xi,1)]\\n= lim\\nγ→γ0+E[', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='≤E[\\nµmax,γ0(Yi−1,Mi−1,Xi,1)]\\n= lim\\nγ→γ0+E[\\nµmin,γ(Yi−1,Mi−1,Xi,1)]\\n. (173)\\nAccording to (173), there exists γ∗that satisﬁes (171). The\\noptimal policy π∗= ˜µλ,γ∗, whereλis deﬁned in (69) to\\nachieve (171). In both cases, the π∗andγ∗selected satisfy\\n(162)-(165).\\nAPPENDIX L\\nPROOF OF LEMMA 1\\n(a) Note that popt∈[p,¯p)∩R, so we consider β∈[p,¯p)∩R.\\nWe deﬁne\\nLi(π;β)\\n=E[∫Di,Mi\\nDi−1,Mi−1p(∆t)dt−β(\\nDi,Mi−Di−1,Mi−1)]\\n.\\n(174)\\nAs is shown in Section V-B,\\nf(β) = inf\\nπ∈ΠiLi(π;β). (175)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='.\\n(174)\\nAs is shown in Section V-B,\\nf(β) = inf\\nπ∈ΠiLi(π;β). (175)\\nIt is easy to see that Li(β,π)is linear in βand thus concave.\\nThen,f(β)is an inﬁmum of a sequence of concave functions\\nand is thus concave in β. For any policy π∈Πiandβ2>\\nβ1, we have Li(β2,π) =Li(β1,π) + (β2−β1)E[Di,Mi−\\nDi−1,Mi−1]. SinceE[Di,Mi−Di−1,Mi−1]is lower bounded by\\na positive value, taking inﬁmum on both sides, f(β)is strictly\\ndecreasing. Therefore, f(β)is concave and strictly decreasing\\ninβ∈[p,¯p)∩R.(b) By Lemma 2, we have h(popt) = 0 . By Lemma 3,\\nh(popt) = 0 is equivalent to f(popt) = 0 . Sincef(β)is strictly\\ndecreasing, there exists a unique root to f(β) = 0 .\\nAPPENDIX M', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='h(popt) = 0 is equivalent to f(popt) = 0 . Sincef(β)is strictly\\ndecreasing, there exists a unique root to f(β) = 0 .\\nAPPENDIX M\\nPROOF OF COROLLARY 2\\nWe use w.p. 1as the abbreviation of “with probability 1”.\\nWe ﬁrst prove the backward direction when (21) is satisﬁed.\\nFor any waiting time z≥0, we have\\nEY′[p(Y+X+z+Y′)|Y,X] (176)\\n≥EY′[p(Y+X+Y′)|Y,X] (177)\\n≥essinfEY′[p(Y+X+Y′)|Y,X]w.p.1, (178)\\n≥E[∫Y+X+Y′\\nYp(t)dt]\\nE[X+Y′]w.p.1. (179)\\nNote that E[∫Y+X+Y′\\nYp(t)dt]\\n/E[X+Y′]is the average age\\npenalty for the zero-wait policy and is no smaller than that o f\\nthe optimal policy. Thus,\\nE[∫Y+X+Y′', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='/E[X+Y′]is the average age\\npenalty for the zero-wait policy and is no smaller than that o f\\nthe optimal policy. Thus,\\nE[∫Y+X+Y′\\nYp(t)dt]\\nE[X+Y′]≥β. (180)\\nTherefore, (176)-(180) gives that w.p. 1, for any waiting time\\nz,EY′[p(Y+X+z+Y′)|Y,X]≥β. Combining with\\n(15) in Theorem 1, the zero-wait policy is optimal.\\nThen, we prove the forward direction. Suppose that by\\nTheorem 1, the zero-wait policy is optimal. Then, the zero-\\nwait policy Zi,j(β) = 0 satisﬁes (15) and (17) in Theorem 1.\\nThen, we have\\nEY′[p(Y+X+Y′)|Y,X]≥β. (181)\\nThus, we have\\nessinfEY′[p(Y+X+Y′)|Y,X]≥β. (182)\\nSince zero-wait policy is optimal, in Theorem 1, we have\\nβ=E[∫Y+X+Y′\\nYp(t)dt]', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='Since zero-wait policy is optimal, in Theorem 1, we have\\nβ=E[∫Y+X+Y′\\nYp(t)dt]\\nE[X+Y′]. (183)\\nThus, the forward direction is shown. Overall, the proof is\\ncompleted.\\nAPPENDIX N\\nPROOF OF COROLLARY 3\\nSuppose that Xi,j=xandYi,j=y. Since the Mi’s are\\ni.i.d and geometrically distributed, we use Mto replace Mi.\\nFrom Corollary 2, it is sufﬁcient to show that\\nE[p(y+M(x+y))]≥E[∫y+M(x+y)\\nyp(t)dt]\\nE[M(x+y)]. (184)\\nHere,\\nE[M(x+y)] =x+y\\n1−α, (185)\\nE[p(y+M(x+y))] =∞∑\\nm=1p(y+m(x+y))αm−1(1−α).\\n(186)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='xxi\\nIn addition,\\nE[∫y+M(x+y)\\nyp(t)dt]\\n=∞∑\\nm=1∫y+m(x+y)\\nyp(t)dt·αm−1(1−α) (187)\\n=∞∑\\nm=1m∑\\nn=1∫y+n(x+y)\\ny+(n−1)(x+y)p(t)dt·αm−1(1−α) (188)\\n=∞∑\\nn=1∞∑\\nm=n∫y+n(x+y)\\ny+(n−1)(x+y)p(t)dt·αm−1(1−α) (189)\\n=∞∑\\nn=1∫y+n(x+y)\\ny+(n−1)(x+y)p(t)dt·αn−1(190)\\n≤∞∑\\nn=1(x+y)p(y+n(x+y))αn−1(191)\\n(i)=E[M(x+y)]E[p(y+M(x+y))], (192)', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='(i)=E[M(x+y)]E[p(y+M(x+y))], (192)\\nwhere(i)comes directly from (185) and (186). Thus, we have\\nshown (184). This completes our proof.', metadata={'pdf': 'https://arxiv.org/pdf/2201.02929', 'link': 'https://openalex.org/works/W4225350605', 'title': 'Optimal Sampling for Data Freshness: Unreliable Transmissions With Random Two-Way Delay'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural\\nlanguage understanding\\nHENRY WELD, The University of Sydney, Australia\\nXIAOQI HUANG, The University of Sydney, Australia\\nSIQU LONG, The University of Sydney, Australia\\nJOSIAH POON, The University of Sydney, Australia\\nSOYEON CAREN HAN, The University of Sydney, Australia\\nIntent classification and slot filling are two critical tasks for natural language\\nunderstanding. Traditionally the two tasks have been deemed to proceed\\nindependently. However, more recently, joint models for intent classification\\nand slot filling have achieved state-of-the-art performance, and have proved\\nthat there exists a strong relationship between the two tasks. This article is\\na compilation of past work in natural language understanding, especially\\njoint intent classification and slot filling. We observe three milestones in\\nthis research so far: Intent detection to identify the speaker’s intention,\\nslot filling to label each word token in the speech/text, and finally, joint\\nintent classification and slot filling tasks. In this article, we describe trends,\\napproaches, issues, data sets, evaluation metrics in intent classification and\\nslot filling. We also discuss representative performance values, describe\\nshared tasks, and provide pointers to future work, as given in prior works.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='approaches, issues, data sets, evaluation metrics in intent classification and\\nslot filling. We also discuss representative performance values, describe\\nshared tasks, and provide pointers to future work, as given in prior works.\\nTo interpret the state-of-the-art trends, we provide multiple tables that\\ndescribe and summarise past research along different dimensions, including\\nthe types of features, base approaches, and dataset domain used.\\nCCS Concepts: •Computing methodologies →Natural language pro-\\ncessing ;Information extraction .\\nAdditional Key Words and Phrases: intent detection, slot labelling, spoken\\nlanguage understanding, natural language understanding\\n1 INTRODUCTION\\nThe efficacy of virtual assistants becomes more important as their\\npopularity rises. Central to their performance is the ability for the\\nelectronic assistant to understand what the human user is saying,\\nin order to act, or reply, in a way that meaningfully satisfies the\\nrequester.\\nThe human-device interface may be text based, but is now most\\nfrequently voice, and will probably in the near future include image\\nor video. To put the understanding of human utterances within a\\nframework, within the natural language processing (NLP) stack lies\\nspoken language understanding (SLU). SLU starts with automatic\\nspeech recognition (ASR), the task of taking the sound waves or\\nimages of expressed language, and transcribing to text. Natural', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='spoken language understanding (SLU). SLU starts with automatic\\nspeech recognition (ASR), the task of taking the sound waves or\\nimages of expressed language, and transcribing to text. Natural\\nlanguage understanding (NLU) then takes the text and extracts\\nthe semantics for use in further processes - information gathering,\\nquestion answering, dialogue management, request fulfilment, and\\nso on.\\nThe concept of a hierarchical semantic frame has developed to\\nrepresent the levels of meaning within spoken utterances. At the\\nAuthors’ addresses: Henry Weld, hwel4188@uni.sydney.edu.au, The University of Syd-\\nney, Sydney, Australia; Xiaoqi Huang, xhua7314@uni.sydney.edu.au, The University\\nof Sydney, Sydney, Australia; Siqu Long, slon6753@uni.sydney.edu.au, The University\\nof Sydney, Sydney, Australia; Josiah Poon, Josiah.Poon@sydney.edu.au, The Univer-\\nsity of Sydney, Sydney, Australia; Soyeon Caren Han, caren.han@sydney.edu.au, The\\nUniversity of Sydney, Sydney, Australia.query find recent comedies by james cameron\\nslots O B-date B-genre O B-dir I-dir\\nintent find_movie\\ndomain movies', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='University of Sydney, Sydney, Australia.query find recent comedies by james cameron\\nslots O B-date B-genre O B-dir I-dir\\nintent find_movie\\ndomain movies\\nTable 1. An example of an utterance as semantic frame with domain, intent\\nand IOB slot annotation (from [Hakkani-Tür et al. 2016])\\nhighest level is a domain, then intent and then slots. The domain\\nis the area of information the utterance is concerned with. The\\nintent (a.k.a. goal in early papers) is the speaker’s desired outcome\\nfrom the utterance. The slots are the types of the words or spans of\\nwords in the utterance that contain semantic information relevant\\nto the fulfilment of the intent. An example is given in Table 1 for', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='words in the utterance that contain semantic information relevant\\nto the fulfilment of the intent. An example is given in Table 1 for\\nthe domain movies . Within this domain the example has intent\\nfind_movie and the individual tokens are labelled with their slot tag\\nusing the IOB tagging format.\\nThe NLU task is thus the extraction of the semantic frame ele-\\nments from the utterance. NLU is important - it is central to devices\\nthat desire a spoken interface with humans - for example, conversa-\\ntional agents, instruction in vehicles (driverless or otherwise), Inter-\\nnet of Things (IoT), personal assistants, online helpdesks/chatbots,\\nrobot instruction, and so on. Improving the quality of the semantic\\ndetection will improve the quality of the experience for the user,\\nand from here it draws its importance and popularity as a research\\ntopic.\\nIn many data sets, and indeed real world applications, the domain\\nis limited; it is concerned only with hotel bookings, or air flight\\ninformation, for example. In these cases the domain level is generally\\nnot part the analysis. However in wider ranging applications, for\\nexample the SNIPS data set discussed later, or the manifold personal\\nvoice assistants which are expected to field requests from various\\ndomains, inclusion of the domain detection in the problem can lead', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='example the SNIPS data set discussed later, or the manifold personal\\nvoice assistants which are expected to field requests from various\\ndomains, inclusion of the domain detection in the problem can lead\\nto better results. However, for the purposes of this survey we will\\ntreat the domain as ancillary.\\nThis leaves us with intent and slot identification. What does the\\nhuman user want from the communication, and what semantic\\nentities carry the details? The two sub-tasks are known as intent\\ndetection and slot filling. The latter may be a misnomer as the task\\nis more correctly slot labelling, or slot tagging. Slot filling is more\\nprecisely giving the slot a value of a type matching the label. For ex-\\nample, a slot labelled “B-city” could be filled with the value “Sydney”.\\nIntent detection is usually approached as a supervised classification\\ntask, mapping the entire input sentence to an element of a finite setarXiv:2101.08091v3  [cs.CL]  22 Feb 2021', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:2 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\nof classes. Slot filling then is a labelling of the sequence of tokens in\\nthe utterance, making it within the sequence-to-sequence (seq2seq)\\nclass of problems.\\nWhile early research looked at the tasks separately, or put them\\nin a series pipeline, it was quickly noted that the slot labels present\\nand the intent class should and do influence each other in ways that\\nsolving the two tasks simultaneously should garner better results\\nfor both tasks. This has been the at the centre of NLU over recent\\nyears though work on the single tasks has continued.\\nA joint model which simultaneously addresses each sub-task\\nmust, to be successful, capture the joint distributions of intent and\\nslot labels, with respect also to the words in the utterance, their\\nlocal context, and the global context in the sentence. A joint model\\nhas the advantage over pipeline models that it is less susceptible to\\nerror propagation, and over separate models in general that there is\\na only a single model to train and fine tune.\\nA drawback is that a large annotated corpus is usually required,\\nthough this is also true of separate models. The model may also\\nbe relatively complicated and take time to train. It has also been\\nobserved that joint models may not generalise well to unseen data,', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='though this is also true of separate models. The model may also\\nbe relatively complicated and take time to train. It has also been\\nobserved that joint models may not generalise well to unseen data,\\ndue to the variety of natural language expressions of similar intent.\\nIn real world applications the domains and label sets may change\\nover time.\\nIn many ways the development of the field has followed a similar\\npath to other areas of NLP, starting with classical (statistical or\\nprobabilistic) models. Neural networks were applied as computing\\npower increased. In particular, due to the sequential nature of the\\nslot labelling sub-task, recurrent neural networks (RNNs) have been\\na technology frequently used in the field. In more recent years\\nthe transformer architecture has debuted to address issues like long\\nrange dependency. As a result, attention has increased in importance.\\nAs far as feature creation goes, convolution, word embeddings,\\nand pre-trained language models have all been applied, amongst\\nmany other methods. The use of external knowledge bases has been\\nobserved in more recent papers.\\nThe most regularly used data sets are two freely available sets -\\nATIS and SNIPS. A common experiment is implied by the literature,\\nfrom which the reported results are compared in this survey. In\\naddition, one of the aims of this survey is to address further stan-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='ATIS and SNIPS. A common experiment is implied by the literature,\\nfrom which the reported results are compared in this survey. In\\naddition, one of the aims of this survey is to address further stan-\\ndardisation, in terms of the parameters of the experiment and the\\nevaluation metrics used.\\nThe approaches to the joint task have been manifold and have\\nshown excellent results in standard supervised training/test experi-\\nments. As new techniques make what may appear to be incremental\\nincreases to the state of the art it is perhaps time to recast the mea-\\nsures of success in the field. Rather than just developing new, more\\nchallenging annotated data sets, increasingly important must be the\\ndevelopment of unstructured semantic detection in new domains.\\nThe motivation for this survey is to take stock of the state of the\\nfield in 2020 following a surge of ideas and approaches over recent\\nyears, particularly in the joint task. We collect information on the\\napproaches pursued so far and the issues encountered and addressed.\\nWith the survey completed we propose some future directions for\\nthe field.\\nIn summary, this survey address three major questions:•Q1: How do these joint models achieve and balance two as-\\npects, intent classification and slot filling?\\n•Q2: Have syntactic clues/features been fully exploited or does\\nsemantics override this consideration?', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='pects, intent classification and slot filling?\\n•Q2: Have syntactic clues/features been fully exploited or does\\nsemantics override this consideration?\\n•Q3: Can successful models in one supervised domain be made\\nmore generalisable to new domains or languages or unseen\\ndata?\\n1.1 Scope\\nThe focus of this survey is on extraction of the intent and slots of\\nsingle utterances. The separate tasks are covered and then the joint', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='data?\\n1.1 Scope\\nThe focus of this survey is on extraction of the intent and slots of\\nsingle utterances. The separate tasks are covered and then the joint\\ntask is addressed in detail. Papers on the following aspects will be\\nreviewed but the information considered as ancillary only:\\n•Multi-domain data sets with annotated domain. Extraction of\\nthe domain is a classification task like intent detection, albeit\\nless granular. Inclusion of the domain identification task may\\naid the two sub-tasks of interest and this will be mentioned;\\n•Dialogue action. Dialogue action is the identification of the\\nnext action to be taken by a dialogue management system\\nonce intent and slots have been identified. In some cases\\ndialogue action is a direct substitute for intent and in others\\na mapping is made from intent and slot labels to the action.\\nWe review papers that include a strong focus on intent and\\nslot detection;\\n•Multi-intent data sets. An utterance may have multiple intent\\n(for example, flight booking and hotel booking). More work\\nhas been done in pure intent detection on this aspect than\\nin the joint task. We will consider it in the pure intent task\\nin particular and make comments on expansion to the joint\\ntask;\\n•Automatic speech recognition (ASR). Some papers begin with\\nthe ASR step and look at error propagation from ASR to intent', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='in particular and make comments on expansion to the joint\\ntask;\\n•Automatic speech recognition (ASR). Some papers begin with\\nthe ASR step and look at error propagation from ASR to intent\\nor slot prediction. We don’t consider this aspect.\\n1.2 Related surveys\\n[Tur and De Mori 2011] is a complete summary of the SLU field at\\nthe advent of the neural era (2011). [Wang and Yuan 2016] concen-\\ntrate on models that jointly address sub-tasks in dialogue systems,\\nincluding NLU, dialogue management (DM) and Natural Language\\nGeneration (NLG). They cover the early models in the joint task but\\npredate the works explicitly tying NLU to dialogue action covered\\nhere.\\n[Tur et al .2018] concentrates on goal-oriented conversational\\nlanguage understanding but within that field provide an excellent\\nprecursor to this survey, covering the state of the art to 2017 in the\\ntwo sub-tasks and 2016 in the joint task. [Hou et al .2019] give a\\nsmall overview of the separate and joint tasks. [Liu et al .2019a]\\nprovides a good survey of intent detection methods up to 2018\\nincluding multi-intent detection and evaluation methods.\\nTangentially related surveys include [Serban et al .2018] which', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='provides a good survey of intent detection methods up to 2018\\nincluding multi-intent detection and evaluation methods.\\nTangentially related surveys include [Serban et al .2018] which\\nsurveys dialogue data sets available for research, and [Deriu et al .\\n2020] which gives an overview of evaluation methods for dialogue\\nsystems.\\nIn this survey we bring the coverage of methods up to mid-2020\\nincluding the many applications of deep learning in the field. As', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:3\\nTable 2. Historical overview of intent detection papers\\nYear # papers Feature engineering Technologies\\n2011 3 Dependency parse SVM, DBN, multi-layer NN, AdaBoost\\n2012 1 Bag-of-words C4.5, RF, NB, KNN, Linear SVM\\n2013 1 n-gram SVM, SVM-HMMs\\n2015 4 n-gram, word2vec, LSTM, RNN, ensemble, RF, clustering, SVM, AdaBoost, NN, J48, FFN\\n2016 1 CNN RF\\n2018 7 GloVe, word2vec, character embedding,\\ngrammatical features, dependency parse,\\nknowledge base, POS, CRF, Regex, PCFG-\\nML, fastText(Bi)CNN, (Bi)LSTM, (Bi)GRU, ensemble, Capsule networks, attention,\\n(Bi)RNN, adversarial networks, gradient reversal layer, SVM, J48, Lo-\\ngistic regression, PPN, RF, Gaussian Naïve Bayes, KNN, NB, softmax\\nregression\\n2019 4 n-gram, character, word2vec, CNN, BiLSTM BiLSTM, attention, Ridge, KNN, MLP, passive aggressive, RF, linear', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='regression\\n2019 4 n-gram, character, word2vec, CNN, BiLSTM BiLSTM, attention, Ridge, KNN, MLP, passive aggressive, RF, linear\\nSVC, SGD, nearest centroid, multinominal NB, Bernoulli NB, K-means,\\nCNN, BiGRU, density-based novelty detection algorithm, local outlier\\nfactor\\n2020 1 BERT, word2vec, CNN Siamese, triple loss\\nwell as a technological survey we look at issues addressed in each\\ntask and the joint task, and the approaches designed to address these\\nissues. We also supply a summary of reported performance on the\\nstandard data sets.\\n1.3 Structure of the survey\\nThe survey begins with a broad overview of the literature in Section\\n2. We then give a detailed description of the methods for each sub-\\ntask (Sections 3 and 4) and the joint task in Section 5, along with the\\nissues addressed and solutions proposed. In Section 6 a survey of\\nthe data sets encountered takes place. In Sections 7 and 8 there is a\\ndescription of the experiments and evaluation methods applied and\\na discussion of standardisation of these. A summary of the results\\nachieved over the history of the field is given in Section 9. We finish\\nwith a discussion of the challenges and opportunities for research', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='a discussion of standardisation of these. A summary of the results\\nachieved over the history of the field is given in Section 9. We finish\\nwith a discussion of the challenges and opportunities for research\\nin the field and give concluding remarks in Section 10.\\n2 OVERVIEW OF THE LITERATURE\\nIntent classification is a form of text classification where the text is a\\nsingle sentence that comes from a spoken or written utterance. Much\\neffort has been made to construct features which encapsulate the\\nsentence, both semantically and syntactically, and the words within\\nit. These features have been passed to classifiers from the suite of\\nclassical and, from 2011, deep learning methods, as outlined in Table\\n2. Issues around ambiguity, shortness of sentences, treatment of\\nout-of-vocabulary words and emerging label sets are amongst those\\ncovered in the literature.\\nSlot tagging (see Table 3) is framed as a sequence labelling prob-\\nlem and in early years drew from methods for statistically mod-\\nelling the dependencies within sequences, like conditional random\\nfields (CRFs) and Hidden Markov models (HMMs). Around 2013 the\\nstrength of RNNs in this area had been observed and was applied to\\nthe task and developed over the ensuing years. Interestingly the use\\nof CRFs returned, often as a post-RNN step, due to their efficacy at', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='strength of RNNs in this area had been observed and was applied to\\nthe task and developed over the ensuing years. Interestingly the use\\nof CRFs returned, often as a post-RNN step, due to their efficacy at\\nhandling label dependency issues. As far as feature creation goes the\\ngeneral goal of the task is to use the semantic information withinthe words and various context windows from small to long-range\\nwithin the sentence. Attention is used as one approach for elicit-\\ning useful context. Slot tagging has experimented with external\\nknowledge bases for extra performance.\\nMethods used by both sub-tasks to extend their features include\\nlooking at meta-data from the data collection. Multi-task learning\\nhas also been used by both tasks to look for synergistic learning from\\nother related tasks. Of course the joint task itself is an example of this\\nsynergistic approach. Both tasks have also considered methods for\\ntransfer learning to other languages and to data with new, unseen\\ntag sets.\\nThe two earliest papers (2008-9) addressing the joint task drew', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='transfer learning to other languages and to data with new, unseen\\ntag sets.\\nThe two earliest papers (2008-9) addressing the joint task drew\\nmethods from classical NLP. Features were constructed from words,\\nn-grams and suffixes, or from a semantic parsing of the utterances.\\nA CRF or a support vector machine (SVM) was used for the analysis.\\nIn 2013 the first neural network was used though it really just\\nconstructed convolutional neural network (CNN) features for use\\nin the CRF model from 2008. In 2014 a recursive neural network\\n(RecNN), which works over trees, was applied to the dependency\\nparse of the utterances. In 2015 the first completely neural network\\nwas devised, using a recurrent neural network (RNN, different to a\\nrecursive neural network) embedding of words, CNN representation\\nof sentences, and a feed forward network (FFN) for the analysis.\\nBy 2016 the RNN encoder-decoder architecture had been found\\nto be useful for seq2seq tasks and started to make its impact in\\nthe joint task. Unidirectional and bi-directional Long Short Term\\nMemory (LSTM) and Gated Recurrent Unit (GRU) cells were tested\\nwithin circuits. Attention made its first appearance. On the input\\nfeature side K-SAN graphs were used as a knowledge base.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='Memory (LSTM) and Gated Recurrent Unit (GRU) cells were tested\\nwithin circuits. Attention made its first appearance. On the input\\nfeature side K-SAN graphs were used as a knowledge base.\\nIn 2017 the field appeared to stay progress, with only character\\nembedding being added to the input features and no improvement\\nof performance results on the major data sets. Perhaps though, re-\\nsearchers were working on the many developments which exploded\\nin 2018. Word embeddings were introduced - word2vec, GloVe and', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:4 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\nTable 3. Historical overview of slot labelling papers\\nYear # papers Feature engineering Technologies\\n2011 1 Neural network, observation feature vector Deep learning, CRF\\n2012 1 n-gram, K-DCN Kernel learning, deep learning, DCN, log-linear model\\n2013 3 Discriminative embedding, named entity,\\ndependency parse, POS, SENNA, RNNLM,\\nbag-of-wordsDBN, RNN, RNN-LM\\n2014 2 RNN, lexicon feature CRF, LSTM, regression model, deep learning\\n2015 3 Word embedding, named entity, word em-\\nbeddingRNN, sampling approach, external memory\\n2016 3 Word embedding, context window, RNN,\\nCNNBiRNN, attention, LSTM, encoder-labeler, CNN\\n2017 1 Word embedding (Bi)LSTM, encoder-decoder, focus mechanism, entity position-aware\\nattention\\n2018 5 BiLSTM, word embedding, character, CNN,\\ndelexicalisationCRF, MTL, segment tagging, NER, BiLSTM, attention, delexicalised sen-\\ntence generation, DNN, reinforcement learning, GRU, pointer network', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='delexicalisationCRF, MTL, segment tagging, NER, BiLSTM, attention, delexicalised sen-\\ntence generation, DNN, reinforcement learning, GRU, pointer network\\n2019 6 Word embedding, web-data, expert feed-\\nback, contextual information, GloVe, POS,\\ncharacter, BERTBiLSTM, BiGRU, different knowledge sources, context gate, MTL, CNN\\n2020 2 ResTDNN Prior knowledge driven label embedding, CRF, TDNN, RNN\\nELMo. The circuits were still largely RNN based. For new architec-\\ntures a capsule neural network and bidirectional circuits were intro-\\nduced. Here bidirectional refers to explicit influence paths through\\nthe circuit: intent2slot refers to intent information being used as\\npart of slot prediction and slot2intent the opposite, slot information\\nbeing used as part of intent prediction.\\nIn 2019 BERT debuted as a word embedding technology and\\nELMo fell away. More knowledge bases were used as input features.\\nWork on pre-processing the data sets included delexicalisation, aug-\\nmentation, and sparse word embeddings using a lasso method. In\\narchitecture RNN and attention continued to be used and CRF made\\na return to handle label dependency issues. Newly applied architec-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='mentation, and sparse word embeddings using a lasso method. In\\narchitecture RNN and attention continued to be used and CRF made\\na return to handle label dependency issues. Newly applied architec-\\ntures included the transformer, and memory neural networks.\\nThe indications from 2020 are that graph embeddings are being\\nused more to capture slot-intent and word-slot-intent relationships.\\n3 INTENT DETECTION\\nIntent detection is typically set up as a sentence classification prob-\\nlem. That is, a feature or features are constructed from the sentence\\nand these are passed through a classification algorithm to predict\\na class for the sentence from a predefined set of classes. As a clas-\\nsification problem the techniques applied look to discover a well\\ndefined decision boundary between the features. Intent classifica-\\ntion differs from classification tasks in other fields due to the nature\\nof the data which are text sentences, coming from spoken language\\nutterances. Hence, at least initially, the features should look to cap-\\nture semantic information in the sentence. Beyond the semantic\\ninformation within the words many approaches have been made\\nto extend the feature set using internal (syntactic, word context) or\\nexternal (meta-data, sentence context) information.3.1 Major areas of research\\nResearch into intent classification in SLU has generally come from', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='to extend the feature set using internal (syntactic, word context) or\\nexternal (meta-data, sentence context) information.3.1 Major areas of research\\nResearch into intent classification in SLU has generally come from\\nfour areas: search engines, question answering systems, dialogue\\nsystems, and text categorisation. Early search engines applied text\\nsimilarity to select results for users. More recently, intent classifica-\\ntion has been applied to understand the searcher’s intent further and\\nthis approach has been proven to give better search results. How-\\never, web queries are usually short and informal, causing difficulties\\nin classifying intents because of insufficient information. Similarly,\\nanswering questions from users also benefits from understanding\\nthe intents of questions to generate better quality responses. In\\ndialogue systems it has been shown to be useful to identify intents\\nof users in order to give appropriate responses to users. Moreover,\\nintent classification can be applied in more general NLP tasks, such', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='of users in order to give appropriate responses to users. Moreover,\\nintent classification can be applied in more general NLP tasks, such\\nas text classification, sentiment analysis and scientific citation.\\n3.2 Overview of technological approaches\\nBefore 2015, most papers focused on classical machine learning\\napproaches, such as SVM, K-nearest neighbours and random forest.\\nFeatures used by these models were mainly generated by depen-\\ndency parsing, word embedding and n-grams. One deep learning\\nmethod explored early on was deep belief networks (DBN). In more\\nrecent years, with the success of deep learning in other areas, neural\\nnetworks, especially RNNs, started to be widely used for this task.\\nAttention mechanisms have been integrated in models for identify-\\ning which parts of sentences should contribute to the classification.\\nSince intent classification is proposed to be integrated with web\\nengineering, which requires the ability to understand short texts\\nthat contain less information, features used for training have been\\nenriched by feature engineering using web metadata.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:5\\nTable 4. Historical overview of joint task papers\\nYear # papers Feature engineering Technologies\\n2008 1 words/n-grams/suffixes CRF\\n2009 1 semantic tree SVM\\n2013 1 CNN CRF\\n2014 1 dependency parse RecNN (diff to RNN)\\n2015 1 RNN words, CNN sentence, Bag of words MLP\\n2016 6 RNN, K-SAN (Bi)LSTM, (Bi)GRU, encoder-decoder RNN, attention\\n2017 4 character, word, CNN BiLSTM\\n2018 18 word2vec, GloVe, ELMo, CNN sentence, at-\\ntention sentenceBiLSTM, BiGRU, encoder-decoder RNN, Capsule NN, BiDirectional\\n2019 29 BERT, GloVe, character, knowledge base (tu-\\nples), delexicalisationmemory NN, transformer, CRF, attention, BiDirectional\\n2020 10 BERT, Graph embedding Graph S-LSTM, BiDirectional, GCN, Capsule\\n3.3 Issues addressed in intent detection\\nIn this section we survey the issues encountered in the literature\\naround intent detection, and the solutions proposed. The issues may\\nbe specific to the task, like ambiguity of semantic intent. They may', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='3.3 Issues addressed in intent detection\\nIn this section we survey the issues encountered in the literature\\naround intent detection, and the solutions proposed. The issues may\\nbe specific to the task, like ambiguity of semantic intent. They may\\nbe general machine learning issues like lack of training data, and\\ndealing with new or adapting domains. They may be issues specific\\nto the available data like imbalanced data, short sentences, or the\\nout-of-vocabulary (OOV) issue. Feature creation to capture informa-\\ntion extra to that in the words is considered to boost performance.\\nExtending the range of the task to multiple intents or to identify\\nout-of-domain sentences is covered.\\n3.3.1 Ambiguity in interpretation. In essence, this issue is at the\\nheart of intent classification; identifying the decision boundary\\nbetween samples close together in feature space, yet belonging\\nto different classes. This issue may be more prevalent with short\\ntexts, since they may include insufficient information and not follow\\ncorrect grammar.\\nAn early approach from [Purohit et al .2015] was to propose a rich\\nfeature representation with an ensemble learning framework giving\\ndifferent perspectives on the classification. The feature creation is\\ncovered further in ensuing sections.\\nA more recent approach from [Ren and Xue 2020] proposed train-\\ning triples of samples - an anchor sample, a positive sample in the', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='different perspectives on the classification. The feature creation is\\ncovered further in ensuing sections.\\nA more recent approach from [Ren and Xue 2020] proposed train-\\ning triples of samples - an anchor sample, a positive sample in the\\nsame class and a negative sample from a different class. Combining\\nconvolutional and BERT encodings of each one and mapping them\\nto Euclidean space with Siamese shared weights, an intermediate\\nloss of the anchor-positive distance minus the anchor-negative dis-\\ntance is minimised. The Euclidean mapping of the anchor is used\\nfor classification.\\nThis latter approach feeds in to the emerging field of contrastive\\nlearning and methods from there should be deployed in the NLU\\nfield.\\n3.3.2 Lack of labelled training data or small training sets. Collecting\\nand labelling large amounts of data for training can be expensive.\\nWith small data sets, models are more likely to be over-trained.\\nFurther, the out-of-vocabulary (OOV) issue, where words appear inthe test set that are not in the training set, is more likely to occur\\nwith them.\\n[Sarikaya et al .2011] proposed a DBN-initialised neural network\\nfor intent classification to learn from unlabelled data and generate\\nfeatures for a feed-forward network. The feed forward network is', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Sarikaya et al .2011] proposed a DBN-initialised neural network\\nfor intent classification to learn from unlabelled data and generate\\nfeatures for a feed-forward network. The feed forward network is\\nthen fine-tuned on labelled data which may be small in number\\nbut still give reasonable results. A DBN is a stack of Restricted\\nBoltzmann Machines (RBMs). To train a DBN, the RBMs are trained\\nlayer-by-layer in sequence using parameters learned by previous\\nlayers. After training the stack of RBMs, the weights of the DBN\\nare used to initialise the weights of a feed-forward neural network.\\nThis approach performed better than traditional machine learning\\nmodels, such as maximum entropy and boosting, and similarly to\\nSVM.\\n[Hasanuzzaman et al .2015] tried to include temporal query under-\\nstanding into web search query intent classification. They tackled\\ntwo major issues: one is the inadequacy of limited training data', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Hasanuzzaman et al .2015] tried to include temporal query under-\\nstanding into web search query intent classification. They tackled\\ntwo major issues: one is the inadequacy of limited training data\\nwhile the other is the limited literal features able to be extracted\\nfrom queries of short length (typically 3-4 words). They utilised\\nexternal resources collected from the web that may help bolster tem-\\nporal information, such as web snippets for queries and the most\\nrelevant year, date etc. Based on this 28 features were designed and\\nextracted. They then proposed an ensemble learning solution frame-\\nwork defined as a multi-objective optimisation problem (MOO) and\\nexplored with 28 classifiers using different optimisation strategies.\\nThe utilisation of external resources and ensemble learning was\\nintended to reduce bias to better handle the limited training data.\\nMethods for dealing with new unannotated domains and data\\nsets by transfer of concept from existing data sets or models weights\\ncombined with few shot methodologies have been explored in the\\nslot labelling and joint task area and are discussed later.\\nSufficient data is essential for training a model. To work with un-\\nlabelled data, unsupervised training methods could be investigated\\nin further research.\\n3.3.3 Multi-domain/multi-lingual generalisability. Most text classi-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='labelled data, unsupervised training methods could be investigated\\nin further research.\\n3.3.3 Multi-domain/multi-lingual generalisability. Most text classi-\\nfication models focus on only one language, one domain and also\\none task. Some models have been proposed to have better general-\\nisability.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:6 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\nTable 5. Intent detection papers reviewed with addressed issue, approach and techniques\\nPaper Addressed issue Approach\\n[González-Caro and Baeza-\\nYates 2011]Multi-faceted query intent prediction Combined multifaceted (multi-label) intent classification\\n[Sarikaya et al. 2011] Small/lack of labelled training data Initialise FFN using DBN derived from trained stacked RBMs\\n[Tur et al. 2011] Short text query in web search Simplified sentence structure as additional feature\\n[Chen et al. 2012] Contextual/temporal information mod-\\nelingSemi-supervised co-training based on two independent features\\n(text/metadata)\\n[Bhargava et al. 2013] Small/lack of labelled training data 1) Incorporating temporal information as additional feature; 2)\\nModeling temporal/session information as a sequence\\n[Ravuri and Stolcke 2015] OOV issue Incorporating temporal information using RNN-based models with\\none-hot word embedding and n-gram hashing\\n[Hasanuzzaman et al .2015] Small/lack of labelled training data Multi-objective ensemble learning with feature engineering (exter-\\nnal resource used)', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='one-hot word embedding and n-gram hashing\\n[Hasanuzzaman et al .2015] Small/lack of labelled training data Multi-objective ensemble learning with feature engineering (exter-\\nnal resource used)\\n[Purohit et al. 2015] Ambiguity in interpretation; Imbal-\\nanced dataHybrid feature representation created by combining top-down\\nprocessing using knowledge-guided patterns with bottom-up pro-\\ncessing using a bag-of-tokens model\\n[Kanhabua et al. 2015] Event-based web searching Time-based and event-based clustering with click-through and\\nstandard statistical feature-based classification\\n[Hashemi et al. 2016] Complex feature engineering CNN feature extracted vector representation\\n[Zhang et al. 2016] Co-occurrence of words from different\\nintents; word correlations addressingHeterogeneous features of pairwise word correlation and POS\\ninformation\\n[Firdaus et al. 2018b] Exploring combination of deep learn-\\ning architecturesPre-trained embedding with ensemble of deep learning models\\n[Xia et al. 2018] Emerging intents detection Capsule-based architectures with zero-shot learning to discrimi-\\nnate emerging intents via knowledge transfer\\n[Costello et al. 2018] Multi-domain/multi-lingual generalisa-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='nate emerging intents via knowledge transfer\\n[Costello et al. 2018] Multi-domain/multi-lingual generalisa-\\ntion abilityMulti-layer ensemble models of different deep learning techniques\\n[Masumura et al. 2018] Multi-task and multi-lingual joint mod-\\nellingAdversarial training method for the multi-task and multi-lingual\\njoint modelling\\n[Mohasseb et al. 2018] Grammar feature exploration Grammar-based framework with 3 main features\\n[Xie et al. 2018] Short text; Semantic feature expansion Semantic Tag-empowered combined features\\n[Qiu et al. 2018] Potential consciousness information\\nminingA similarity calculation method based on LSTM and a traditional\\nmachine learning method based on multi-feature extraction\\n[Kim and Kim 2018] OOD utterances Multi-task learning\\n[Cohan et al. 2019] Utilisation of naturally labelled data Multitask learning based on joint loss\\n[Shridhar et al. 2019] OOV issue; Small/lack of labelled train-\\ning dataSubword semantic hashing\\n[Wang et al. 2019b] Learning of deep semantic information Hybrid CNN and bidirectional GRU neural network with pre-\\ntrained embeddings (Char-CNN-BGRU)', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='ing dataSubword semantic hashing\\n[Wang et al. 2019b] Learning of deep semantic information Hybrid CNN and bidirectional GRU neural network with pre-\\ntrained embeddings (Char-CNN-BGRU)\\n[Lin and Xu 2019] Emerging intents detection Maximise inter-class variance and minimise intra-class variance\\nto get the discriminative feature\\n[Ren and Xue 2020] Similar utterance with different intent Triples of samples used for training\\n[Yilmaz and Toraman 2020] OOD utterances KL divergence vector for classification\\n[Costello et al .2018] developed a novel multi-layer ensembling\\napproach that ensembles both different model initialisation and dif-\\nferent model architectures to determine how multi-layer ensembling\\nimproves performance on multilingual intent classification. They\\nconstructed a CNN with character-level embedding and a bidirec-\\ntional CNN with attention mechanism. In addition, they exploredLSTM and GRU with or without character-level embedding and at-\\ntention mechanism. When ensembling models, they use a majority', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='tional CNN with attention mechanism. In addition, they exploredLSTM and GRU with or without character-level embedding and at-\\ntention mechanism. When ensembling models, they use a majority\\nvote with confidence approach.\\n[Masumura et al .2018] proposed an adversarial training method\\nfor the multi-task and multi-lingual joint modelling to improve per-\\nformance on minority data. The language-specific network can be\\nshared between multiple tasks, where words in the input utterance\\nare converted into language-specific hidden representations. Next,', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:7\\neach word representation is converted into a hidden representation\\nthat uses BiLSTMs to take neighbouring word context information\\ninto account. Task-specific networks can be shared between multiple\\nlanguages, where the language-specific hidden representations are\\nconverted into task-specific hidden representations. The proposed\\nmethod combines a language-specific task adversarial network with\\na task-specific language adversarial network.\\n3.3.4 Emerging intents detection. In dynamic real world applica-\\ntions the intent set evolves. A method to detect and classify emerging\\nintents is a desirable adjunct task.\\n[Hashemi et al .2016] proposed to use a CNN to extract query\\nfeatures for intent classification, which is trained based on word-\\nlevel embeddings generated by word2vec trained on Google News.\\nQuery representations are taken after a max pooling layer. They\\nperform clustering on these representations and observe that new\\nexamples far from the clusters could be used to identify emerging\\nintents, though they do not perform that task.\\n[Xia et al .2018] proposed two capsule-based architectures to de-\\ntect emerging intents. They construct three capsules, SemanticCaps,\\nDetectionCaps and Zero-shot DetectionCaps. SemanticCaps is based', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='tect emerging intents. They construct three capsules, SemanticCaps,\\nDetectionCaps and Zero-shot DetectionCaps. SemanticCaps is based\\non a bidirectional RNN with multiple self-attention heads and is\\nused to extract semantic features from utterances. Then, Detection-\\nCaps aggregate the low-level information from SemanticCaps to\\nhigh-level information in an unsupervised routing-by-agreement\\napproach and obtain intent representations. For detecting emerging\\nintents, the Zero-shot DetectionCap takes information from Seman-\\nticCaps and DetectionCaps to calculate vote vectors for information\\ntransferral. Then, the vote vectors are multiplied with similarity\\nbetween embeddings of existing intents and emerging intents and\\nsummed to generate representations of emerging intent labels.\\n3.3.5 Unseen intents. Dealing with intents which are unseen in\\nthe training data is a related challenging task. [Lin and Xu 2019]\\nproposed a two-stage method to detect unseen intent labels. First,\\nthey used a Bi-LSTM to extract features of a sentence. Then, the\\nforward output vector and the backward output vector were con-\\ncatenated and the concatenation result was used as the input of\\nthe next stage. The model uses large margin cosine loss (LMCL) as', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='forward output vector and the backward output vector were con-\\ncatenated and the concatenation result was used as the input of\\nthe next stage. The model uses large margin cosine loss (LMCL) as\\nthe loss function, instead of softmax loss, which aims to maximise\\nthe decision margin. Thus, the inter-class variance is maximised\\nand the intra-class variance is minimised. This is to ensure that\\nthe features extracted by Bi-LSTM can be more discriminative. In\\nthe second stage, the model takes the concatenation vector and\\napplies a local outlier factor (LOF) to detect unseen intents, which\\nis a density-based detection algorithm.\\nThe OOV issue. Most word embedding based approaches are de-\\npendent on vocabularies and may suffer to some extent from OOV\\nissues, though small training data sets may be affected more. Using\\ncharacter n-grams is a common approach to handle unseen words\\nbased on the idea that similar words may come from a common\\nroot. Another is to replace all words below a chosen frequency in\\nthe training set with a special token, say UNKNOWN.\\n[Ravuri and Stolcke 2015] proposed character n-grams as their', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='root. Another is to replace all words below a chosen frequency in\\nthe training set with a special token, say UNKNOWN.\\n[Ravuri and Stolcke 2015] proposed character n-grams as their\\nword input encoding method with both RNN and LSTM, since theythought the OOV issues became more severe when using RNNs be-\\ncause an unknown word could propagate an effect to the consequent\\nwords. Similarly, [Shridhar et al .2019] proposed sub-word semantic\\nhashing inspired by the Deep Semantic Similarity Model for solving\\nthe OOV issue which comes with small training data sets. Before\\nsub-word semantic hashing, sentences are transferred into lower\\ncase, pronouns in sentences are replaced by ‘-PRON-’, and special\\ncharacters except stop characters are removed. Then, classes with', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='sub-word semantic hashing, sentences are transferred into lower\\ncase, pronouns in sentences are replaced by ‘-PRON-’, and special\\ncharacters except stop characters are removed. Then, classes with\\nless sentences are oversampled by adding augmented sentences,\\nwhich are generated using synonym replacement. After this, every\\ntoken in each sentence is wrapped by two ’#’ symbols and repre-\\nsented using trigrams. These sub-tokens are then vectorised using\\nan inverse document frequency vector and the Euclidean norm. In\\nthe end, the vectors can be used in any intent classification model.\\n3.3.6 Short text queries. User queries for search engines are usually\\nshort (3-4 words) and lack context, so it is essential to extract more\\ninformation from queries for successful classification. Syntactic\\nfeatures, such as POS tags, and also external knowledge sources\\nhave been used to enrich query features.\\n[Hasanuzzaman et al .2015] included temporal query understand-\\ning into web search query intent classification and their model\\nworks well with the limited literal features for queries of short\\nlength. [Purohit et al .2015] focused on intent understanding of\\nsocial media text such as tweets. Some of these can be short, leading\\nto ambiguity of interpretation and sparsity of relevant behaviours.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='length. [Purohit et al .2015] focused on intent understanding of\\nsocial media text such as tweets. Some of these can be short, leading\\nto ambiguity of interpretation and sparsity of relevant behaviours.\\nThey try to improve the expressiveness of data by utilising multiple\\npatterns from knowledge sources and fuse the top-down knowledge-\\nguided patterns with bottom-up frequency-based representation for\\nfeature formation. Based on this, they utilise an ensemble learning\\nstrategy to reduce the bias.\\n[Xie et al .2018] proposed a model called Semantic Tag-\\nempowered User Intent Classification (ST-UIC), based on a con-\\nstructed semantic tag repository. This model uses a combination of\\nfour kinds of features including characters, non-key-noun part-of-\\nspeech tags, target words, and semantic tags. After pre-processing,\\ncharacters and target word features are extracted for maintaining\\nthe contextual information. Then, key nouns are expanded using\\nsemantic tags and POS tags are used as features if a query does not\\ncontain target words. With this approach, representation can be\\nenriched for short queries.\\nIn contrast, [Tur et al .2011] tried to simplify the query input\\nbased on a dependency parser to generate simple and well-formed\\nqueries. They were motivated by the performance gain of existing', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='enriched for short queries.\\nIn contrast, [Tur et al .2011] tried to simplify the query input\\nbased on a dependency parser to generate simple and well-formed\\nqueries. They were motivated by the performance gain of existing\\nstatistical SLU models on simple, well-formed queries as well as\\nthe need for handling increased web search queries formed by key\\nwords. They simply kept the top level predicate and its dependants\\nfor the query simplification, and combined it with the sentence input\\nfor further classification using AdaBoost. The essence here is to try\\nto provide the extracted key word pieces as auxiliary information,\\nwhich proved to decrease the intent classification error rate. Because\\nsome semantic and syntactic information contained in the sentence\\nare filtered out, when this simplified syntactic structure of sentence\\nwas used alone as input for classification, a decrease of performance\\nwas reported.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:8 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\nThis issue mainly occurs with user queries for web searching.\\nWhile not widely reported on in the joint task literature, short texts\\ndo occur in other data sets and the methods described above can be\\napplied there. Rather than the rule based feature construction ap-\\nproach, knowledge graphs may be further investigated as a method\\nfor adding relevant external information.\\n3.3.7 Other feature engineering. Even when the utterances are\\nlonger the challenge is to extract information relevant to the classi-\\nfication task. One early solution generating features using neural\\nnetworks was by [Sarikaya et al .2011], who generated features for\\na feed-forward network using their DBN-initialised neural network.\\nAfter training, the features generated by DBNs were found to be\\nuseful in discriminative classification tasks.\\nMany papers since have used standard word embeddings, RNN\\nand CNN feature creation. In order to boost semantic understand-\\ning [Wang et al .2019b] proposed to use both in a model called\\nCharacter-CNN-BGRU. Firstly this model uses character embed-\\ndings to represent sentences, rather than word embeddings. A CNN\\ntakes the character embedding as the input and extracts local fea-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='Character-CNN-BGRU. Firstly this model uses character embed-\\ndings to represent sentences, rather than word embeddings. A CNN\\ntakes the character embedding as the input and extracts local fea-\\ntures via max pooling after a convolutional layer. Meanwhile, a\\nwindow feature sequence layer is added on the convolutional layer\\nto obtain temporal information, which is important for the bidirec-\\ntional gated recurrent unit (BiGRU). Finally, the output of the max\\npooling layer and the output of BiGRU are concatenated and passed\\nto a softmax layer.\\nWhile semantic features are useful, methods to extract other\\nusable information for classification have been developed.\\nGrammar feature exploration. From the question answering field\\ncomes a feature creation technique based on grammar. Question\\nwords, such as \"what\", \"how\" and \"where\", and also domain specific\\ngrammar may indicate the class of a question. Based on this idea,\\n[Mohasseb et al .2018] proposed a grammar-based framework for\\nquestion classification, which utilises three features: grammatical\\nfeatures, domain specific grammatical features and grammatical\\npatterns. Grammatical features are used to parse a question into a\\nsequence of grammatical terms. Domain specific features are used\\nto identify the domains which grammatical terms in the sentence', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='features, domain specific grammatical features and grammatical\\npatterns. Grammatical features are used to parse a question into a\\nsequence of grammatical terms. Domain specific features are used\\nto identify the domains which grammatical terms in the sentence\\ncorrespond to and tag them. After parsing and tagging each term\\nin the question, the pattern is formulated. The classification task is\\nprocessed using machine learning models, such as SVM or the J48\\nalgorithm.\\n3.3.8 Imbalanced data. A data set is unlikely to have the same\\nnumber of samples for each class and sometimes data can be quite\\nimbalanced. Training a model using imbalanced data can cause poor\\nperformance on minority classes.\\n[Purohit et al .2015] noticed that social media text corpora can\\nhave such imbalanced data. They suggested that two of their con-\\nstructed features aid with imbalanced data in their data set. These\\nare Contrast Patterns features, where they mine sequential pat-\\nterns within each intent class then contrast them. [Shridhar et al .\\n2019] dealt with imbalanced data through oversampling by adding\\naugmented sentences for classes with less samples during the pre-\\nprocessing stage of their model.ATIS, one of the major data sets for the joint task is very imbal-\\nanced in the intent aspect, and yet performance is excellent. The', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='processing stage of their model.ATIS, one of the major data sets for the joint task is very imbal-\\nanced in the intent aspect, and yet performance is excellent. The\\nimbalanced data issue is rarely brought up in the joint task literature.\\n3.3.9 Co-occurrence of words from different intents. This is a partic-\\nular form of ambiguity. Words important to different intents may\\nco-occur in a query of a particular intent and how these words are\\npositioned may convey crucial information for intent detection of\\nthe current query.\\nBased on this idea, [Zhang et al .2016] proposed two types of het-\\nerogeneous information: (1) pairwise word feature correlations (2)', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='the current query.\\nBased on this idea, [Zhang et al .2016] proposed two types of het-\\nerogeneous information: (1) pairwise word feature correlations (2)\\nPOS tags of the queries. The pairwise feature correlations are calcu-\\nlated based on cosine similarity between each semantic feature pair\\nand learned by CNNs with pooling layers. Here each dimension of\\nthe word vector is deemed to be a semantic feature. It tries to model\\nthe intent through these feature-level representations. Meanwhile\\nthe POS tags provide the word-level information about word cate-\\ngories. Their experiment results show that utilising the feature-level\\nsemantic representation outperform the baseline model using only\\nword-level features and incorporating POS information with the\\nfeature-level representation significantly improves the performance.\\n3.3.10 Contextual/temporal information modelling. A single sen-\\ntence in a conversation can be ambiguous, but the ambiguity can be\\neliminated if previous utterances are considered during intent classi-\\nfication. Meanwhile, web queries are sensitive to time and the intent\\ncarried by them may change over time; for example as world events\\nwax and wane in importance. Therefore, some studies incorporated\\ncontextual and temporal information in intent classification.\\nWith multi-turn dialogue [Bhargava et al .2013] included the', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='wax and wane in importance. Therefore, some studies incorporated\\ncontextual and temporal information in intent classification.\\nWith multi-turn dialogue [Bhargava et al .2013] included the\\ncontext from previous queries for the intent classification and slot\\nfilling of the current query. Each sub-task is treated separately, so\\nthis is not a joint model. For intent classification, they compared\\ntwo approaches. The first is to construct a context sessions feature\\nby simply using 1 for the type of intent inferred from the previous\\nutterance set and 0 to all others. This is combined with a basic bag-of-\\nn-gram feature for the current utterance and fed to an SVM for intent\\nclassification. The second approach is to treat the query sequence\\nas a sequential tagging problem using SVM-HMMs with a Viterbi\\nalgorithm. The incorporation of intent from previous utterances as\\nadditional information showed a significant reduction in error rate.\\n[Hasanuzzaman et al .2015] utilised external resources collected\\nfrom the web that may help bolster temporal information, such\\nas web snippets for queries and the most relevant year, date and\\nother time indicators. Based on this, 28 features are designed and\\nextracted. Another solution to generate features is referring to one\\nof a set of contemporaneous events, known as event-based web', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='other time indicators. Based on this, 28 features are designed and\\nextracted. Another solution to generate features is referring to one\\nof a set of contemporaneous events, known as event-based web\\nsearching. [Kanhabua et al .2015] utilised the event-related log pat-\\nterns that reveal both implicit and explicit temporal information\\nneeds, together with general lexical information such as named\\nentities for feature representation. Classification is performed by\\nSVM, AdaBoost, decision tree/J48, and a neural network.\\n[Chen et al .2012] included temporal information in their model\\nas well. They proposed a metadata feature for enhancing community\\nquery intent classification. The metadata feature included query\\ntopic, query time, and user experience indicated by the number of\\nprevious queries. They firstly explored supervised learning using the', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:9\\ntext and metadata features separately. The result showed that using\\nboth two features together outperformed the separate experiment\\nfor query intent classification. This drove them to use a co-training\\nprocedure, which is a semi-supervised learning framework that can\\nutilise a small amount of annotated queries plus a large amount\\nof unlabelled ones. During the training, two separate and indepen-\\ndent classifiers are trained first based on the two features. Then\\nthe prediction with higher confidence from either of the classifiers\\nwill be used as the label for the unlabelled query for training until\\na stopping criteria is reached. Utilising the predictions of the two\\nseparate classifiers as labels for further training requires that the\\ntwo features are conditionally independent and sufficient for clas-\\nsification. Experimenting with SVM, higher micro and macro F1\\nscores were achieved from semi-supervised co-training compared\\nto supervised learning with a combination of the two features.\\nRather than temporal information [Qiu et al .2018] proposed\\nthe construction of multiple features from user metadata, regex\\nextraction of named entities, and probabilistic context free grammar\\nof composite entities.\\nContextual and temporal information may be not suitable for', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='the construction of multiple features from user metadata, regex\\nextraction of named entities, and probabilistic context free grammar\\nof composite entities.\\nContextual and temporal information may be not suitable for\\nall data sets, but, when available, future research can attempt to\\nuse it with their models. The multi-turn dialogue approach will be\\nexplored further under the joint task. Graphs may also be explored\\nfor integration of contemporaneous topics and events.\\n3.3.11 Target variation. Typically in intent classification the pre-\\ndefined intents are enumerated and a cross-entropy loss is calculated.\\n[Qiu et al .2018] rather calculated LSTM embeddings of the training\\nsentences and averaged them within samples of the same intent.\\nFor test prediction they calculate a similarity measure of the LSTM\\nembedded test sample with the training samples averaged by intent\\nand choose the closest.\\nA label can be composed from several words; \"play_music\" is\\ncomposed of \"play\" and \"music\", for example. Future research may\\ninvestigate whether some words in the sentence correspond to \"play\"\\nand some other words correspond to \"music\".\\n3.3.12 Generalisability via ensembles. Overfitting of models to the\\ntraining data distribution leads to poor generalisability. One method', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='and some other words correspond to \"music\".\\n3.3.12 Generalisability via ensembles. Overfitting of models to the\\ntraining data distribution leads to poor generalisability. One method\\nto address this is to use ensembles of models to synergistically ex-\\nploit the benefits of each. Deep learning architectures, such as LSTM,\\nGRU and CNN, have been used frequently in intent classification.\\n[Firdaus et al .2018b] proposed to combine those deep learning ar-\\nchitectures. They used GloVe and word2vec for word embedding. To\\nstart exploring combinations of different models, they constructed\\nCNN, LSTM and GRU individually. Then, four ensemble models\\nwere built, which are CNN-LSTM, CNN-GRU, LSTM-GRU and CNN-\\nLSTM-GRU. In these models, predictions from individual models\\nare combined using a MLP model. [Qiu et al .2018] also used an\\nensemble of classical methods, being random forest, SVM, Naïve\\nBayes and softmax regression, with the ensemble outperforming\\nthe components.\\nOut-of-domain utterances. Not all utterances made to SLU devices\\ncontain an intent related to the purpose of the device. They may be\\nincidental conversation or have intent that the device is not meant', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='Out-of-domain utterances. Not all utterances made to SLU devices\\ncontain an intent related to the purpose of the device. They may be\\nincidental conversation or have intent that the device is not meant\\nto fulfil.[Kim and Kim 2018] augmented a dataset with such utterances\\nand performed a multi-task learning approach to perform classi-\\nfication of in domain utterances and detection of out-of-domain\\n(OOD) utterances simultaneously. A loss function which maximises\\nthe intent accuracy while accepting a value of false acceptance rate\\n(1-recall) for OOD utterances below a threshold is back-propagated.\\nIncluding the second task boosts the intent detection performance.\\n[Yilmaz and Toraman 2020] also constructed augmented data sets', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='(1-recall) for OOD utterances below a threshold is back-propagated.\\nIncluding the second task boosts the intent detection performance.\\n[Yilmaz and Toraman 2020] also constructed augmented data sets\\nwith OOD utterances. They constructed a vector of KL divergence\\nvalues for subsequent pairs of intent probabilities determined from\\nhidden states of a unidirectional LSTM fed with word embeddings.\\nThe KL vectors are fed to an SVM, Naïve Bayes and Logistic Re-\\ngression for OOD classification. Logistic regression gives the best\\nresults.\\n3.3.13 Multifaceted query intent prediction. Most annotated queries\\nin training data sets express only one intent. In real life however,\\nqueries may contain more than one intent. For example, the query\\n“find Beyonce’s movie and music” has two intents, ‘find_movie’ and\\n‘find_music’. An NLU system should be able to handle multi-intent\\nqueries.\\nOne straightforward solution is to use the top couple of predic-\\ntions from existing single label classifiers. Another solution is having\\nbinary classifiers for every label in single classifiers. [González-Caro\\nand Baeza-Yates 2011] used this approach. In their model, each utter-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='binary classifiers for every label in single classifiers. [González-Caro\\nand Baeza-Yates 2011] used this approach. In their model, each utter-\\nances has multiple facets, each a class with at least two categorical\\nlabels. For instance, in the Task facet the intent can be ’Informa-\\ntional’, ’Not Informational’, or ’Ambiguous’. They experimented\\nwith linear SVMs for intent classification of different combination\\nof the facets. Compared with the corresponding single facet classifi-\\ncation, additional supervision from multiple labels led to improve-\\nment of the overall performance. This additional information was\\nfound beneficial to small categories (classes with few samples in the\\ncorpus) with the recall of those small categories improving.\\nTreating multi-labels as atomic labels has been explored in some\\nstudies. This approach may suffer data sparsity problem, but has\\ngood classification accuracy. Based on this, [Xu and Sarikaya 2013]\\nproposed two approaches to exploit the information shared among\\ndifferent intent combinations. The first one is adding class features,\\nwhich is to add n-gram features for combined intent appropri-\\nate to the separated intents. For example, the multi-intent label,', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='different intent combinations. The first one is adding class features,\\nwhich is to add n-gram features for combined intent appropri-\\nate to the separated intents. For example, the multi-intent label,\\n’buy_game#play_game’, should have added two features for the em-\\nbedded intents ’buy_game’ and ’play_game’. The other is adding\\nhidden variables to identify segments belonging to each intent. In-\\nstead of using existing segmentation algorithms, they add a layer\\nof hidden states corresponding to each word. This can indicate the\\nembedded intent which a word most strongly aligns to. Following\\nthat, a perceptron layer performs the classification.\\nUnderstanding queries with multiple intents can make conversa-\\ntions with dialogue systems more natural and smooth, but there is\\nnot much work in this area. Further research could explore more\\napproaches on modelling relations among label combinations.\\n4 SLOT FILLING\\nSlot filling is the second critical task in natural language understand-\\ning. It is the attachment of a label to each token in an utterance. The', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:10 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\nlabel describes the type of semantic information contained in the\\nword represented by the token. A span is a contiguous set of words\\nwhich together make up a semantic unit, for example “new york city”\\nis a single span represented in BIO notation with the labels B-city\\nI-city I-city . Slot filling is treated as a sequence labelling task. The\\ntask is learning not just slot label distributions for words but also\\nwhat slot labels typically co-occur in utterances (label dependency),\\nand in what order. Reference to context in both directions of a word\\nshould be included to maximise performance.\\n4.1 Major areas of research\\nSlot filling is a key task in dialogue systems, to interpret natural\\nlanguage from users, from which the system can judge what infor-\\nmation to retrieve or what task to complete for the user. Slot filling\\nmodels are also integrated with online shopping websites, whose\\ncore is a task-oriented dialog system. Product search queries can\\nbe better understood and shopping assistance can be provided to\\ncustomers. The field of question answering has provided research\\nto extract the semantic features within queries.\\n4.2 Overview of technological approaches\\nTraditionally, generative models (for example, HMMs [Wang et al .', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='customers. The field of question answering has provided research\\nto extract the semantic features within queries.\\n4.2 Overview of technological approaches\\nTraditionally, generative models (for example, HMMs [Wang et al .\\n2005]) which capture the joint probability distribution of the utter-\\nance tokens and their slot labels, and discriminative models (like\\nCRFs) that estimate slot label conditional probabilities given the\\nobserved token sequence, were used to address this problem. With\\nthe success of deep learning, researchers experimented with putting\\ncomponents, for example, CRFs and brief networks, within a deep\\nstructure.\\nSince 2013, RNNs have been increasingly popular in this field. In\\nRNNs each word can access information from the previous words.\\nLater, bi-directional RNNs were applied to utilise both the past and\\nfuture context. However, the distance between words is linear in\\nRNNs, and the vanishing gradient problem may occur, meaning that\\nlong-term dependencies cannot be learnt by the model. As a result,\\nLSTM cells began to be used more frequently because of their ability\\nto forget unimportant information and more successfully model\\nlonger dependencies. However, even LSTMs can underperform with\\nvery long sentences. Other models are thus incorporated to cap-\\nture label dependency, which refers to the situation that some slots', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='longer dependencies. However, even LSTMs can underperform with\\nvery long sentences. Other models are thus incorporated to cap-\\nture label dependency, which refers to the situation that some slots\\nappear in context with some other slots more frequently, and per-\\nform sequence-level optimisation. The combination of CRF layers\\nattached to RNNs is often seen.\\nAnother issue is that RNNs are typically not able to process mul-\\ntiple words simultaneously due to their sequential nature. Thus,\\nattention mechanisms which can take more tokens into account\\nsimultaneously than RNNs are used. Additional features are also\\nincorporated to improve the performance of RNNs, such as named\\nentity features, segment features and external memory. Integrat-\\ning extra knowledge from different sources is also considered an\\neffective approach. Some recent slot filling models also attempt\\nto handle unseen semantic labels and multiple domain tasks by\\nadapting neural CRFs and label embedding.\\n4.2.1 Exploring new models in detail. Models that have proved re-\\nliable for sequence labelling in other fields have been adopted inaddressing the slot filling problem. In particular, deep learning mod-\\nels have been applied in slot filling.\\n[Deng et al .2012] made an early deep model by constructing a', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='els have been applied in slot filling.\\n[Deng et al .2012] made an early deep model by constructing a\\nstacked model, in their case a deep convex network (DCN), and\\nextended it to the kernel version (K-DCN) for domain and intent\\nclassification tasks. With the kernel approach, the number of layers\\ncan be increased. Later, they attempted to solve slot filling problems\\nusing K-DCN as feature extractors.\\nRNNs with different architectures have been explored in many\\nstudies, considering their promising performance in sequence mod-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='using K-DCN as feature extractors.\\nRNNs with different architectures have been explored in many\\nstudies, considering their promising performance in sequence mod-\\neling elsewhere. In 2013, [Mesnil et al .2013] compared recurrent\\nneural networks, including Elman-type and Jordan-type networks\\nand bi-directional Jordan-type RNNs. Two years later, [Mesnil et al .\\n2015] implemented Elman-type and Jordan-type networks and also\\ntheir variations. Both Elman and Jordan-type networks are con-\\nstructed with a 3-word context window. Moreover, a bi-directional\\nJordan-type network was implemented which takes both past and\\nfuture information into account.\\n[Yao et al .2013] adopted Recurrent Neural Network Language\\nModels (RNN-LMs) to predict slot labels rather than words. This\\nmodel used an Elman architecture RNN which can remember past\\nwords. Originally, the output of the training model is exactly the in-\\nput word sequence, but in the new model, the outputs are sequences\\nof labels instead. Future words, named entities, syntactic features\\nand word-class information were also integrated in the analysis.\\nIn the first models using RNNs in NLU, only words preceding the\\ncurrent word were considered. However, words occurring after the', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='and word-class information were also integrated in the analysis.\\nIn the first models using RNNs in NLU, only words preceding the\\ncurrent word were considered. However, words occurring after the\\ncurrent word can also provide useful information. Therefore, [Vu\\net al.2016] use bi-directional Elman-type networks with a 3-word\\ncontext window. In their network, the BiLSTM generates forward\\noutput and backward output, which are combined for making pre-\\ndictions. The model adopts the ranking loss function, so the model is\\nnot forced to learn a pattern for the artificial class O. In an extension\\n[Vu 2016] proposed a bi-directional sequential CNN for slot labelling\\nwhich considers both previous contextual words with preserved\\norder, surrounding context and also past and future information. To\\nlabel a word, two matrices are separately generated for the previous\\nand future context words of the word. These are combined to form a\\nmatrix for the current word. Then, the two matrices for the past and\\nfuture information are passed to corresponding vanilla sequential\\nCNNs. The output of networks are concatenated with the matrix for\\nthe current word. After that two matrices can be combined using\\na weighted sum of the forward and the backward hidden layer or\\nby concatenating. For training, the ranking loss function is again\\napplied.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='the current word. After that two matrices can be combined using\\na weighted sum of the forward and the backward hidden layer or\\nby concatenating. For training, the ranking loss function is again\\napplied.\\n[Korpusik et al .2019] perform a useful comparison of BiGRU,\\nCNN and BERT based models with the then new BERT outperform-\\ning the other candidates.\\nThe incorporation of newer technologies for slot labelling, par-\\nticularly seemingly suitable attention based methods like the Trans-\\nformer, has been subsumed by the joint task in more recent years\\nas will be explored in Section 5.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:11\\nTable 6. Slot filling papers reviewed with addressed issue and approach\\nPaper Addressed issue Approach\\n[Yu et al. 2011] Long-range state dependency Deep learning, CRF\\n[Deng et al. 2012] To extend DCN Kernel learning, deep learning, DCN, log-linear model\\n[Deoras and Sarikaya 2013] Data sparsity problem (CRF) Deep belief network (DBN)\\n[Mesnil et al. 2013] To explore RNN RNN\\n[Yao et al. 2013] To explore RNN-LM RNN-LM\\n[Yao et al. 2014b] Label dependencies, label bias problem RNN, CRF\\n[Yao et al. 2014a] Gradient diminishing and exploding\\nproblem, label dependencies, label bias\\nproblemLSTM, regression model, deep learning\\n[Liu and Lane 2015] Label dependencies RNN, sampling approach\\n[Mesnil et al. 2015] To explore RNN RNN\\n[Peng and Yao 2015] Vanishing and exploding gradient RNN, external memory\\n[Kurata et al. 2016] Label dependencies LSTM, encoder-labeler\\n[Vu et al. 2016] To explore past and future information Bi-directional RNN, ranking loss function', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Kurata et al. 2016] Label dependencies LSTM, encoder-labeler\\n[Vu et al. 2016] To explore past and future information Bi-directional RNN, ranking loss function\\n[Vu 2016] To explore CNN CNN\\n[Zhu and Yu 2017] To explore attention mechanism Bi-directional LSTM, LSTM, encoder-decoder, focus mechanism\\n[Dai et al. 2018] Unseen slots CRF\\n[Gong et al. 2019] To explore MTL MTL, segment tagging, NER\\n[Louvan and Magnini 2018] To explore MTL MTL, NER, bi-LSTM, CRF\\n[Shin et al. 2018] To better labelling common words Encoder-decoder attention, delexicalised sentence generation\\n[Wang et al. 2018a] Imbalanced data DNN, reinforcement learning\\n[Zhao and Feng 2018] OOV GRU, attention, pointer network\\n[Gong et al. 2019] To explore MTL MTL, segment tagging, NER\\n[Kim et al. 2019] To extend original SLU to H2H conver-\\nsationsBi-LSTM, different knowledge sources\\n[Shen et al. 2019b] Continual learning Bi-LSTM, context gate', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='sationsBi-LSTM, different knowledge sources\\n[Shen et al. 2019b] Continual learning Bi-LSTM, context gate\\n[Veyseh et al. 2019] Restricted utilising contextual informa-\\ntionMTL, Bi-LSTM\\n[Korpusik et al. 2019] Architecture comparison BiGRU, CNN, BERT\\n[Louvan and Magnini 2019] Low resource data set MTL\\n[Zhu et al. 2020] Data sparsity problem Prior knowledge driven label embedding, CRF\\n[Zhang et al. 2020a] Long range dependency, vanishing gra-\\ndientTDNN\\n4.3 Issues addressed by slot labelling papers\\nLike intent detection, issues found in slot filling can be task specific,\\nmore general machine learning issues, data set issues, or may in-\\nvolve feature engineering or methodological approaches for better\\nresults. Slot filling introduces issues typical to seq2seq tasks like\\nlabel dependency and long distance dependency.\\n4.3.1 Label dependency. There are dependencies between slot la-\\nbels, meaning that some slots appear more commonly with some\\nother slots in the same utterance. For example, in a travel data set\\nit is highly probable that B-FromCity andB-ToCity are in the same\\nsentence. Capturing such label dependencies would help find the', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='other slots in the same utterance. For example, in a travel data set\\nit is highly probable that B-FromCity andB-ToCity are in the same\\nsentence. Capturing such label dependencies would help find the\\nbest slot combinations and generate better prediction results.\\nOne approach is to integrate CRFs and regression models. [Yao\\net al.2014a] applied an LSTM for the slot labelling task and included\\na regression model to capture label dependencies. [Yao et al .2014b]proposed a recurrent conditional random field (R-CRF) which inte-\\ngrates recurrent neural networks and a CRF to explicitly model the\\ndependencies between semantic labels and achieve sequence-level\\noptimisation. The R-CRF can use the RNN activations as features of\\nthe CRF. Similar to CRFs, this model can use sequence-level optimi-\\nsation as well.\\nAnother solution utilises the encoder-decoder architecture, which\\nhad been applied for machine translation previously and is able to\\nencode the global information of the input sentence. [Kurata et al .\\n2016] proposed the encoder-labeler LSTM. This architecture encodes\\nthe sentence to a fixed length vector. Then, the encoding vectors\\nare used as the input of another LSTM, the labeler LSTM, which', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='the sentence to a fixed length vector. Then, the encoding vectors\\nare used as the input of another LSTM, the labeler LSTM, which\\nconsiders label dependencies. The labeler LSTM can predict the\\nslot label conditioned on the encoded sentence information. With', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='are used as the input of another LSTM, the labeler LSTM, which\\nconsiders label dependencies. The labeler LSTM can predict the\\nslot label conditioned on the encoded sentence information. With\\nsuch a method, the model is able to label slots utilising the whole\\nsentence information. [Zhu and Yu 2017] proposed a BiLSTM-LSTM', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:12 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\nencoder-decoder model, where a sentence is encoded using a bi-\\ndirectional LSTM and the encoded sentence is then decoded using\\na uni-directional LSTM. At the same time, they developed a focus\\nmechanism for this model because of the alignment limitation of\\nattention mechanisms.\\nMoreover, [Liu and Lane 2015] used continuous vectors to repre-\\nsent possible output labels, which are fed to recurrent connections.\\nThese continuous vectors are also fed to hidden layers, so every\\nhidden layer can utilise word input, previous hidden states and pre-\\ndicted output labels. Moreover, both true labels and the predicted\\noutput labels can be fed to some layers in a fashion decided by a\\nsampling approach for robustness. Because the previous predicted\\nlabels are used as input to the next step, error propagation should\\nbe studied further.\\n4.3.2 Long range dependency. Long-range dependency (LRD), also\\ncalled long memory or long-range persistence, is a phenomenon that\\nmay arise in the analysis of spatial or time series data. It relates to the\\nrate of decay of statistical dependence of two points with increasing\\ntime interval or spatial distance between the points. While the short', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='may arise in the analysis of spatial or time series data. It relates to the\\nrate of decay of statistical dependence of two points with increasing\\ntime interval or spatial distance between the points. While the short\\ntext queries described in the intent section should not suffer from\\nthis, utterances in SLU data sets can be much longer.\\nThe approach from [Yu et al .2011] is a deep structured CRF\\nwhich is made up of several simple CRFs. Lower layers can generate\\nframe-level marginal posterior probabilities. Then the higher layer\\ntakes these probabilities along with the observation sequence of\\nthe previous layer. In the end, the highest level will make the final\\npredictions. In the training process, layers are trained separately for\\nefficiency. For each layer, the parameters are determined once the\\nlayer is trained.\\n[Zhang et al .2020a] addressed the shortcomings of RNN being the\\nlong range dependency issue and vanishing or exploding gradient.\\nThey used a deep stacking of time delay neural networks for feature\\ncreation. These create convolutional features from context windows\\nof varying size and varying step sizes through the sentences. The\\nfeatures are then passed through a final RNN and classified.\\nThe Transformer architecture, which utilises self attention across\\nutterances, and memory networks which can store longer range\\ninformation, are now studied in the joint task, as described in the', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='The Transformer architecture, which utilises self attention across\\nutterances, and memory networks which can store longer range\\ninformation, are now studied in the joint task, as described in the\\nnext section. Focused research using these methods for only the slot\\ntask may uncover useful methods for use in the joint task.\\n4.3.3 The label bias problem. Label bias is a seq2seq issue related\\nto maximum entropy Markov models (MEMM). In MEMM, the\\nstates with a single outgoing transition can ignore their observation,\\nmeaning that the model can tend to stay in a state which is unlikely\\nto happen. Most approaches to this problem combine CRFs with\\nRNNs.\\n[Yao et al .2014a] applied LSTM cells, which contain a gate which\\ncan forget unimportant information, and also incorporated a regres-\\nsion model to model label dependencies. In order to avoid the label\\nbias problem, the regression model took non-normalised scores be-\\nfore softmax. The R-CRF of [Yao et al .2014b] also addresses label\\nbias. Similarly, [Mesnil et al .2015] explored RNNs with multiple\\ndifferent architectures and proposed to apply Viterbi encodings and\\nrecurrent CRFs to eliminate the label bias problem.4.3.4 Learning common words. The surrounding words of one slot', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='different architectures and proposed to apply Viterbi encodings and\\nrecurrent CRFs to eliminate the label bias problem.4.3.4 Learning common words. The surrounding words of one slot\\nin different sentences are usually similar. For example, the word\\n\"to\" is highly likely to be lie between B-FromCity and B-ToCity .\\nTherefore, [Kurata et al .2016] thought that learning the common\\nwords around slots in different ways may be helpful for slot filling.\\n[Shin et al .2018] introduced a model which can jointly generate\\ndelexicalised sentences and predict labels using the encoder-decoder\\nframework with input alignment. In the delexicalised sentences,', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Shin et al .2018] introduced a model which can jointly generate\\ndelexicalised sentences and predict labels using the encoder-decoder\\nframework with input alignment. In the delexicalised sentences,\\nwords are replaced by their corresponding slot labels. For example,\\nto delexicalise the sentence “i want to fly from baltimore to dallas”,\\nthe words ‘baltimore’ and ‘dallas’ should be replaced by B-FromCity\\nandB-ToCity . This approach is based on the fact that different words\\nthat correspond to the same slot usually play a similar semantic and\\nsyntactic role in the sentence, which allows the model to learn the\\ncommon words surrounding the slots.\\n4.3.5 Low resource data sets. A more general machine learning\\nissue is that methods generally rely on the presence of annotated\\ntraining data which is costly to produce. [Louvan and Magnini\\n2019] tested models which also trained on a large freely available\\nannotated data set for a similar task (NER for example) in a multi-\\ntask learning environment (see Section 4.3.11. They then used just\\n10% of the available training data from slot tagging data sets to train\\nthe slot labelling task. They varied this proportion and observed\\nwhen it reached 40% that the auxiliary task stopped having much\\neffect.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='10% of the available training data from slot tagging data sets to train\\nthe slot labelling task. They varied this proportion and observed\\nwhen it reached 40% that the auxiliary task stopped having much\\neffect.\\n4.3.6 Diminishing and exploding gradients. In neural networks with\\nmultiple layers, or long RNN sequences, the gradient may become\\nvanishingly small, preventing the weights from changing value\\nduring back-propagation. Alternatively, large gradients may self-\\npropagate and lead to unstable networks.\\n[Yao et al .2014a] combined an LSTM and a regression model for\\nslot filling. LSTM are partially designed to address these issues. To\\navoid the gradient diminishing and exploding problem, the memory\\ncells within them are linearly activated and propagated between\\ndifferent time steps.\\n[Peng and Yao 2015] introduced an external memory to overcome\\nthe limitations on memory capacity of simple RNNs and therefore\\nthe diminishing and exploding gradient problems can be addressed.\\nThe new model is call RNN-EM, where the hidden layer has an addi-\\ntional input that comes from the external memory. A weight vector\\nis used to retrieve the content from the external memory, which is\\ndetermined according to the similarity between the contents and\\nthe hidden layer.\\n4.3.7 Data sparsity problem. Data sparsity can be an issue when', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='is used to retrieve the content from the external memory, which is\\ndetermined according to the similarity between the contents and\\nthe hidden layer.\\n4.3.7 Data sparsity problem. Data sparsity can be an issue when\\nthere are a large number of discrete features. If those discrete feature\\nare represented using matrices, those matrices can be large and\\nsparse, which may lead to a model ignoring the relations among\\nfeatures.\\n[Deoras and Sarikaya 2013] applied deep belief networks (DBN)\\nfor semantic tagging integrated with lexical, named entity, depen-\\ndency parser based syntactic features and part of speech (POS) tags.\\nA DBN is a stack of Restricted Boltzmann Machines (RBMs), where\\nthe input of one layer is the output of the previous one and each\\nlayer applies a sigmoid activation function on their inputs. In this', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:13\\nmodel, features are embedded into vectors at the first layer and\\npassed to the next layer due to the large input layer. During the\\npre-training process, the parameters of neurons are learnt using the\\nonline version of conjugate gradient (CG) optimisation on several\\nsmall batches. Compared to CRF, DBN is more general.\\n[Zhu et al .2020] noticed that the data sparsity problem can also\\noccur with labels because labels are usually encoded using one-hot\\nvectors, so they also proposed a label embedding which is con-\\nstructed using prior knowledge including atomic concepts, slot\\ndescriptions, and slot exemplars. An atomic concept assumes that\\neach slot can be represented as a set of atoms. Slot descriptions are\\nthe textual description for slots in natural language. Slot exemplars\\nare to extract label embeddings for slot labels which contain values\\nof each slot and their neighbour contexts.\\n4.3.8 Continuous learning. With new data becoming available\\nquickly, it is desirable to have a retrained model incorporating the\\nnew data. However, the training process could be time and cost con-\\nsuming and keeping all the existing data can introduce redundancy.\\nThus, there is a problem of how to continuously learn from new\\ndata.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='new data. However, the training process could be time and cost con-\\nsuming and keeping all the existing data can introduce redundancy.\\nThus, there is a problem of how to continuously learn from new\\ndata.\\n[Shen et al .2019b] proposed a ProgModel, consisting of a context\\ngate. This gate aims to transfer previously learned knowledge to a\\nsmall expanded component, which is placed after the hidden state of\\nthe new model. The training procedure is progressively conducted\\nat each batch. Therefore, the model can learn faster from the new\\ntraining data without forgetting the previous expressions.\\n4.3.9 Imbalanced data. Training data sets can be imbalanced, dom-\\ninated by some tags while only containing a small number of ex-\\namples of other tags. This can lead to poorer performance in the\\nminority tags. One solution from the slot labelling literature comes\\nfrom [Wang et al .2018a] who design a deep reinforcement learning\\n(DRL) based augmented tagger with a deep neural network, which\\nincludes a training part and an inference part. While the whole data\\nset is used in the training part, only partial data with unsatisfactory\\nperformance will be evaluated by the augmented tagger.\\nSimilarly to intent classification, augmentation via generating\\nsentences which contain the minor tags could be researched.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='set is used in the training part, only partial data with unsatisfactory\\nperformance will be evaluated by the augmented tagger.\\nSimilarly to intent classification, augmentation via generating\\nsentences which contain the minor tags could be researched.\\n4.3.10 Unseen labels. As with intent classification models, slot la-\\nbelling models can rely heavily on the training data and will struggle\\nto correctly assign a label which does not appear in the training\\ndata.\\n[Zhao and Feng 2018] proposed a seq2seq model together with\\na pointer network to solve this problem. This model predicts slot\\nvalues by jointly learning to copy a word which may be out-of-\\nvocabulary (OOV) from an input utterance through a pointer net-\\nwork, or generate a word within the vocabulary through a seq2Seq\\nmodel with attention.\\n[Dai et al .2018] proposed an elastic conditional random field\\n(eCRF) which can utilise semantic meaning in slot embedding for\\nopen-ontology slot filling. The model has a slot description encoder\\nwhich takes all slot descriptions as input, and outputs distributed\\nrepresentations for slots. Meanwhile, a BiLSTM is used to extract\\nfeatures from utterances. Then, the eCRF labeller, which is a poten-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='which takes all slot descriptions as input, and outputs distributed\\nrepresentations for slots. Meanwhile, a BiLSTM is used to extract\\nfeatures from utterances. Then, the eCRF labeller, which is a poten-\\ntial function containing two terms for semantic similarity of the slotdescriptions and the extracted contextual features and interactions\\nbetween the slot labels, is applied.\\n4.3.11 Exploring multi-task learning. Multi-task learning (MTL) is\\nthe idea that similar auxiliary tasks can assist a main task. Some\\npapers have used this idea setting slot labelling as the main task.\\n[Louvan and Magnini 2018] attempted to perform slot filling and\\nnamed entity recognition (NER) jointly in a multi-task framework\\nconsidering that most slot values are also named entities and NER', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Louvan and Magnini 2018] attempted to perform slot filling and\\nnamed entity recognition (NER) jointly in a multi-task framework\\nconsidering that most slot values are also named entities and NER\\nhas high state-of-the-art performance. They mentioned that a better\\nslot tagging result can be achieved if NER is at a lower level. Similarly,\\n[Gong et al .2019] investigated hierarchical multi-task learning to\\nperform low-level tasks first, namely named entity tagging and\\nsegment tagging, and then the high-level task, that is slot labelling,\\ncan make use of the results from the low levels with cascade and\\nresidual connections. [Louvan and Magnini 2019] then performed\\na more wide ranging experiment with two auxiliary tasks (NER\\nand semantic tagging (SemTag)), and a comparison of a training on\\nauxiliary task(s) followed by fine-tuning on the main task approach\\nversus the previously explored hierarchical approach. They found\\ngenerally the hierarchical approach gave better results and that\\nparsimoniously using only one auxiliary task (NER) worked better.\\nMost models utilise contextual information, but they use it in a\\nrestricted manner, for example, self-attention. Therefore, [Veyseh\\net al.2019] proposed a multi-task setting to train a model to incor-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='restricted manner, for example, self-attention. Therefore, [Veyseh\\net al.2019] proposed a multi-task setting to train a model to incor-\\nporate the contextual information in two different levels which are\\nrepresentation level and task-specific level. This multi-task setting\\nincludes the slot filling as the main task and two auxiliary tasks.\\nThe first one is to increase consistency between the word represen-\\ntation and its context and another one is to enhance task specific\\ninformation in contextual information.\\n4.3.12 Extending to human-to-human conversations. As the main\\nthrust of this survey shows, task oriented language understanding\\nin human-to-machine (H2M) conversations has been extensively\\nstudied. An interesting twist is to perform slot tagging in human-to-\\nhuman (H2H) conversations. Here the agent is a third party listening\\nin, not being directly asked to perform a task.\\n[Kim et al .2019] focused on slot filling in H2H conversations\\nand explored LSTMs with different knowledge sources. First, the\\ncharacter embedding and the word embedding are concatenated\\nfor each word. Then, the embeddings are passed to a bi-directional\\nLSTM, which will be used for making final predictions. Further-\\nmore, there is an additional model which can utilise knowledge', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='for each word. Then, the embeddings are passed to a bi-directional\\nLSTM, which will be used for making final predictions. Further-\\nmore, there is an additional model which can utilise knowledge\\nfrom multiple sources, including sentence embeddings for H2H con-\\nversation, contextual information and H2M expert feedback. The\\nsentence embeddings are generated by a sentence level embedding\\nmodel trained using tweets with URL and web search queries to the\\nsame URL. The contextual information is extracted from previous\\nutterances in the conversation. Also, this model uses pre-trained\\nslot filling models for H2M conversations on similar domains as the\\nexpert model. The knowledge from three sources is encoded into\\nvectors which are then combined and aggregated with the output\\nof the bi-directional LSTM.\\nSlot tagging introduces the problem of generating a sequence of\\nhidden labels to a sequence of word tokens, qualitatively different\\nto the intent classification task. Together, in SLU, the two sub-tasks', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:14 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\ncontribute to a better representation of the semantics of an utterance\\nthan each one separately. In the next section we consider the joint\\ntask where both are addressed in one model.\\n5 JOINT INTENT AND SLOT MODELS\\nThe joint task marries the objectives of the two sub-tasks. As most\\npapers point out there is a relationship between the slot labels\\nwe should expect to see conditional on the intent, and vice versa.\\nA statistical view of this is that a model needs to learn the joint\\ndistributions of intent and slot labels. The model should also pay\\nregard to the distributions of slot labels within utterances, and one\\nwould expect to inherit approaches to label dependency from the\\nslot-labelling sub-task. Approaches to the joint task range from\\nimplicit learning of the distribution, through explicit learning of the\\nconditional distribution of slot labels over the intent label, and vice\\nversa, to fully explicit learning of the full joint distribution.\\nThe joint task should also expect to inherit most of the issues of\\neach sub-task and we find this is true. The mass of research now\\nappears in the joint task and as such newer methods tried there\\nhave not been tried previosly in the sub-tasks.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='each sub-task and we find this is true. The mass of research now\\nappears in the joint task and as such newer methods tried there\\nhave not been tried previosly in the sub-tasks.\\n5.1 Major areas of research\\nResearch in the joint task has largely come from the personal assis-\\ntant or chatbot fields. The chatbot is usually task-oriented within a\\nsingle domain, while the personal assistant may be single or multi-\\ndomain.\\nOther areas to contribute papers are IoT instruction, robotic in-\\nstruction (there is also a different concept of intent in robotics to\\ndescribe what action the robot is attempting), and in vehicle di-\\nalogue for driverless vehicles. These areas also need to filter out\\nutterances not applied to the device.\\nResearchers have also drawn data from question answering sys-\\ntems, for example [Zhang and Wang 2016] who annotated a Chinese\\nquestion dataset from Baidu Knows.\\n5.2 Overview of technological approaches\\nIn this section we give an overview of papers which focused on the\\njoint task itself, measuring their efficacy largely on performance\\nagainst state-of-the-art. Generally they are using new technologies\\nas they became available, or new architectures to make the learning\\nmore explicit.\\n5.2.1 Classical methods. The earliest work on the joint task used a', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='as they became available, or new architectures to make the learning\\nmore explicit.\\n5.2.1 Classical methods. The earliest work on the joint task used a\\ntri-level CRF with the three layers being token features, slot labels\\nand intent labels. [Jeong and Lee 2008] showed this architecture per-\\nformed better than performing the two sub-tasks in a pipeline. Other\\nearly statistical models used a maximum entropy model (MEM) for\\nintent and a CRF for slot labelling ([Wang 2010]), and a multilayer\\nHMM ([Celikyilmaz and Hakkani-Tur 2012].\\n5.2.2 Recursive neural networks. The earliest attempt at a neural\\nmodel to address the joint task was in [Guo et al .2014] which\\nused recursive neural networks (RecNNs) (different to recurrent\\nneural networks (RNN)). RecNNs work over trees, in this case the\\nconstituency parse tree of the utterance, with leaves corresponding\\nto the words (represented by word vectors). A neural network isapplied at each node of the tree, recursively upwards to the root,\\ncomputing a state for each node. At each node the states from\\nchildren nodes are combined with a weight vector representing the\\nnode’s syntactic type. Individual slot label classifiers are applied', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='computing a state for each node. At each node the states from\\nchildren nodes are combined with a weight vector representing the\\nnode’s syntactic type. Individual slot label classifiers are applied\\nto each leaf using a combination of the word vectors of itself and\\nits neighbours and the state vectors along the path from the leaf\\nto the root. The state at the root is passed to an intent classifier.\\nA combined loss over the slots and intent (and domain) is back-\\npropagated. An optional post-processing, Viterbi decoded Markov\\nlayer is applied to the slots. Results were close to, but below, the\\nthen state-of the art for the tasks treated separately.\\n5.2.3 Recurrent neural networks. In 2016 the power of the RNN', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='layer is applied to the slots. Results were close to, but below, the\\nthen state-of the art for the tasks treated separately.\\n5.2.3 Recurrent neural networks. In 2016 the power of the RNN\\ncircuit for seq2seq tasks was explored in multiple papers. Features\\nrepresenting tokens are passed in temporal sequence to RNN units\\nwhich have a hidden state. Intermediate hidden states may be used\\nfor slot labelling. The final hidden state is an embedding of the entire\\nutterance and may be used for intent prediction. The classic encoder-\\ndecoder, which produces a sequential output, is the most commonly\\nused architecture ([Liu and Lane 2016a]. Issues with the original\\nRNN cells are addressed by LSTM and GRU cells. Bidirectional RNNs,\\nwhere the input sequence is passed in in both forward and backward\\ndirection, address issues with unidirectional capturing of context.\\nOther architectures include (a joint loss is back-propagated unless\\nmentioned):\\n•a two layer LSTM with the top layer hidden states informing\\nslot labelling and the first layer final state informing intent\\nclassification [Zhou et al. 2016];\\n•the slot tagging task is softmax classifiers applied to the out-\\nput of a simple BiLSTM using the concatenated hidden states.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='classification [Zhou et al. 2016];\\n•the slot tagging task is softmax classifiers applied to the out-\\nput of a simple BiLSTM using the concatenated hidden states.\\nA special token is added to encapsulate the whole utterance\\nfor use in intent classification [Hakkani-Tür et al. 2016];\\n•a Bi-LSTM encoder decoder but with separate losses for intent\\nand slot prediction ([Zheng et al. 2017];\\n•rather than seq2seq [Kim et al .2017] perform a global slot\\nprediction (learning the joint distribution) from a matrix of\\nthe hidden states to a matrix of slot tag probabilities for each\\nword, intent is predicted from a sum of hidden states;\\n•[Wen et al .2018] propose to use both a hierarchical (multi-\\nlayer) and a contextual (BiLSTM or LSTM) approach, inves-\\ntigating various combinations and using differing layers for\\nintent and slot prediction;\\n•an ensemble using both BiLSTM and BiGRU fed to separate\\nMLPs whose outputs are fused then projected and a softmax\\napplied to predict intent and slots concurrently is proposed\\nby [Firdaus et al. 2018a].\\nFor RNNs the input is typically token feature by token feature', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='MLPs whose outputs are fused then projected and a softmax\\napplied to predict intent and slots concurrently is proposed\\nby [Firdaus et al. 2018a].\\nFor RNNs the input is typically token feature by token feature\\nin temporal sequence. [Hakkani-Tür et al .2016] compared that to\\nusing context windows with superior results. However [Zheng et al .\\n2017] showed inferior results with context windows.\\nOne critical observation made of many purely recurrent models\\nis that the sharing of the information between the two sub-tasks\\nis implicit. That is, while the sub-tasks are addressed jointly, it is\\noften only through back-propagation of a joint loss.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:15\\n5.2.4 Attention. Attention is an obvious technique for forcing an\\ninteraction between information from the two sub-tasks, in a learned\\nway. Some attention constructions may still be seen as an implicit\\nway of sharing information, but stronger methods start to force\\nexplicit learning.\\nIn early papers a basic concept of attention used was the weighted\\nsum of Bi-RNN hidden states as an input to slot and intent prediction\\n([Liu and Lane 2016a]). Then [Goo et al .2018] used a stronger, more\\nexplicit attention. The base circuit is a BiLSTM taking word vectors\\nin sequence and using a different learned weighted sum of the\\nintermediate states of the BiLSTM for each slot prediction (the slot\\nattention) and the final state for intent detection. The new addition\\nis a slot gate which takes the current slot attention vector and\\ncombines it with the current intent vector in an attention operation.\\nThe output of the slot gate feeds the slot prediction. This circuit is an\\nearly example of intent2slot, a path through the circuit where intent\\nprediction information is also fed explicitly to the slot prediction\\nelement. Another variation on intent2slot is provided in [Li et al .\\n2019].', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='early example of intent2slot, a path through the circuit where intent\\nprediction information is also fed explicitly to the slot prediction\\nelement. Another variation on intent2slot is provided in [Li et al .\\n2019].\\n[Qin et al .2019] also use an intent2slot architecture but with\\nBERT encoding and and using stack propagation. Rather than a gate\\nlike [Goo et al .2018], the intent detection itself directly feeds the\\nslot filling. Also the intent detection is performed at token level\\nand the final intent is taken by vote. [Wang et al .2020b] too use an\\nintent2slot gate with BERT embeddings.\\n[Yu et al .2018] in a sense provide the dual approach to that of [Goo\\net al.2018], providing an attended slot prediction as the main input\\ninto intent prediction. The attention is additive on the weighted\\nhidden states of a BiLSTM encoder and the weighted sum of the\\npredicted slot labels. We call this explicit feed of slot information to\\nthe intent slot2intent.\\n[Zhang et al .2019] extend the intent2slot gate of [Goo et al .2018]\\nwith a pair of slot gates, one carrying the global intent information\\nto the slot task, and one taking it to each slot location individu-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='with a pair of slot gates, one carrying the global intent information\\nto the slot task, and one taking it to each slot location individu-\\nally. [Zhang et al .2019b] also apply intent2slot but only to tokens\\ndetermined to be not labelled ‘O’.\\n[Li et al .2018b] introduce self-attention to the BiLSTM architec-\\nture to force a stronger learning “at the semantic level” between\\nthe slots and the intent. A first self-attention layer performs at-\\ntention on word and convolutional character embeddings. This is\\nconcatenated with the word embeddings and fed to a BiLSTM layer.\\nThe final state informs intent detection. Self attention is performed\\nbetween the intermediate states of the BiLSTM. This self attention\\nis combined with the intent prediction which is then combined\\nwith the intermediate states to perform slot tagging. [Chen et al .\\n2019a] starts with word and character embeddings from a BiLSTM\\nlayer, then performs multi-head self-attention on these, followed\\nby a BiLSTM encoder whose final state informs intent prediction.\\nAnother multi-head self-attention on the second BiLSTM hidden\\nstates, combined with the masked intent prediction, feed a CRF for', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='by a BiLSTM encoder whose final state informs intent prediction.\\nAnother multi-head self-attention on the second BiLSTM hidden\\nstates, combined with the masked intent prediction, feed a CRF for\\nslot prediction.\\nIn [Chen and Yu 2019] a BiLSTM layer takes the word inputs.\\nState attention is performed as follows. For slots each hidden state\\nis combined with the softmax of a weighted sum of all the hidden\\nstates passed through a feed forward network. Intent detection takes\\nthe last hidden state in combination with a similar weighted sumof the intermediate states. A similar formulation is used for word\\nattention by weighting sums of word vectors rather than hidden\\nstates. All these features are combined in a fusion layer to inform\\nthe two tasks.\\n[Xu et al .2020] use a standard encoder-decoder LSTM which\\nincorporates a length variable attention, that is attention of a sub-\\nsequence of learned width over the hidden states.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='the two tasks.\\n[Xu et al .2020] use a standard encoder-decoder LSTM which\\nincorporates a length variable attention, that is attention of a sub-\\nsequence of learned width over the hidden states.\\nTransformer. The transformer architecture [Vaswani et al .2017],\\na non-recurrent model useful for capturing global dependencies via\\nmulti-head self-attention (among other strengths) appears in [Thi\\nDo and Gaspers 2019] to construct contextual embeddings of the\\nword tokens. In their model attention is applied between all these\\nto inform the intent prediction sub-task where it gives a superior\\nresult.\\n[Zhang and Wang 2019] also use the transformer architecture.\\nThey pass word embeddings to a 3 level transformer layer, then\\nextract a global output to inform intent detection and token level\\noutput to pass to a CRF for slot detection. Differently to [Thi Do\\nand Gaspers 2019], a special token is added to represent the whole\\nutterance. Both these models only use the bidirectional encoder of\\n[Vaswani et al. 2017].\\n5.2.5 Hierarchical models. A hierarchical model passes information\\nlearned to be relevant through ordered levels. While this flow is\\nexplicit it is often unidirectional. For example, [Lee et al .2018]', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='learned to be relevant through ordered levels. While this flow is\\nexplicit it is often unidirectional. For example, [Lee et al .2018]\\nsupply a hierarchical approach with slot, intent and domain levels.\\nEach element of the intent level is represented as the vector sum of\\nthe components in the slot layer coming from the same utterance.\\n[Zhang et al .2019a] provided relevant feedback from the highest\\nlevel back to the lowest in their capsule network solution, a novel\\napproach that sought to explicitly capture the words-slots-intent\\nhierarchy. A capsule represents of a group of neurons whose output\\ncan be used for predictions at the next level; word capsules can\\nbe used to make slot label predictions, and so on. The hierarchy is\\nlearned using a routing-by-agreement mechanism: the prediction is\\nonly endorsed when there is strong agreement from the incoming\\ncapsule. The authors also propose a mechanism whereby a strong\\nintent message at the highest level can be fed back to the earlier\\nlevels to help them in their task. This explicit and direct feedback is\\nstronger than the implicit or indirect joint learning typically found\\nin RNN models. [Stali ¯unait ˙e and Iacobacci 2020] extended this work\\nto a multi-task setting with extra mid-level capsules for NER and\\nPOS labels, with mixed results.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:16 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\nTable 7. Joint task papers reviewed with addressed issue, approach and techniques\\nPaper Addressed issue Approach\\n[Jeong and Lee 2008] Joint solution of related tasks Tri-layer CRF, extra layer for classification\\n[Wang 2010] Small training sets MEM and CRF, joint task versus pipeline\\n[Celikyilmaz and\\nHakkani-Tur 2012]Small training sets Tri-level HMM, bolstered features\\n[Xu and Sarikaya 2013] Automated feature creation CNN features into TriCRF\\n[Guo et al. 2014] Incorporate discrete constituency parse of ut-\\nteranceRecNN on word vecs and parse tree\\n[Shi et al. 2015] Context from multi-turn dialogue RNN (token) and CNN (sentence) features, MLP\\n[Zhou et al. 2016] Hierarchical task relationship RNN, LSTM\\n[Hakkani-Tür et al. 2016] Seq2seq, joint model, architectures BiLSTM\\n[Chen et al. 2016] Incorporate language knowledge K-SAN attention network, GRU\\n[Zhang and Wang 2016] Apply RNN to intent GRU', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Chen et al. 2016] Incorporate language knowledge K-SAN attention network, GRU\\n[Zhang and Wang 2016] Apply RNN to intent GRU\\n[Liu and Lane 2016a] Employ encoder-decoder with attention Encoder-decoder with attention\\n[Liu and Lane 2016b] Real time analysis LSTM, MLP\\n[Zheng et al. 2017] NLP in navigation dialogue BiLSTM encoder decoder, seq2seq\\n[Ma et al. 2017] No long term memory, linearity LSTM, sparse attention\\n[Kim et al. 2017] Error propagation, information sharing be-\\ntween tasksWord and character RNN embedding\\n[Yang et al. 2017] Noisy NLU outputs Dialogue act unit after NLU\\n[Goo et al. 2018] Learn relationship between slot and intent\\nattention vectorsSlot gate, BiLSTM\\n[Pan et al. 2018] Multiple utterance dialogue Utterance to utterance attention\\n[Wen et al. 2018] Using hierarchy and context Two layer (Bi)LSTM\\n[Wang et al. 2018c] Capturing local semantic information CNN, BiLSTM encoder decoder\\n[Firdaus et al. 2018a] Domain dependence Ensemble model, GRU', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Wang et al. 2018c] Capturing local semantic information CNN, BiLSTM encoder decoder\\n[Firdaus et al. 2018a] Domain dependence Ensemble model, GRU\\n[Shen et al. 2018] Slow training time Progressive multi-task model using user information\\n[Li et al. 2018a] Correlation of different tasks Multi-task model incl. POS tag\\n[Li et al. 2018b] Sharing semantic information Self-attention\\n[Zhang et al. 2018] Tagging strategy Token tags include intent and slot\\n[Zhang et al. 2019a] Hierarchical structure Capsule network with rerouting (feedback)\\n[Zhao et al. 2018] Spatial (context) and serial (order) informa-\\ntionEncoder-decoder, CNN\\n[Wang et al. 2018b] slot2intent and intent2slot Bi-directional architecture\\n[Siddhant et al. 2019] Unsupervised learning ELMo on unused utterances, BiLSTM\\n[Yu et al. 2018] Use sequence labelling output for intent Cross attention, BiLSTM, CRF\\n[Lee et al. 2018] Hierarchical vector approach Learn vectors representing elements of frame\\n[Jung et al. 2018] Model relationship between text and its se-\\nmantic frameVector representation of frame', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Lee et al. 2018] Hierarchical vector approach Learn vectors representing elements of frame\\n[Jung et al. 2018] Model relationship between text and its se-\\nmantic frameVector representation of frame\\n[Ray et al. 2018] Rare, OOV words Paraphrasing input utterances\\n[Liu et al. 2019b] Unidirectional information flow Memory network\\n[Shen et al. 2019a] Poor generalisation in deployment Sparse word embedding (prune useless words)\\n[Ray et al. 2019] Slots which take many values perform poorly Delexicalisation\\n[Wang et al. 2019a] Language knowledge base, history context Attention over external knowledge base, multiturn his-\\ntory\\n[Li et al. 2019] Implicit knowledge sharing between tasks BiLSTM, multi-task (DA)\\n[Gupta et al. 2019a] Speed Non-recurrent and label recurrent networks\\n[Gupta et al. 2019b] Multi-turn dialogue, using context Token attention, previous history\\n[Chen et al. 2019a] Capturing intent-slot correlation Multi-head self attention, masked intent\\n[Chen et al. 2019b] Poor generalisation BERT\\n[Bhasin et al. 2019] Learning joint distribution CNN, BiLSTM, cross-fusion, masking', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Chen et al. 2019b] Poor generalisation BERT\\n[Bhasin et al. 2019] Learning joint distribution CNN, BiLSTM, cross-fusion, masking\\n[Thi Do and Gaspers 2019] Lack of annotated data, flexibility Language transfer, multitasking, modularisation', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:17\\n[Zhang et al. 2019] Key verb-slot correlation Key verb in features, BiLSTM, attention\\n[Zhang and Wang 2019] Learning joint distribution Transformer architecture\\n[Daha and Hewavitharana\\n2019]Efficient modelling of temporal dependency Character embedding and RNN\\n[Dadas et al. 2019] Lack of annotated data, small data sets Augmented data set\\n[Chen and Yu 2019] Learning joint distribution Word embedding attention\\n[E et al. 2019] Learning joint distribution Bidirectional architecture, feedback\\n[Zhang et al. 2019b] Poor generalisation BERT encoding, multi-head self attention\\n[Qin et al. 2019] Weak influence of intent on slot Use intent prediction instead of summarised intent info\\nin slot tagging\\n[Gangadharaiah and\\nNarayanaswamy 2019]Multi-intent samples Multi-label classification methods\\n[Firdaus et al. 2019] Multi-turn dialogue history, learning joint dis-\\ntributionRNN, CRF\\n[Pentyala et al. 2019] Optimal architecture BiLSTM, different architectures\\n[Castellucci et al. 2019] Non-recurrent model, transfer learning BERT, language transfer', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Pentyala et al. 2019] Optimal architecture BiLSTM, different architectures\\n[Castellucci et al. 2019] Non-recurrent model, transfer learning BERT, language transfer\\n[Schuster et al. 2019] Low resource languages Transfer methods with SLU test case\\n[Okur et al. 2019] Natural language Locate intent keywords, non-other slots\\n[Xu et al. 2020] Only good performance in one sub-task Joint intent/slot tagging, length variable attention\\n[Bhasin et al. 2020] Learning joint distribution Multimodal Low-rank Bilinear Attention Network\\n[Firdaus et al. 2020] Learning joint distribution Stacked BiLSTM\\n[Zhang et al. 2020b] Limitations of sequential analysis Graph representation of text\\n[Wang et al. 2020a] Non-convex optimisation Convex combination of ensemble of models\\n[Wang et al. 2020b] BERT issues with logical dependency (I be-\\nfore B)CRF and self attention over BERT\\n[Ni et al. 2020] Model transfer, IoT Pipeline structure from medical analogue\\n[Krone et al. 2020] Unseen labels Few-shot meta-learning\\n[Bhathiya and Thayasi-\\nvam 2020]Unseen labels, language transfer Few-shot meta-learning', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Krone et al. 2020] Unseen labels Few-shot meta-learning\\n[Bhathiya and Thayasi-\\nvam 2020]Unseen labels, language transfer Few-shot meta-learning\\n[Tang et al. 2020] Linear chain CRF limitations GCN based CRF\\n[Stali ¯unait ˙e and Iacobacci\\n2020]Extend capsule network Capsule network with MTL', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:18 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\n5.2.6 Bi-directional models. A model where there is a pipeline\\nfrom one sub-task to the other may be seen as unidirectional. A\\nbi-directional model, different to the bi-directionality seen in RNNs,\\nhas an explicit path from slot processing into intent prediction and\\nalso from intent processing into slot prediction. This can form two\\nparallel paths through the circuit, often with a fusion layer or a joint\\nloss.\\n[Wang et al .2018b] proposes the first such bi-directional circuit.\\nIn this paper each path is a a BiLSTM and the hidden states from each\\npath are shared with the other, another form of explicit influence\\nbetween the tasks. An optional LSTM decoder is supplied on each\\nside. Interestingly the loss is not a joint loss but the circuit alternates\\nbetween predicting intent for a batch, and back-propagating intent\\nloss, then predicting slots for the same batch and back-propagating\\nslot loss. They call this asynchronous training.\\n[Bhasin et al .2019] also uses bi-directional paths. Starting with\\nGloVe word embeddings, an intent path converts them to convo-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='slot loss. They call this asynchronous training.\\n[Bhasin et al .2019] also uses bi-directional paths. Starting with\\nGloVe word embeddings, an intent path converts them to convo-\\nlutional features which are concatenated then projected. The slot\\npath passes the word vectors through a BiLSTM with a CRF on\\ntop with the results also projected. Three types of fusion of the\\npaths (after reshaping/broadcasting) were tested: addition, average\\nor concatenation.\\n[E et al .2019] also consider bi-directionality. They start with a\\nBiLSTM encoder. A weighted sum of intermediate states for each\\nstep (the slot contexts) feeds a slot sub-net, while the weighted\\nfinal hidden state (the intent context) feeds an intent sub-net. These\\ntwo interact in either a slot2intent fashion (slot affects intent) or\\nintent2slot. The outputs then feed a softmax intent classifier and\\na CRF respectively. In slot2intent mode a learned combination of\\nthe slot contexts and intent context then feed the intent sub-net,\\nwhere they are combined with the intent context for prediction.\\nIn intent2slot mode the intent context is combined with the slot\\ncontexts to form a slot informed intent context. This is then fed to', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='where they are combined with the intent context for prediction.\\nIn intent2slot mode the intent context is combined with the slot\\ncontexts to form a slot informed intent context. This is then fed to\\nthe slot sub-net where it is combined with the slot contexts to feed\\nthe CRF for prediction. As may be expected intent2slot gave better\\nslot results and slot2intent gave better intent results. That only one\\ncan be applied is a weakness of the architecture.\\n5.2.7 Memory networks. [Liu et al .2019b] consider that even with\\nthe inclusion of feedback that the circuit of [Zhang et al .2019a]\\nis still overly unidirectional. To overcome this they consider the\\nuse of memory networks to the joint task. As they see the typical\\ninteraction as a pipeline from words to slots to intent, they alternate\\ninteraction from slots to intent and vice versa via multiple blocks of\\nmemory nets. The network begins with GloVe word embeddings and\\nmax pooled convolutional character embeddings. These feed the first\\nmemory block, which constructs slot features, intent features and\\nhidden states. Further memory blocks in the stack take the previous\\nblock’s hidden states as inputs. The memory blocks perform three\\noperations, which also strive to capture local context and global\\nsequential patterns:', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='hidden states. Further memory blocks in the stack take the previous\\nblock’s hidden states as inputs. The memory blocks perform three\\noperations, which also strive to capture local context and global\\nsequential patterns:\\n•Deliberate Attention: a slot memory (with number of cells\\nequal to number of slot labels) and intent memory (ditto for\\nnumber of intent labels) are randomly initialised then updated.\\nAt each word position each memory is updated as a weighted\\nsum of the other memory and of the block hidden states forthe current word. Diffusion of influence between slots and\\nintents thus takes place and can inform the hidden states for\\nthe next word.\\n•Local Calculation: this is a recurrent process receiving the in-\\nput embeddings or previous block’s hidden states. It calculates\\nslot representation and intent representations as interactions\\nbetween its inputs and the slot and intent memories. It is an\\nLSTM network.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='slot representation and intent representations as interactions\\nbetween its inputs and the slot and intent memories. It is an\\nLSTM network.\\n•Global Recurrence: a BiLSTM layer on top which encodes\\nglobal sequential interactions.\\nAfter the stacked blocks a final prediction takes place. Slots are\\nlabelled via a CRF on the final hidden states and slot representa-\\ntions. Intent is via an average of the final hidden states and intent\\nrepresentations.\\n5.2.8 Meta-studies of flow architectures. In an approach which con-\\nsiders both feature creation and architecture [Pentyala et al .2019]\\ngive an interesting generalisation of multi-task learning architec-\\ntures then apply it to the joint task. For example a three sub-task\\nparallel architecture would take samples with training labels for\\neach sub-task, develop universal features, task specific features, and\\ngrouped features, concatenate them and then feed them to task spe-\\ncific decoders. Series architectures are also given. Their base circuit\\nuses word and character embeddings and is a standard BiLSTM\\nencoder feeding an LSTM decoder for slots and a softmax classifier\\non the final hidden states for intent. No attention or slot gating\\noccur. The base circuit is then adjusted to match some of the series', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='encoder feeding an LSTM decoder for slots and a softmax classifier\\non the final hidden states for intent. No attention or slot gating\\noccur. The base circuit is then adjusted to match some of the series\\nand parallel architectures. [Firdaus et al .2020] also look at varieties\\nof series architectures from multi-task circuit design.\\n5.2.9 Graph networks. Graph networks can be used to address\\nshortcomings of limited context windows suffered by RNNs and\\nCRFs, as they can learn global relationships between words and\\nlabels.\\n[Zhang et al .2020b] use a graph S-LSTM network to overcome\\nperceived shortcomings of RNNs, being lack of parallelisation (due\\nto sequential nature), weak local context use, and lack of long range\\ndetection. The graph has as nodes the word representations and\\nsentence representation from an LSTM, hence the network simulta-\\nneously works on the whole sentence. Only word nodes within a\\ncontext window are connected by edges. The sentence node is con-\\nnected to all word nodes. Messages are passed between the nodes\\nto enable global coordination. The final node states for each slot go\\nthrough a convolution unit and self attention before being used for\\nslot filling. The final sentence node state is used directly for intent\\ndetection.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='to enable global coordination. The final node states for each slot go\\nthrough a convolution unit and self attention before being used for\\nslot filling. The final sentence node state is used directly for intent\\ndetection.\\n[Tang et al .2020] see shortcomings of linear chain CRFs as be-\\ning limited context and only applicable to the slot sequence. They\\nconstruct a graph based CRF graph convolutional network which\\nlearns relationships between words, slot labels and intent labels.\\nBERT embeddings are passed through a BiLSTM which feed the\\nGCN for prediction. A weighted joint loss is back-propagated.\\n5.2.10 Importing methods from analogous fields. [Bhasin et al .2020]\\npropose an interesting analogy; that the relationship between intent\\nand slots is similar to that between the query and image in visual\\nquestion answering. Thus they borrow an idea from the latter field -', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:19\\nMultimodal Low Rank Bilinear (MLB) fusion, between the features\\nof each part.\\n[Ni et al .2020] also propose an analogy with the joint task of clin-\\nical domain detection and entity recognition in medical literature.\\nComing from the IoT field they also propose a pipeline structure\\nwhere intent is detected first and then slots determined in a closed\\ndomain setting.\\n5.3 Feature creation and enhancement\\nAs discussed in the sub-task sections, feature creation is a critical\\npart of the design of circuits in NLU as it ideally should capture, at\\nleast, semantic information of the individual tokens, their context,\\nand of the entire sentence. Then, any other information that may be\\nused to enhance the result may be considered, including meta-data\\nand syntactic information.\\n5.3.1 Token embedding. The earliest models used features familiar\\nfrom methods like POS tagging and containing one-hot word em-\\nbedding, n-grams, affixes etc. ([Jeong and Lee 2008]). [Celikyilmaz\\nand Hakkani-Tur 2012] incorporated entity lists from sites such as\\nIMDB (movie titles) or Trip Advisor (hotel names).\\nNeural models enable the embedding of diverse natural language', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='and Hakkani-Tur 2012] incorporated entity lists from sites such as\\nIMDB (movie titles) or Trip Advisor (hotel names).\\nNeural models enable the embedding of diverse natural language\\nwithout such feature engineering. The first neural features were con-\\nvolutional embeddings of the utterance words in [Xu and Sarikaya\\n2013], which fed to a statistical model after [Jeong and Lee 2008].\\n[Shi et al .2015] was the first to use RNN based token embeddings\\nbut also combined those into a CNN based sentence embedding.\\n[Ma et al .2017] used for input at each step a convolution of the\\ncurrent word and the previously predicted slot labels. [Wang et al .\\n2018c] used multiple convolutional features of the embedding words\\nbut also maintained the order of the words within the convolutions.\\nThese were then fed to an RNN layer.\\nThe gamut of word embedding methods have been used including\\nword2vec ([Pan et al .2018; Wang et al .2018c]), fastText ([Firdaus\\net al.2020]), GloVe ([Bhasin et al .2019; Bhasin et al .2020; Dadas\\net al.2019; Liu et al .2019b; Okur et al .2019; Pentyala et al .2019; Thi', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='et al.2019; Liu et al .2019b; Okur et al .2019; Pentyala et al .2019; Thi\\nDo and Gaspers 2019; Zhang and Wang 2016]), ELMo [Zhang et al .\\n2020b] and [Krone et al .2020] (pre-print only), BERT ([Ni et al .2020;\\nQin et al .2019; Zhang et al .2019b] and [Castellucci et al .2019; Chen\\net al.2019b; Krone et al .2020] (pre-print only). [Firdaus et al .2018a]\\nand [Firdaus et al .2019] used concatenated GloVe and word2vec\\nembeddings to capture more word information.\\nWhile BERT displays impressive performance, [Wang et al .2020b]\\nidentify a limitation (logical dependency for slot filling) and counter\\nit by feeding it to an intent2slot gate, an attention layer and a CRF.\\n[Gupta et al .2019a] tested ten different word contextualisation\\nembeddings from four different method groups (feed forward, CNN,\\nattention, LSTM) with different depths.\\n[Kim et al .2017] were the first to use a combination of character\\nand word embedding. Others also used this ([Chen et al .2019a;', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='attention, LSTM) with different depths.\\n[Kim et al .2017] were the first to use a combination of character\\nand word embedding. Others also used this ([Chen et al .2019a;\\nFirdaus et al .2019; Liu et al .2019b; Pentyala et al .2019]. On the\\nother hand, [Daha and Hewavitharana 2019] use only character\\nembedding.\\nPre-computed syntactic features, for example POS tags for each\\ntoken using the nltk library ([Firdaus et al .2018a] have been included\\nwith word embeddings.[Zhang et al .2019] take from the service robotics field the impor-\\ntance of a key verb in an instruction in informing the slot labels.\\nThe key verb is deduced from a dependency parsing. A feature is\\nconstructed from the training data to encode a priori dependencies\\nbetween words and key verbs. The circuit takes the key verb feature\\nand concatenates it with each word’s one hot encoding. These are\\npassed to a BiLSTM layer to produce token embeddings.\\n5.3.2 Sentence embedding. The use of the final hidden state in an\\nRNN as the sentence embedding was used frequently ([Liu and', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='5.3.2 Sentence embedding. The use of the final hidden state in an\\nRNN as the sentence embedding was used frequently ([Liu and\\nLane 2016a; Wang et al .2018c; Zhou et al .2016]). Sentences were', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='5.3.2 Sentence embedding. The use of the final hidden state in an\\nRNN as the sentence embedding was used frequently ([Liu and\\nLane 2016a; Wang et al .2018c; Zhou et al .2016]). Sentences were\\nalso embedded by using a special token for the whole sentence in\\n[Hakkani-Tür et al .2016; Zhang and Wang 2019], as a max pooling\\nof the RNN hidden states ([Zhang and Wang 2016], as a learned\\nweighted sum of Bi-RNN hidden states ([Liu and Lane 2016a]), as\\nan average pooling of RNN hidden states ([Ma et al .2017]), as\\na convolutional combination of the input word vectors ([Bhasin\\net al.2019; Zhao et al .2018], and as self-attention over BERT word\\nembeddings ([Zhang et al. 2019b]).\\n[Ma et al .2017] also apply a sparse attention mechanism which\\nevaluates word importance over a batch and applies weights within\\neach sample utterance for the intent detection.\\n[Daha and Hewavitharana 2019] used an extra <TAGG> token\\nafter the end-of-sentence <EOS> token for sentence encapsulation\\nand see better intent prediction performance. [Okur et al .2019]', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='after the end-of-sentence <EOS> token for sentence encapsulation\\nand see better intent prediction performance. [Okur et al .2019]\\nencode both a <BOU> and <EOU> token at the beginning and end\\nof the utterance in their BiLSTMs.\\n5.4 Target variations\\nThe targets are typically the annotated intent and slot labels. [Zhang\\net al.2018] construct a single tag for each token which incorporates\\nthe slot tag and the sentence intent. Their circuit then just performs a\\nsingle seq2seq task and the sentence intent is deduced by a majority\\nvote of the intent portion of the predicted tags. [Xu et al .2020] use\\nthe same single tag set. [Qin et al .2019] perform the intent detection\\nat token level though separate to the slot prediction, and the final\\nintent is taken by vote.\\n[Lee et al .2018] works with learned embeddings of slot labels,\\nintents and domains where the sum of slot label embeddings for\\nan utterance is close to the intent embedding in vector space. A\\nnetwork can then be trained to map tokens to vectors close to the\\nslot labels and intent for the utterance.\\n[Jung et al .2018] proposes a vector embedding of the entire se-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='network can then be trained to map tokens to vectors close to the\\nslot labels and intent for the utterance.\\n[Jung et al .2018] proposes a vector embedding of the entire se-\\nmantic frame (intent, slot labels, slot values) as the target. In training\\nthe utterance and the semantic frame are input and vectorised. A\\nsemantic frame vector is output. The distance between the output\\nvector and input frame vector is minimised. In testing the text is\\ninput and a vector is output and the nearest semantic frame vector\\nis chosen.\\n[Okur et al .2019] proposed an extra token tag for intent keywords,\\nfor example the word “play” in an utterance with intent PlayMusic .\\nIn one of their models only intent keywords and non-Other slot\\ntokens contribute to intent detection.', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='111:20 •Henry Weld, Xiaoqi Huang, Siqu Long, Josiah Poon, and Soyeon Caren Han\\n5.5 Issues addressed and solutions proposed\\n5.5.1 Narrowness of approach. The use of features constructed only\\nfrom the tokens in the sentences may be too narrow an approach.\\nExternal knowledge about the words’ places in the language, or the\\nsyntactic structure of the sentence, or of co-occurrence statistics\\namongst word and labels may aid the task. Methods to incorporate\\nextra elements have been developed.\\nKnowledge bases. Knowledge bases are constructs containing in-\\nformation or statistical priors that may be useful to the task at hand.\\nThey may be constructed independent of the task, or as a prelim-\\ninary step using information from the training data. They have\\nbeen used for feature construction, as features themselves, and to\\nbe consulted via attention.\\n[Chen et al .2016] was the first to use an extra knowledge base\\nto inform the joint task. They use a K-SAN input, being a struc-\\ntured knowledge network. Two K-SANs are constructed, one taking\\na dependency parse of the utterance (syntactic), and the other an\\nAbstract Meaning Representation (AMR) graph (semantic). Each rep-\\nresentation is tested separately. A CNN encodes the representation', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='a dependency parse of the utterance (syntactic), and the other an\\nAbstract Meaning Representation (AMR) graph (semantic). Each rep-\\nresentation is tested separately. A CNN encodes the representation\\ninto a vector, while a separate CNN encodes the sentence itself into\\nanother vector. Attention is applied between the two vectors and\\nthe results combined to give a “knowledge guided representation”\\nof the utterance. This is included as an input to a GRU RNN cell\\nalong with the word encodings in sequence. A second RNN just\\ntakes the utterance words as input. A weighted sum of the hidden\\nstates of the two RNNs is used for prediction.\\n[Wang et al .2019a] incorporate the ConceptNet1framework as a\\nknowledge base source. (Head, Relation, Tail) triples are extracted\\nfor each word in the utterance. The TransE model ([Bordes et al .\\n2013]) for embedding multi-relational data is used to encode the\\nknowledge. Attention is applied between words and the knowledge\\nbase encoding.\\n[Qin et al .2020b] capture the interaction between multiple intents,\\nand slots, with a graph representation. For multi-intent a score is\\ncalculated for each intent and those above a threshold are returned.\\nThe graphs use graph attention networks. Tokens are encoded by', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='and slots, with a graph representation. For multi-intent a score is\\ncalculated for each intent and those above a threshold are returned.\\nThe graphs use graph attention networks. Tokens are encoded by\\na BiLSTM and then multiple intents are predicted. These slot path\\ntakes the token embeddings through an LSTM which provides a\\nfeature for each token which interacts with the intent predictions\\nand the slot-intent graph to make slot predictions.\\nThe inclusion of knowledge embedded in graph representations,\\nor networks that perform tasks on such graphs has borne fruit in\\nthe very recent literature. Further research in this area could include\\nother types of such graphical representations and incorporate infor-\\nmation not just from the current training set or external knowledge\\nbases but some combination of the two, or data from several training\\nsets.\\n5.5.2 Multi-turn dialogue. Typically in NLU only the current single\\nutterance is analysed. Temporal information or previous utterance\\ncontext or previous dialogue action are not considered. However as\\nnoted in the intent and slot sections using such information in the\\nmodel can lead to better performance.\\n1http://conceptnet.ioThere are multiple data sets available which contain a multi-\\nturn dialogue around a single intent or set of related intents. In\\nthese cases incorporating the history from previous turns can be', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='1http://conceptnet.ioThere are multiple data sets available which contain a multi-\\nturn dialogue around a single intent or set of related intents. In\\nthese cases incorporating the history from previous turns can be\\nincorporated. [Shi et al .2015] fed a sentence embedding along with\\nthe predicted intent and domain labels of previous turns into the\\nintent prediction for the current turn. [Pan et al .2018] calculate\\nattention between the BiGRU embeddings of successive utterances\\nwhich make up a single sample and contribute to a single intent.\\n[Wang et al .2019a] similarly use attention between the BiLSTM\\nencoding of each utterance to the previous utterances in the history.\\n[Gupta et al .2019b] look at multiple contextual inputs in multi-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='[Wang et al .2019a] similarly use attention between the BiLSTM\\nencoding of each utterance to the previous utterances in the history.\\n[Gupta et al .2019b] look at multiple contextual inputs in multi-\\nturn dialogues for the current utterance. For the current utterance\\nthey apply token2token attention and sentence2token attention at\\nthe input. Information from previous turns, including intents, slots\\nand dialogue actions can then be attached.\\nWhile it is sensible for the research to focus on single utterance\\nanalysis it should be noted that SLU devices are often listening\\nto all dialogue, filtering out-of-domain utterances using methods\\ndiscussed in Section 3.3.4, and that incorporating lead in dialogue\\ncan be useful to the joint task.\\nMulti-task learning. Looking for synergies with related tasks has\\nbeen an approach in the two sub-tasks and has been actively applied\\nin the joint task. As described earlier the full semantic frame contains\\nthree levels - domain, intent and slots. Simultaneously solving the\\ndomain with the other layers has been explored [Hakkani-Tür et al .\\n2016; Shi et al. 2015].\\n[Shen et al .2018] introduced an extra task to predict tags for\\nknown user information from metadata (for example location, times-', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='2016; Shi et al. 2015].\\n[Shen et al .2018] introduced an extra task to predict tags for\\nknown user information from metadata (for example location, times-\\ntamp). The metadata task is preliminary and thus informs the BiL-\\nSTM word embedding. The results of the preliminary task feed the\\nregular joint task training and the BiLSTM word embeddings are\\nupdated.\\n[Li et al .2018a] works on the theory that adding a further sequen-\\ntial task (POS tagging) will aid the joint tasks. A single LSTM layer\\ntakes word embeddings and performs an intent and slot prediction\\nat each step, feeding those predictions with the LSTM hidden state\\nto a next-word POS tagger. A joint loss across all tasks is calculated.\\nThe results show that the extra task helps improve intent detection.\\n[Yang et al .2017] claim that noisy SLU output can be mitigated by\\nmaking it part of an end-to-end network including dialogue action\\nprediction in the dialogue manager, with errors back-propagating\\nfrom the dialogue manager refining the NLU prediction. The hidden\\nstates of a BiLSTM SLU model also feed a second BiLSTM which\\nperforms the dialogue action prediction. A joint loss across all tasks', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='from the dialogue manager refining the NLU prediction. The hidden\\nstates of a BiLSTM SLU model also feed a second BiLSTM which\\nperforms the dialogue action prediction. A joint loss across all tasks\\nis back-propagated. In related work, [Li et al .2019] also tied together\\nan SLU network and a network to predict the next dialogue action.\\nThey use a stronger NLU segment to improve overall results. A\\njoint loss across intent, slots and actions was back-propagated and\\nperformance exceeded the SLU model alone. [Gupta et al .2019b]\\nuse dialogue action in a multi-turn data set. [Firdaus et al .2020]\\nincorporate dialogue action, typically as the first task in a multi-task\\npipeline, rather than the last.\\n[Stali ¯unait ˙e and Iacobacci 2020] incorporated POS and NER tag-\\nging simultaneously with slot tagging and intent detection using a\\ncapsule network, however the results were generally poorer when', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " Document(page_content='A survey of joint intent detection and slot-filling models in natural language understanding •111:21\\nboth NER and POS were included rather than just one, and mixed\\nfor different data sets indicating a generalisability issue.\\nThe method of using SLU as fine-tuning with pre-training on\\nanother task, or vice versa, has shown improvements in the SLU per-\\nformance. However the results of [Stali ¯unait ˙e and Iacobacci 2020],\\nechoing those of [Louvan and Magnini 2019] on slot tagging, indi-\\ncate a parsimonious approach to adding extra tasks simultaneously\\nmore often yields a better result.\\n5.5.3 Generalisability.\\nDomain dependence. An issue found is that a model trained suc-\\ncessfully on one domain or data set does not perform as well on\\na different domain or data set, implying it has simply learned sta-\\ntistical properties of the training data set. One issue suggested by\\n[Firdaus et al .2018a] is that the language in the data sets is not\\nparticularly “natural”. Though their ensemble model with syntactic\\nPOS features performed well on ATIS it is unclear it generalised to\\na second data set.\\n[Firdaus et al .2018a] propose to design a domain invariant model', metadata={'pdf': 'https://arxiv.org/pdf/2101.08091', 'link': 'https://openalex.org/works/W3122866338', 'title': 'A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding'}),\n",
              " ...]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymilvus import connections, Collection, utility, MilvusException\n",
        "\n",
        "# Thay đổi các thông số kết nối tới Milvus\n",
        "MILVUS_HOST = 'localhost'  # Thay bằng địa chỉ IP của Milvus instance\n",
        "MILVUS_PORT = 19530        # Thay bằng cổng của Milvus instance\n",
        "COLLECTION_NAME = 'Vin'\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Kết nối tới Milvus\n",
        "        connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)\n",
        "        print(f\"Connected to Milvus at {MILVUS_HOST}:{MILVUS_PORT}\")\n",
        "\n",
        "        # Kiểm tra sự tồn tại của collection\n",
        "        if COLLECTION_NAME in utility.list_collections():\n",
        "            collection = Collection(COLLECTION_NAME)\n",
        "            print(f\"Collection {COLLECTION_NAME} exists.\")\n",
        "        else:\n",
        "            print(f\"Collection {COLLECTION_NAME} does not exist.\")\n",
        "            return\n",
        "\n",
        "        # Kiểm tra schema của collection\n",
        "        print(f\"Schema of collection {COLLECTION_NAME}: {collection.schema}\")\n",
        "\n",
        "        # Tải collection vào bộ nhớ\n",
        "        try:\n",
        "            collection.load()\n",
        "            print(f\"Collection {COLLECTION_NAME} loaded successfully.\")\n",
        "        except MilvusException as e:\n",
        "            print(f\"Failed to load collection: {e}\")\n",
        "            # Xử lý lỗi load collection\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "            # Xử lý các lỗi khác có thể xảy ra\n",
        "\n",
        "        # Thực hiện các thao tác khác trên collection nếu cần\n",
        "\n",
        "    except MilvusException as e:\n",
        "        print(f\"Milvus error occurred: {e}\")\n",
        "        # Xử lý các lỗi Milvus khác\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        # Xử lý các lỗi khác có thể xảy ra\n",
        "\n",
        "    finally:\n",
        "        # Đóng kết nối tới Milvus sau khi hoàn thành công việc\n",
        "        connections.disconnect()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqgZMHLIeaJc"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Milvus\n",
        "\n",
        "# Bắt đầu lưu trữ embedding vào Milvus\n",
        "vector_store = Milvus.from_documents(\n",
        "    splits,\n",
        "    embedding=embeddings,\n",
        "    # metadatas=metadatas,\n",
        "    collection_name=\"Vin\",\n",
        "    drop_old=False,\n",
        "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT}\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "General",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
